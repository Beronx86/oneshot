@inproceedings{Abbeel2004,
author = {Abbeel, Pieter and Ng, Andrew Y},
booktitle = {{International Conference on Machine Learning (ICML 2004)}},
file = {:Users/Brenden/Documents/Mendeley/Abbeel, Ng - 2004 - Apprenticeship Learning via Inverse Reinforcement Learning.pdf:pdf},
keywords = {inverse optimal control,planning},
mendeley-tags = {inverse optimal control,planning},
title = {{Apprenticeship Learning via Inverse Reinforcement Learning}},
year = {2004}
}
@inproceedings{Ahmadi2011,
author = {Ahmadi, Babak and Kersting, Kristian and Sanner, Scott},
booktitle = {{International Joint Conference on Artificial Intelligence (IJCAI-11)}},
file = {:Users/Brenden/Documents/Mendeley/Ahmadi, Kersting, Sanner - 2011 - Multi-Evidence Lifted Message Passing , with Application to PageRank and the Kalman Filter.pdf:pdf},
keywords = {graphical},
mendeley-tags = {graphical},
title = {{Multi-Evidence Lifted Message Passing , with Application to PageRank and the Kalman Filter}},
year = {2011}
}
@article{Ahn1992,
annote = {Shows people can acquire schemas, for complex events, from one example, if they have the relevant background knowledge for it
- This paper is inspired by EBL, but does not provide a computational model that can actually do this task

        
Note: Structured probabilistic models, in some sense, integrate explanation and similarity based models in a natural way.

        
Story was about an indian ceremony, which invovles inviting guests and giving gifts. However, only some of the gifts were important, because he was trying to lower the status of one of his ancestors

        
Also, shows you can acquire a schema and generate new exemplars, whic is impressive

        
-----------
Early models of concept learning:
-rules (classical theory)
-probabilistic models (prototype), summary description
-exemplar
All of these are too simple to account of real concept learning

        
Previous examples of schema learning
-- typically use stimuli that are too simple
-- It's hard to see how similarity models will acquire a schema from one example, when they involve things like money, etc. or have suprious correlations
-- also similarity based models are poor at taking background knowledge into account

        
explanation based learning (EBL) uses previous schemas to interpret the one example, and learn
- relies of domain background knowledge

        
GENSIS:
when a person achieves a specific goal, the system generalizes what aspect of the plan schema was important

        
Can learn a kidnapping schema form just a single example, where it processes a whole story in terms of variables, and extract away irrelevant details

        
Is EBL really learning, in the inductive sense?

        
          
Experiments
        

        
Experiment 1: answer true/false statements about variables in the schema

        
Conditions:
abstract- given abstract information about schema
instance - background information, then shown instance passage

        
Then shown same test questions

        
          
REsults:

        
        
EBL would predict the groups do the same, but here the abstract group performed better. 

        
But... isn't EBL hard? Not done automatically every time? seems like a strange experiment

        
Experiment 1b: control group that received instance information without background infromation.

        
Also, ran a new condition where the group that got background data was asked to state the purpose of the ceremony in detail, after reading the instance passage

        
This group performed worse than the group with background information with purpose, showing some evidence for one-shot schema acquisition
        

        
Experiment 1c: similarty base group (SBL) got multiple examples of passages, and wher some variables were changed. But they didn't get eth background knowledge

        
EBL group got the passages and the background knowledge

        
          
results
        
Multiple instances seem to help the SBL group, since they were better than just one instance

        
discussion: if people are dsown strongly contrast pairs of instances, they can use SBL to select out variables. But in the real world, it is unlikely to be this lear

        
Also, since getting two instances was beter in the EBL group, they did much better, but this is inconsistent with a machien based EBL theroy

        

        
Experiment 2: generate a new example of the schema, or generate an abstract description

        
This time, they chose three scehams that people would have relevant background knowledge, but  not know the actual schema

        
Conditions:
- relevant background knowlege (EBL)
-n on backgroudn knowlege (non-EBL), like korean wedding ceremony

        
Exp 2a) direct test of contraints on variables in schema (True/false)
2b) how weel subjects can generate new instances of the schema (generation)
        
2c) generate a general description of specific instance

        
          
Results:

        
        
Instance group was as good as abstract group, showing efficient EBL

        
Also, the non-EBL condition did not learn well

        
Exp 2b) people wrote another story to convey the schema 

        
People got many of the constraints correct in their own stories from EBL condition (80%), but not from the non-EBL conditio (11%)

        
I guess people can generate compelling new stories

        
Exp 2c) didn't read

        
          
Discussion

        
        
Simple stimuli in category learning tasks may elimante important forms of learning like EBL

        
Experiment 2 showed people can do EBL using a different measure, which is generated storeis

        
With the right domain knowledge, you can construct the right causal structure for an example, and learners do not wait for further examples, before learning the schema   },
author = {Ahn, Woo-kyoung and Brewer, William F and Mooney, Raymound J},
file = {:Users/Brenden/Documents/Mendeley/Ahn, Brewer, Mooney - 1992 - Schema Acquisition From a Single Example.pdf:pdf},
journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
keywords = {EBL,one-shot learning},
mendeley-tags = {EBL,one-shot learning},
number = {2},
pages = {391--412},
title = {{Schema Acquisition From a Single Example}},
volume = {18},
year = {1992}
}
@article{Anderson1991,
author = {Anderson, J R},
journal = {Psychological Review},
pages = {409--429},
title = {{The adaptive nature of human categorization}},
volume = {98},
year = {1991}
}
@article{Anderson1992,
author = {Anderson, J R and Matessa, M},
journal = {Machine Learning},
pages = {275--308},
title = {{Explorations of an Incremental, Bayesian Algorithm for Categorization}},
volume = {9},
year = {1992}
}
@incollection{Anderson2000,
annote = {Classical conditioning chapter
        
Unconditioned stimulus (shock/juice/etc.)
Unconditioned response (avoidance/salivation/etc.)
Condition stimulus (tone/light/etc.)
Condition response (the same as unconditioned response)
        
The typical order is presenting the CS then US, in close succession. This leads to the strongest conditioned response.
                  
Sensitization and habituation
                
sensitization: if there is no relationship between the US and the CS, there can still be an increased likelihood of the response (like an eye blink). Thus, good studies use this as a control
        
habituation: the magnitude of the UR (or CR) decreases over time, like the animal is being toughened.
                  
Conditioning and awareness
                
classical conditioning seems to show similar behavioral profiles, whether or not the subject is aware
        
        Neural basis of classical conditioning
                
Simple sea slug.
CS: touch its siphon
US: shock it's tail
UR: gill response
        
This seems to work by presynaptic facilitation, where it strengthens the conenction from the siphon to the gill by an axon to axon synapse
        
Rabits and eye-blinking is more complicated. It seems like an area (purkinje cells) gets inhibited, which usually inhibits another area (interpositus), which connects the cochlear nucleus to a pathway for blinking.
                  
S-S or S-R Associations?        
S-R association: CS to response
S-S association: CS to US
There is some evidence for both of these things. You can test for the difference by
        
response-prevention paradigm: prevent the agent from making a response (the UR), and seeif you can still learn the association. If so, it shows SS
        
devaluation paradigm: make the US matter less (maybe the animal is full), and see if the response to the CS changes.
        
There is evidence for both of these things. But on the whole, they tend to be S-R. This mostly depends on whether the stimulus or response is more salient.
                  
What is the conditioned stimulus?
                
Of course, you have a generalization gradient (as studied by Shepard). And generalization is complicated.
        
The conditioned response is often an opponent response, which makes the US easier to handle, etc.
                  
The role of contingency        
        
Rescorla (1986) showed that it's not just frequency that is important. It's the predictive relationships between the CS and the US, like the difference between P(US|CS+) - P(US|CS-).  He showed this by varing the latter term, and showing it affects the strength.
                  
conditioned inhibition        
A => R(+)
A + B => R(-)
Thus
B => R(-)
        
This is an indirect effect, where you learn the B is probably strongly negative. Rescola-Wagner captures this
                  
Associative bias        
Some things are easier to associate, like taste of rates with sickness and color for quails (also called the "Garcia effect")
        
This can be accounted for by Bayesian reasoning, where you have a prior probability for an effect occuring
                  
Blocking        
A => R(+)
A + B => R(+)
Thus
B !=> R(-/+), this reverts to prior sort of
        
Thus, we don't learn much for B, since it's already predicted
                  
configural cue        
People are able to learn things like XOR, and this can't be done by individual associations -- you need associations to things like pairs.
(see Gluck and Bower)
                  
Rescoal wagner model
                
- Basically the delta rule, for a linear unit. 
- If there is no error, then there is no learning. This explains blocking (also known as competitive learning)
        
Problems with the model
-- latent inhibition: if you pre-program an association to be off, it stays off for people/animals, but RW doesn't explain this
-- can't explain learning XOR without configural cue. But no theory provided on whether to treat cues as singletons or interaction terms.
                  
conclusion        
-- classical conditioning was used in the behaviorism paradigm, hoping to study learning without cognition.
-- it is a very long lasting theory that continues today. It explains some effects, although not all
-- it is probably the case that it's not the same mechanism that operates in simple animals, other animals, and humans. Probably just adaptive, and evolved in different ways
-- It probably plays a role, but it is not the whole story of learning
-- Also, all of these results can be explained in a more causal context
        
        
        
        
        
        
        
        
        
        
        
      },
author = {Anderson, John R},
booktitle = {Learning and memory},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
pages = {39--77},
title = {{Classical conditioning}},
year = {2000}
}
@article{Anderson1974,
annote = {Introduced the fan-effect
        
Sentences were like:
The hippie was in the bank
The hippie was in the park
The lawayer was in the park
        
Participants had to decide whether or not they saw that sentence.
        
Time increases with the fan-factor, either in the number of places that person occured, or the number of people in that place. This was taken as evidence for a spreading activation theory of memory.
        
The effect seems to follow the minimum fan, of each of the objects, and also 
        
Training: each object/location participated in 1,2,or 3 sentences. Participants cycled through the set until they made no errors on questions like "who is in the park?" "where are the hippies?"},
author = {Anderson, John R},
file = {:Users/Brenden/Documents/Mendeley/Anderson - 1974 - Retrieval of Propositional Information from Long-term Memory.pdf:pdf},
journal = {Cognitive Psychology},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
pages = {451--474},
title = {{Retrieval of Propositional Information from Long-term Memory}},
volume = {6},
year = {1974}
}
@article{Anderson1983,
annote = {ACT theory -- a spreading activation theory of memory
        
Core tenents:
-- the units of memory are larger pieces like propositions
-- can be organized hierarchically, such that one proposition is a unit of the other
-- all traces have a strength associated with them, each trial increases the strength by one unit, which determines the probability and speed of retrieval
-- traces also decay as a power function
-- if a trace has multiple strengthenings, its overall strength is the sum of the multiple attempts
-- spreading activation is involved in retrieval
-- RT = I + 1/A, where A is activation
-- probability of recall is also based on activation
-- activation diffuses to all of the connections, so it loses power if there are more places to spread
-- model assumes activation levels asymptote, and this state is reached relatively quickly
- unit = proposition, element in object, and I think activation is treated the same for both (both are nodes)
- activation originates in the elements, and activates the corresponding propositions
        
Interference
-- paired associate paradigm, A-B, A-D comapred to A-B, C-D
-- you need extra study in the intereference case, so that the trace's strength can compete
-- proactive intereference: retention of A-D is worse, even if both types are brought to the same level by study. Initially, it was thought ACT made the wrong prediction, but further tests showd it was right
        
Reaction time and intereference
-- fan effect
-- study location-subject-verb sentences, like "in the winery the fireman slept"
-- by overloading any of these dimensions, RT increases
-- what exactly was the task? should read (Andreson, 1976)
-- if you have thematic relations between the facts, you don't get a fan effect, but perhaps people just judged a theme. If the foils are also from the theme, you get the fan effect again.
        
Inferential reconstructions
-- you can use facts, stored in schema. If you get a new object that participates in a partial role, you can subsitute it in the schemas that you had
        
Conclusion
-- the former ACT (which was all or nothing activation) had trouble with many of these phenomena, but continuous activation helps.},
author = {Anderson, John R},
file = {:Users/Brenden/Documents/Mendeley/Anderson - 1983 - A Spreading Activation Theory of Memory.pdf:pdf},
journal = {Journal of Verbal Learning and Verbal Behavior},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
title = {{A Spreading Activation Theory of Memory}},
volume = {22},
year = {1983}
}
@article{Anderson1991a,
author = {Anderson, John R},
file = {:Users/Brenden/Documents/Mendeley/Anderson - 1991 - The adaptive nature of human categorization.pdf:pdf},
journal = {Psychological Review},
keywords = {classic AI,classic psychology,classics on concepts},
mendeley-tags = {classic AI,classic psychology,classics on concepts},
number = {3},
pages = {409--429},
title = {{The adaptive nature of human categorization}},
volume = {98},
year = {1991}
}
@article{Anderson2004,
abstract = {Adaptive control of thought-rational (ACT-R; J. R. Anderson & C. Lebiere, 1998) has evolved into a theory that consists of multiple modules but also explains how these modules are integrated to produce coherent cognition. The perceptual-motor modules, the goal module, and the declarative memory module are presented as examples of specialized systems in ACT-R. These modules are associated with distinct cortical regions. These modules place chunks in buffers where they can be detected by a production system that responds to patterns of information in the buffers. At any point in time, a single production rule is selected to respond to the current pattern. Subsymbolic processes serve to guide the selection of rules to fire as well as the internal operations of some modules. Much of learning involves tuning of these subsymbolic processes. A number of simple and complex empirical examples are described to illustrate how these modules function singly and in concert.},
annote = {There isn't really a good, unified theory of cognition? Is there any sense that people who do decision making, concepts, online-inference in language processing know that they are studying the same thing?
        
      },
author = {Anderson, John R and Bothell, Daniel and Byrne, Michael D and Douglass, Scott and Lebiere, Christian and Qin, Yulin},
doi = {10.1037/0033-295X.111.4.1036},
file = {:Users/Brenden/Documents/Mendeley/Anderson et al. - 2004 - An integrated theory of the mind.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Basal Ganglia,Basal Ganglia: physiology,Brain,Brain Mapping,Brain: physiology,Cognition,Goals,Humans,Mathematics,Memory,Mental Processes,Mental Processes: physiology,Models,Neurological,Psychological Theory,Psychomotor Performance,Task Performance and Analysis},
month = oct,
number = {4},
pages = {1036--60},
pmid = {15482072},
title = {{An integrated theory of the mind.}},
volume = {111},
year = {2004}
}
@article{Anderson1990,
annote = {Surgical lesion to left premotor area (BA6). Parallel impairments in reading and writing of letters. But reading and writing of non-verbal symbols and numbers was unimpaired. 
        
It seems likely that this neural unit participates in both reading and writing. Especially considering the similarity of the behavioral pattern.
        
---
        
alexia: inability to perceive written words
agraphia: loss of ability to write
aphasia: loss of ability to express/understand speech
        
This is a very rare pattern of impairment. They usually come with some sort of aphasia, which this patient did not have. This is the first case of pure alexia caused by a focal frontal lobe lesion.
        
Entirely normal reading and writing of figures and numbers. 
        
She complained of trouble finding words and typing, and had a small surgical lesion. Post-op assessment had no evidence of intracranial tumour. But she complained of major writing/reading deficit, with no significant improvment from training.
        
Seemed to have no major cognitive deficits, besides those mentioned. She could read aloud less than 21% of all words presented to her.
        
She tended to read shorter words more accurately. There was also an effect of frequency. There was also an effect of imageability. Nouns were read correctly more often.
                  
reading letters: she could identify about 50% of typewritten letters. Generally substituted visually similar letters (B and D). Could match some upper-case letters with lower-case.
                  
reading digits: no difficulty.
                  
100% correct on 15 symbosl on typerwriters        
        
No impairment on oral spelling.
        
        Severe graphia: she could not longer witer her name ledigiblty. On rare cases where individual graphemes were legidble, should would fail to move her pen over.
                  
could kind of do writing-to-copy         
        
She could write numbers without difficulty (single and multidgit). These numbers look quite good.
                  
discussion
                
they argue for common mechanism underlying both the reading difficulties and agraphia. 
        
Since she did not have basic motor difficulties, it is likely the complex sequence of motor movements that is disturbed.
                  
main point        
It seems likely that this neural unit participates in both reading and writing. Especially considering the similarity of the behavioral pattern.
        
it seems exner's area, which was always thought to be involved in writing, is coactive at visual or maybe even acousti patterns forletters
        
"the neural network emboding `letter knowledge' would conjoin sensory and motor representations"
        
This is a relatively rare lesion to have, and other caes at their hospital were caused by strokes.
        
Interestingly, the representation  of letters and numbers seems to use distinct resources.},
author = {Anderson, Steven W and Damasio, Antonio R and Damasio, Hanna},
file = {:Users/Brenden/Documents/Mendeley/Anderson, Damasio, Damasio - 1990 - Troubled letters but not numbers Domain specific cognitive impairments following focal damage in frontal cortex.pdf:pdf},
journal = {Brain},
keywords = {embodied cognition,handwriting,part-based models},
mendeley-tags = {embodied cognition,handwriting,part-based models},
pages = {749--766},
title = {{Troubled letters but not numbers: Domain specific cognitive impairments following focal damage in frontal cortex}},
volume = {113},
year = {1990}
}
@article{Andrieu2003,
annote = {        Mixtures and cycles of MCMC kernels
                
If K1 and K2 are valid transition kernels, 
        
K2K2 and a mixture vK1  + (1-v)K2  are also valid transition kernels
        
Cycles allow you to split a multivariate state into compoennts (blocks) that are updated separately.
Obviously, this has trade-offs. If you sample one-at-a-time, it may take a long time. If you sample everything at once, you get very low acceptance probabilities.
        
Example 1:
- with probability v, apply global proposal
- with probability 1-v, apploy local proposal
        
Example 2: 
- blocked sampling. where you only sample a sub-set of the variables at once
        
You can mix together Gibbs and MH, such that you use gibbs when you can sample from standard distributions, and otherwise MH
                  
reversible jump mcmc
                
If you define a joint distribution, with a prior on the cardinality of the latent variable state, and then also the latent variables, you can use reversible jump mcmc
        
You then need a proposal that lifts, and a proposal that collapses.
                  
IF YOU HAVE CONTINUOUS VARIABLES, you can transform them in the reversible jump moves, you NEED TO INCLUDE THE JACOBIAN
        
For a mixture model, you can mix together birth moves, death moves, merge moves, split moves, etc.},
author = {Andrieu, Christophe and {De Freitas}, Nando and Doucet, Arnaud and Jordan, Michael I},
file = {:Users/Brenden/Documents/Mendeley/Andrieu et al. - 2003 - An Introduction to MCMC for Machine Learning.pdf:pdf},
journal = {Machine Learning},
keywords = {markov chain monte carlo,mcmc,sampling,stochastic algorithms},
pages = {5--43},
title = {{An Introduction to MCMC for Machine Learning}},
volume = {50},
year = {2003}
}
@article{Armstrong1983,
annote = {Even well-defined categories show typicality effect
        
-------
Problems with feature view: not all features have the same relations to the concept, some features like "wings" don't seem any simpler than just birds
        
-- Prototype theory shares many woes of definition theory: what are the prototypes?
-- doesn't explain composition of concepts, like "foolish bird"
-- if the typicality findings force us to accept prototypes, there must be some definitional concepts that DO NOT show these effects
                  
Experiment: ratings        
odd number, mother, etc. were tested in typicality rating
-- they are also rated very consistently, although less typical on average
                  
Experiment: category verification        
effect on verification is powerful, and about the same as with poolry defined concepts
                  
conclusion        
Giving up on features doesn't make it any harder to explain compositionality. },
author = {Armstrong, S L and Gleitman, L R and Gleitman, H},
file = {:Users/Brenden/Documents/Mendeley/Armstrong, Gleitman, Gleitman - 1983 - What some concepts might not be.pdf:pdf},
journal = {Cognition},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {5},
title = {{What some concepts might not be}},
volume = {1},
year = {1983}
}
@inproceedings{Asadi1991,
annote = {You almost always encounter new words

        
          
detecting new wrods
        
First, they have a model that detects new words, based on phoneme transitions for a general new word model

        
speaker dependent
- can detect about 71% of the nw words with few false alarms (1%)

        
speaker independent:
about 50% correct with 2% false alarm

        

        phonetic recogition

        
        
- can we recognize the word by recognizing phonemes? this is in gneral very hard, with only about 85% correct for the individual phonemes using triphones
-Just have a phoneme transition model (diphone or triphones) is not good enough for great phonetic recognition accuracy
- this is not high enough, so they used other approaches that combine both speech and text

        

        speech and text system
        
DECtalk has text to sound rules, which do a decent job at providing phonemes from the top down

        
You can also compute a phoneme confusion matrix, and use this to make a noisy template out of DECtalks phonetic transcription

        
end result around 4.5% error rate},
author = {Asadi, Ayman and Schwartz, Richard and Makhoul, J},
booktitle = {Acoustics, Speech, and Signal Processing},
file = {:Users/Brenden/Documents/Mendeley/Asadi, Schwartz, Makhoul - 1991 - Automatic modeling for adding new words to a large-vocabulary continuous speech recognition system.pdf:pdf},
keywords = {one-shot learning,speech recognition},
mendeley-tags = {one-shot learning,speech recognition},
pages = {305--308},
title = {{Automatic modeling for adding new words to a large-vocabulary continuous speech recognition system}},
volume = {1},
year = {1991}
}
@article{Ashby1999,
author = {Ashby, F G and Queller, S and Berretty, P M},
journal = {Perception and Psychophysics},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {6},
pages = {1178--1199},
title = {{On the dominance of unidimensional rules in unsupervised categorization}},
volume = {61},
year = {1999}
}
@article{Aslin1998,
annote = {Rules out word frequencies, and favors transition probabilities, as the mechanism behind Saffran et al. statistical learning paper
        
----
Distributional information, combined with prior tendnecies, are used to learn language
        
Previous study on statistical learning to discover word boundaries
+ from just two minutes of exposure, infants could discriminate words from non-words afterwards
+ transition probabilitie of syllables helped discriminate words
        
Problem with this study: it could have been the frequency, rather than transitional probabilities, that mattered
        
This study: 
- equated frequencies of the syllable sequences within versus across words, while maintaining differences in transitional probabilities
- two words occured twice as often as other two
+ thus, syllable sequence across boundarie between the two common words occured relatively frequently
++ precisely equal to less common 3-syllable word
+ still difference of 1 vs. .5 ofr transition probabilities
                  
experiment
                
3 minute corpus
        
four test items, where two were words
+ infants could control the duration of the trial
                  
results
                
averaged across two different artificial languages
        
significant difference betwen two types of test items
        
previous study's result could not be familiarity effect},
author = {Aslin, R. N. and Saffran, J. R. and Newport, E. L.},
doi = {10.1111/1467-9280.00063},
file = {:Users/Brenden/Documents/Mendeley/Aslin, Saffran, Newport - 1998 - Computation of Conditional Probability Statistics by 8-Month-Old Infants.pdf:pdf},
issn = {0956-7976},
journal = {Psychological Science},
keywords = {classic psychology,statistical learning},
mendeley-tags = {classic psychology,statistical learning},
month = jul,
number = {4},
pages = {321--324},
title = {{Computation of Conditional Probability Statistics by 8-Month-Old Infants}},
volume = {9},
year = {1998}
}
@article{Aslin2012,
abstract = {Statistical learning is a rapid and robust mechanism that enables adults and infants to extract patterns of stimulation embedded in both language and visual domains. Importantly, statistical learning operates implicitly, without instruction, through mere exposure to a set of input stimuli. However, much of what learners must acquire about a structured domain consists of principles or rules that can be applied to novel inputs. Although it has been claimed that statistical learning and rule learning are separate mechanisms, here we review evidence and provide a unifying perspective that argues for a single mechanism of statistical learning that accounts for both the learning of the input stimuli and the generalization to novel instances. The balance between instance-learning and generalization is based on two factors: the strength of perceptual biases that highlight structural regularities, and the consistency of unique versus overlapping contexts in the input.},
annote = {Can you model the statistical learning system that, depending on how variables the roles of elements are, you can learn first-order statistics amongst elements (Saffran, Aslin, Newport) or rules (Marcus et al.). 
+ It seems you need more random choices to predict data with rules, since you must select amongst elements
        
--------
Leaner must extract the correct structure when faced with raw input
                  
statistical learning in language and vision
          
language        
Saffran, Aslin, Newport (1996). Infants can learn transition probabilities between non-sense syllables.
        
Maye et al: unimodal vs. bimodal distributions in phonetic categories
- only bimodal distribution facilities discrimination of phonetic category
                  
vision        
Kirkham et al.: infants as young as 2 months can discriminate between familiar and novel sequences of shapes
        
Fiser and Aslin (2002): infants can learn statistical consistency of how shapes were arranged in space
+ important for discovering visual features that form parts of a scene
                  
How does the learner acquire rules?        
+ generalize to new elements never been seen or heard
        
        From statistical learning to rule learning
                
Gomez and Gerken: evidence for learning grammatical categories from nonsense words, and infants generalized "famililar" pattern to new words
        
Marcus et al. (1999):
7 month olds
AAB vs. ABB strings
+ able to generalize reptition rule to completely new words
        
Marcus claims these are two different mechanisms
+ since statistical learning uses the same elements
+ but they could be different outputs of the same learning mechanism
        
Video game example: by learning statistical chunks, it is easier to learn rules later on top of those
        
Salient perceptual dimensions also constrain what people acquire, like 1-2 day infants are sensitive to stimulus repetition (like in Marcus)
        
        rule learning without perceptual cues
                
Mechanism my trigger word learning, if they realize several elements can occur interchangeable in the same place
        
Gerken's (2006) adapation of Marcus showed that by keeping the last syllable constant in the AAB pattern, infants did not generalize
        
Reeder et al.: aludts can learn grammatical categories, where A B X play role of noun, verb, and direct objet, where sometimes A and X could appear in the same contexts
+ tendency to generalize dependend on precise degree of overlap among word contexts
+ adults generalize when contexts are largely the same, and only sometimes non-overlap
                  
statistical learning is just one mechanism, whose outcome either applies to experience elements or in general        
        
Hudson et al. showed that same input produced a general rule or not, depending on whether subject learned natural language -- thus, rule sticking can be influenced by common patterns in language
        
challenges for statistical learning:
- develop an overall model that occounts for both types, statistical and rule-based
- find neural mechanisms},
author = {Aslin, Richard N and Newport, Elissa L},
doi = {10.1177/0963721412436806},
file = {:Users/Brenden/Documents/Mendeley/Aslin, Newport - 2012 - Statistical learning From acquiring specific items to forming general rules.pdf:pdf},
issn = {0963-7214},
journal = {Current directions in psychological science},
keywords = {and your parents have,but the instructions are,generalization,given you a new,imagine that it,infants,miss-,rule learning,s your 10th birthday,statistical learning,video game},
mendeley-tags = {statistical learning},
month = jun,
number = {3},
pages = {170--176},
pmid = {24000273},
title = {{Statistical learning: From acquiring specific items to forming general rules}},
volume = {21},
year = {2012}
}
@article{Atran1998,
author = {Atran, S},
journal = {Behavioral and Brain Sciences},
pages = {547--609},
title = {{Folk biology and the anthropology of science: Cognitive universals and cultural particulars}},
volume = {21},
year = {1998}
}
@article{Augustine2011,
annote = {Structural description theory has separate role of parts and relations
        
Here they find evidence that these aspects of shape representation are distinct, where toddlers more readily generalize a new word based on the shape of the parts.
        
However, relational deformations are more important when identifiyng known objects 
        
-----
Results show importance of part shape and part relations, it is a real and developmentally important distinction
        
Introduction
        
Hummel and Biederman: Objects have geometric shapes and relations between them
        
Smith 2003: 18-24 motns, compared children's recognition of geon represntation to real objects
- older children categorized the sparse representations as well as the other ones
- younger children did not
- shape develops rapidly in infanct (like the sahpe bias)
        
Experiment 1: separated object shape from object relations, and looked at whether 1.5-2 yo children could match along both dimensinos of simialrity
        
Part-shape matching task
Part relations matching task
        
Exemplar, where there are three choices, where either the distractors have deformed shaped or deformed relations
        
Two groups:
relations
parts
        
Also looked at shape caricature task, where you get rid of color/texture feautres
        
Procedure:
Look at this daks:
        
See all of these? Can you get me another dax?
        
Results: 
- near perfect familiarty with shape carciature task
        
Sparse object recognition correlates with the number of object names in a child's vocabulary (r=.37), replicationg a previous result
        
 Shapes test group (M=50%) was significantly better than the relations test group (M=36%)
- chance performancei nthe relations groups
+ interesting, because all they had to do was perceive the identical exemplar
        
Representations might begin with parts and later develop relations, and idea with some precedence in the literature (Gentner)
        
Both could be important for word learning, since perfornace on both tasks correlates with productive vocabularies
                  
Experment 2        
        
Is one component, shape or relations, more important than the other for recognition?
        
Rather than changing all of the parts, the stimuli here just changed one part.
        
There was no example object... presented with three caricatures and asked by name ot find the category instance
        
"Where is the ice cream?
        
19-24 mo
                  
Results
                
89% correct in the realistic object recognition task
        
49% correct for part relations
39% correct for part shapes
        
The part shape task was not significantly better than chane
        
Thus, children are highly sensitive to the relational structure of known object, but not unknown objects
        
        General discussion
                
Object shape is clearly important, but very little is known about what aspect of shape
        
Biederman proposes a sparse representaiton based on shape and relations, and given that children can recognize these impoverished relations, this gives it some support
        
Also, suggests that the two coponents of representation are separable in development
        
Shape is more important initially, but relations are more important for well-known cateogires
        
Visual object recognition may change in fundamental ways over the course of development},
author = {Augustine, Elaine and Smith, Linda B. and Jones, Susan S.},
doi = {10.1080/15248372.2011.560586},
file = {:Users/Brenden/Documents/Mendeley/Augustine, Smith, Jones - 2011 - Parts and Relations in Young Children's Shape-Based Object Recognition.pdf:pdf},
issn = {1524-8372},
journal = {Journal of Cognition and Development},
keywords = {part-based models,word learning},
mendeley-tags = {part-based models,word learning},
month = oct,
number = {4},
pages = {556--572},
title = {{Parts and Relations in Young Children's Shape-Based Object Recognition}},
volume = {12},
year = {2011}
}
@inproceedings{AusterweilGriffiths,
author = {Austerweil, J and Griffiths, T L},
booktitle = {{Advances in Neural Information Processing Systems}},
file = {:Users/Brenden/Documents/Mendeley/Austerweil, Griffiths - 2009 - Analyzing human feature learning as nonparametric Bayesian inference.pdf:pdf},
keywords = {representation learning},
title = {{Analyzing human feature learning as nonparametric Bayesian inference}},
year = {2009}
}
@inproceedings{Austerweil2011,
author = {Austerweil, Joseph L and Griffiths, Thomas L},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:Users/Brenden/Documents/Mendeley/Austerweil, Griffiths - 2011 - Learning invariant features using the Transformed Indian Buffet Process.pdf:pdf},
keywords = {non-parametric Bayes,part-based models},
mendeley-tags = {non-parametric Bayes,part-based models},
title = {{Learning invariant features using the Transformed Indian Buffet Process}},
year = {2011}
}
@article{BabcockFreyd1988,
annote = {Motor-based features can be inferred from the static image. A first group of participants did speeded drawing, for novel characters in method A or B that differ in stroke direction. The most distorted participant in each condition was chosen. Another group of participants learned to classify the characters drawn by A or B. Then in a later production task, hey tended to draw the strokes in a way that was consistent with the learned examples.
---
Experiment 1:
        
Participants received static character examplars where all the last strokes were drawn up or drawn down. They learned to identify 9 different characters. 
        
After, participants had to write down a subset of the characters they learned (in triplets). Although there are general biases (like a strong downward bias), there is an effect in the direction in which the image was actually drawn.
        
Some characters, there is a huge effect. Others, not so much.
        
They also have explicit access to this knowledge, where they guessed the direction at roughly the same rates as in the implicit task. 
        
There is no correlation between the judgements of participants in the implicit vs. the explicit version of the tasks (weird). Means they have no conscious awareness? There is not just a group of people that is "more sensitive" to this.
        
Some of the most revealing characters were those that contained diagonals,.
        
Experiment 2: 
Thus,
Same thing but only with diagonal strokes (either first stroke or last [manipulated] stroke). 
        
It is easier to detect the direction of the last stroke is diagonal. This, is likely because the overall downwards bias is strongly reduced.
        
There is no effect of earlier diagonal strokes.
                  
Discussion
                
"perceivers spontaneously infer the underlying dynamic pattern of motor movements used to produce handwritten characters by utilizing knowledge of common production processes"
        
Goal was to demonstrate that this was possible, although generality might be limited by just choosing one person's drawings
        
Probably understimate effect, since it was done with novel characters
        
Also, in natural letter recogntion, people share a preferred production system. They share preferred directions, etc.
        
They suggest it would be wonderful to have a model that can infer the dynamics, given these important features. Well, maybe we can, 20 years later?
        
      },
author = {Babcock, M K and Freyd, J},
file = {:Users/Brenden/Documents/Mendeley/Babcock, Freyd - 1988 - Perception of dynamic information in static handwritten forms.pdf:pdf},
journal = {American Journal of Psychology},
keywords = {classic psychology,classics on concepts,embodied cognition,part-based models},
mendeley-tags = {classic psychology,classics on concepts,embodied cognition,part-based models},
number = {1},
pages = {111--130},
title = {{Perception of dynamic information in static handwritten forms}},
volume = {101},
year = {1988}
}
@inproceedings{Bahlmann2001,
annote = {Introduces statistical DTW. Where a template is usually a static sequence of points, now the template is a sequence of points that is stochastic, where you have a Gaussian on each point. This can be a multivariate Gaussian and use arbitrary features.
        
This is similar to an HMM, and you can use it to define a distance between two HMMs.
        
===
statistical DTW:
-- You have several classes
-- Each class has a prototype
-- You classify by picking the best prototype, from the best class, where you can have different priors on classes. The prototypes can have Gaussian distributions over each of the points, rather than just a single coordinate.
-- This makes it like an HMM. You have an observation model, and you can stretch the states like a left-to-right HMM
        
You can define the similarity between HMMs with DTW distance, where distance is now KL-divergenve.},
author = {Bahlmann, C. and Burkhardt, H.},
booktitle = {Proceedings of Sixth International Conference on Document Analysis and Recognition},
doi = {10.1109/ICDAR.2001.953822},
file = {:Users/Brenden/Documents/Mendeley/Bahlmann, Burkhardt - 2001 - Measuring HMM similarity with the Bayes probability of error and its application to online handwriting recognition.pdf:pdf},
isbn = {0-7695-1263-1},
keywords = {handwriting},
mendeley-tags = {handwriting},
pages = {406--411},
publisher = {IEEE Comput. Soc},
title = {{Measuring HMM similarity with the Bayes probability of error and its application to online handwriting recognition}},
year = {2001}
}
@inproceedings{Bahlmann2002,
annote = {On-line character recognition. Uses SVMs, with a Gaussian kernel based on DTW distance. Clever, and seems to beat HMMs, but this would not work for small sample sizes.
        
=========
HMMs are most common method for on-line handwriting recognition, where they generate some observed features of the pen tip curve
        
Model:
-- features include normalized x and y coordinates, and a tangent line
-- distance based on DTW (dynamic time warp)
-- kernel is Gaussian
-- classification by SVM
        
Results:
-- for binary classification, better performance than modified DTW technique},
author = {Bahlmann, Claus and Haasdonk, Bernard and Burkhardt, Hans},
booktitle = {Proceedings of the Eight International Workshop on Frontiers in Handwriting Recognition},
file = {:Users/Brenden/Documents/Mendeley/Bahlmann, Haasdonk, Burkhardt - 2002 - On-line Handwriting Recognition with Support Vector Machines — A Kernel Approach.pdf:pdf},
isbn = {0769516920},
keywords = {handwriting},
mendeley-tags = {handwriting},
title = {{On-line Handwriting Recognition with Support Vector Machines — A Kernel Approach}},
year = {2002}
}
@article{Bahrick1984,
annote = {Introduced the notion of:
        
Permastore -- knowledge seems to be stored in a relatively permanent form.
        
A whole bunch of previous or current students of Spanish were studied. Test performance was based on amount of initial training, grades, etc. but practice after training was so little that it had no effect.
        
Knowledge declines exponentially for the first 3-6 years, but afterwards it is relatively stable for up to 30 years.
        
This disjoint curve, the latter part is the "permastore" 
        
      },
author = {Bahrick, Harry P},
file = {:Users/Brenden/Documents/Mendeley/Bahrick - 1984 - Semantic memory content in permastore Fifty years of memory for Spanish learned in school.pdf:pdf},
journal = {Journal of Experimental Psychology : General},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {1},
title = {{Semantic memory content in permastore: Fifty years of memory for Spanish learned in school}},
volume = {113},
year = {1984}
}
@article{Baker2007a,
abstract = {How do category-selective regions arise in human extrastriate cortex? Visually presented words provide an ideal test of the role of experience: Although individuals have extensive experience with visual words, our species has only been reading for a few thousand years, a period not thought to be long enough for natural selection to produce a genetically specified mechanism dedicated to visual word recognition per se. Using relatively high-resolution functional magnetic resonance imaging (1.4 x 1.4 x 2-mm voxels), we identified a small region of extrastriate cortex in most participants that responds selectively to both visually presented words and consonant strings, compared with line drawings, digit strings, and Chinese characters. Critically, we show that this pattern of selectivity is dependent on experience with specific orthographies: The same region responds more strongly to Hebrew words in Hebrew readers than in nonreaders of Hebrew. These results indicate that extensive experience with a given visual category can produce strong selectivity for that category in discrete cortical regions.},
author = {Baker, Chris I and Liu, Jia and Wald, Lawrence L and Kwong, Kenneth K and Benner, Thomas and Kanwisher, Nancy},
doi = {10.1073/pnas.0703300104},
file = {:Users/Brenden/Documents/Mendeley/Baker et al. - 2007 - Visual word processing and experiential origins of functional selectivity in human extrastriate cortex.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Adolescent,Adult,Female,Humans,Internationality,Language,Learning,Learning: physiology,Magnetic Resonance Imaging,Male,Middle Aged,Ocular,Ocular: physiology,Vision,Visual Cortex,Visual Cortex: physiology,Vocabulary},
month = may,
number = {21},
pages = {9087--92},
pmid = {17502592},
title = {{Visual word processing and experiential origins of functional selectivity in human extrastriate cortex.}},
volume = {104},
year = {2007}
}
@article{Banerjee2008,
author = {Banerjee, Onureena and {El Ghaoui}, Laurent and D'Aspremont, Alexandre},
file = {:Users/Brenden/Documents/Mendeley/Banerjee, El Ghaoui, d'Aspremont - 2008 - Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {binary data,convex optimization,gaussian graphical model,graphical models,maximum likelihood estimation,model selection,sparsity},
mendeley-tags = {graphical models,sparsity},
pages = {485--516},
title = {{Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data}},
volume = {9},
year = {2008}
}
@article{Bara2004,
author = {Bara, Florence and Gentaz, Edouard and Col\'{e}, Pascale and Sprenger-Charolles, Liliane},
doi = {10.1016/j.cogdev.2004.05.003},
file = {:Users/Brenden/Documents/Mendeley/Bara et al. - 2004 - The visuo-haptic and haptic exploration of letters increases the kindergarten-children’s understanding of the alp.pdf:pdf},
issn = {08852014},
journal = {Cognitive Development},
keywords = {embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
month = jul,
number = {3},
pages = {433--449},
title = {{The visuo-haptic and haptic exploration of letters increases the kindergarten-children’s understanding of the alphabetic principle}},
volume = {19},
year = {2004}
}
@article{Barker1985,
abstract = {This note describes a novel method of directly stimulating the human motor cortex by a contactless and non-invasive technique using a pulsed magnetic field.},
author = {Barker, A T and Jalinous, R and Freeston, I L},
journal = {The Lancet},
number = {8437},
pages = {1106--1107},
pmid = {2860322},
title = {{Non-invasive magnetic stimulation of human motor cortex.}},
volume = {1},
year = {1985}
}
@article{Barsalou2008,
abstract = {Grounded cognition rejects traditional views that cognition is computation on amodal symbols in a modular system, independent of the brain's modal systems for perception, action, and introspection. Instead, grounded cognition proposes that modal simulations, bodily states, and situated action underlie cognition. Accumulating behavioral and neural evidence supporting this view is reviewed from research on perception, memory, knowledge, language, thought, social cognition, and development. Theories of grounded cognition are also reviewed, as are origins of the area and common misperceptions of it. Theoretical, empirical, and methodological issues are raised whose future treatment is likely to affect the growth and impact of grounded cognition.},
annote = {Does the brain contain amodal symbols?
-- Some researchers think modal symbols are peripheral
-- },
author = {Barsalou, L W},
doi = {10.1146/annurev.psych.59.103006.093639},
file = {:Users/Brenden/Documents/Mendeley/Barsalou - 2008 - Grounded cognition.pdf:pdf},
institution = {Department of Psychology, Emory University, Atlanta, Georgia 30322, USA. barsalou@emory.edu},
issn = {00664308},
journal = {Annual Review of Psychology},
keywords = {cognition,cognition physiology,embodied cognition,humans,imagination,linguistics,memory,psychological theory,social behavior,social perception,symbolism},
mendeley-tags = {embodied cognition},
number = {1},
pages = {617--45},
pmid = {17705682},
publisher = {Annual Reviews},
title = {{Grounded cognition.}},
volume = {59},
year = {2008}
}
@article{Barsalou1999,
abstract = {Prior to the twentieth century, theories of knowledge were inherently perceptual. Since then, developments in logic, statistics, and programming languages have inspired amodal theories that rest on principles fundamentally different from those underlying perception. In addition, perceptual approaches have become widely viewed as untenable because they are assumed to implement recording systems, not conceptual systems. A perceptual theory of knowledge is developed here in the context of current cognitive science and neuroscience. During perceptual experience, association areas in the brain capture bottom-up patterns of activation in sensory-motor areas. Later, in a top-down manner, association areas partially reactivate sensory-motor areas to implement perceptual symbols. The storage and reactivation of perceptual symbols operates at the level of perceptual components--not at the level of holistic perceptual experiences. Through the use of selective attention, schematic representations of perceptual components are extracted from experience and stored in memory (e.g., individual memories of green, purr, hot). As memories of the same component become organized around a common frame, they implement a simulator that produces limitless simulations of the component (e.g., simulations of purr). Not only do such simulators develop for aspects of sensory experience, they also develop for aspects of proprioception (e.g., lift, run) and introspection (e.g., compare, memory, happy, hungry). Once established, these simulators implement a basic conceptual system that represents types, supports categorization, and produces categorical inferences. These simulators further support productivity, propositions, and abstract concepts, thereby implementing a fully functional conceptual system. Productivity results from integrating simulators combinatorially and recursively to produce complex simulations. Propositions result from binding simulators to perceived individuals to represent type-token relations. Abstract concepts are grounded in complex simulations of combined physical and introspective events. Thus, a perceptual theory of knowledge can implement a fully functional conceptual system while avoiding problems associated with amodal symbol systems. Implications for cognition, neuroscience, evolution, development, and artificial intelligence are explored.},
annote = {Summary: Barsalou argues against the amodal theory of concepts, where the relation between concept and perceptual state is arbitrary like "names for words." Perceptual and conceptual systems instead share the same hardware and cannot be divorced. A perceptual symbol is a record of neural activation -- which can arise both during perception and also by top-down conceptual processes (called simulation). Rather than containing the raw whole like many characterizations of perceptual theories (recording theories), it contains a schematic piece (like Mandler's how to build a baby). Simulation runs this system in reverse, generating details instead of abstracting them away.
        
Related to "embodied" or "grounded" cognition. 
        
Overall reaction: Many points seem right, but given the complete lack of computational grounding, it's really hard to understand what a perceptual symbol really is -- unless it's implemented in neurons. The simulator theory sounds a lot like a generative model with a compositional structure, perhaps like in Churhc?
        
Relevance to handwritting project: "If a simulator for a category can produce a satisfactory simulation of a perceived entity, the entity belongs to the category" p. 587.
        
---
A common system underlies perception and cognition: e.g., resources for color of objects in perceptual systems are the same as color in perception
        
Amodal symbols bear no correspondence to the perceptual states -- this is what Barsalou is fundamentally arguing against. Arbitrary as in the "names" for objects.
        
Evidence against amodal systems:
-- damage to visual areas influence coneptual proceessing
-- how would these symbols arise in an amodal way?
-- how can a symbol be grounded?
        
Why are people skeptical of perceptual symbol systems?
-- don't seem productive, just a bundle of perception
-- represent types and tokens?
        
Examples of perceptual theories:
-- Mandler, how to build a bab
-- Kosslyn, on mental imagery
-- Shepard and Cooper, on mental rotation
        
Central tenant: a perceptual symbol is a record of neural activation that arises during perception. Rather than containing the raw whole, it contains a schematic aspect.
        
Qualities
-- they are componential, not holistic
-- they can be indeterminate
-- they are multimodal
-- they can be dynamic, not discrete
-- they can simulate unseen aspects (do inference)
        
Qualitatively oriented neurons can represent "stripes" without a specific number.
        
Simulation: if trying to hide from someone in a restaurant, you can simulate that a newspaper provides cover while a notebook does not (p. 588)
-- Comment: this seems like a generative model. But there is an important difference: he talks like simulation is just a single sample from the generative capacity, with an actual instantiation.
        
What about bottom-up dominance (as in the modulatiry view, the Muller-Lyer illusion)? From the grounded perspective, cognition penetrates perception when sensory input is abent, or when top-down is compatible. Even infants can simulated object trajectories.
        
Can inbed simulators in other simulators
        
Linguistic symbols are just perceptual symbols, in the language modality
        
Compositionality: simulators for objects and relations can compose in novel ways. They can also compose recurisvely, where simulators (themselves composed) are embedded in other relations with new objects.
        
Perception: schematic information is extracted
Simluation: detailed information is added back
        
Type/Token: within a simulation, there is a specific token which is bound to the type
        
Comment: while perceptual symbols may have some aspects of propositional systems, what about quantifiers?
        
Abstract concepts can check to see if a simulation fits a particular situation -- truth, falsity, anger evaluted in terms of the perceptual symbols
        
Disjunctions, "a cat or a dog was in the barn" can be represented by alternating between two simulations, with different fillers of a role
        
Simulation may displace the role of intuitive theory -- the notion of diameter can be derived from hour a pizza and a quarter are produced
        
"Working memory" is the system that runs simulation
        
Language provides instructions to the simulator -- so you can activate simulations in others. This might be the aspect that is unique to humans, and created an particularly powerful simulator system
        
Argues against functionalism as a philosophy of mind -- you need the human sensory-motor aparatus},
author = {Barsalou, L W},
file = {:Users/Brenden/Documents/Mendeley/Barsalou - 1999 - Perceptual symbol systems.pdf:pdf},
issn = {0140-525X},
journal = {Behavioral and Brain Sciences},
keywords = {Cognition,Concept Formation,Humans,Knowledge,Memory,Models,Perception,Psychological,embodied cognition},
mendeley-tags = {embodied cognition},
month = aug,
number = {4},
pages = {577--609; discussion 610--60},
pmid = {11301525},
title = {{Perceptual symbol systems.}},
volume = {22},
year = {1999}
}
@article{Barsalou1983,
annote = {Ad hoc cateogires: "things to sell at a garage sale"
        
They have a graded structure, must like common categories (prototypes). But they are much less established in memory, and weaker concept-to-istances and instance-to-concept associations
        
Another example of concept production.
        
--------
Good survey of categorization literature: prototypes, Tversky's similarity theory, semantic networks
        
How might ad hoc categories be different?
1: graded structure
2. not associated in memory, so more difficult to retrieve instances
        
If they don't have correlational structure, like Rosch's basic level categories, then why might people seem them as categories?
                  
Experiment 1: ratings        
People reated examples of categories for typicality,
like thigns to take in a fire
There is graded structure, and overall high agreement
                  
Studying concept-to-instance associations
          
Experiment 2A: graded structure in production        
some examples were more dominant, but less so that common cateogires. People have stronger association with common categories
                  
Experiment 2B: people generate more examples of concrete categories. },
author = {Barsalou, Lawrence W},
file = {:Users/Brenden/Documents/Mendeley/Barsalou - 1983 - Ad hoc categories.pdf:pdf},
journal = {Memory \& Cognition},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {3},
pages = {211--227},
title = {{Ad hoc categories}},
volume = {11},
year = {1983}
}
@article{Barsalou1985,
annote = {What determines typicality?
1) exemplar's similarity to ideals
2) exmplar similarity to the central tendency (family resemblance)
3) exemplars frequency of instantiation (people's estimate of how often it is encountered as a category member)
        
Ideals matter, even in common taxaonimc categories, but especially for goal derived categories! Same with frequency of instantiation.
        
        
But "familiarity" did not predict typicality
        
Investigated this for taxonomic and goal-derived categories
        
Also, ideals are context sensitive, so graded structures do not reflect invariant structures but also dnyamic construction of concepts.
        
----
        
Ideals: "foods to eat on a diet", "things to take from one's hom during a fire" -- categories that have a goal
        
Frequency: in all contexts, or the frequency they have experience an entity as a member of a particular category? 
        
goal-dervied: includes ad hoc and better establisehd ad-hoc categories. They often apear to vioalte the correlational structure of natural categories.
        
The goal for the taxonomic categories was picked to be something reasonalbe, like "how much do people like it" for vegetables          
        Exemplar goodness ratings, however, were context insensitive -- so it's interesting that this will end of correlating          
          
Experiment 1:
          
exemplar generation: each subject generated exempalrs to each of 18 categories. Wrote down as many as possible in a 15 second interval.
        
Responses were pooled so frequency could be calculated.
        
Also made the following judgments:
- exemplar goodness judgments.
- frequency of instantiation judgments (1...7)
- same with ideals, but this is with respect to a parcitular goal (efficiency of transport, necessary of wearing, etc.)
- family resemblance was collected by similarity judgments between randomly selected pairs, which has been repoted to correlate with feature listings around .9
        
Both output dominance and exemplar goodness are correlatied (.39 for goal-derived, and .55 for common taxonomic)
        
People also generated exemplars fo common categories at a faster rate
        
partial correlations
- tried to predict exemplar goodness, or output domainance, by the three independent variables
                  
partial correlation for output dominance        
-- for goal dervied, only frequeny of instantiation is significant
- for common, all three factors are significant, and central tendency is a much better predictor than in the goal-derived
                  
similar for exemplar goodness
          
Experiment 2        
Do ideals causally determine typicality? Since central tendency has been tested casually.
- also, does the graded structure depend on the context
        
Method
learned two categories, each contained a peron's last name associated with 5 things they like to do (the features). Each had a defining dimension (like all members of one jogged), but they varied in the amount of the defining dimension (daily, weekly, monthly)
The main manipulation was how subjets were indcued to perceive the defining dimensions (related or not)
If it was related, it was sports teachers vs. current event teachers (who read alot). It's likely that ideals would determine typicality here.
        
Otherwise, itwas programmers in language Q vs. Z, and it's unliekly that ideals would determine the typicatliy here
        
Also, some subjects learned to discriminate the categories, and another group had an irrelevant procesing task
        
Task: told that spare time activities predict how good people would be ta teaching courses. For releveant group, they would learn to discriminate one from the other. They received feedback.
        
Other tasks at test procedure:
-- rate typicality
-- rank by typicality
                  
Results:        
Central tendency mattered, but not much on the relevenat dimensions (which varied in degree). Ideals mattered a lot on the relevant dimension
        
It showed that the group mattered, so ideals can vary with context. Ideal was not very important for the programmer subjects.
                  
Discussion        
graded sturcutre may largely refelct people's current concept of the category, which can change
        
Size and ferocity may be higher when viewing the category animal in a forest ranger's point of view than a pet store},
author = {Barsalou, Lawrence W},
file = {:Users/Brenden/Documents/Mendeley/Barsalou - 1985 - Ideals, Central Tendency, and Frequency of Instantiation as Determinants of Graded Structure in Categories.pdf:pdf},
journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
keywords = {classic psychology,classics on concepts,exemplar generation},
mendeley-tags = {classic psychology,classics on concepts,exemplar generation},
number = {4},
pages = {629--649},
title = {{Ideals, Central Tendency, and Frequency of Instantiation as Determinants of Graded Structure in Categories}},
volume = {11},
year = {1985}
}
@article{Barsalou2010,
annote = {Grounded cognition: core knowledge representation is not amodal. The enviornment, situations, body, and simulations ground the central representations in cognition.
        
Embodied cognition could be another word to refer to this, but a body is only one kind of grounding.
        
Long history but made little dent in amodal theories
        
Resurgance in the last 10 years
        
Looking for more integration in next 30
                  
Notes from keynote talk, Cogsci2012
                
What is a concept?
"basic elements of human knowledge"
- aggregated information about experiences with caetgory members
        
concepts needed for online and offline processing
(offline = thought, language, etc.)
        
dominant paradigm: study working memory separately, etc. without perception/action
        
grounded cognition: cognition depends on environment, body, social situation
        
example: when thinking/processing verbs, the motor system is active (in specific ways)
        
cognition is not modular -- it is emergent from all these various factors
        
When you sense a dog, you connect all the sensory modalities for perception and action, with whatever might store the "abstract concept"
- when you think about a dog, you run the brain in a way that if you really see a dog
- this seems like a "generative model"
        
when you think about a dog, it's not abstract -- floating in space. It's situated somehow
- you don't just pull up an abstract description, a concept is more like an instruction manual for interaction
        
example: when you ask people to produce features of objects, it's not just physical properites, they describe settings and events, mental states, categories etc. [40% were non object features]
        
a concept: can be pulled up and run off-line, simulating how it fits in a situation
        
what is an exemplar?
- records that cpatures the state of the situationed processing architecture on specific occasions
- when we retrive the exemplar, we retrieve all those states
        
are those abstractions? schemeta?
- are these really fundamental and abstract? He thinks we need evdeince for this, rather than vice versa
        
Alex Martin (2001,2007)
- asked people to think of tools
+ activity in motor regions, frontal area for actions,
+ the tool "concept" is the emergent network that arises when all of the areas that process tools are active
        
Pattern completion inferences:
- basic function of conceptual system
- see an object, find the best exemplar, which reconstructs all the other states, and thus can make inferences
+ Seems a bit like a PDP approach, like the semantic cognition net with lots of modalities?
        
Subjective realism
- When you see a picture of food, you automatically salivate, as if you are eating it
- When you imagine emotion, you get physio. signals that are consistent with that emotion
        
Can you remove this? [practical applications, like stress reduction]
- if you explain to subjectives that they have these "real" reactions, they have some conscious control to remove it
                  
that was theory, now applications
- Chao & Martin (2000). When shown a hammer, people activate part of motor cortex that would interact with it. Thus auto. simulation
- when looking at food vs. places, there is auto. activation of taste area (primary gustatory area)
+ also activates food reward areas
- embodied states affect cognitive states: manipulate similing/frowning expression. This influences liking judgments
- mirroring: [mirror neurons] people associate how an action looks with how it feels to perform. Thus, pattern completion
        
emotions are very much like other types of abstract concepts
- contrast physical vs. social fear, and you end up with different brain areas. Not modular 
- },
author = {Barsalou, Lawrence W.},
doi = {10.1111/j.1756-8765.2010.01115.x},
file = {:Users/Brenden/Documents/Mendeley/Barsalou - 2010 - Grounded Cognition Past, Present, and Future.pdf:pdf},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {architectures,atlanta,barsalou,correspondence should be sent,department of psychology,e-mail,edu,embodied cognition,embodiment,emory,emory university,ga 30322,grounding,imagery,knowledge,mental simulation,situated cognition,symbolic operations,to lawrence w},
mendeley-tags = {embodied cognition},
month = oct,
number = {4},
pages = {716--724},
title = {{Grounded Cognition: Past, Present, and Future}},
url = {http://doi.wiley.com/10.1111/j.1756-8765.2010.01115.x},
volume = {2},
year = {2010}
}
@article{Barsalou2003,
abstract = {The human conceptual system contains knowledge that supports all cognitive activities, including perception, memory, language and thought. According to most current theories, states in modality-specific systems for perception, action and emotion do not represent knowledge - rather, redescriptions of these states in amodal representational languages do. Increasingly, however, researchers report that re-enactments of states in modality-specific systems underlie conceptual processing. In behavioral experiments, perceptual and motor variables consistently produce effects in conceptual tasks. In brain imaging experiments, conceptual processing consistently activates modality-specific brain areas. Theoretical research shows how modality-specific re-enactments could produce basic conceptual functions, such as the type-token distinction, categorical inference, productivity, propositions and abstract concepts. Together these empirical results and theoretical analyses implicate modality-specific systems in the representation and use of conceptual knowledge.},
annote = {Generally, theories assume that knowledge resides in a modular semantic system, separate from episodic memory and perception/action
        
However, researchers increasingly report evidence that knowledge is grounded in modality-specific systems.
        
--
        
Amodal systems store a concept as a feature list, semantic network, schema etc.
        
Modal systems: sensory neurons are converted to a higher-level representation, which can be re-used to reactive the original sensory representation (comment: basically, a deep Boltzmann machine)
        
Evidence:
- for making feature judgments, one group is asked to use "imagery" and another is neutral. There is little difference, suggesting imagery might be a spontaneous strategy
- verifying "loud" properties is faster than verifying "quiet" properties (loud for blender vs. rustling for leaves)
- priming from visually similar objects, where verying a "pony has a mane" is faster after horse but not lion
- when verifying "Open the drawer" is a sentence, it is faster when the response is a pulling motion (over pushing)
- Social psychology: positive valence items are processed faster when pulling rather than pushing (avoidance)
        
Evidence from neuroscience
- conceptualizing color actives color areas near V4
- conceptuatling object motion activates motion areas
- verying visual properties activates visual areas
        
Amodal symbol: a symbol for "roof" represents all kinds of roofs
        
Box 2: Is there evidence for purely amodal symbols? Comment: maybe not neurally, but at least conceptually
        
Types-tokens: simulator vs. simulation, respectively
-- useful for pattern completion
productivity -- you can embed simulations in one another, combining concpets
      },
author = {Barsalou, Lawrence W. and {Kyle Simmons}, W and Barbey, Aron K. and Wilson, Christine D.},
file = {:Users/Brenden/Documents/Mendeley/Barsalou et al. - 2003 - Grounding conceptual knowledge in modality-specific systems.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
month = feb,
number = {2},
pages = {84--91},
pmid = {12584027},
title = {{Grounding conceptual knowledge in modality-specific systems.}},
volume = {7},
year = {2003}
}
@inproceedings{Bart2005,
annote = {There are techniques for learning features, like image fragments, for a set of categories
- try a bunch and keep the most useful ones
- then you can build a weighted function of the feature responses and see if it is over a threshold, where the weight is the probability ratio of the feature belonging to the class vs. the backgournd

        
but hundreds of training examples are required for fargment extraction

        
adaption: replace familiar feature with most similar feature form the novel class, where the new feature is an image fragment from the new example

        
          
results

        
        
- on cal-tech 101, cross-generalization improves performance over a baseline of just extracting features (there were 2 eaxpmles here)

        
- also, they tried it with just 11 classes, showing you don't need a lot

        
- also, you get an advantage with a training set size of up to 10

        
there was no use of spatial relationsin the model, whcih could improve generalization},
author = {Bart, E and Ullman, S},
booktitle = {Computer Vision and Pattern Recognition (CVPR)},
file = {:Users/Brenden/Documents/Mendeley/Bart, Ullman - 2005 - Cross-generalization Learning novel classes from a single example by feature replacement.pdf:pdf},
keywords = {one-shot learning,part-based models},
mendeley-tags = {one-shot learning,part-based models},
title = {{Cross-generalization: Learning novel classes from a single example by feature replacement}},
year = {2005}
}
@article{Battaglia2013,
annote = {"To see is to know what is where by looking."
- this is true, but it is also knowing physical attributes, relationships, afforances, and past/future
        
A workshop is a good example of a complex scene that supports many of these inferences.
        
Early work on intuitive physics:
- people are incompatible with Newtonia mechanics
- but modern studies show this can change, and even the majority of respondents in original studies gave the right answers
        
Other work on "noisy Newtonian" framework, assuming Newton's laws plus noisy observations
+ but just one or two body interactions
+ but cases are simple, much closer to examples in intro physics than  real world problems
        
Craik: runnable mental models
        
Approach:
- modern graphic simulation + Bayesian modelling
- "intuitive physics engine" (IPE)
        
It can make many intuitive judgements, but it differs from ground truth in crucial ways        
        
At its core is an object based representation of 3D scenes
+ rather than using equations, it represents things procedurally
        
Use "Open Dynamics Engine" (ODE), although people may use much coarser representations than ODE allows for, with simpler object models
        
Can make predictions about totally new events, that you may not have to
 experience first hand
        
Model has sigma parameter, which is s.d. of location, think of as a Bayesian Observer's posterior 
        
OTher parameters for forces, or relative masses between objects
        
        Results:
          
Exp 1: Will it fall?        
        
Two conditions, where participants either received feedback about judgements or not
        
High correlations (0.92 and 0.95)  between model and human predictions, which fit better than the ground truth (0.64)
        
Also tried a feature-based model, that uses geometric features to predict the results
                  
Experiment 2: In which direction?
                
Since predicates can be arbitrary, we can also ask about direction          
                
Judge the direction in which a tower would fall
        
Predicts better (r=.8) than ground truth model (r=.6)
                  
Experiment  3 and 4: Varying object mass
                
Experiment 3: will it fall?
Experiment 4: in what direction?          
                
Tests sensitivity of people's predictions to object physical attributes
        
Some blocks were heavy, others were light. This was indicated by the color.
        
Also, created pairs of items where the attributes of the blocks were switched.
                  
Approximations: Based on matching the variance, it seems people used rougly 3-7 stochastic simulation samples per trial
- suggests that people may not need that many samples
                  
Discussion:
                
Consistent with other recent propals that intuitive physical judgements can be viewed as prob. Newtonian mechanics
+ but here, they focus on 3D scenes with objects
        
Much of recent computer vision is based on model-free, data-driven approahes
+ unclear how such models could interface with rich language, reasoning, imagination, planning etc.
+ IPE does not require substantial task-specific learning
        
Future directions
- more inverse models, that can infer mass or friction
- dynamics of other entities, like nonrigid objects and fluids
        
PRobabilistc simulation offers a way to integrate symbolic reasoning and statistical inference - two clasically competing approaches},
author = {Battaglia, P. W. and Hamrick, J. B. and Tenenbaum, J. B.},
doi = {10.1073/pnas.1306572110},
file = {:Users/Brenden/Documents/Mendeley/Battaglia, Hamrick, Tenenbaum - 2013 - Simulation as an engine of physical scene understanding.pdf:pdf;:Users/Brenden/Documents/Mendeley/Battaglia, Hamrick, Tenenbaum - 2013 - Simulation as an engine of physical scene understanding(2).pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = oct,
title = {{Simulation as an engine of physical scene understanding}},
volume = {2013},
year = {2013}
}
@article{Battig1969,
annote = {Well-known set of category production norms. There is a strong correlation between frequency of mentioning and item and the order in which it is mentioned.
        
-------
- You get the name of a category, and write down as many examples as you can think of
        
Collected
1) For each item, the total frequence of occurence of the item in the category for the sample of 442 Ss
2) Also, the number of times each response was given first in the response sequence (parens to the right of the total frequency)
3) 4th and final column give the mean rank position (R) of the respone in the response sequence of each S
        
There is a correlation of about .5-.8 for the frequency of response and rank in the order. Part of the variability seems to be due to reliability in the two independent frequency samples.},
author = {Battig, William F and Montague, William E},
file = {:Users/Brenden/Documents/Mendeley/Battig, Montague - 1969 - Category norms for verbal items in 56 categories A replication and extension of the Connecticut category norms.pdf:pdf},
journal = {Jounral of Experimental Psychology Monograph},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {3},
title = {{Category norms for verbal items in 56 categories: A replication and extension of the Connecticut category norms}},
volume = {80},
year = {1969}
}
@article{Bavelier2012,
annote = {Action videogames bear little resemblance to many of the lab tasks that it improves performance on. How does it enhance such a varied set of skills?

        
Video games may help with "learning to learn", or quickly figuring out statistics and decision rules in a new task

        
------
People have tremendous capacity to learn, but learning is often quite task specific
- this is usually a curse

        
More general learning comes ffrom:
- aerobic activitiy
- atheltic training
- music
- working memory training
- video games

        
Maybe video games help with "learning to learn"
- not improvement in ability, but ability to improve faster

        
Action video games have relatively broad transfer

        
          
vision
        
- better ability to ignore distractors, where VGPs can tolerate them being closer (better spatial resolution)
-and not specific to retinal location, like most aspects of perceptual learning
-helps with backward masking, but not forward masking, where only backwards masking is thought to be related to attentional bottlenecks
- seems to improve many aspects of vision

        
cognitive functions
- better task switching
- better mental rotation
- better spatial cognition
(interesting, because these spatial skills are usually correalted with math achievement)

        
Decision making:
- where participants terminate the display at their own pace -- influences information accumulation?
- answer about 20% faster than other participants
- surgeons that are gamers can execute faster and with the same or higher accuracy

        
Reaction time and speed-accuracy tradeoff
- like needing to break while driving
- over 80 studies in a meta-analysis, gamers were on average 12% faster
- multiplcative relationship, not additive, so it is probably not a postdecisional factor

        
Attention
- better at top-down attentional tasks, but no difference in bottom-up tasks

        
Causality
- critical, since their interest is in learning rather than identifying good individuals
- trained on action video games vs. non-action video games
- controls for test/retest and intervention
- participants come to the lab to play 1-2 h per day for 2-10 weeks
+ 10, 30, or 50 h used in work
- 24 hours elapsed between training and ne test
- many different causal results

        
          
Learning to learn
        
Why do games produces these results? What is the common mechansim?
- learning to learn?
- if they have a stronger statistical signal, which of course might be learned, they might be better at "learning" in general
- why do we know that they "learned" more? What dose that mean? better prior, more accurate likelihood?

        
Allocating attention
- pro soccer places can kepp track of all players on both teams, rather than just some
- evidence that resource allocation comes to guide learing abilities, where video-games improve top-down attentiona allocatio

        
Knowledge
- transfer through hierarchy, is one mechanism

        
SVMs are not an appropriate modle of classification, since they must be retrained with new data

        
Learning algorithms
- deep learning: instantiating the "one algorithm" idea

        
Possible attentional mechanisms
- enhanced attentinon : better multi-object tracking and lessens attentional blink
- divided attention: 
- sustatined attention
- resource allocation
+ better at overriding bottom-up targets

        
in brain imaging, VGPs showed little activation in a frontopariet network, showing automatic resource allocation

        
          
discussion

        
        
learning to learn accounts for a wide range of skill enhancements, but only to the extent that new tasks share structure with video games},
author = {Bavelier, Daphne and Green, C S and Pouget, Alexandre and Schrater, Paul},
doi = {10.1146/annurev-neuro-060909},
file = {:Users/Brenden/Documents/Mendeley/Bavelier et al. - 2012 - Brain Plasticity Through the Life Span Learning to Learn and Action Video Games.pdf:pdf},
journal = {Annual Review of Neuroscience},
keywords = {cognitive control,cognitive training,generalization,hierarchy,knowledge,learning rules,probabilistic inference,resource allocation,transfer},
mendeley-tags = {cognitive training},
pages = {391--416},
title = {{Brain Plasticity Through the Life Span: Learning to Learn and Action Video Games}},
volume = {35},
year = {2012}
}
@inproceedings{Bechtel2012,
annote = {Diagrams figure centrally in the reasoning processes of scientists
        
Diagrams are important way to represent and reason about mechanisms in science
        
Focus on diagrams on chronobioogy -- circadian rythms
        
Visualizing the statics, over a number of days, it'es easy to see the structure across time (actograms)
        
Sometime's it's useful to show 48 hours (two 24 hours blocks side-to-side), while also repeating the same information downward. Then you can see shift
                  
phase response curves        
        
You have to learn to understand the diagram.
      },
author = {Bechtel, William and Abrahamsen, Adele},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Bechtel, Abrahamsen - 2012 - Diagramming Phenomena for Mechanistic Explanation.pdf:pdf},
title = {{Diagramming Phenomena for Mechanistic Explanation}},
year = {2012}
}
@article{Bedny2011,
abstract = {Humans are thought to have evolved brain regions in the left frontal and temporal cortex that are uniquely capable of language processing. However, congenitally blind individuals also activate the visual cortex in some verbal tasks. We provide evidence that this visual cortex activity in fact reflects language processing. We find that in congenitally blind individuals, the left visual cortex behaves similarly to classic language regions: (i) BOLD signal is higher during sentence comprehension than during linguistically degraded control conditions that are more difficult; (ii) BOLD signal is modulated by phonological information, lexical semantic information, and sentence-level combinatorial structure; and (iii) functional connectivity with language regions in the left prefrontal cortex and thalamus are increased relative to sighted individuals. We conclude that brain regions that are thought to have evolved for vision can take on language processing as a result of early experience. Innate microcircuit properties are not necessary for a brain region to become involved in language processing.},
author = {Bedny, Marina and Pascual-Leone, Alvaro and Dodell-Feder, David and Fedorenko, Evelina and Saxe, Rebecca},
doi = {10.1073/pnas.1014818108},
file = {:Users/Brenden/Documents/Mendeley/Bedny et al. - 2011 - Language processing in the occipital cortex of congenitally blind adults.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Adult,Behavior,Blindness,Blindness: congenital,Blindness: physiopathology,Female,Humans,Language,Magnetic Resonance Imaging,Male,Middle Aged,Models,Neurological,Occipital Lobe,Occipital Lobe: physiopathology,Photic Stimulation,Rest,Rest: physiology,Visually Impaired Persons},
month = mar,
number = {11},
pages = {4429--34},
pmid = {21368161},
title = {{Language processing in the occipital cortex of congenitally blind adults.}},
volume = {108},
year = {2011}
}
@article{Beer2000,
abstract = {Dynamical ideas are beginning to have a major impact on cognitive science, from foundational debates to daily practice. In this article, I review three contrasting examples of work in this area that address the lexical and grammatical structure of language, Piaget's classic 'A-not-B' error, and active categorical perception in an embodied, situated agent. From these three examples, I then attempt to articulate the major differences between dynamical approaches and more traditional symbolic and connectionist approaches. Although the three models reviewed here vary considerably in their details, they share a focus on the unfolding trajectory of a system's state and the internal and external forces that shape this trajectory, rather than the representational content of its constituent states or the underlying physical mechanisms that instantiate the dynamics. In some work, this dynamical viewpoint is augmented with a situated and embodied perspective on cognition, forming a promising unified theoretical framework for cognitive science broadly construed.},
annote = {Dynamical approach: focusing on intenral and external forces that shape an unfolding trajectory of a system, rather than the representational content.
        
The more sophisticated the use of internal state to mediate perception and action, the more cognitive behavior emerges from the dynamics of situated action
        
----
        
Until recently, there is one game in town: cognition as computation, the formal manipulation of symbols
                  
Example 1: lexical and grammatical struture of language
                
Usually the strongest argument against non-symbolic approaches to cognition. 
        
But Elman's networks show how you don't necessarily need a symbolic representaiton, to capture the notion of noun/verb/etc. and animate/inanimate
        
The same word has a different representation, depending on the context. So it can capture grammatical constraints.
        
performance degres on deep center-embedded sentences
        
        Dynamical systems concepts:        
vector field: instantaneous direction and magnitude from each state
solution trajectory: the sequence of actions
        
limit set: dynamics keep the state in a certain place
+ equilbirum point: single place with constant behavior
+ limit cycle: trajectory that closes on itself, producing an endless rhythmic behavior
        
For some equilibrium poits, small perturbations keep it there, but for others (unstable) this is not the case. Saddle limits are only stable from a certain direction.
                  
Example 2: the A-not-B error
                
An object is hidden in contained A many times. But if it is hidden in B, in full view of the infant and a short delay is imposed, the majority of 7-12 month olds infants will attempt to retrieve the object from container A
        
Piaget: immature concpt of object permanence
        
But lots of weird effects turn this on/off, like wanting the object more, the color of the containers, etc.
        
Dynamic field model, where visual input, recent memory, etc. influence direction of reaching. The model suggests it is an immature motor system, not an immature model of object permanence.
        
If the resting level of the system is low, it can't maintain the specific visual input. Otherwise, it can.
        
It also makes novel predictions, that you can also get the effect in older children with various manipulations
                  
Experiment 3: Robot catching objects
                
Used a recurrent neural network in a robot, with a coarse light sensor that can detect the shape of falling objects. 
        
Trained to catch circles, but avoid squares. It produces a categorical percption curve, when shown a range of intermediate objects.
        
There is a finally tuned relationship between the sensory input and the internal state, that needs to be jointly modeled
                  
Conclusion
                
Most connectionist simulations focus on the architecture, the learning algorith, and distributed representations
        
By contrast, dynamicla models are expressed as a set of differentail equations, that express how the system's state changes over time
        
dynamic approach: the more sophiistciated the use of internal state to mediate perception and action, the more cognitive bheavior emerges from the dynamics of situated action},
author = {Beer, Rd},
file = {:Users/Brenden/Documents/Mendeley/Beer - 2000 - Dynamical approaches to cognitive science.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
month = mar,
number = {3},
pages = {91--99},
pmid = {10689343},
title = {{Dynamical approaches to cognitive science}},
volume = {4},
year = {2000}
}
@article{Bell1997,
abstract = {It has previously been suggested that neurons with line and edge selectivities found in primary visual cortex of cats and monkeys form a sparse, distributed representation of natural scenes, and it has been reasoned that such responses should emerge from an unsupervised learning algorithm that attempts to find a factorial code of independent visual features. We show here that a new unsupervised learning algorithm based on information maximization, a nonlinear "infomax" network, when applied to an ensemble of natural scenes produces sets of visual filters that are localized and oriented. Some of these filters are Gabor-like and resemble those produced by the sparseness-maximization network. In addition, the outputs of these filters are as independent as possible, since this infomax network performs Independent Components Analysis or ICA, for sparse (super-gaussian) component distributions. We compare the resulting ICA filters and their associated basis functions, with other decorrelating filters produced by Principal Components Analysis (PCA) and zero-phase whitening filters (ZCA). The ICA filters have more sparsely distributed (kurtotic) outputs on natural scenes. They also resemble the receptive fields of simple cells in visual cortex, which suggests that these neurons form a natural, information-theoretic coordinate system for natural images.},
author = {Bell, a J and Sejnowski, T J},
file = {:Users/Brenden/Documents/Mendeley/Bell, Sejnowski - 1997 - The independent components of natural scenes are edge filters.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Algorithms,Animals,Contrast Sensitivity,Contrast Sensitivity: physiology,Humans,Models,Psychological,Visual Perception,Visual Perception: physiology},
month = dec,
number = {23},
pages = {3327--38},
pmid = {9425547},
title = {{The "independent components" of natural scenes are edge filters.}},
volume = {37},
year = {1997}
}
@article{Bell1995,
abstract = {We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in "blind" signal processing.},
annote = {convergence of unsupervised learning work and methods for separating out independent sources (blind separation)

        
Independent Component Analysis (ICA), a network that solves a blind separation task

        
Basic problem: how to maximize mutual information that an output Y has with its input X

        
I(X,Y) = H(Y) - H(Y|X)

        
maximizing mutual information is the same as maximizing the entropy of Y, since H(Y|X) doesn't depend on weights

        
can use continouous definition of entropy, and it is well behaved sine we just take derivative

        
gradient descent
pushes the linear part of the curve towards the the peak of the Gaussian distribution},
author = {Bell, a J and Sejnowski, T J},
file = {:Users/Brenden/Documents/Mendeley/Bell, Sejnowski - 1995 - An information-maximization approach to blind separation and blind deconvolution.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Humans,Learning,Models,Neural Networks (Computer),Neurons,Probability,Problem Solving,Speech,Statistical,classic AI,sparsity},
mendeley-tags = {classic AI,sparsity},
month = nov,
number = {6},
pages = {1129--59},
pmid = {7584893},
title = {{An information-maximization approach to blind separation and blind deconvolution.}},
volume = {7},
year = {1995}
}
@article{Bengio1995,
abstract = {We introduce a new approach for on-line recognition of handwritten words written in unconstrained mixed style. The preprocessor performs a word-level normalization by fitting a model of the word structure using the EM algorithm. Words are then coded into low resolution "annotated images" where each pixel contains information about trajectory direction and curvature. The recognizer is a convolution network that can be spatially replicated. From the network output, a hidden Markov model produces word scores. The entire system is globally trained to minimize word-level errors.},
annote = {Basic approach
1) Take pixel image, and annotate pixels with direction and curvature information. Working in the time domain is sensitive to stroke order, and other "irrelevant factors"
2) Classify with convolutional net
3) HMM on top, to take advatnage of context and linguistic structure to segment the characters within words
        
The entire system is globally trained to minimize word-level errors},
author = {Bengio, Y and LeCun, Y and Nohl, C and Burges, C},
file = {:Users/Brenden/Documents/Mendeley/Bengio et al. - 1995 - LeRec a NNHMM hybrid for on-line handwriting recognition.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Algorithms,Automated,Handwriting,Humans,Markov Chains,Neural Networks (Computer),Pattern Recognition,Reproducibility of Results,handwriting},
mendeley-tags = {handwriting},
month = nov,
number = {6},
pages = {1289--303},
pmid = {7584903},
title = {{LeRec: a NN/HMM hybrid for on-line handwriting recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7584903},
volume = {7},
year = {1995}
}
@article{Bergelson2012,
abstract = {It is widely accepted that infants begin learning their native language not by learning words, but by discovering features of the speech signal: consonants, vowels, and combinations of these sounds. Learning to understand words, as opposed to just perceiving their sounds, is said to come later, between 9 and 15 mo of age, when infants develop a capacity for interpreting others' goals and intentions. Here, we demonstrate that this consensus about the developmental sequence of human language learning is flawed: in fact, infants already know the meanings of several common words from the age of 6 mo onward. We presented 6- to 9-mo-old infants with sets of pictures to view while their parent named a picture in each set. Over this entire age range, infants directed their gaze to the named pictures, indicating their understanding of spoken words. Because the words were not trained in the laboratory, the results show that even young infants learn ordinary words through daily experience with language. This surprising accomplishment indicates that, contrary to prevailing beliefs, either infants can already grasp the referential intentions of adults at 6 mo or infants can learn words before this ability emerges. The precocious discovery of word meanings suggests a perspective in which learning vocabulary and learning the sound structure of spoken language go hand in hand as language acquisition begins.},
annote = {Most think that words can't be acquired until after a development of intention, around 9-12 months. Otherwise it's just too hard to learn words.
        
Contrary to this view, infants seem to learn words around 6 months.They simply used a looking time procedure, with two objects, and the parents named one. 
        
 But there is no positive correlation between age in 6-9 month range and ability.
        
There is a large discontinuity, between looking time up to 14 months and after 14 months
        
Is this some untapped mechanism in younger children? Are they just fussier? Do 14 month olds understand syntax?},
author = {Bergelson, Elika and Swingley, Daniel},
doi = {10.1073/pnas.1113380109},
file = {:Users/Brenden/Documents/Mendeley/Bergelson, Swingley - 2012 - At 6-9 months, human infants know the meanings of many common nouns.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
month = feb,
number = {9},
pages = {3253--8},
pmid = {22331874},
title = {{At 6-9 months, human infants know the meanings of many common nouns.}},
volume = {109},
year = {2012}
}
@inproceedings{Bergevin1992,
author = {Bergevin, Robert and Levine, Martin D},
booktitle = {CVGIP: Image Understanding},
file = {:Users/Brenden/Documents/Mendeley/Bergevin, Levine - 1992 - Part Decomposition of Objects from Single View Line Drawings.pdf:pdf},
number = {1},
pages = {73--83},
title = {{Part Decomposition of Objects from Single View Line Drawings}},
volume = {55},
year = {1992}
}
@article{Berkes2011,
abstract = {The brain maintains internal models of its environment to interpret sensory inputs and to prepare actions. Although behavioral studies have demonstrated that these internal models are optimally adapted to the statistics of the environment, the neural underpinning of this adaptation is unknown. Using a Bayesian model of sensory cortical processing, we related stimulus-evoked and spontaneous neural activities to inferences and prior expectations in an internal model and predicted that they should match if the model is statistically optimal. To test this prediction, we analyzed visual cortical activity of awake ferrets during development. Similarity between spontaneous and evoked activities increased with age and was specific to responses evoked by natural scenes. This demonstrates the progressive adaptation of internal models to the statistics of natural stimuli at the neural level.},
author = {Berkes, Pietro and Orb\'{a}n, Gergo and Lengyel, M\'{a}t\'{e} and Fiser, J\'{o}zsef},
doi = {10.1126/science.1195870},
file = {:Users/Brenden/Documents/Mendeley/Berkes et al. - 2010 - Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment.pdf:pdf},
issn = {1095-9203},
journal = {Science},
keywords = {Action Potentials,Adaptation,Aging,Animals,Bayes Theorem,Bayesian perception,Darkness,Electrodes,Evoked Potentials,Ferrets,Implanted,Models,Neurological,Neurons,Neurons: physiology,Photic Stimulation,Physiological,Visual,Visual Cortex,Visual Cortex: growth & development,Visual Cortex: physiology,Visual Perception},
mendeley-tags = {Bayesian perception},
month = jan,
number = {6013},
pages = {83--7},
pmid = {21212356},
title = {{Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment.}},
volume = {331},
year = {2010}
}
@inproceedings{Berndt1994,
abstract = {Knowledge discovery in databases presents many interesting challenges within the context of providing computer tools for exploring large data archives. Electronic data repositories are growing qulckiy and contain data from commercial, scientific, and other domains. Much of this data is inherently temporal, such as stock prices or NASA telemetry data. Detecting patterns in such data streams or time series is an important knowledge discovery task. This paper describes some primary experiments with a dynamic programming approach to the problem. The pattern detection algorithm is based on the dynamic time warping technique used in the speech recognition field. Keywords: dynamic programming, dynamic time warping, knowledge discovery, pattern analysis, time series.},
author = {Berndt, D and Clifford, J},
booktitle = {AAAI-94 Workshop on Knowledge Discovery and Databases},
file = {:Users/Brenden/Documents/Mendeley/Berndt, Clifford - 1994 - Using dynamic time warping to find patterns in time series.pdf:pdf},
keywords = {dynamic programming,dynamic time warping,handwriting,knowledge discovery,pat,tern analysis,time series},
mendeley-tags = {handwriting},
organization = {AAAI Techinical Report},
pages = {359--370},
title = {{Using dynamic time warping to find patterns in time series}},
url = {http://www.mendeley.com/research/using-dynamic-time-warping-to-find-patterns-in-time-series/},
year = {1994}
}
@article{Biederman1987,
annote = {To read:
Tversky and Hemenway, 1984
Ballard and Brown, 1982
Witkin and Tenenbaum, 1983
        
        
Like in speech, our impressive recognition ability comes from the free combination of primitives, called geons.
        
Biederman defines 6 attributes of geons, which vary to create 36 geons.
        
Relevance to 1-shot learning: This is not a learning theory. Thus, when you see an object for the first time or the 100th, you get the same structural descirption, in terms of geons. This can lead to rapid learning.
        
Predicts the same similarity function combines multiple views, and multiple examples of a concept, together.
        
Experiments:          
geons are necessary and sufficient        
1) Accurate recognition from just a few geons, and the lack of advantage for color photos over bare geons, show sufficiency
2) Recognition fails when geons aren't recoverable, by deleting the non-accidental properties of line drawings. Thus shows necessariy
        
        
---
        
Human object recognition is highly impressive
- we can perceive objects from an infinite number  of viewpoints, under occlusion, etc.
- in addition, the RBC theory can recognize new objects, not just the familiar ones. It doesn't matter if you have seen the object once or hundreds of times
        
analogy to speech:
- only 55 phones are needed to represent all words in all languages
- only need qualitative judgements of their properties to pick the best parts
        
theory goal: basic level categorization of objects
criteria:
1) no need for careful, quantitative judgements. These take a long time
2) orientation invariacne
3) partial matches are allowed
                  
stages of processing
- line drawing description
- parse at deep concavities
- identification of the components
- match components to object representation
        
also, relations (as in structural description) are curical
        
nonaccidential properties
- collinearity (finding a straight line), curves, symmetry, 
- coterminatin (T, Y junctions, etc.)
Each readily preceivable, and also a cue to the relevant geons
                  
geons
- constant cross-section of a cone produces parallel lines
- changing cross-section produces junctions          
non-accidental properties distinguish geons        
- 6 attributes varied make a total of 36 geons
        
additional types of variation
- how do you represent the asymmetries?
- early termination, metric judgments, etc.
        
gestalt principes indicate good parts, not whole objects
        
Marr and Nishihara: pipe cleaner represntation might work for animals, but not in general (tables might look like animals in this representation)
        
memory regularization bias provided by geons -- you don't remember the details of the objects, just the struture?
        
Biederman estimates we can discern about 30K objects
- this would reuiqre children to learn about 13.5 a day
- they are not learned independently!
- combinatorial pattern of geons variables exceeds this 30K number
+ sparesly populated space promotes easy recognition
                  
Empirical support
                
the theory predicts that we can easily identify objects from their geons
        
Exp 1) can you recognize an object from just the most important geons?
- vary the # of geons
- vary object complexity
- 100 ms exposures, ask particpants to name the object
        
results
-very high accuracy from few geons
- complex objects have lower RT when complete than simple objects
+ this isn't predicted by many other theories (I think)
                  
line drawings vs. colored photos        
- similar recognition performance
- little advantage for color
but luminance gradient can be helpful, giving shape cues to the geons
                  
degraded objects        
-deleting non-accidental properties sould kill performance (if geons cannot be recovered)
- stimuli where same amount of line is deleted, but either the geons are recoverable or they are not
        
event with strong object familiarization, recognition is very hard with non-accidental properties removed (50%+ error)
        
also varied parametically amount of deletion at vertices of mid-segment
- performance does get better with longer duration
(1 sec) presentation
        
compare component vs. midsegment completion
- midsegment (b.c. of filling in process) varies with exposure duration while deletion less so
                  
summary        
- sufficiency of geons: partial objects and no photo advantage
- necessary: contour deletion studies suggest underlying principle of recognition
                  
discussion
- accuracy changes across orientation may relate to perceivability of geons
- geons tie multiple viewpoints together
- also ties different exemplar together
                  
strong prediction: it would be the same similarity function, for viewpoints and exemplars
        
relation to the basic level: names for objects with different geons?
        
Tversky style imilarity measure with same/different components?
                  
conclusion        
like speech, our impressive ability is due to teh free combination of primitives},
author = {Biederman, I},
file = {:Users/Brenden/Documents/Mendeley/Biederman - 1987 - Recognition-by-components a theory of human image understanding.pdf:pdf},
issn = {0033-295X},
journal = {Psychological Review},
keywords = {Attention,Concept Formation,Discrimination Learning,Form Perception,Humans,Orientation,Pattern Recognition,Visual},
number = {2},
pages = {115--47},
pmid = {3575582},
title = {{Recognition-by-components: a theory of human image understanding.}},
volume = {94},
year = {1987}
}
@article{Biederman1999,
abstract = {Humans often evidence little difficulty at recognizing objects from arbitrary orientations in depth. According to one class of theories, this competence is based on generalization from templates specified by metric properties (MPs), that were learned for the various orientations. An alternative class of theories assumes that non-accidental properties (NAPs) might be exploited so that even novel objects can be recognized under depth rotation. After scaling MP and NAP differences so that they were equally detectable when the objects were at the same orientation in depth, the present investigation assessed the effects of rotation on same-different judgments for matching novel objects. Judgments of a sequential pair of images of novel objects, when rendered from different viewpoints, revealed relatively low costs when the objects differed in a NAP of a single part, i.e. a geon. However, rotation dramatically reduced the detectability of MP differences to a level well below that expected by chance. NAPs offer a striking advantage over MPs for object classification and are therefore more likely to play a central role in the representation of objects.},
annote = {People can recognize new objects in new orientaitnos, but are only accurate when they can exploit non-accidental properties (like those that arise from geons)
        
=-----
How do people recognize objects in novel orientations in depth?
        
Two theories:
- storage of 2D template views, and comparison on metric properties (MPs)
- 3D model with geons, and attention to non-accidentail properties (NPs)
        
Evidence for MPs:
- increase in RT as the orientaiton difference increased
- BUT the effects disappear when there is no prior experience wiht the objets
        
Do NPs have special status, or are they just like any other metric property?
                  
Experiment
                
Participants had to decide if two sequentially presented objects were the same or different... where difference ones changed by one NP or MP          
                
- one-shot: no prior experience was given with the object
        
Created 12 objects, where they varied either a metric property of changed a geon (NP)
- produced to be of "approximately equal salience" --
BUT this is not true for me.. the geon change is much more obvious
                  
Design
                
1) subjects tried to detect whether two objects were the same or different, with no orientation change
2) same task, but there was always an orientation change
        
to reduce habituation to the mask, 4 different ones were used
                  
Results
                
Error and RT wer enot very different between MP and NAP differences in the unrotated condition
        
However, MP differences were very hard to detect in the rotation condition
                  
Experiment 2 - mixed blocks
                
Stimuli could change rotaiton every trial, or could not
        
This is a better approxmation to realistic scenarios
        
However, this data looks a bit messier than the originla task
        
Also, the equivalence scaling fell apart, where MPs were much harder to detect
                  
Discussion
                
People are very good at recognizing novel objects in new viewpoints, even from one example
        
previous reports that suggest this was difficult used bent paperclips andother objects that don't have good geon descriptions
        
It is not that there is no ruole for learning, but for many objects the generalization is quite natural without it},
author = {Biederman, I and Bar, M},
file = {:Users/Brenden/Documents/Mendeley/Biederman, Bar - 1999 - One-shot viewpoint invariance in matching novel objects.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adolescent,Adult,Depth Perception,Depth Perception: physiology,Form Perception,Form Perception: physiology,Humans,Judgment,Reaction Time,Rotation,one-shot learning,part-based models},
mendeley-tags = {one-shot learning,part-based models},
month = aug,
number = {17},
pages = {2885--99},
pmid = {10492817},
title = {{One-shot viewpoint invariance in matching novel objects.}},
volume = {39},
year = {1999}
}
@article{Blanco2013,
abstract = {What effect does labeling an object as a member of a familiar category have on memory for that object? Recent studies suggest that recognition memory can be negatively impacted by categorizing objects during encoding. This paper examines the "representational shift hypothesis" which argues that categorizing an object impairs recognition memory by altering the trace of the encoded memory to be more similar to the category prototype. Previous evidence for this idea comes from experiments in which a basic-level category labeling task was compared to a non-category labeling incidental encoding task, usually a preference judgment (e.g., "Do you like this item?"). In two experiments, we examine alternative tasks that attempt to control for processing demands and the degree to which category information is explicitly recruited at the time of study. Contrary to the predictions of the representational shift hypothesis, we find no evidence that memory is selectively impaired by category labeling. Overall, the pattern of results across both studies appears consistent with well-established variables known to influence memory such as encoding specificity and distinctiveness effects.},
annote = {Does labeling an item, rather than saying whether you like it, hurt your recognition memory?
        
Lupyan: either preference judgment or basic-level categorizatoin. Found lower recognition memory for labeled items. "representational shift"
        
Or, are preference judgements just lead to better memory than other tasks?
                  
Experiment 1        
        
task requires judging objects oreientation, which isn't a label and avoid emotional processing of preference
        
Conditions:
- orientation judgement
- preference judgement
- label judgement
        
Testing:
recognition of previous images
        
Found that label and orientaiton produced similar discrmination, which was worse than label
                  
Experiment 2:        
- Luypan: asked for typicality ratings. and RT is largest aroudn 4 out of 5 on the scale. This had the lowest hit-rate for memory, which he took to indicate it had the most top-down category effect -- since you spent the most time processing it.
        
But same pattern for preference judgmenets
        
Also, could ahve been a distinctiveness effect, since extreme items are rarest},
author = {Blanco, Nathaniel and Gureckis, Todd},
doi = {10.1007/s10339-012-0530-4},
file = {:Users/Brenden/Documents/Mendeley/Blanco, Gureckis - 2013 - Does category labeling lead to forgetting.pdf:pdf},
issn = {1612-4790},
journal = {Cognitive processing},
keywords = {Adult,Concept Formation,Concept Formation: physiology,Female,Humans,Male,Memory,Memory: physiology,Neuropsychological Tests,Pattern Recognition,Recognition (Psychology),Recognition (Psychology): physiology,Space Perception,Space Perception: physiology,Visual,Visual Perception,Visual Perception: physiology,Visual: physiology,Young Adult},
month = mar,
number = {1},
pages = {73--9},
pmid = {23064883},
title = {{Does category labeling lead to forgetting?}},
volume = {14},
year = {2013}
}
@inproceedings{Blei2004,
author = {Blei, David M and Jordan, Michael I and Griffiths, Thomas L and Tenenbaum, Joshua B},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:Users/Brenden/Documents/Mendeley/Blei et al. - 2004 - Hierarchical Topic Models and the Nested Chinese Restaurant Process.pdf:pdf},
title = {{Hierarchical Topic Models and the Nested Chinese Restaurant Process}},
year = {2004}
}
@article{Blei2003,
abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
author = {Blei, David M and Ng, Andrew Y and Jordan, Michael I},
chapter = {993},
doi = {10.1162/jmlr.2003.3.4-5.993},
editor = {Lafferty, John},
file = {:Users/Brenden/Documents/Mendeley/Blei, Ng, Jordan - 2003 - Latent Dirichlet Allocation.pdf:pdf},
institution = {University of California},
issn = {15324435},
journal = {Journal of Machine Learning Research},
number = {4-5},
pages = {993--1022},
publisher = {JMLR. org},
title = {{Latent Dirichlet Allocation}},
volume = {3},
year = {2003}
}
@book{Bloom2000,
address = {Cambridge, MA},
annote = {Word learning is not a specialized system, but instead it builds off of abilities that exist for other purposes. There are three main systems:
        
1) Conceptual resources, like fast mapping and mutual exclusitivity
2) Theory of mind
3) Language resources like syntax
        
Thus, while it will be complex to fully understand word learning, it will tell us a lot about the mind in general.
        
Chapter 1: First words
Word learning is not as simple as it appears.
-- Quine's Gavagai problem
-- Figuring out what extensions are possible
-- Segmentation of speech sounds, syntax
-- How do you do generalization?
        
People know between 60,000 and 80,000 words. Children learn about 10 new words a day until the end of high school.
        
Main thesis: Word are learned through abilities that exist for other purposes.
        
This is at odds with a constraint based view (Markman, Clark, etc.)
        
The rich mental life of humans is the foundation of word learning, it is not the product of it.},
author = {Bloom, P},
keywords = {fast mapping,word learning},
mendeley-tags = {fast mapping,word learning},
publisher = {MIT Press},
title = {{How Children Learn the Meanings of Words}},
year = {2000}
}
@article{Blough2013,
author = {Blough, Donald S},
file = {:Users/Brenden/Documents/Mendeley/Blough - 1982 - Pigeon Perception of Letters of the Alphabet.pdf:pdf},
journal = {Science},
number = {4570},
pages = {397--398},
title = {{Pigeon Perception of Letters of the Alphabet}},
volume = {218},
year = {1982}
}
@inproceedings{Blundell2013,
annote = {stochastic block model: tries to recover blocks of an adjacency matrix

        
- can have greedy hierarchical clustering model as well, but not probabilistic

        
- infinitie relationalmodel (IRM): infers flat community structure

        
- current approache for learning hierarchies in the IRM or either inefficient or limited in various ways, including unable to learn general tree structures

        
stochasitc block model: relation between groups is defined as just an overall probability of having a relation
- different priors between/within clusters

        
phi: partition on vertices

        
in IRM, the CRP is used to define a prior on partitions

        
in their approach, they use a tree to define a prior on paritions, whree only partitions consistent with teh tree are included in the sum
- thus, each tree contributes multiple partitions at very levels of granulaity, even though each individual partition is not graded (rather, all or nothing)
- prior on partitions can be defined as a process that recurses down the tree, with a probability of stopping at each point

        
You need another procedure for searching over trees, which is done with agglomerative tree search (like with simple hierarchical clustering)
- there, you consider building up the dataset piece by piece, where you only include the block when desired

        
There are a few different types of merge options: see figure 2, where you can create a new node, or conjoin one tree as a subst of the other

        
Results: sampson's monastery, recovers something similar to ground truth observed groups

        
- predicts held-out links more accurately more quickly, but not necessarily in general},
author = {Blundell, Charles and Teh, Yee Whye},
booktitle = {Advances in Neural Information Processing Systems 26},
file = {:Users/Brenden/Documents/Mendeley/Blundell, Teh - 2013 - Bayesian Hierarchical Community Discovery.pdf:pdf},
keywords = {essentialism},
mendeley-tags = {essentialism},
title = {{Bayesian Hierarchical Community Discovery}},
url = {http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2013_5048.pdf},
year = {2013}
}
@article{Boccignone1993,
abstract = {It is generally agreed that the advantage of on-line character recognition methods with respect to off-line ones mostly relies on the availability of dynamic information. This mainly concerns the order in which the strokes forming characters have been drawn. In this paper we present and discuss a method which attempts, in the off-line case, to recover part of the lost script dynamics. The method makes it possible to reconstruct one of the most likely trajectories followed by the writer while drawing characters. It is based on a suitable implementation of good continuity criteria which take into account direction, length and width of the strokes making up characters. The algorithm either subdivides or unfolds the digital ribbon forming isolated characters as well as groups of connected characters, by solving the ambiguities which arise at every joint. Experimental results are reported and discussed.},
annote = {Previous approaches to handwriting consider it as a sequence of basic curve elements
        
On-line recognition is considered useful, due to order information},
author = {Boccignone, G},
doi = {10.1016/0031-3203(93)90168-V},
file = {:Users/Brenden/Documents/Mendeley/Boccignone - 1993 - Recovering dynamic information from static handwriting.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {dynamic information,handprint,handwriting,ocr,off-line recognition,program induction,skeleton shape fidelity,thinning},
mendeley-tags = {handwriting,program induction},
month = mar,
number = {3},
pages = {409--418},
title = {{Recovering dynamic information from static handwriting}},
volume = {26},
year = {1993}
}
@inproceedings{Bowden2004,
author = {Bowden, Richard and Windridge, David and Kadir, T and Zisserman, A and Brady, M},
booktitle = {Proceedings of the 8th European Conference on Computer Vision (ECCV04)},
file = {:Users/Brenden/Documents/Mendeley/Bowden et al. - 2004 - A Linguistic Feature Vector for the Visual Interpretation of Sign Language.pdf:pdf},
keywords = {one-shot learning,part-based models},
mendeley-tags = {one-shot learning,part-based models},
pages = {391--401},
title = {{A Linguistic Feature Vector for the Visual Interpretation of Sign Language}},
year = {2004}
}
@article{Bowers2009,
abstract = {A fundamental claim associated with parallel distributed processing (PDP) theories of cognition is that knowledge is coded in a distributed manner in mind and brain. This approach rejects the claim that knowledge is coded in a localist fashion, with words, objects, and simple concepts (e.g. "dog"), that is, coded with their own dedicated representations. One of the putative advantages of this approach is that the theories are biologically plausible. Indeed, advocates of the PDP approach often highlight the close parallels between distributed representations learned in connectionist models and neural coding in brain and often dismiss localist (grandmother cell) theories as biologically implausible. The author reviews a range a data that strongly challenge this claim and shows that localist models provide a better account of single-cell recording studies. The author also contrast local and alternative distributed coding schemes (sparse and coarse coding) and argues that common rejection of grandmother cell theories in neuroscience is due to a misunderstanding about how localist models behave. The author concludes that the localist representations embedded in theories of perception and cognition are consistent with neuroscience; biology only calls into question the distributed representations often learned in PDP models.},
annote = {What does it mean to be localist? You can interpret the meaning of a single unit, without the need to consult the others
(like a cat is present, etc.)
        
It does not mean other things must be localist, like the proposition "have a nice day"
- it is not the case that each thing has just one cell, it can be that multiple neruons represnt the same thing
        
Even weak activation of cells to other stimuli has been taken to falsify the grandmother hypothesis -- but why should this be the case?
        
dense distributed representations - many cells are active, and its hard to interpret any one
        
coarse coding -- cells respond to a range of stimuli, and a population can narrow on the specific response.
Also supports generalization
        
Hippocampus -- this is where the Jennifer Anstion and Halle Barry cells have been found. It also respond to the written word for Halle Berry. The authors of this study claimed that if there were grandmother cells, they never would have been found, so that can't be the explanation. This cell must also fire for 50-150 other people. But this is a flawed argument: there could also just be 50-150 neurons in the hippocampus that code for Jennifer Aniston.
        
---- 
Plaut and McClelland critique:
        
- the 50-150 argument is wrong
- the main problem: a theory of localist representation. When do you need an individua unit? Every time you encounter a tulip, etc.?
-- localist units should represent categories, but where do you stop in dividing into cateogires? There will be some distinction that is important that you don't capture
        
-- but can't we encode properties, relations, etc. separately?},
author = {Bowers, Jeffrey S},
doi = {10.1037/a0014462},
file = {:Users/Brenden/Documents/Mendeley/Bowers - 2009 - On the biological plausibility of grandmother cells implications for neural network theories in psychology and neuroscience.pdf:pdf;:Users/Brenden/Documents/Mendeley/Bowers - 2009 - On the biological plausibility of grandmother cells implications for neural network theories in psychology and neuroscience(2).pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Animals,Association Learning,Association Learning: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Cognition,Cognition: physiology,Concept Formation,Concept Formation: physiology,Face,Haplorhini,Humans,Mental Recall,Mental Recall: physiology,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurons,Neurons: physiology,Neurosciences,Pattern Recognition,Psychological Theory,Sensory Thresholds,Sensory Thresholds: physiology,Species Specificity,Visual,Visual: physiology,classic psychology,neural coding,neural networks},
mendeley-tags = {classic psychology,neural coding,neural networks},
month = jan,
number = {1},
pages = {220--51},
pmid = {19159155},
title = {{On the biological plausibility of grandmother cells: implications for neural network theories in psychology and neuroscience}},
volume = {116},
year = {2009}
}
@book{Boyd2004,
author = {Boyd, S and Vandenberghem, L},
publisher = {Cambridge University Press},
title = {{Convex Optimization}},
year = {2004}
}
@article{Boyden2005,
abstract = {Temporally precise, noninvasive control of activity in well-defined neuronal populations is a long-sought goal of systems neuroscience. We adapted for this purpose the naturally occurring algal protein Channelrhodopsin-2, a rapidly gated light-sensitive cation channel, by using lentiviral gene delivery in combination with high-speed optical switching to photostimulate mammalian neurons. We demonstrate reliable, millisecond-timescale control of neuronal spiking, as well as control of excitatory and inhibitory synaptic transmission. This technology allows the use of light to alter neural processing at the level of single spikes and synaptic events, yielding a widely applicable tool for neuroscientists and biomedical engineers.},
annote = {great to know:
- part list: list of kinds of neurons
- how cells are connected, what molecules they have
- want to perturb subsets of cells to test their function
                  
classifying cell types        
- patch clamping: breaking into cell, and applying suction
+ invivo recording from cells, sub-millisecond timescale recordsings
        
automatic patch clamping, with 70% accuracy
                  
optogenetics
                
expanding the class of molecules (channel rhodopsins) that change cell properties with light
+ some cause spikes
+ some prevent spikes
        
found new molecules that turn on/off with high temporal precision
+ also new colors
+ so that you have stimulate two different poplutions at different time scales, by two different colors of light
        
      },
author = {Boyden, Edward S and Zhang, Feng and Bamberg, Ernst and Nagel, Georg and Deisseroth, Karl},
doi = {10.1038/nn1525},
file = {:Users/Brenden/Documents/Mendeley/Boyden et al. - 2005 - Millisecond-timescale, genetically targeted optical control of neural activity.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Action Potentials: radiation effects,Algal Proteins,Algal Proteins: chemistry,Algal Proteins: genetics,Algal Proteins: metabolism,Animals,Cells,Cultured,Dose-Response Relationship,Electric Stimulation,Electric Stimulation: methods,Electrophysiology,Electrophysiology: methods,Excitatory Amino Acid Antagonists,Excitatory Amino Acid Antagonists: pharmacology,GABA Antagonists,GABA Antagonists: pharmacology,Green Fluorescent Proteins,Green Fluorescent Proteins: genetics,Green Fluorescent Proteins: metabolism,Hippocampus,Hippocampus: cytology,Ion Channel Gating,Ion Channel Gating: physiology,Ion Channels,Ion Channels: chemistry,Ion Channels: genetics,Ion Channels: metabolism,Neural Inhibition,Neural Inhibition: drug effects,Neural Inhibition: physiology,Neural Inhibition: radiation effects,Neurons,Neurons: physiology,Neurons: radiation effects,Newborn,Optics and Photonics,Photobiology,Photobiology: methods,Pyridazines,Pyridazines: pharmacology,Quinoxalines,Quinoxalines: pharmacology,Radiation,Rats,Reaction Time,Reaction Time: physiology,Reaction Time: radiation effects,Reproducibility of Results,Rhodopsin,Rhodopsin: chemistry,Rhodopsin: genetics,Rhodopsin: metabolism,Sprague-Dawley,Synaptic Transmission,Synaptic Transmission: physiology,Synaptic Transmission: radiation effects,Time Factors,Transfection},
month = sep,
number = {9},
pages = {1263--8},
pmid = {16116447},
title = {{Millisecond-timescale, genetically targeted optical control of neural activity.}},
volume = {8},
year = {2005}
}
@article{Brady2008,
abstract = {One of the major lessons of memory research has been that human memory is fallible, imprecise, and subject to interference. Thus, although observers can remember thousands of images, it is widely assumed that these memories lack detail. Contrary to this assumption, here we show that long-term memory is capable of storing a massive number of objects with details from the image. Participants viewed pictures of 2,500 objects over the course of 5.5 h. Afterward, they were shown pairs of images and indicated which of the two they had seen. The previously viewed item could be paired with either an object from a novel category, an object of the same basic-level category, or the same object in a different state or pose. Performance in each of these conditions was remarkably high (92%, 88%, and 87%, respectively), suggesting that participants successfully maintained detailed representations of thousands of images. These results have implications for cognitive models, in which capacity limitations impose a primary computational constraint (e.g., models of object recognition), and pose a challenge to neural models of memory storage and retrieval, which must be able to account for such a large and detailed storage capacity.},
annote = {memory for object details is much richer than most have thought

        
Estimates memory capacity by computing the number of bits needed to reach a certain level of performance, if items are assigned codes at random},
author = {Brady, Timothy F and Konkle, Talia and Alvarez, George a and Oliva, Aude},
doi = {10.1073/pnas.0803390105},
file = {:Users/Brenden/Documents/Mendeley/Brady et al. - 2008 - Visual long-term memory has a massive storage capacity for object details.pdf:pdf;:Users/Brenden/Documents/Mendeley/Brady et al. - 2008 - Visual long-term memory has a massive storage capacity for object details(2).pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Adult,Humans,Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,Recognition (Psychology),Recognition (Psychology): physiology,Time Factors,Visual,Visual: physiology},
month = sep,
number = {38},
pages = {14325--9},
pmid = {18787113},
title = {{Visual long-term memory has a massive storage capacity for object details.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2533687&tool=pmcentrez&rendertype=abstract},
volume = {105},
year = {2008}
}
@article{Brady2013,
abstract = {When remembering a real-world scene, people encode both detailed information about specific objects and higher order information like the overall gist of the scene. However, formal models of change detection, like those used to estimate visual working memory capacity, assume observers encode only a simple memory representation that includes no higher order structure and treats items independently from one another. We present a probabilistic model of change detection that attempts to bridge this gap by formalizing the role of perceptual organization and allowing for richer, more structured memory representations. Using either standard visual working memory displays or displays in which the items are purposefully arranged in patterns, we find that models that take into account perceptual grouping between items and the encoding of higher order summary information are necessary to account for human change detection performance. Considering the higher order structure of items in visual working memory will be critical for models to make useful predictions about observers' memory capacity and change detection abilities in simple displays as well as in more natural scenes.},
author = {Brady, Timothy F and Tenenbaum, Joshua B},
doi = {10.1037/a0030779},
file = {:Users/Brenden/Documents/Mendeley/Brady, Tenenbaum - 2013 - A probabilistic model of visual working memory Incorporating higher order regularities into working memory cap.pdf:pdf},
issn = {1939-1471},
journal = {Psychological review},
keywords = {change detection,hierarchical bayes,memory,visual short-term memory,working memory},
mendeley-tags = {memory},
month = jan,
number = {1},
pages = {85--109},
pmid = {23230888},
title = {{A probabilistic model of visual working memory: Incorporating higher order regularities into working memory capacity estimates.}},
volume = {120},
year = {2013}
}
@inproceedings{Braithwaite,
author = {Braithwaite, David W and Goldstone, Robert L},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (CogSci2012)},
file = {:Users/Brenden/Documents/Mendeley/Braithwaite, Goldstone - 2012 - Inducing Mathematical Concepts from Specific Examples The Role of Schema-Level Variation.pdf:pdf},
keywords = {analogy,comparison,instruction,mathematics,schemas,transfer},
number = {c},
pages = {138--143},
title = {{Inducing Mathematical Concepts from Specific Examples : The Role of Schema-Level Variation}},
year = {2012}
}
@electronic{Branson2004,
author = {Branson, K},
file = {:Users/Brenden/Documents/Mendeley/Branson - 2004 - A Practical Review of Uniform B-splines.pdf:pdf},
title = {{A Practical Review of Uniform B-splines}},
year = {2004}
}
@inproceedings{Briggs2006,
author = {Briggs, F and O'Neill, M},
booktitle = {Third Asian-Pacific workshop on Genetic Programming},
file = {:Users/Brenden/Documents/Mendeley/Briggs, O'Neill - 2006 - Functional Genetic Programming with Combinators.pdf:pdf},
keywords = {program induction},
mendeley-tags = {program induction},
pages = {110--127},
title = {{Functional Genetic Programming with Combinators}},
year = {2006}
}
@article{Broadbent1954,
abstract = {Found that spatially separated sources lead to more correct responses and also that apparent separation produced by stereophonic techniques produced the same results. In addition, it was found that spatially separated sounds may pass through the perceptual mechanism successively rather than simultaneously.},
annote = {If you present letter streams in two ears, people only report one well, and they lose the other
        
Led to the "filter" model of visual attention, where you only process some aspects of the physical stimulus
        
But if you are asked to attend to both ears, usually you write down all the numbers from one, then all from the other ear. This supports the idea that information can pass through the bottleneck only one at a time.},
author = {Broadbent, D. E.},
file = {:Users/Brenden/Documents/Mendeley/Broadbent - 1954 - The role of auditory localization in attention and memory span.pdf:pdf},
journal = {Journal of Experimental Psychology},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {3},
pages = {191--196},
title = {{The role of auditory localization in attention and memory span}},
volume = {47},
year = {1954}
}
@article{Browman1992,
abstract = {An overview of the basic ideas of articulatory phonology is presented, along with selected examples of phonological patterning for which the approach seems to provide a particularly insightful account. In articulatory phonology, the basic units of phonological contrast are gestures, which are also abstract characterizations of articulatory events, each with an intrinsic time or duration. Utterances are modeled as organized patterns (constellations) of gestures, in which gestural units may overlap in time. The phonological structures defined in this way provide a set of articulatorily based natural classes. Moreover, the patterns of overlapping organization can be used to specify important aspects of the phonological structure of particular languages, and to account, in a coherent and general way, for a variety of different types of phonological variation. Such variation includes allophonic variation and fluent speech alternations, as well as 'coarticulation' and speech errors. Finally, it is suggested that the gestural approach clarifies our understanding of phonological development, by positing that prelinguistic units of action are harnessed into (gestural) phonological structures through differentiation and coordination.},
author = {Browman, C P and Goldstein, L},
file = {:Users/Brenden/Documents/Mendeley/Browman, Goldstein - 1992 - Articulatory phonology an overview.pdf:pdf},
issn = {0031-8388},
journal = {Phonetica},
keywords = {Female,Humans,Male,Phonetics,Speech,Speech Production Measurement,Speech: physiology},
month = jan,
number = {3-4},
pages = {155--80},
pmid = {1488456},
title = {{Articulatory phonology: an overview.}},
volume = {49},
year = {1992}
}
@inproceedings{Brown2001,
author = {Brown, Andrew D and Hinton, Geoffrey E},
booktitle = {{Proceedings of Artificila Intelligence and Statistics}},
file = {:Users/Brenden/Documents/Mendeley/Brown, Hinton - 2001 - Products of Hidden Markov Models.pdf:pdf},
keywords = {classic AI},
mendeley-tags = {classic AI},
title = {{Products of Hidden Markov Models}},
year = {2001}
}
@inproceedings{Burl1998,
annote = {Early paper on deformable part models

        
objects: parts arranged in a deformable configuration

        
parts: image patches placed at particular positions

        
previous work: hard-detect parts from bottom-up features, and see which object fits the best

        
If the parat positions are not independent, it is much more difficult to build an optimla detector, assuming part are just image patches (with Gaussian white noise)
+ need to trade off the optimal part position (the configuration prior) with the optimal data response
+ uses approximation that only explots the shape of the configuraiton, an dnot translation, rotation, and scaling (which improves invariance)},
author = {Burl, Michael C and Weber, Markus and Perona, Pietro},
booktitle = {European Conference on Computer Vision},
file = {:Users/Brenden/Documents/Mendeley/Burl, Weber, Perona - 1998 - A Probabilistic Approach to Object Recognition Using Local Photometry and Global Geometry.pdf:pdf},
keywords = {part-based models},
mendeley-tags = {part-based models},
title = {{A Probabilistic Approach to Object Recognition Using Local Photometry and Global Geometry}},
year = {1998}
}
@inproceedings{Buzan2004,
author = {Buzan, Dan and Sclaroff, Stan and Kollios, George},
booktitle = {International Conference on Pattern Recognition},
file = {:Users/Brenden/Documents/Mendeley/Buzan, Sclaroff, Kollios - 2004 - Extraction and Clustering of Motion Trajectories in Video.pdf:pdf},
keywords = {handwriting},
mendeley-tags = {handwriting},
title = {{Extraction and Clustering of Motion Trajectories in Video}},
year = {2004}
}
@article{Cakmak2010,
annote = {When teaching robot, what type of interaction to people prefer?
        
- people preferred interactive models, where robot asked questions
        
active learning is evaluted in the reduction of number of training examples it needs, as opposed to passive learning
        
stimuli: objects are simple shape cut-outs of various colors, which the robot can detect
        
concepts are pairs of objects
        
Simon can ask you to replace either the top or bottom of a stimulus with another object
        
Once an objet is ain the area
1) the teacher can label it as positive or negative
2) or test Simon on the object
        
Simple logical conjunctive concepts are learned (like triangle on top of a house)
        
Best concept is the one that is most consistent with the data
                  
active learning:        
- select example with maximal disagreement between the different hypotheses
                  
Experiment:
                
Place object in from of robot, and say one of 3 things:
- this is an X
- this is not an X
- is htis an X?
        
Conitions:
- no queries
- query afte reah example
- query only after uniformative info.
- you can ask him "do you have any questions?"
        
Better learning in active conditions, from Robot's perspetive
        
in part, it is hard for teachers to keep track of how much of hte space they have covered -- so you want people to ask questions!
        
from humans' perspective, all of hte active situations were more enjoyable
        
It was easier to teach when Simon asked the most questions
        
Slight differences in preferences of conditions},
author = {Cakmak, Maya and Chao, Crystal and Thomaz, Andrea L},
doi = {10.1109/TAMD.2010.2051030},
file = {:Users/Brenden/Documents/Mendeley/Cakmak, Chao, Thomaz - 2010 - Designing Interactions for Robot Active Learners.pdf:pdf},
issn = {1943-0604},
journal = {IEEE Transactions on Autonomous Mental Development},
keywords = {active learning,learning from demonstration},
mendeley-tags = {active learning,learning from demonstration},
month = jun,
number = {2},
pages = {108--118},
title = {{Designing Interactions for Robot Active Learners}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5471105},
volume = {2},
year = {2010}
}
@article{Cakmak2010a,
annote = {Active learning with characters:
        
If it is a special case of semi-supervised learning, you have a set of unlabeled examples, presumably drawn from a mixture over characters. Then, you can just update the proper class, when queried for the label
        
If active learning involves two classes (or a class and a background), and you can draw an example at ask what it is, then you might update it based on posterior probability of labeled class
        
-----------
Active learning is needed for robots, because users have limited patience for training them
        
Skill learning, where we use Kernel regression to map staets to velocities, which define the next state
        
Types of queries:
        
Label queries
- learning requests a label for an instance
        
      },
author = {Cakmak, Maya and Thomaz, Andrea L and Atlanta, Atlantic},
file = {:Users/Brenden/Documents/Mendeley/Cakmak, Thomaz, Atlanta - 2010 - Active Learning with Mixed Query Types in Learning from Demonstration.pdf:pdf},
journal = {Proceedings of the ICML Workshop on New Developments in Imitation Learning},
keywords = {active learning,learning from demonstration},
mendeley-tags = {active learning,learning from demonstration},
number = {2009},
title = {{Active Learning with Mixed Query Types in Learning from Demonstration}},
year = {2010}
}
@article{Cakmak2012,
address = {New York, New York, USA},
annote = {What does it mean for a robot to ask a good question?

        

        query types in active learning

        
        

        label queries: skill acquistion, where instances are inherently positive
- it is unnatural to label "what not to do"
- robot exectures a motion, and ask whether the skill was peformed correctly or not

        
It is unclear what to do with negative examples

        
          
demonstration query:  asking for an example of a certain class

        
          
feature query:  is a word a good indicator of a particular category?

        
Can we use huma quesiton asking behavior as inspiration?

        
          
Study

        
        
asked people to ask yes/no questions after a demonstration},
author = {Cakmak, Maya and Thomaz, Andrea L.},
doi = {10.1145/2157689.2157693},
file = {:Users/Brenden/Documents/Mendeley/Cakmak, Thomaz - 2012 - Designing robot learners that ask good questions.pdf:pdf},
isbn = {9781450310635},
journal = {Proceedings of the seventh annual ACM/IEEE international conference on Human-Robot Interaction - HRI '12},
keywords = {active learning,learning from demonstration},
mendeley-tags = {active learning,learning from demonstration},
pages = {17},
publisher = {ACM Press},
title = {{Designing robot learners that ask good questions}},
year = {2012}
}
@article{Candes2008,
abstract = {It is now well understood that (1) it is possible to reconstruct sparse signals exactly from what appear to be highly incomplete sets of linear measurements and (2) that this can be done by constrained ℓ 1 minimization. In this paper, we study a novel method for sparse signal recovery that in many situations outperforms ℓ 1 minimization in the sense that substantially fewer measurements are needed for exact recovery. The algorithm consists of solving a sequence of weighted ℓ 1-minimization problems where the weights used for the next iteration are computed from the value of the current solution. We present a series of experiments demonstrating the remarkable performance and broad applicability of this algorithm in the areas of sparse signal recovery, statistical estimation, error correction and image processing. Interestingly, superior gains are also achieved when our method is applied to recover signals with assumed near-sparsity in overcomplete representations—not by reweighting the ℓ 1 norm of the coefficient sequence as is common, but by reweighting the ℓ 1 norm of the transformed object. An immediate consequence is the possibility of highly efficient data acquisition protocols by improving on a technique known as Compressive Sensing.},
author = {Cand\`{e}s, Emmanuel J. and Wakin, Michael B. and Boyd, Stephen P.},
doi = {10.1007/s00041-008-9045-x},
file = {:Users/Brenden/Documents/Mendeley/Cand\`{e}s, Wakin, Boyd - 2008 - Enhancing Sparsity by Reweighted l1 Minimization.pdf:pdf},
issn = {1069-5869},
journal = {Journal of Fourier Analysis and Applications},
keywords = {Mathematics and Statistics,sparsity},
mendeley-tags = {sparsity},
month = oct,
number = {5-6},
pages = {877--905},
publisher = {Birkh\"{a}user Boston},
title = {{Enhancing Sparsity by Reweighted l1 Minimization}},
volume = {14},
year = {2008}
}
@article{Canini2014,
abstract = {We explored people's inductive biases in category learning-that is, the factors that make learning category structures easy or hard-using iterated learning. This method uses the responses of one participant to train the next, simulating cultural transmission and converging on category structures that people find easy to learn. We applied this method to four different stimulus sets, varying in the identifiability of their underlying dimensions. The results of iterated learning provide an unusually clear picture of people's inductive biases. The category structures that emerge often correspond to a linear boundary on a single dimension, when such a dimension can be identified. However, other kinds of category structures also appear, depending on the nature of the stimuli. The results from this single experiment are consistent with previous empirical findings that were gleaned from decades of research into human category learning.},
author = {Canini, Kevin R and Griffiths, Thomas L and Vanpaemel, Wolf and Kalish, Michael L},
doi = {10.3758/s13423-013-0556-3},
file = {:Users/Brenden/Documents/Mendeley/Canini et al. - 2014 - Revealing human inductive biases for category learning by simulating cultural transmission.pdf:pdf},
issn = {1531-5320},
journal = {Psychonomic bulletin & review},
keywords = {bayesian modeling,category learning},
month = jan,
pmid = {24395094},
title = {{Revealing human inductive biases for category learning by simulating cultural transmission.}},
year = {2014}
}
@article{Cao2012,
abstract = {We examined the hypothesis that learning to write Chinese characters influences the brain's reading network for characters. Students from a college Chinese class learned 30 characters in a character-writing condition and 30 characters in a pinyin-writing condition. After learning, functional magnetic resonance imaging collected during passive viewing showed different networks for reading Chinese characters and English words, suggesting accommodation to the demands of the new writing system through short-term learning. Beyond these expected differences, we found specific effects of character writing in greater activation (relative to pinyin writing) in bilateral superior parietal lobules and bilateral lingual gyri in both a lexical decision and an implicit writing task. These findings suggest that character writing establishes a higher quality representation of the visual-spatial structure of the character and its orthography. We found a greater involvement of bilateral sensori-motor cortex (SMC) for character-writing trained characters than pinyin-writing trained characters in the lexical decision task, suggesting that learning by doing invokes greater interaction with sensori-motor information during character recognition. Furthermore, we found a correlation of recognition accuracy with activation in right superior parietal lobule, right lingual gyrus, and left SMC, suggesting that these areas support the facilitative effect character writing has on reading. Finally, consistent with previous behavioral studies, we found character-writing training facilitates connections with semantics by producing greater activation in bilateral middle temporal gyri, whereas pinyin-writing training facilitates connections with phonology by producing greater activation in right inferior frontal gyrus. Hum Brain Mapp, 2012. © 2012 Wiley Periodicals, Inc.},
author = {Cao, Fan and Vu, Marianne and {Lung Chan}, Derek Ho and Lawrence, Jason M and Harris, Lindsay N and Guan, Qun and Xu, Yi and Perfetti, Charles a},
doi = {10.1002/hbm.22017},
file = {:Users/Brenden/Documents/Mendeley/Cao et al. - 2012 - Writing affects the brain network of reading in Chinese A functional magnetic resonance imaging study.pdf:pdf},
issn = {1097-0193},
journal = {Human brain mapping},
keywords = {character,embodied cognition,handwriting,orthography,phonology,pinyin,semantics,sensori-motor,writing},
mendeley-tags = {embodied cognition,handwriting},
month = feb,
pmid = {22378588},
title = {{Writing affects the brain network of reading in Chinese: A functional magnetic resonance imaging study.}},
year = {2012}
}
@article{Carey2011,
abstract = {A theory of conceptual development must specify the innate representational primitives, must characterize the ways in which the initial state differs from the adult state, and must characterize the processes through which one is transformed into the other. The Origin of Concepts (henceforth TOOC) defends three theses. With respect to the initial state, the innate stock of primitives is not limited to sensory, perceptual, or sensorimotor representations; rather, there are also innate conceptual representations. With respect to developmental change, conceptual development consists of episodes of qualitative change, resulting in systems of representation that are more powerful than, and sometimes incommensurable with, those from which they are built. With respect to a learning mechanism that achieves conceptual discontinuity, I offer Quinian bootstrapping. TOOC concludes with a discussion of how an understanding of conceptual development constrains a theory of concepts.},
annote = {The Origin of Concepts (TOOC)
        
A theory of conceptual developmet must specify
1) The innate representational primatives
2) How the initial state is different from the adult state
3) How this transformation can occur
        
This book has three theses:
1) With respect to the initial state, primitives are not just sensory. There are innate conceptual representations
2) Conceptual development involves discontinuities
3) Quinian boostrapping can achieve conceptual discontinuity
                  
Comments:         
Language is an example of acquiring the discrete, symbolic from a more iconic core cognition.
        
Other examples of conceptual change include acquiring just a few complex, inter-related concepts (weight/density, or natural number). Carey beliefs people construct place-holders, and somehow they can leap to the new version of the concept. But crucially, you can't represent the CS2 in your hypothesis space -- so it's not "Bayesian"
        
I think the central question is that starting with a hypothesis space of fully-formed alternative theories seems unsatisfying. It doesn't really "explain" how this theory is acquired, in a way people feel it needs explaining. Quinian bootstrapping is Carey's attempt to overcome this tension -- can we give it a more solid computational grounding?
        
------
Carey argues for a "dual factor theory" of concepts. The two factors are called "reference" and "narrow content". Reference refers to a causal connection between the mental symbol and the entity in the extension. 
- But current work in psychology is all about the mental representation, but Carey believes this plays a role in determining the content
        
Addressing a gap in the psyhological literature: where do featuers come from?
- flies/lays eggs, has wings etc. are not good features for birds -- they are almost as complex and theory-laden than the original word
- one of the goals of TOOC is to characterize where new primitives come from
                  
Core cognition: the primatives
-- middle-size, middle-distant objects, and their relations
-- agents, including goals, communicative interaction, causal potency
-- number, including parallel individuation, analog magnitude, and set-based quantification
        
+ preverbal infants can sum continuous quantities, comapred one-to-one correposndence and distinguist singletons from large sets
+ physical causality is constrained by whether participants are agents
+ representations of objects, agents, and umber are evolutionaily anceint, innate, modular, and likely operate on iconic representations, funtion throughout lifespan
        
        
        dedicate input analyzers        
- only process one type of information
- both spatiotemporal descriptions, and static appearance, seem to be routes towards identifying agents.
- these representations are innate, not the product of learing. But most studies are with 2-5 month olds or older. Why is it not the product of learning?
+ objects emerge in neonate chicks, but it is an existence proof that evolution can build this int
+ simultaneousl emergence of different aspects of a whole system. 
++ after representing a complete object, they can infer the number of objects, also represent object constraints
+ you would expect statistical learning to be more piecemeanl (really?)
- it would be difficult to have "object" merge out of just perceptual regularities. Qhinian bootstrapping would work, but it requires explicit symbols
                  
iconic format        
- represented in analogy format, where parts resemble parts?
- number is the clearest case: if it is represented in an analog way, then it would obey Weber's law
- TOOC speculates that core cognition is all iconic, meaning that these systems are relatively perception-like
- also explains why some things emerge quite early in looking times, but only much later in explicit linguistic representations
        
Also, TOOC argues these systems remain online in adults.
                  
4. Beyond core cognition: Central innate representations        
- is causation innate? Michotte claimed it is, and part of the central object representation
- TOOC rejects this proposal, since it seems to operate across different domains of core cognition
+ but causality (finding it) vs. applying it in specific cases (objects and agents) could be innate
        
Language
- goes beyond core cognition, since symobls are not iconic
- in many ways, core cognition helps with learning language. Like the use of the set-system helps learn the meaning of quantifies
                  
5. Discontinuity: The descriptive problem        
- concepts like "planet" and "germ" are not iconic.
+ these concepts can be overturned in the course of develpoment
+ qualitatively different from core cognition
        
discontinuities happen at the more specific level as well
- they can have more expressive power than the previous
- the new theory might be incommensuralbe with the previous
- initially, the child should think about CS2 in terms of CS1
                  
6. discontinuities leading to increase expressive power        
For number, you can't use analog system for 10 vs. 11
- You have to learn that the next item in the count words, represents the next cardinality
- STages
+ young 2 year olds know "one" vs. all
+ 7/9 months later, they learn "two", other numerals mean "some"
+ then learn "three" then "four"
Subset knowers differ qualitatively from children who have worked out the count list -- on a range of tasks.
+ here, you see the adult language of CS2 is represented by the child as CS1
+ CS2 is hard to learn -- 1/2 of college bound high school stduetns don't fully understand fcations and decimals
                  
7. Discontinuities in natural kind concepts        
- you can ask about theory change in the philosophy of science, and even locally in an individual child, despite the major differences between scientists and children
- conceptual change is when sets of concepts are inter-defined and acquired together, which is differnt tha belief revision
+ the new concpts rae not representalbe in CS1
+ in history, differentiation of "heat" vs. "temperature" 
+ juxtaposed with develpomental examples of "weight" vs. "density"
+ eventually, these concepts are differentiated, and the original concepts can't be expressed in the new terms
        
Concept of matter
+ in CS1, "degree of heaviness" is the key concept, where a large piece of styrofoam has it but a small peice does not
                  
Quinian bootstrapping
- intially, the learner cannot represent the variables that could be associated to input into Bayesian learning (it does not belong in the hypothesis space at all...?) Is this what she is saying?
- Quinian bootstrapping is one learning process that can create new representional machinery, new concepts that articulate hypotheses that were previously unstatble
        
1) Step 1: create a bunch of place-holder concepts, defined in relatoin to eachother
2) step 2: model the phenomena in the domain in terms of these symbols, using "analogy construction", "limiting case anaylses"," and indcutive inference"
        
For numbers, the child learns that one maps to one, two maps to two, etc. and then they make the "critical anlogy" betwen order on the list and order in the series of sets
                  
Boostrapping in science        
Scientists construct incorrect "placeholder concepts" to stand in and align with the phenomena 
(Kepler had a placeholder for gravity, or the force holding the planets around the sun)
(for darwin, it was artificial selection)
+ many aspects are the same for a scientists or a child
                  
implications
- for natural concepts, we generally believe it is science's role to define then, we kind of just have a place-holder. This opens the door to "wide concent"
- concepts are used for thought, inference, and planning. Whatever we posit conept to be must be compatible with these functions
        
        
        Commentary:
                
Spelke: Quinian bootstrapping is probably not the mechanism behind learning natural numbers, she suspects the analog magnitude system also plays an important role          
                
Xu: it's too early to say whether core cognition is innat e-- it could be Bayesian. Also, if having all the beliefs in the hypothesis space is trivial (Fodor), then the interesting work is evaluating the beliefs -- in which Bayesian inference is an interesting account.
        
Gopnik: Carey separates the tension of account for abstract knowledge, at a young age, by dividing the responsibility between innatism and learning. But it's possible that, in the Bayesian framework, that the initial knowledge can be evaluated and revised -- from the very beginning.},
author = {Carey, Susan},
doi = {10.1017/S0140525X10000919},
file = {:Users/Brenden/Documents/Mendeley/Carey - 2011 - Pr\'{e}cis of 'The Origin of Concepts'.pdf:pdf},
issn = {1469-1825},
journal = {The Behavioral and brain sciences},
keywords = {Cognition,Concept Formation,Human Development,Humans,Instinct,Learning,Mathematical Concepts,Psychological Theory,classic psychology,classics on concepts,conceptual change},
mendeley-tags = {classic psychology,classics on concepts,conceptual change},
month = jun,
number = {3},
pages = {113--24; discussion 124--62},
pmid = {21676291},
title = {{Pr\'{e}cis of 'The Origin of Concepts'.}},
volume = {34},
year = {2011}
}
@book{Carey1985,
address = {Cambridge, MA},
annote = {Main idea:
        
Children undergo conceptual change. Here the concepts of a previous theory are displaced by totally new concepts, not present in the previous theory.
        
Key result:
        
There is a change in how children understand animals and biology
        
4 year olds: Humans are the central prototype. They view other animals as having idiosyncratic properties (bees make honey, buffalos have horns). Thus, if you tell them a bee has a spleen, they don't think a bug has a spleen.
        
BUT if you tell them a human has a spleen, then they think a bug does. This is a weird asmmetry that really does look like theory change.
        
10 year olds: They don't show an asmmetry. If you tell them a bee has a spleen, they think a bug does too.
      },
author = {Carey, Susan},
booktitle = {Conceptual Change in Childhood},
keywords = {conceptual change,theory theory},
mendeley-tags = {conceptual change,theory theory},
publisher = {MIT Press},
title = {{Conceptual Change in Childhood}},
year = {1985}
}
@book{Carey2009,
address = {New York, New York, USA},
annote = {        General
                
Intuitive theories share many essential features with scientific theories.          
                
Conceptual change: creating new concepts not expressible in terms of previously available vocabulary.          
                
Incommensuarbility:  simultaneous additions, deletions, differentiations, coalescenes, and changes in type and core between Theory 1 and Theory 2, where the concepts of the old theory do not play a role in the new.          
                
Key examples of conceptual change commonly involve splitting or combining concepts -- is this like structural forms?          
          
Introduction        
        
Three part thesis:
1) Core cognition. Modular innate perceptual-input devices. Different than intuitive theories
2) Discontinuities in conceptual development. "That is, human beings create new representational resources that are qualitatively different from the representations they are built from." (p18)
3) Quinian bootstrappin. Mechanism for conceptual change.  Acquiring placeholders for new concepts, then filling in their meanings.
        
Examples of innate animal core cognition. 
-- Indigo bunting learn to identify North from the night sky. They have innately track the center of rotation of the night sky, since it rotates on an axis around north.
-- Imprinting. Chicks do not imprint equally likely on anything, instead they have a rough sketch of what a conspecific looks like (Mark Johnson) 
        
Argument against Fodor (1975,1980) that one cannot learn what one cannot represent. The development of irrational numbers in math -- is this present in a new born? But cognitive science has not solved this problem.
        
        Beyond core object cognition
                
Conceptual change.
Examples in science: defining role for heat and temperature, collapsing heat and cold, collapsing natural and artifical motion of Aristotle, replacing phlogiston
        
Examples in child development:
        
Change from theory 1 (CS1) to theory 2 (CS2) regarding mass, weight, density.
        
1) Undifferentiated concepts of weight/density differentiate. 
        
Conservation of mass involves taking two equal balls of clay, smashing one, and young  children think the round one has more clay. This is because they don't differentiate weight and density, much like heat and temperature in the history of science. Smith asked kids to order objects by size, absolute weight, and by density -- finding intruisions where heavier objects are made of a "heavier type of thing."
(key people Piaget, Au)
        
2) Coalescences include thinking solid, liquids and gases are the same thing -- matter. Before this, children think shadows are material but air is not.
        
3) Matter has weight and occupies space, different from perceptual access.
        
It is not until age 12 that children have a theory of continuous matter. Before then, they believe if you keep dividing something (clay) that weighs something, you eventually get a substance that weighs nothing and takes up no space.
                  
The Process of conceptual change
                
Failed accounts
1) It can't just be socially constructed and transmitted. Most verbal descriptions can be entirely misconstrued.
2) Inconsistencies are often just ignored, since they can't be accomodated
3) Domain-general improvements could play a role, but they do not themselves explain the transition.
        
Quinian bootstrapping:
 Acquiring placeholders for new concepts, then filling in their meanings. This is her version of "pulling yourself up by your own bootstraps"
        
Examples:
Darwin -- had an initial Modad theory, where a group of species related by an ancestor is a single animal. Although in his notebook he formulated some laws consistent with natural selection, he went on with Modad theory for years later
Kepler -- who is noted for trying to explain why the planets revolve around the sun . He noted they move slower if further away. Although impetus theories though the planets had anima motrix, or a force within that moves them, he devised that only the sun has this at transmits it. Although mostly wrong, it was a placeholder for his further elaborations and a direct predecessor to newton.
Rational number -- children's understanding that matter is infinitely divisible covaries with their understanding or rational numbers, often preceding. If a child is taught fractions/decimals in school and doesn't understand, they are using it as a placeholder. 
        
        
      },
author = {Carey, Susan},
keywords = {conceptual change,theory theory},
mendeley-tags = {conceptual change,theory theory},
publisher = {Oxford University Press},
title = {{The Origin of Concepts}},
year = {2009}
}
@article{CareyBartlett1978,
annote = {        initial pilot        
Children asked "Can you get the chromium tray? Not the red one, the chromium one." Children grab the correct one. 
        
Some children even repeated an approximatino to "chromium"
        
This shows children can do one-shot learning. But it does not show generalization, conflating learning with mutual exlcusivity.
                  
current study        
1) assessed color vocab
2) exposure to word chromium
3) learning about "chromium" was assessed 7-10 days later
        
asessed learning by asking for:
1) production "what color is this?
2) comprehension "bring me the cromium one"
3) is chromium a color?
        
There is a clear improvment in color storing (matchi paper in the box with the same color) of chromium, when exposed to the word
        
Trend towards improvement in comprehnsion, but only marginally signifcant
        
After second exposure, there was a dramatic increase in ability to produce the word "chromium" when shown green
- some children say "thats a hard one", but you never get that in the control data
        
No difference in learning "chromium" between children with large color lexicons and those with small color lexicions
        
      },
author = {Carey, Susan and Bartlett, Elsa},
file = {:Users/Brenden/Documents/Mendeley/Carey, Bartlett - 1978 - Acquiring a single new word.pdf:pdf},
journal = {Papers and Reports on Child Language Development},
keywords = {classic psychology,classics on concepts,fast mapping,one-shot learning,word learning},
mendeley-tags = {classic psychology,classics on concepts,fast mapping,one-shot learning,word learning},
pages = {17--29},
title = {{Acquiring a single new word}},
volume = {15},
year = {1978}
}
@article{Carmichael1932,
annote = {How does language change the format of visual representaiton?
Do we have schemas, which regularize our experience?
        
Ss saw a series of figures, which they knew they would have to draw later. They said "The next figure resembles..." and the label was given
        
there was a marked change in how the figure was reproduced, depending on the label
        
Figures were somehow labeled "more like" one of the two lists, but I'm not sure how this was done..},
author = {Carmichael, L and Hogan, H P and Walter, A A},
file = {:Users/Brenden/Documents/Mendeley/Carmichael, Hogan, Walter - 1932 - An experimental study of the effect of language on the reproduction of visually perceived form.pdf:pdf},
journal = {Journal of Experimental Psychology},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
pages = {73--86},
title = {{An experimental study of the effect of language on the reproduction of visually perceived form}},
volume = {15},
year = {1932}
}
@inproceedings{Carvalho2012,
annote = {What is the optimal order for teaching a concept to someone?
        
Previous proposals:
- start with low variability items, and later increase the items' variability
- interleave presentation of different categories
- give hard items first
Which is correct? Unification?
        
Two ways learing can be hard:
- high between-category similarity
- low within-category similarity
        
Experiment 1:
Advantage for blocked vs. interleaved when within category similarity is low?
+ alternate between categories [often] or [rarely]
        
results: there is a robust benefit for blocking -- in the case that it is hard to figure out what the categories have in common
        
Experiment 2: There is a lot of between-category similarity
+ strong within-category similarity
        
results: there is a strong advantage for block in the training set
but at test: there is an advnatage for inter-leaving the categories
        
conclusions:
- if your barrier is finding a feature that all the members have, then block is beneficial
- if th e barrier is finding something different, then interleaving is beneficial
        
Optimal sequencing is likely to depend on the stimuli.
      },
author = {Carvalho, Paulo F and Goldstone, R L},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Carvalho, Goldstone - 2012 - Category structure modulates interleaving and blocking advantage in inductive category acquisition Experiment 1 High Similarity.pdf:pdf},
keywords = {category learning,interleaving,order effects},
pages = {186--191},
title = {{Category structure modulates interleaving and blocking advantage in inductive category acquisition Experiment 1 : High Similarity}},
year = {2012}
}
@inproceedings{Carvalho2004,
author = {Carvalho, Vitor R and Cohen, William W},
booktitle = {Conference on Email and Anti-Spam},
file = {:Users/Brenden/Documents/Mendeley/Carvalho, Cohen - 2004 - Learning to Extract Signature and Reply Lines from Email.pdf:pdf},
keywords = {signature scraping},
mendeley-tags = {signature scraping},
title = {{Learning to Extract Signature and Reply Lines from Email}},
year = {2004}
}
@inproceedings{ChandrasekaranSanghavi2009,
author = {Chandrasekaran, V and Sanghavi, S and Parrilo, P A and Willsky, A S},
booktitle = {15th IFAC Symposium on System Identification (SYSID 2009)},
keywords = {sparsity},
mendeley-tags = {sparsity},
title = {{Sparse and Low-Rank Matrix Decompositions}},
year = {2009}
}
@unpublished{Chandrasekaran2010,
author = {Chandrasekaran, Venkat and Parrilo, Pablo A and Willsky, Alan S},
booktitle = {Preprint},
file = {:Users/Brenden/Documents/Mendeley/Chandrasekaran, Parrilo, Willsky - 2010 - Latent Variable Graphical Model Selection via Convex Optimization.pdf:pdf},
keywords = {algebraic statistics,covariance selection,gaussian graphical models,high-dimensional asymptotics,latent variables,low-rank,regularization,sparsity},
mendeley-tags = {sparsity},
title = {{Latent Variable Graphical Model Selection via Convex Optimization}},
year = {2010}
}
@article{Changizi2005,
abstract = {A writing system is a visual notation system wherein a repertoire of marks, or strokes, is used to build a repertoire of characters. Are there any commonalities across writing systems concerning the rules governing how strokes combine into characters; commonalities that might help us identify selection pressures on the development of written language? In an effort to answer this question we examined how strokes combine to make characters in more than 100 writing systems over human history, ranging from about 10 to 200 characters,and including numerals, abjads, abugidas, alphabets and syllabaries from five major taxa: Ancient Near-Eastern, European, Middle Eastern, South Asian, Southeast Asian. We discovered underlying similarities in two fundamental respects. (i) The number of strokes per characters is approximately three, independent of the number of characters in the writing system; numeral systems are the exception, having on average only two strokes per character. (ii) Characters are ca. 50% redundant, independent of writing system size; intuitively, this means that acharacter's identity can be determined even when half of its strokes are removed. Because writing systems are under selective pressure to have characters that are easy for the visual system to recognize and for the motor system to write, these fundamental commonalities may be a fingerprint of mechanisms underlying the visuo-motor system.},
author = {Changizi, Mark a and Shimojo, Shinsuke},
doi = {10.1098/rspb.2004.2942},
file = {:Users/Brenden/Documents/Mendeley/Changizi, Shimojo - 2005 - Character complexity and redundancy in writing systems over human history.pdf:pdf},
issn = {0962-8452},
journal = {Proceedings of the Royal Society B.},
keywords = {Form Perception,Form Perception: physiology,Genetic,Humans,Language,Selection,Writing,handwriting},
mendeley-tags = {handwriting},
month = feb,
number = {1560},
pages = {267--75},
pmid = {15705551},
title = {{Character complexity and redundancy in writing systems over human history.}},
volume = {272},
year = {2005}
}
@article{Changizi2006,
abstract = {Are there empirical regularities in the shapes of letters and other human visual signs, and if so, what are the selection pressures underlying these regularities? To examine this, we determined a wide variety of topologically distinct contour configurations and examined the relative frequency of these configuration types across writing systems, Chinese writing, and nonlinguistic symbols. Our first result is that these three classes of human visual sign possess a similar signature in their configuration distribution, suggesting that there are underlying principles governing the shapes of human visual signs. Second, we provide evidence that the shapes of visual signs are selected to be easily seen at the expense of the motor system. Finally, we provide evidence to support an ecological hypothesis that visual signs have been culturally selected to match the kinds of conglomeration of contours found in natural scenes because that is what we have evolved to be good at visually processing.},
annote = {Characters are selected for visual recognition, not optimized for motor complexity. 
        
Statistics were recorded for the distribution of junctions in a character. Characters correlate well with trademark symbols (optimized for recognition not motor), and they do not corelate with scribbles.
                  
comparisoin with natural scenes        
it doesn't much matter what the content on the natural scene is, the statistics are rather similar
        
correalte 0.76 with writing system, 0.85 with chinese, and very strongly (r2 = 0.88) with non-linguistic symbosl
                  
sub-configurations        
I'm confused about what is going on in this last section, about sub-configurations},
author = {Changizi, Mark a and Zhang, Qiong and Ye, Hao and Shimojo, Shinsuke},
doi = {10.1086/502806},
file = {:Users/Brenden/Documents/Mendeley/Changizi et al. - 2006 - The structures of letters and symbols throughout human history are selected to match those found in objects in natural scenes.pdf:pdf},
isbn = {1670541010},
issn = {1537-5323},
journal = {The American naturalist},
keywords = {Cultural Evolution,Form Perception,Humans,Language,Paleography,Symbolism,handwriting},
mendeley-tags = {handwriting},
month = may,
number = {5},
pages = {E117--39},
pmid = {16671005},
title = {{The structures of letters and symbols throughout human history are selected to match those found in objects in natural scenes.}},
volume = {167},
year = {2006}
}
@book{ChapelleBook,
editor = {Chapelle, O and Scholk\"{o}pf, B and Zien, Alexander},
publisher = {MIT Press},
title = {{Semi-Supervised Learning}},
year = {2006}
}
@book{Chemero2009,
address = {Cambridge, MA},
annote = {        radical embodied cognitive science: Animals are active perceivers of and actors in an information-rich environment, and some of the information in the environment, the information to which animals are especially attuned, is about affordances. Unified animal-envirnonment systems are to be modeled using the tools of dynamical systems theory. There is no need to posit representations of the environment inside the animal (or computations thereupon) because animals and environments are taken, both in theory and models, to be coupled.
        
---
        
example 1: Beer's robot
- recurrent neural net, evolved to catch falling diamonds but avoid squares
- you can describe system by dynamical system, with equations relating how all the variables (neurons) and the environment evolve over time
        
2) will this scale up? what if the object moves out of attention?
- example with "can a stick reach the target?" where you get a sequence of sticks and you predit the next response. Somehow you can get sequential effects, simulation etc.
                  
What is representation?
                
- some consensus: using a stand-in for something in the environment that is not currently present
- Grush's emulator theory: you can use stand-ins to provide early feedback, like in reaching
- dynamical cognitive science: like netwon's laws, removing teology?
- is it that representations are unnecessary, and not the best way of understanding? or they really don't exist?
+ it seems like the first question is scientific, and the second question is philosophical
        
Gibson's ecoloical psychology: Direct perception
1) perception is nonmediated contact with object
2) perception is for action
3) perception is of environment opportunities for action, which follows from the other two
- if perception is direct, no information is added by the mind
+ BUT THIS IS JUST WRONG! what about visual illusions?
        
Analogy:
- pigeons/monkeys can detect "same" vs. "difference"
- discrimination based on entropy?
+ that requires hidden units
+ Chemero claims you can do okay without hidden units
+ thus, if he counts hidden units as representation, we are in big trouble. Of course you at least need these!
        
Comment: Doesn't Chris's work clearly show a need for representation?},
author = {Chemero, Anthony},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
publisher = {MIT Press},
title = {{Radical embodied cognitive science}},
year = {2009}
}
@article{Chen2000,
author = {Chen, Hao and Hu, Jianying},
file = {:Users/Brenden/Documents/Mendeley/Chen, Hu - 2000 - Integrating Geometrical and Linguistic Analysis for Email Signature Block Parsing.pdf:pdf},
journal = {{ACM Transactions on Information Systems}},
keywords = {signature scraping},
mendeley-tags = {signature scraping},
number = {4},
pages = {343--366},
title = {{Integrating Geometrical and Linguistic Analysis for Email Signature Block Parsing}},
volume = {17},
year = {2000}
}
@article{Cheng1993,
annote = {Here, they basically do one-shot learning, since you only use one image from each training class. Based on stroke matchng.
        
---
Steps
1) Partitions characters into sub-strokes
2) Matches sub-strokes, based on various statistics about them (local and relational). This can handle different numbers of sub-strokes.
These statistics are
-- shared start/end points
        
        
3) For recognition, pick the best anchor character for each training class. This character minimizes error on the training set. Then match new input characters to that anchor.
        
This doesn't report a percent correct?
        
radicals -- repeating patterns in Chinese characters},
author = {Cheng, F-H and Hsu, W-H and K, M-C},
file = {:Users/Brenden/Documents/Mendeley/Cheng, Hsu, K - 1993 - Recognition of Handprinted Chinese Characters via Stroke Relaxation.pdf:pdf},
journal = {Pattern Recognition},
keywords = {handwriting,part-based models},
mendeley-tags = {handwriting,part-based models},
number = {4},
pages = {579--593},
title = {{Recognition of Handprinted Chinese Characters via Stroke Relaxation}},
volume = {26},
year = {1993}
}
@article{Cheng1989,
annote = {Recognizing Chinese characters by stroke analysis
        
1) Thin the character
2) Apply hough transform, to get straight lines
3) Now features are the angle, radius, and length for each stroke
4) Somehow this is recognized, using a feature matching procedure},
author = {Cheng, F.-H. and Hsu, W.-H. and Chen, M.-Y.},
doi = {10.1109/34.19042},
file = {:Users/Brenden/Documents/Mendeley/Cheng, Hsu, Chen - 1989 - Recognition of handwritten Chinese characters by modified Hough transform techniques.pdf:pdf},
issn = {01628828},
journal = {{IEEE Transactions on Pattern Analysis and Machine Intelligence}},
keywords = {handwriting},
mendeley-tags = {handwriting},
month = apr,
number = {4},
pages = {429--439},
title = {{Recognition of handwritten Chinese characters by modified Hough transform techniques}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=19042},
volume = {11},
year = {1989}
}
@article{Cheng1989a,
annote = {On-line (?) recognition of Chinese characters.
        
Matches sub-components (stroke or sub-strokes) in one-to-one correspondence between a target and an item in memory. To deal with differences in the number of strokes, similarity is positive [0,1] and overall similarity is the sum of the stroke similarities.
        
-------
Strategy:
-- break a candidate image into strokes (line framgnets)
-- Using the same method as my CogSci paper, define a distance between strokes, and match strokes using a linear program
-- Distance is based on midpoint location, and angle o the stroke
-- Overall simimlarity is the sum of each stroke. Thus, the more strokes you match, the higher the similarity. This allows you to deal with differences in the number of strokes},
author = {Cheng, Fang-Hsuan and Hsu, Wen-Hsing and Chen, Chien-An},
file = {:Users/Brenden/Documents/Mendeley/Cheng, Hsu, Chen - 1989 - Fuzzy approach to solve the recognition problem of handwritten Chinese characters.pdf:pdf},
journal = {Pattern Recognition},
keywords = {handwriting,part-based models},
mendeley-tags = {handwriting,part-based models},
number = {2},
pages = {133--141},
title = {{Fuzzy approach to solve the recognition problem of handwritten Chinese characters}},
volume = {22},
year = {1989}
}
@article{Cheng2007,
abstract = {Spatial judgments and actions are often based on multiple cues. The authors review a multitude of phenomena on the integration of spatial cues in diverse species to consider how nearly optimally animals combine the cues. Under the banner of Bayesian perception, cues are sometimes combined and weighted in a near optimal fashion. In other instances when cues are combined, how optimal the integration is might be unclear. Only 1 cue may be relied on, or cues may seem to compete with one another. The authors attempt to bring some order to the diversity by taking into account the subjective discrepancy in the dictates of multiple cues. When cues are too discrepant, it may be best to rely on 1 cue source. When cues are not too discrepant, it may be advantageous to combine cues. Such a dual principle provides an extended Bayesian framework for understanding the functional reasons for the integration of spatial cues.},
annote = {If you have two unbiased sources of information for a quantity, you can integrate them by a weighted average, with weight proportional to their variance
        
This could be two cues, or also a draw from a prior, perturbed by gaussian noise},
author = {Cheng, Ken and Shettleworth, Sara J and Huttenlocher, Janellen and Rieser, John J},
doi = {10.1037/0033-2909.133.4.625},
file = {:Users/Brenden/Documents/Mendeley/Cheng et al. - 2007 - Bayesian integration of spatial information.pdf:pdf},
issn = {0033-2909},
journal = {Psychological bulletin},
keywords = {Animal,Animal: physiology,Animals,Ants,Bayes Theorem,Bees,Behavior,Columbidae,Cricetinae,Cues,Humans,Rats,Space Perception,Space Perception: physiology,Spatial Behavior,Spatial Behavior: physiology,spatial reasoning},
mendeley-tags = {spatial reasoning},
month = jul,
number = {4},
pages = {625--37},
pmid = {17592958},
title = {{Bayesian integration of spatial information.}},
volume = {133},
year = {2007}
}
@article{Cherry1953,
annote = {How do we solve the "cocktail party problem?"
        
People seem to regularize reconstructed messages.
        
IF you are doing dichotic listening, what factors are recognized in the rejected ear?
-- language of "rejected" ear is unrecognized
-- change in gender is identified
-- a pure tone was idenitified
-- the "rejected' signal has certain statilstical properties reocgnized, but detailed aspects of the words, remained unnoticed},
author = {Cherry, E Colin},
file = {:Users/Brenden/Documents/Mendeley/Cherry - 1953 - Some Experiments on the Recognition of Speech, with One and with Two Ears.pdf:pdf},
journal = {The Journal of the Acoustical Society of America},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {5},
pages = {975--979},
title = {{Some Experiments on the Recognition of Speech, with One and with Two Ears}},
volume = {25},
year = {1953}
}
@inproceedings{Choi2008,
address = {Las Vegas, Nevada},
author = {Choi, Myung Jin and Chandrasekaran, Venkat and Willsky, Alan S},
booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)},
file = {:Users/Brenden/Documents/Mendeley/Choi, Chandrasekaran, Willsky - 2008 - Maximum Entropy Relaxation for Multiscale Graphical Model Selection.pdf:pdf},
isbn = {1424414849},
keywords = {sparsity},
mendeley-tags = {sparsity},
pages = {1889--1892},
title = {{Maximum Entropy Relaxation for Multiscale Graphical Model Selection}},
year = {2008}
}
@article{Choi2010,
author = {Choi, Myung Jin and Chandrasekaran, Venkat and Willsky, Alan S},
file = {:Users/Brenden/Documents/Mendeley/Choi, Chandrasekaran, Willsky - 2010 - Gaussian Multiresolution Models Exploiting Sparse Markov and Covariance Structure.pdf:pdf},
journal = {IEEE Transactions on Signal Processing},
keywords = {graphical models,sparsity},
mendeley-tags = {graphical models,sparsity},
number = {3},
pages = {1012--1024},
title = {{Gaussian Multiresolution Models : Exploiting Sparse Markov and Covariance Structure}},
volume = {58},
year = {2010}
}
@article{Choi2011,
author = {Choi, Myung Jin and Tan, Vincent and Anandkumar, Animashree and Willsky, Alan S},
file = {:Users/Brenden/Documents/Mendeley/Choi et al. - 2011 - Learning Latent Tree Graphical Models.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {1771--1812},
title = {{Learning Latent Tree Graphical Models}},
volume = {12},
year = {2011}
}
@article{Chun1995,
annote = {Studied the attentional blink. When stimuli are shown during RSVP, there are two targets. If the second target follows the first, a lag of 1 there is no problem, but a lag or 2 or 3 it is very hard to detect.
        
They account for this by a rapid perception process. But the stimulus must be transferred to a more permanent memory store, and this happens serially. Thus this delays the perception of the second element.},
author = {Chun, Marvin M and Potter, Mary C},
file = {:Users/Brenden/Documents/Mendeley/Chun, Potter - 1995 - A Two-Stage Model of Multiple Target Detection in Rapid Serial Visual Presentation.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
keywords = {attention,classic psychology},
mendeley-tags = {attention,classic psychology},
number = {1},
pages = {109--127},
title = {{A Two-Stage Model of Multiple Target Detection in Rapid Serial Visual Presentation}},
volume = {21},
year = {1995}
}
@article{Clark1999,
abstract = {The last ten years have seen an increasing interest, within cognitive science, in issues concerning the physical body, the local environment, and the complex interplay between neural systems and the wider world in which they function. Yet many unanswered questions remain, and the shape of a genuinely physically embodied, environmentally embedded science of the mind is still unclear. In this article I will raise a number of critical questions concerning the nature and scope of this approach, drawing a distinction between two kinds of appeal to embodiment: (1) 'Simple' cases, in which bodily and environmental properties merely constrain accounts that retain the focus on inner organization and processing; and (2) More radical appeals, in which attention to bodily and environmental features is meant to transform both the subject matter and the theoretical framework of cognitive science.},
annote = {Distinction between two kinds of embodiment
1) Simple cases, where the body and envrionment merely constraint accounts of the inner organization
2) more radical appeals, where they are supposed to transform the subject matter and theoretical framework
        
To understand how a bluefin tuna swims so quickly, you need to analyze how it exploits local currents and pressure gradients to do so
                  
vision:        
You can repeatedly query the outside world, rather than build a detailed world model (just in time representation, the world is its own best model)
        
when chasing a fly ball, the fiedler adjusts his or her run so that the ball never seems to curve towards the groud, but moves in a straight line
- then you don't need to solve the whole problem, it is not sovled ahead of time
        
the sunflower tracks the sun, but only when it is actually there. It doesn't have a representation, since it is actively coupled
        
simple embodied congition: just use these as constraints
        
radical embodied cognition: change the theoretical framework of cognitive science
+ we need new analytic tools, like dynamical systems theroy
+ traditional internal representations are not necessary
+ traditional decomposition of the neural system is misleading
        
But evidence for these don't usually come from "representation-hungry" problems.
      },
author = {Clark, Andy},
file = {:Users/Brenden/Documents/Mendeley/Clark - 1999 - An embodied cognitive science.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
month = sep,
number = {9},
pages = {345--351},
pmid = {10461197},
title = {{An embodied cognitive science?}},
volume = {3},
year = {1999}
}
@article{Clark1998,
annote = {Classic paper on extended cognition.
        
If someone solves a math problem in the mind, and another person solves it on paper -- shouldn't the paper be counted as part of the cognition?
        
There is no less cognition going on, as a whole
        
Growing body of thought, where cognition is often taken to be continuous with the processes in the environment
        
Evolution might have taken advantage of other possibilities, which are part of the environment, and brought them into the cognitive system.
        
There tends to be a set of core capacities, which we carry with us all the time (in the brain). Would it make a difference if we always carried a calculator? Also, some of these core functions can be turned off (by sleepiness, or intoxiation, etc.)
        
        
What if an Alzheimer's disease patient, writes down a lot of facts in a notebook, including the location of the MOMA in NY. Is the notebook part of the cognitive system?
      },
author = {Clark, Andy and Chalmers, David},
file = {:Users/Brenden/Documents/Mendeley/Clark, Chalmers - 1998 - The extended mind.pdf:pdf},
journal = {Analysis},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
number = {1},
pages = {7--19},
title = {{The extended mind}},
volume = {58},
year = {1998}
}
@article{Cohen2000,
abstract = {A standard model of word reading postulates that visual information is initially processed by occipitotemporal areas contralateral to the stimulated hemifield, from whence it is subsequently transferred to the visual word form (VWF) system, a left inferior temporal region specifically devoted to the processing of letter strings. For stimuli displayed in the left visual field, this transfer proceeds from the right to the left hemisphere through the posterior portion of the corpus callosum. In order to characterize the spatial and temporal organization of these processes, reading tasks with split-field presentation were performed by five control subjects and by two patients suffering from left hemialexia following posterior callosal lesions. The subjects' responses were studied using behavioural measures and functional brain imaging techniques, providing both high spatial resolution (functional MRI, fMRI) and high temporal resolution (high-density event-related potentials, ERPs). Early visual processing was revealed as activations contralateral to stimulation, located by fMRI in the inferior occipitotemporal region and presumably coincident with area V4. A negative wave occurring 150-160 ms post-stimulus, also strictly contralateral to stimulation, was recorded over posterior electrodes. In contrast with these hemifield-dependent effects, the VWF system was revealed as a strictly left-hemispheric activation which, in control subjects, was identical for stimuli presented in the left or in the right hemifield and was located in the middle portion of the left fusiform gyrus. The electrical signature of the VWF system consisted of a unilateral sharp negativity, recorded 180-200 ms post-stimulus over left inferior temporal electrodes. In callosal patients, due to the inability of visual information to pass across the posterior part of the corpus callosum, the VWF system was activated only by stimuli presented in the right visual field. Similarly, a significant influence of the word/non-word status on ERPs recorded over the left hemisphere was discernible for either hemifield in controls, while it affected only right-hemifield stimuli in callosal patients. These findings provide direct support for the main components of the classical model of reading and help specify their timing and cerebral substrates.},
author = {Cohen, L and Dehaene, S and Naccache, L and Leh\'{e}ricy, S and Dehaene-Lambertz, G and H\'{e}naff, M a and Michel, F},
file = {:Users/Brenden/Documents/Mendeley/Cohen et al. - 2000 - The visual word form area spatial and temporal characterization of an initial stage of reading in normal subjects and posterior split-brain patients.pdf:pdf},
issn = {0006-8950},
journal = {Brain},
keywords = {Adult,Case-Control Studies,Corpus Callosum,Corpus Callosum: pathology,Electroencephalography,Evoked Potentials,Female,Functional Laterality,Humans,Magnetic Resonance Imaging,Male,Mental Processes,Mental Processes: physiology,Occipital Lobe,Occipital Lobe: physiology,Reading,Temporal Lobe,Temporal Lobe: physiology,Visual Perception,handwriting},
mendeley-tags = {handwriting},
month = feb,
pages = {291--307},
pmid = {10648437},
title = {{The visual word form area: spatial and temporal characterization of an initial stage of reading in normal subjects and posterior split-brain patients.}},
volume = {123 ( Pt 2},
year = {2000}
}
@article{Cohn1996,
annote = {We can write the expected error of a learning, in a regression problem
        
We want to minimize the variance of the predictions, compared ot the average prediction, based on what the dataset is
        
 and thus choose datapoints for which the variance in minimzed, when averaging over possible values of that new label},
author = {Cohn, D and Ghahramani, Zoubin and Jordan, Michael I},
file = {:Users/Brenden/Documents/Mendeley/Cohn, Ghahramani, Jordan - 1996 - Active learning with statistical models.pdf:pdf},
journal = {Journal of Artificial Intelligence Research},
title = {{Active learning with statistical models}},
year = {1996}
}
@article{Cohn1994,
author = {Cohn, Davikd and Atals, Les and Ladner, Richard},
file = {:Users/Brenden/Documents/Mendeley/Cohn, Atals, Ladner - 1994 - Improving generalization with Active Learning.pdf:pdf},
journal = {Machine learning},
keywords = {active learning},
mendeley-tags = {active learning},
number = {2},
pages = {201--221},
title = {{Improving generalization with Active Learning}},
volume = {15},
year = {1994}
}
@article{Cole2010,
abstract = {The ability to rapidly reconfigure our minds to perform novel tasks is important for adapting to an ever-changing world, yet little is understood about its basis in the brain. Furthermore, it is unclear how this kind of task preparation changes with practice. Previous research suggests that prefrontal cortex (PFC) is essential when preparing to perform either novel or practiced tasks. Building upon recent evidence that PFC is organized in an anterior-to-posterior hierarchy, we postulated that novel and practiced task preparation would differentiate hierarchically distinct regions within PFC across time. Specifically, we hypothesized and confirmed using functional magnetic resonance imaging and magnetoencephalography with humans that novel task preparation is a bottom-up process that involves lower-level rule representations in dorsolateral PFC (DLPFC) before a higher-level rule-integrating task representation in anterior PFC (aPFC). In contrast, we identified a complete reversal of this activity pattern during practiced task preparation. Specifically, we found that practiced task preparation is a top-down process that involves a higher-level rule-integrating task representation (recalled from long-term memory) in aPFC before lower-level rule representations in DLPFC. These findings reveal two distinct yet highly inter-related mechanisms for task preparation, one involving task set formation from instructions during rapid instructed task learning and the other involving task set retrieval from long-term memory to facilitate familiar task performance. These two mechanisms demonstrate the exceptional flexibility of human PFC as it rapidly reconfigures cognitive brain networks to implement a wide variety of possible tasks.},
annote = {        hypothesis
                
Practiced task preparation predicts a reversal of information flow in PFC. anterior PFC (high-level) is active first (during econding), and activates the low-level rules in dorsolateral PFC (during first trial)
        
Their predition: this should be reversed for new tasks. Bottom of procedure of using the known rules in DLPFC and combining them in new ways.
        
Task parameters
1)Same, just one, second, not second
2) semantic rule. is it sweet?
3) motor response
        
Then get two stimuli, liek "grape" and "apple"
                  
people can do RITL        
Accuracy on the very first performance of the 64 tasks was 91%
        
        resulsts
                
compared encoding (early) vs. first trial (late)
        
fMRI: got strong double-disscociated between practiced and novel tasks
        
confirmed with MEG
                  
discussion        
Previous work showed that an abstract description highlights the necesary component rules in a practiced task
        
Compatible wtiha  shift from bottom-up to top-down processing
      },
author = {Cole, Michael W and Bagic, Anto and Kass, Robert and Schneider, Walter},
doi = {10.1523/JNEUROSCI.1662-10.2010},
file = {:Users/Brenden/Documents/Mendeley/Cole et al. - 2010 - Prefrontal dynamics underlying rapid instructed task learning reverse with practice.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Adult,Brain Mapping,Cognition,Cognition: physiology,Computer-Assisted,Female,Humans,Image Processing,MD system,Magnetic Resonance Imaging,Magnetoencephalography,Male,Mental Recall,Mental Recall: physiology,Practice (Psychology),Prefrontal Cortex,Prefrontal Cortex: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Reversal Learning,Reversal Learning: physiology,Young Adult},
mendeley-tags = {MD system},
month = oct,
number = {42},
pages = {14245--54},
pmid = {20962245},
title = {{Prefrontal dynamics underlying rapid instructed task learning reverse with practice}},
volume = {30},
year = {2010}
}
@article{Cole2012,
abstract = {The human ability to flexibly adapt to novel circumstances is extraordinary. Perhaps the most illustrative, yet underappreciated, form of this cognitive flexibility is rapid instructed task learning (RITL)-the ability to rapidly reconfigure our minds to perform new tasks from instructions. This ability is important for everyday life (e.g., learning to use new technologies) and is used to instruct participants in nearly every study of human cognition. We review the development of RITL as a circumscribed domain of cognitive neuroscience investigation, culminating in recent demonstrations that RITL is implemented via brain circuits centered on lateral prefrontal cortex. We then build on this and the recent discovery of compositional representations within lateral prefrontal cortex to develop an integrative theory of cognitive flexibility and cognitive control that identifies mechanisms that may enable RITL within the human brain. The insights gained from this new theoretical account have important implications for further developments and applications of RITL research.},
annote = {rapid instructed task learning (RTL) - the ability to rapidly reconfigure our minds to perform new tasks from instructions
        
RITL is implemented via brain circuits centered on lateral prefrontal cortex
- compositional representations within this area
        
System used for all psychology experiments: given a person a new task
        
characterstics
- speed (one trial)
- adaptability
        
examples:
- new techonlogy
- new recipe
- new game
        
+ can't just be reinforcement learning, which is way too slow
        
learn quickly be first-trial learning that the instructor specifies a good example, to hone you in on task space
        
First trial learning requires RITL, not reinforcement learning
+ can be given verbal instructions
+ can be other kinds of instructions (diagrams)
                  
computational models        
Turing machine - a machien can be rapidly configured to perform any computable task
+ every computer in some esne has the human capacity for RITL
+ but does not translate into insight
        
production mdoels (Anderson)
        
connectionist models, where error-driven learning requires thousands of trials
                  
human intelligence
                
- primates take forever to learn a new task
- LPFC has undergone great evolutionary expansion
                  
methods
                
encoding phase: studying the task
execution phase: doing the task
        
but can only study a single trial
+ use meta-task that can spawn many specific tasks
        
imitation: a form of RITL
        
task switching: rapidly changing between well-practiced tasks
- but switching cmoponent is the same
- can use practiced switched, vs. novel swithced, s a constrast set
        
Ruge and Wolfensteller (concrete task)
- anterior LPFC: more active initially,
- posterior LPFC: more active afterwards
        
Cole and colleagues used more abstract tasks
- found a similar shift, but everything was shifted more anterior (mid vs. post)
                  
basal ganglia        
controlling for difficulty and stimulus novely, Stocco et al issolated the basal ganglia in RITL
                  
cognitive control network
                
LPFC is strongly conneted with cortical regions referred to as the cognitive control network
        
How does this relate to the Duncan's multiple-demand region story?
        
LPFC is selectively active for novel vs practiced
+ controlling for difficulty?
                  
integrated theory of RITL
                
1) compositionality: combining concepts creates many new concepts
+ RITL can manage novel rule combinations
        
2) immediate transfer: benefits of prior experience with component rules
        
3) abstraction: grouping representations or features into categories, where featuers are shared. Allows you to share featuers and make coffee in different situations, even if the ground changed, etc. Related to compositionality
        
combine several semi-task-relevant abstract representations
        
4) analogy: recognitive the similarity between two or more representations
        
5) compositional hiearchy: a hiearchy of representations, such that lower-level ones can be combined to construct more abstract ones
        
        general processing hierarchy        
low-level featuers, left and button, combine to make higher-level left button
        
then, task markers can select which if the highever-level features are to be connceted
+ practice strengthen conenctions
+ don't have dedicted task neurons
        
but combinatorial explosion might be an issues for neural theories of RITL
+ but see dynamic binding (Hummel eand Biederman)
        
                  
do neurons change receptive fields adaptively?
debate over yes or no        
Duncan: neurons change receptive fields adaptively?
        
+ because monkey neurons represent whatever rule is be considered
+ Is this compatible, the compositinal theory?
++ consitutent-rule representations remain stable within LPFC across task context
        
Relevant Miller experiments
                  
predictions of composition
                
- rapid task learning
- higher learning rate should result in WORSE RITL task performance, while better for most other types of learning
+ inconsistent with weight-based learning in LPFC for RITL
                  
future direcitons        
RITL provides unprecendted access to the kind of cognitive flexibility that makes human cognition unique},
author = {Cole, Michael W and Laurent, Patryk and Stocco, Andrea},
doi = {10.3758/s13415-012-0125-7},
file = {:Users/Brenden/Documents/Mendeley/Cole, Laurent, Stocco - 2012 - Rapid instructed task learning A new window into the human brain's unique capacity for flexible cognitive control.pdf:pdf},
issn = {1531-135X},
journal = {Cognitive, affective & behavioral neuroscience},
keywords = {MD system,animal models,cognitive control,cognitive flexibility,compositionality,computational model,control,flexible cognitive,prefrontal cortex},
mendeley-tags = {MD system},
month = oct,
pmid = {23065743},
title = {{Rapid instructed task learning: A new window into the human brain's unique capacity for flexible cognitive control.}},
year = {2012}
}
@article{Coley1997,
author = {Coley, J D and Medin, D L and Atran, S},
file = {:Users/Brenden/Documents/Mendeley/Coley, Medin, Atran - 1997 - Does rank have its privilege Inductive inferences within folkbiological taxonomies.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {80 and over,Adult,Aged,Analysis of Variance,Animal Population Groups,Animal Population Groups: classification,Animals,Central American,Central American: psychology,Concept Formation,Cross-Cultural Comparison,Female,Guatemala,Humans,Indians,Logic,Male,Middle Aged,Plants,Plants: classification,Terminology as Topic,United States,property induction},
mendeley-tags = {property induction},
month = jul,
number = {1},
pages = {73--112},
pmid = {9342932},
title = {{Does rank have its privilege? Inductive inferences within folkbiological taxonomies.}},
volume = {64},
year = {1997}
}
@article{Collins1975,
annote = {Classic model of semantic memory and priming. The notion of aggregate connection strength (summing across paths) creates graphs that look a lot like structural sparsity, in theory.
        
--
Quillian's original model:
-- isa, modifier, disjunctive set links
-- activation spreads in a breadth-first way from starting nodes
-- there can be model starting nodes, and they meet at an intersection
-- this type of search can be used for categorization, but also priming, which prime links and nodes
        
Misconceptions about the original theory:
-- cognitive economy, that concepts are only stored once, and associations stored only at the highest level
-- all links are equal (because some can have different strengths)
-- activation only spread from instance to the category (in fact it can go both ways)
        
The extended theory:
-- activation attenuates as it travels longer distances
-- the longer something is processed, the more activation is released
-- semantic distance is the distance along the shortest path, but semantic relatedness is the aggregate distance along all the paths
-- also, if a node is active, its activation diffuses more if it connects to lots of thing
        
Matching process:
-- evidence for a positive (or negative) match is accumulated, until it reaches some threshold
-- this is like an exemplar model of sorts, where you compare to all examples of a category and look at similarity
        
Experimental data:
-- when first "fruit" primes "apple," then "red" primes it, this is better than the other way around.  Or fruit primes lemon before sour, although lemon and sour are closer associates. This is because of the diffusion of activation strength. This could be explained in terms of hierarchical knowledge, or spreading activation.
-- accounts for asymmetries. If the category primes the instance highly, faster RT if category is first. If the instance primes the category highly, faster RT for the instance first. Again, based on spreading activation
-- Subjects are much better at being primed by a letter, if they know a letter is coming. Can they off-weight work on the lexical network then?
        
They dismiss some other attacks on the spreading activation theory.
        
The role of similarity and typicality: why are we slower at saying a chicken is a bird? while it has the is-a links, there are other properties that make it different , like the fact that we eat it. This is the role of aggregate similarity. Also, links can be primed and strengthened, so perhaps bird and robin are more strongly related.
        
Criticize the two-stage model of Smith et al (1974) that uses all features and "defining" features in two stages},
author = {Collins, Allan M and Loftus, Elizabeth F},
file = {:Users/Brenden/Documents/Mendeley/Collins, Loftus - 1975 - A spreading-activation theory of semantic processing.pdf:pdf},
journal = {Psychological Review},
keywords = {conceptual change,semantic network,sparsity},
mendeley-tags = {conceptual change,semantic network,sparsity},
number = {6},
pages = {407--428},
title = {{A spreading-activation theory of semantic processing}},
volume = {82},
year = {1975}
}
@article{Collins1968,
annote = {Classic semantic network model. Spreading activation theory, where it takes longer to evaluate properties stored further way from the target object. These objects were organized in a hiearchy, with the properties stored at the most general nodes. RT correlated with distance in the model.
        
Criticisms of this model in later work:
-- Doesn't explain prototype effects (or irregular objects like chicken). I think a chicken is faster to identify as an animal than a bird.
-- Distances of links must be different lengths
-- How do you decide when a sentence is false?
 You can find a contradiction, but predictions about RT did not hold for this. You could also try self-terminating search. But this does not seem to be simple, and is a weakness for the model.},
author = {Collins, Allan M and Quillian, M R},
file = {:Users/Brenden/Documents/Mendeley/Collins, Quillian - 1968 - Retrieval time from semantic memory.pdf:pdf},
journal = {Journal of Verbal Learning and Verbal Behavior},
keywords = {semantic network},
mendeley-tags = {semantic network},
number = {2},
pages = {240--247},
title = {{Retrieval time from semantic memory}},
volume = {8},
year = {1968}
}
@inproceedings{Collins2002,
annote = {For tagging
-- HMMs have a latent state, which is a set of tags
-- You then generaet words from those tags},
author = {Collins, Michael},
booktitle = {{Proceedings of the Conference of Empirical Methods in Natural Processing (EMNLP)}},
file = {:Users/Brenden/Documents/Mendeley/Collins - 2002 - Discriminative Training Methods for Hidden Markov Models Theory and Experiments with Perceptron Algorithms.pdf:pdf},
keywords = {classic AI},
mendeley-tags = {classic AI},
number = {July},
pages = {1--8},
title = {{Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms}},
year = {2002}
}
@article{Colunga2005,
abstract = {In the novel noun generalization task, 2 1/2-year-old children display generalized expectations about how solid and nonsolid things are named, extending names for never-before-encountered solids by shape and for never-before-encountered nonsolids by material. This distinction between solids and nonsolids has been interpreted in terms of an ontological distinction between objects and substances. Nine simulations and behavioral experiments tested the hypothesis that these expectations arise from the correlations characterizing early learned noun categories. In the simulation studies, connectionist networks were trained on noun vocabularies modeled after those of children. These networks formed generalized expectations about solids and nonsolids that match children's performances in the novel noun generalization task in the very different languages of English and Japanese. The simulations also generate new predictions supported by new experiments with children. Implications are discussed in terms of children's development of distinctions between kinds of categories and in terms of the nature of this knowledge.},
annote = {For solid objects, shape is a principle dimension of organization and generalization.
        
For substances, material is a principle dimension of organization and generalization.
        
How is it possible to learn this? From the correlations present in the input, a simple neural network can learn to generalize the name of a new substance based on material, and based on shape for solids.},
author = {Colunga, Eliana and Smith, Linda B},
doi = {10.1037/0033-295X.112.2.347},
file = {:Users/Brenden/Documents/Mendeley/Colunga, Smith - 2005 - From the lexicon to expectations about kinds a role for associative learning.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Association Learning,Child,Child Language,Humans,Infant,Linguistics,Preschool,Vocabulary},
month = apr,
number = {2},
pages = {347--82},
pmid = {15783290},
title = {{From the lexicon to expectations about kinds: a role for associative learning.}},
volume = {112},
year = {2005}
}
@article{Cook2011,
abstract = {Probabilistic models of expected information gain require integrating prior knowledge about causal hypotheses with knowledge about possible actions that might generate data relevant to those hypotheses. Here we looked at whether preschoolers (mean: 54 months) recognize "action possibilities" (affordances) in the environment that allow them to isolate variables when there is information to be gained. By manipulating the physical properties of the stimuli, we were able to affect the degree to which candidate variables could be isolated; by manipulating the base rate of candidate causes, we were able to affect the potential for information gain. Children's exploratory play was sensitive to both manipulations: given unambiguous evidence children played indiscriminately and rarely tried to isolate candidate causes; given ambiguous evidence, children both selected (Experiment 1) and designed (Experiment 2) informative interventions.},
annote = {Can preschoolers isolate variables to intervene on the enviornment to gain information?
        
Is exeperimental design only relevant to scientists?
        
When unlocking a door, you change just one thing at a time, if it doesn't unlcock
        
While the knowledge in a child might look scientific, there is a surprisingly mixed story about the acquisition of this knowledge
        
causal reasoning provides strongest evidence of good experimental design
+ like backwards blocking in blicket tasks
        
However, previous work falls short in showing children know what makes "good" evidence to collect
        
Reinfocmeent learning models provide one formal account for maximizing expected information gain and ultimately reward
        
This really puts the analogy between children and scientists to the test
        
Hypothesis: children are likely to perform actions with high information gain, although it may not be precisely "scientific", or that they perform only informative experiments (they do just playful actions too)
+ also, this can be disrupted by increasing the number of variables
+ handling complexity might require formal scientific training
        
Simple toy world:
        
conditions
all beads: 4/4 active toy
some beads: 2/4 beads active toy
        
After training, they show all children two pairs of beads, where one can be broken apart and the other is glued together
        
In "all" conditino, it is relatively unambiguos that both beads would work
- in "some" condition, the evidence fails to distinguish which bead works
        
They will have to figure out how to test this with the material at hand
                  
Experiment 1
                
warm-up: sponatneous play with beads
        
base rate training: "special machine", that "some things make the machine go..."
either 2/4 or 4/4 active the machine
        
demonstration of bead pair: shown that the pair makes it goes off. Also, shown a stuck pair and separable pair, and shown that the separable pair is indeed separable
        
The child was alowed to try each pair to veryify its status
        
results:
        
dependent measure: did they separate the beads, and test each one indiviudally?
(criterion was they ahd to test both)
        
only one child in "all beads" condition separated beads, but half did in the "some beads" condition
        
Also, evidence that children were not simply exploring more boradly, they were targeted exploartion (coded other types of exploration)
                  
Experiment 2
                
In this experiment, the actions were already familiar to the children (breaking apart the blocks). What if they were unfamiliar actions?
        
In the previous experiment, some children played the beads on the detector vertically, to isolate one block
        
agian, and 4-5 year olds
        
results:
Replicated results of previuos experiment, where about 50% of the children tried the novel intervention
                  
discussion
                
preschoolers can isolate variables and maximize the potential for information gain
        
      },
author = {Cook, Claire and Goodman, Noah D and Schulz, Laura E},
doi = {10.1016/j.cognition.2011.03.003},
file = {:Users/Brenden/Documents/Mendeley/Cook, Goodman, Schulz - 2011 - Where science starts spontaneous experiments in preschoolers' exploratory play.pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
keywords = {Child,Exploratory Behavior,Exploratory Behavior: physiology,Female,Humans,Learning,Male,Mental Processes,Play and Playthings,Play and Playthings: psychology,Preschool,Psychomotor Performance,Psychomotor Performance: physiology,active learning,causal reasoning},
mendeley-tags = {active learning,causal reasoning},
number = {3},
pages = {341--9},
pmid = {21561605},
publisher = {Elsevier B.V.},
title = {{Where science starts: spontaneous experiments in preschoolers' exploratory play.}},
volume = {120},
year = {2011}
}
@article{Cooper2012,
annote = {How do you recognize signs? It would be intractable to build a classifier for each one. Speech recognition has the same problem, and the solution was to recognize the sub-components (phonemes). A similar solution could work for sign language.
        
Three different types of sub-units:
- from appearance data
- from 2D tracking data
- from 3D tracking data
        
Learning not just synaptic placitiy, but more like exploring -- child as scientist paradigm
        
        
Sign-language has many more phonemes than spoken languages (40-50). Also, sign sub-units are parallel (handshape sub-units can be combined with all orienation sub-units, in theory)
        
Different signals can be recognized independently, and combined at the word level. Thus you can incoporate the correct invariances
                  
learning appearance based sub-units
        Features require segmentation of the hands, and knowledge of where the face is
+ Viola/Jones face detector
+ colored gloves are used
        
Location
+ sign localized relative to the signer
+ grid placed around face
+ each pixel is classifed as skin or not, and grid cells fire when 50% or more of th pixels have glove/skin
+ classifer trained to detect "On right shoulder" or "Face", etc. Features are simply binary (whether a grid cell fires or not)
        
Motion and hand-arrangement
+ use moment values of a frame, concatenated over time
+ motion classifiers are looking for changes i the moments over time
+ binary pattern (BP) describes the sign of change (increase or decrease) over time for each element in the feature vector
+ Features are chosen in this space 
                  
2D trakcing based on sub-units
+ appearance based classifiers require annotated data
+ This dataset uses hand and head trajectories
+  types of motion can be derived directly from deterministic rules on the x and y co-ordinates of the hand position
+ Location features: x and y coords are described relative to the signer
        
handshapre: hands are segmented using the motion dadta, and a skin model
+ HOG featuers are used
+ uses annotated sub-parts for training, and the sub-parts can be picked out by segmenting the motion data
+ classified with Random forests
        
HMMs can be used to build a model of each sign, using the code entires are the data (as determined by the classifier)
        
Also, Squential Patterns (SPs), which I don't really understand.          
          
Experiments
                
appearnce only: only ten examples of each sign, 1640 total. Sub-unit classifes are built using only data from four of the 10 examples
+ about 72% classification performance
        
With the 3D tracking data, you can do ok on generalizing across signers.},
author = {Cooper, Helen and Eng-Jon, Ong and Pugeault, Nicolas and Bowden, Richard},
file = {:Users/Brenden/Documents/Mendeley/Cooper et al. - 2012 - Sign Language Recognition using Sub-Units.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {data set,depth cameras,one-shot learning,part-based models,sequential pattern boosting,sign language recognition,signer independence,sub-units},
mendeley-tags = {one-shot learning,part-based models},
pages = {2205--2231},
title = {{Sign Language Recognition using Sub-Units}},
volume = {13},
year = {2012}
}
@article{Corcoran1970,
annote = {Evidence that different programs might underly recognition of handwritten vs. printed words.
      },
author = {Corcoran, DWJ and Rouse, RO},
file = {:Users/Brenden/Documents/Mendeley/Corcoran, Rouse - 1970 - An aspect of perceptual organization involved in reading typed and handwritten words.pdf:pdf},
journal = {Quarterly Journal of Experimental Psychology},
keywords = {handwriting,part-based models},
mendeley-tags = {handwriting,part-based models},
number = {3},
pages = {526--530},
title = {{An aspect of perceptual organization involved in reading typed and handwritten words}},
url = {http://www.tandfonline.com/doi/abs/10.1080/14640747008401930},
volume = {22},
year = {1970}
}
@article{Cornforth2012,
annote = {Most modeling techniques assume a particular structure in advance, ex HMMs
        
Others, like neural networks, are hard to interpret
        
But genetic programming can learn explicit, hand-crafted-like representations automatically without assuming a particular form of structure
                  
problem        
the inverse problem, of identiying the form and parameters of a system of ODEs, given a time series of variables
                  
inference        
genetic programming, with cross-over and mutation. Mutations occurs by sub-tree regeneration.
+ cross-over involves replacing a sub-tree with a sub-tree from the other model
        
in addition to optimizing fitness, you penalize the model by the age of the nodes - as a way to maintain diversity
        
Selection is chosen from a population of parents and children
        
It can be difficult to evolve constants in this way, so they do a local search iteration to help evolve constants
        
They have a two-component objective, but rather than choose a penalization costant, they track a Pareto front of models that represent the best-so-far trade-offs
        
 The number of hidden variables is assumed to be known in advance
                  
experiments
                
experiments where you try to recover equations from data, where the data is synethtic
        
equations are abstract, from physics, or chemistry, and typically involve just 2-3 variables
        
At most one or two variables are witheld at a time, and treated as hidden
        
There are many identifiability issues
        
      },
author = {Cornforth, Theodore W. and Lipson, Hod},
doi = {10.1007/s10710-012-9175-4},
file = {:Users/Brenden/Documents/Mendeley/Cornforth, Lipson - 2012 - Inference of hidden variables in systems of differential equations with genetic programming.pdf:pdf},
issn = {1389-2576},
journal = {Genetic Programming and Evolvable Machines},
keywords = {differential equations \'{a},genetic programming \'{a} ordinary,hidden variables \'{a} modeling,program induction,\'{a} symbolic identification},
mendeley-tags = {program induction},
month = nov,
title = {{Inference of hidden variables in systems of differential equations with genetic programming}},
year = {2012}
}
@inproceedings{Cottrell1990,
annote = {Gary Cottrell's "Holons" - a distributed representation that extends across the whole object
        
A non-linear autoencoder is trained on images. The hidden unit representaiton is then fed to a two-layer classifier, for identity/emotion/sex etc.
        
Generalization performance on emotion is not that impressive (about 40%)
        
An analysis of the hidden unit representations. Each hidden unit looks like white noise. If you look at the response across the whole dataset, and take the PCA, then you get whole face images -- much like the eigenfaces of Turk and Pentland},
author = {Cottrell, Gary W and Metcalfe, Janet},
booktitle = {{Advances Neural Information Processing Systems (NIPS) 3}},
file = {:Users/Brenden/Documents/Mendeley/Cottrell, Metcalfe - 1990 - {EMPATH Face, Emotion, and Gender Recognition using Holons}.pdf:pdf},
keywords = {classic AI,classic psychology},
mendeley-tags = {classic AI,classic psychology},
pages = {564--571},
title = {{{EMPATH: Face, Emotion, and Gender Recognition using Holons}}},
year = {1990}
}
@book{Coxhead2006,
author = {Coxhead, P},
file = {:Users/Brenden/Documents/Mendeley/Coxhead - 2006 - Introduction to Natural Language Processing.pdf:pdf},
pages = {1--13},
title = {{Introduction to Natural Language Processing}},
volume = {1},
year = {2006}
}
@article{Craik1972,
author = {Craik, F I M and Lockheart, R S},
file = {:Users/Brenden/Documents/Mendeley/Craik, Lockheart - 1972 - Levels of Processing A Framework for Memory Research.pdf:pdf},
journal = {Journal of Verbal Learning and Verbal Behavior},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
pages = {671--684},
title = {{Levels of Processing: A Framework for Memory Research}},
volume = {11},
year = {1972}
}
@book{Crockford2008,
annote = {        KEY TIPS
                
objects are passed by reference          
                
not including the "var' keyword makes
variables global
                  
          
          
GOOD OBJECT CONSTRUCTION        
var myObject = function () {
  var value = 0;
        
  var private1 = function () { ... };
  var private2 = function () { ... };
        
 return {
      public1  : function () { ... };
      public 2 : function () { ... };
   }
}( );
        
We return an invocation of a function, which is really an object with methods.
        
using the "new" operator, on an ordinary function, ends up clobbering global variables. Don't use it!
        
------
Good ideas: loose types
        
Bad ideas: global variables, which are fundamental in javascript. They are all tossed together
        
Numbers: no specific integer type
        
Strings: single or double quotes
can be created by adding, have length property
        
Return: if a return is not specified, a function returns "undefined"
        
Functions: 
- optional name
        
Objets:
Javascript has simple types (strings number booleans)
Everything else is an object, which are class-free
        
object litera:
var stooge = {
	"first-name" : "Jerome",
	"last-name" : Howard"
};
        
retrieved by stooge.first-name
                  
Objects are passed around by reference. They are never copied
                  
Prototypes        
When you make a new object, you can select what you want to be its prototype. Then you inherit all it's properties
If you add a new property to a prototype, it immediately becomes true of all its successors
        
"typeof" can be use to test type
                  
for in        
can loop over all property names in an object
                  
global abatement        
You can use a single global variable, and put everything in there
+ lessens footprint and bad interactions with other applications
                  
functions        
every function has a prototype and a constructor property
        
since they are objects, they can be used like any other value
        
var add = function(a,b) {
  return a + b;
};
        
the name of the function is anonymous
        
objects can have functions inside them
                  
nested functions:        
- inner functions have access to parameters and variables of outer functions
                  
function invocation        
invocation: called by ()
when used liek this, "this" is bound to the global object
(a method's inner function's "this" is notbound to the other function.. this is a mistake"
You can easily fix this by 
        
var that = this; inside a method
        
and calling "that" from 
                  
constructors (NEW, don't use)        
functions intended to be used with the "new" prefix. USE CAP CONVENTON
- he doesn't recommend using this convention
                  
arguments        
functinos are invoked with an "arguments" array. This way, you don't need to specify the number of arguments
                  
augmenting types        
by using prototypes, we can make a  new method avaiable to all functions
                  
scope        
- does not have block scope (variabales within parens only accesible within)
- but it does have funtion scope
                  
best to declare all variablesa function needsa at the top of the function body        
        
        GOOD OBJECT CONSTRUCTION
                
var myObject = function () {
  var value = 0;
        
  var private1 = function () { ... };
  var private2 = function () { ... };
        
 return {
      public1  : function () { ... };
      public 2 : function () { ... };
   }
}( );
        
We return an invocation of a function, which is really an object with methods.
        
The object can also have arguments, and if so, it is designed not to use the "new" prefix
                  
currying        
can build your own currying capability, which allows you to produce a new fucntion by combining a function and an argument
        
        inheritance:        
didn't read
                  
arrays        
can contain mixtures of values
has "splice" operator, which aremove cells
                  
style        
he uses a single global variable to contain an application or library
                  
defining global variables
                
defining outside a functoin
var foo = value; // global variable
        
window.foo = value; // can be inside a fuction
        
foo = value; // by not declaring it (implied global) THIS MAKES FOR WEIRD BUGS
                  
parseInt  is awful
        
awlays use ===
                
don't use ++
        
function foo () {}
is the same as
var foo = function foo () {};
      },
author = {Crockford, Douglas},
file = {:Users/Brenden/Documents/Mendeley/Crockford - 2008 - JavaScript The Good Parts.pdf:pdf},
isbn = {9780596517748},
publisher = {O'Reilly Media / Yahoo Press},
title = {{JavaScript: The Good Parts}},
year = {2008}
}
@article{Crump2013,
annote = {For RT tasks, this was the qualifying procedure:
        
Asked workers to type a sentence, and only allowed workers that did so less than 40 words per minute to cotinue.
        
----
        
Dropout rate:   10%-50%, depending on the the task
        
However, it did not interact with condition in the SHJ categorization studies. Thus, more people did not drop out in the harder conditions.
        
Did not replicate priming effects for very fast (<50ms) presentation times.  This is an important limitation of Turk studies
        
SHJ category learning task:
- the six different groups of the stimuli show different ease of learning. However, the stimuli could have just as easily been memorized in each case
- this is evidence that people learned soem form of "abstract representation"
        
Payment influences the sign-up rate, but it did not change the quality of reuslts in a category learning task
        
Results:
It was difficult to quantitatively replicate SHJ, but the relative order of the problems was basically replicated. However, Type 2 was similar to Type 4 in difficulty, but previous replication studies have also reported this. It may be due to how the instructions suggest verbal rules
        
---
                  
Ideas for good experiments:
        
Button to display task instructions if necessary
        
- use outlier analysis to remove outliers in RT data
        
- prompts to encourage fast responding, if a deadline is missed
        
- giving summary asessments of performance after blocks of trials, keeps people engaged and perhaps could help mitigate "label switching" in my Turing test tasks
        
- should monitor and report drop-out rate by condition. There is less social pressure to leave a task online
        
- can inforce that participants are located in the United States
        
- record workerIDs to make sure you can't participate twice. Using multipe workerIDs would violate amazon's terms of use
        
- ask them not to use pen and paper
(did you use any external learning aids?)
        
- 1/10 participants randomly received a bonus "$10", which is incentive to copmlete the task
        
- test on more than one brower/platform},
author = {Crump, Matthew J. C. and McDonnell, John V. and Gureckis, Todd M.},
doi = {10.1371/journal.pone.0057410},
editor = {Gilbert, Sam},
file = {:Users/Brenden/Documents/Mendeley/Crump, McDonnell, Gureckis - 2013 - Evaluating Amazon's Mechanical Turk as a Tool for Experimental Behavioral Research.pdf:pdf},
issn = {1932-6203},
journal = {PLoS ONE},
keywords = {classic psychology,experimental methods},
mendeley-tags = {classic psychology,experimental methods},
month = mar,
number = {3},
title = {{Evaluating Amazon's Mechanical Turk as a Tool for Experimental Behavioral Research}},
volume = {8},
year = {2013}
}
@article{Davis2007,
annote = {Problem of sketch understanding: sketch naturally, and have the computer understand what you have drawn
        
You can't just use affine transformations, like in simple character recognition
        
You start with the on-line data, and it converts it to a piece-wise linear approximation
        
It is challenging to learn about new domains -- what constitutes a symbol?},
author = {Davis, Randall},
doi = {10.1109/MC.2007.324},
file = {:Users/Brenden/Documents/Mendeley/Davis - 2007 - Magic Paper Sketch-Understanding Research.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
keywords = {handwriting,sketch-understanding},
mendeley-tags = {handwriting,sketch-understanding},
month = sep,
number = {9},
pages = {34--41},
title = {{Magic Paper: Sketch-Understanding Research}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4302611},
volume = {40},
year = {2007}
}
@article{Dayan1995,
abstract = {Discovering the structure inherent in a set of patterns is a fundamental aim of statistical inference or learning. One fruitful approach is to build a parameterized stochastic generative model, independent draws from which are likely to produce the patterns. For all but the simplest generative models, each pattern can be generated in exponentially many ways. It is thus intractable to adjust the parameters to maximize the probability of the observed patterns. We describe a way of finessing this combinatorial explosion by maximizing an easily computed lower bound on the probability of the observations. Our method can be viewed as a form of hierarchical self-supervised learning that may relate to the function of bottom-up and top-down cortical processing pathways.},
annote = {More technical description of the Helmholtz machine.
        
Science article has cleaner description with better applications.},
author = {Dayan, P and Hinton, G E and Neal, R M and Zemel, R S},
file = {:Users/Brenden/Documents/Mendeley/Dayan et al. - 1995 - The Helmholtz machine.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Automated,Feedback,Humans,Models,Pattern Recognition,Perception,Perception: physiology,Psychological,Stochastic Processes,Visual,neural networks},
mendeley-tags = {neural networks},
month = sep,
number = {5},
pages = {889--904},
pmid = {7584891},
title = {{The Helmholtz machine.}},
volume = {7},
year = {1995}
}
@article{deBoer2003,
author = {de Boer, B and Kuhl, P K},
journal = {Acoustics Research Letters Online},
pages = {129--134},
title = {{Investigating the role of infant-directed speech with a computer model}},
volume = {4},
year = {2003}
}
@article{DeDeyne2008,
abstract = {Features are at the core of many empirical and modeling endeavors in the study of semantic concepts. This article is concerned with the delineation of features that are important in natural language concepts and the use of these features in the study of semantic concept representation. The results of a feature generation task in which the exemplars and labels of 15 semantic categories served as cues are described. The importance of the generated features was assessed by tallying the frequency with which they were generated and by obtaining judgments of their relevance. The generated attributes also featured in extensive exemplar by feature applicability matrices covering the 15 different categories, as well as two large semantic domains (that of animals and artifacts). For all exemplars of the 15 semantic categories, typicality ratings, goodness ratings, goodness rank order, generation frequency, exemplar associative strength, category associative strength, estimated age of acquisition, word frequency, familiarity ratings, imageability ratings, and pairwise similarity ratings are described as well. By making these data easily available to other researchers in the field, we hope to provide ample opportunities for continued investigations into the nature of semantic concept representation. These data may be downloaded from the Psychonomic Society's Archive of Norms, Stimuli, and Data, www.psychonomic.org/archive.},
author = {{De Deyne}, Simon and Verheyen, Steven and Ameel, Eef and Vanpaemel, Wolf and Dry, Matthew J and Voorspoels, Wouter and Storms, Gert},
doi = {10.3758/BRM.40.4.1030},
file = {:Users/Brenden/Documents/Mendeley/De Deyne et al. - 2008 - Exemplar by feature applicability matrices and other Dutch normative data for semantic concepts.pdf:pdf},
issn = {1554-351X},
journal = {Behavior research methods},
keywords = {Adolescent,Adult,Female,Humans,Judgment,Male,Middle Aged,Netherlands,Reproducibility of Results,Semantics,Vocabulary},
month = nov,
number = {4},
pages = {1030--48},
pmid = {19001394},
title = {{Exemplar by feature applicability matrices and other Dutch normative data for semantic concepts.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19001394},
volume = {40},
year = {2008}
}
@article{deSa1998,
author = {de Sa, V R and Ballard, D},
journal = {Neural Computation},
pages = {1097--1117},
title = {{Category Learning Through Multimodality Sensing}},
volume = {10},
year = {1998}
}
@book{Dehaene2009,
address = {New York, NY},
annote = {Reading in the brain
main hypothesis: "neuron recycling" we can only read because we have systems closely adapted to related tasks, requiring only minimal tuning
- contrasts with the blank slate view of the mind
        
----
**Introduction**
- "neuron recycling hypothesis" - general visual processes are cooped for reading
- the average person knows more about a car than how their own brain works, with is a sad state of affairs
- only humans actively tech themselves things, develop culture. Why is that?
        
things that evolved are not perfectly formed
- blood vessels are IN FRONT of the retina
- note: what about a language of thought? how could this form?
- cannot explain where the Visual word form area (VWFA) comes from, since writing is culturally modern
        
British empiricists ("the blank slate brain")
- Lock, Hume, Berkeley
- implied that children in different cultures have little in common
- reading shows how learning can be rigidly specified by our genes
        
neuron recycling - the witting is mostly generic, but it can tolerate some variation
- lots of compromises on reading mechanisms
- words explode into millions of fragments
- only later are they brought back together
- math, art, music, etc. can be submitted to a similar analysis -- no evolved region of these abilities
        
**How do we read?**
- brain is not like a scanner
- fovea is the only high-resolution region
- smaller/larger text does not change writing speed
+ larger text is pushed further into the periphery
        
Rayner showed that if you are doing eye-tracking, and all of the text around your fixation is turned into XXXs, you don't even notice
- 50 ms fixation is enough to capture what you need
        
RSVP - people can read at enormous speed, since they don't have to move their eyes
        
problem of invariance
- cannot use simple template matching to recognize letters
- the visual system can reject some differences, while enhancing others
        
For some letters, like "R" and "r", the association between the capital and lower-case are basically arbitrary
- nervous system has learned invariants to case
- processing: hierarchy, where the word is a group of higher and higher-level units
- visual system snips out morphemes -- tested with priming.
- we do not process at the single letter level
- we also group by syllables
        
Two reading routes
1) phonological route (phonological recoding)
+ there can be priming at the level of sounds
2) direct lexical route
+ need this route, since "board" and "bored" sound the same
        
In Italian, letters map directly onto phonemes
- but in English, we have too many phonemes
+ but you could map each sound to just one letter combo ("task" vs. "taxi")
++ but what about coarticulation?
        
Chinese
- tons of syllables
- characters stand for words (morphemes) and sound markers
        
Deep dyslexia
- you can mix up "meat" and "ham", due to semantic association
- shows pronunciation route is damaged
Surface dyslexia
- can pronounce regular words, but hopeless at irregulars (no lexicon route)
        
neural net account: while one route might be possible computationally, most researchers now believe in two (at least)
- should look at biology to help distinguish accounts
        
We know 40-50K words
        
-interactive activation model of reading, is a good example of Selfridge's pandemonium model
- recognition of words take roughly constant time (not a serial process)
        
Word superiority effect
- discriminating "D" vs. "T" is easier in context ('HEAD' vs. 'HEAT')
- this shows that letter perception is not purely stagewise
- must be interactive, top-down process
        
- neighboring words in orthography space can help processing
- mostly we don't notice ambiguities
        
**The brain's letterbox**
- selective letter perception deficit (1887)
+ but patient could trace lines, recognize objects, etc.
+ could also recognize numbers still!
+ also, he could still write!
++ but could still recognize character by tracing contours, NOte, by the motor program?
        
pure alexia: impaired reading without writing
        
- Cohen and Dehaene: overlaid MRI images of lesioned brains, to pinpoint the deficit area
        
VWFA: left occipital-temporal area (next to the fusiform gyrus)
- information for reading seems to be funneled here first
        
Petersen et al. Language PET experiment
- revealed unique VWFA activity
- all people Dehaene scanned, they find letterbox
- reacts to written words, ignores spoken words
+ between FFA and object area (LO?)
        
- lateralization of words (left) vs. faces (right) is evident with 150 ms, by MEG (direct cortex recording found this too)
        
position invariance
- regardless of left/right retinal field, all the activity moved to left at 160-200 ms
- prediction: damage to corpus callosum leads to lateralize reading deficit (Reading is slower for everyone on the left of fixation)
        
case invariance 
- initial evidence from Farah and Polk
- use fMRI adaptation
- subliminal presentation
- same level of adaptation "HoTel" to "Hotel"
        
hierarchy of abstractors
- letters by letter slots
- can recognize shared letters, position changed from "anger" vs. "range" 
- at high levee, more word based
        
how do we know this region is tuned for reading?
- case invariance provides strong evidence (quite arbitrary)
- in VWFA, "G" to "g" as "O" to "o"
- responds better to plausible non-words than bad non-words
* does not respond well to foreign scripts
- same area (VWFA) responds to different cultural alphabets (Chinese)
- VWFA must be turned to sub-structure of Chinese characters, in a hierarchical way
- Chinese characters may not be holistic
- lots of outgoing connections from VWFA, particularly to language regions
see: Pammer et al. (2004) visual word recognition: the first second
        
neurological evidence for phonological (sound) and lexical/semantic (meaning) route
- planum temporal is important for phonological recoding
- left middle temporal cortex responds to semantic associates (Damasio's "convergence zones")
- words also seem to be embodied (Friedman and Pulvermuller, 2005, "bite" vs. "kick")
- cross-language differences are a matter of degree, not type
+ Italian has stronger phonological route
+ also depends on the word's regularity
        
** the reading ape **
- VWFA is in Brodmann's 37, which is clearly used for object recognition
- IT is critical for object recognition invariance
+ need more than a bar/edge
+ highly selective
+ big receptive fields
+ rotation activates nearby, over-lapping columns
+ some cells are highly rotation invariant
        
Tanaka - "neuronal alphabet" of shapes
- simplification method, where a picture of an apple is reduced to the limiting stimuli that makes a strong reaction, like a circle with a stick on top
- there is a systematic layout: neighboring neurons tend to have similar shapes (defining extended columns along service)
- combinatorial, sparse code
+ can change by adding/removing features
- striking correspondence with IT neuron selective shapes and our letters ("proto-letters")
- useful for "T","Y","F" corners of 3D objects
- these are invariant features used to encode shapes, or identify geons (Biederman)
* - we did not invent our letter-shapes, they were long dormant in our cortex for millions of years
- are these shapes genetic code or learned? (lots of data, probably learned)
- invariance over time - these neurons track temporal correlations
- can also learn arbitrary associations
        
** RADICAL HYPOTHESIS: "neuron recycling" we can only read because we have systems closely adapted to related tasks, requiring only minimal tuning
- contrasts with the blank slate view of the mind
        
two major constraints
1) slow evolution of cortical resources
2) rapid cultural adaptation of writing to fit these resources
        
receptive field x2 or x3 at each step, increase in size
1. LGN - local contrats
2. V1 - oriented bars
3. V2 - contour detection, "T" vs. "Y"
4. V4 - letters (case-sensitive)
(already responds to these shapes before training)
5. V8 - case invariance (cultural learning)
fMRI evidence (not entire retina)
6. VWFA - bigram detection "EN" for "rENt" and "mEaN"
        
Open bigrams
- tradeoff between two specific and just single letters
- tested with priming studies (Grainger)
- can read sentences where every letter is mixed up, except the first and last (this is because list of bigrams is still pretty good)
- does not uniquely distinguish all words, but maybe local receptive fields helps (2 letters away at most, for bigram)
        
must also have "top-down" connections
see (word superiority effect)
- need about half a square centimeter of cortex all the way up
- you don't get a space explosion, from the combinatorics, if you allocate space to only the most needed higher-level features
        
Location of the VWFA
-gradient of location of specialized visual area (FFA, PPA, VWFA) based on eccentricity (big/small object)
- left bias because of language, or left bias for fine-discriminations
- simply the "Best fit" area, and it can change if another is available
        
**inventing reading**
- black text on white paper is optimal contrast
- usually around 3 strokes per charter
+ allow soft a single neuron to respond to a character
- certain junctions "T","L","X" are common across alphabets
+ correlates with their presence is natural images
- drawings only work because we have cells that respond to the properties they have
- earliest painting (33K years ago) appeared around the earliest writing symbols
        
- writing appeared around 8000 BC
+ clearly related to numbers at the beginning
+ Egyptioan hieroglyphics seemed to build on simple objects (not places)
+ Mayans used faces
+ places are faces (right hemisphere) are far away form the VWFA, and this system didn't seem to work very well for them
        
- pictorial systems are progressively simplified 
- phonology between word and symbol, can also play a role
        
- future systems took their core characteristics 
- cuneiform alphabets in 1300 BC gave rise to modern alphabets
- Greeks invested the alphabet as we know it, and had complete translation of speech sounds (not image based)
+ compatible with the VWFA, and link to speech sounds
        
** Learning to read**
Frith's (1985) stages
1) "pictorial" words are objects (just a few logos are recognized, tend to be tricked by visual resemblance)
2) grapheme-to-phoneme - links letter groups to sounds
+ can sound out words
+ acquire explicit representation of phonemes (know how many are in a word)
+ phonemes acquired at the same time as reading is learned
+as reading improves, more fMRI activation in the letterbox area
(lateralized act. appears around age 8)
+corpus callosum is thicker in literatures, learning to read changes brain chemistry
        
cortical competition - is something lost by learning to read? no evidence yet 
+ FFA used for expertise? some evidence experts on other things are worse at faces
synesthesia - color area (V4) is near VWFA, perhaps this is a fair of neuronal recycling?
        
whole-word method - maps word to meaning
+ word superiority effect as evidence
+ we recognize letters, but in parallel 
        
Learning to read
+ trace letters to learn how they differ
+ learn phonemes (this is not automatic)
        
Dyslexia
- most common improvement is conversion to phonemes -- a speech deficit:
+ caused by low-level deficits?
+ disoragnized temporal lobe?
        
Exner's area (motor cortex): Chinese dyslexics have lower activity here -- motor memory play a bigger role here?
        
**Reading and symmetry**
- children often write mirror-style for a few years (can't tell between letters and mirror images)
- we don't encode left-right mirror distinction berry well (which way does lincoln face on the penny?)
        
Corballis - two hemispheres store visual learning, 
+ but transferring learning across the corpus callosum inverts the image, so you store the mirror image on the other side
we must turn this off to read
- explains confusion of left/right hand in young children as well
+ spontaneous generalization of IT cells in monkeys, to the mirror image, supports this idea
+ lesioning the corpus callosum makes learning symmetry easier
+ lesion studies - ventral stream seems blind to mirror-reversal 
+ need dorsal stream to help
++ but not when these patients read! VWFA breaks symmetry
        
* we must unlearn spontaneous mirror reveral
* Montessori method for learning alphabet - trace letters with finger
+ helps break the symmetry
+ Gentas: leads to faster learning
        
** Towards a culture of neurons **
        
Other parts of culture that obviously co-opted some other brain area
- classifying animals
- number
- arts
- religion
        
Why are the humans the only ones that have culture?
- you need a place in the brain to recombine idea, invent new things
- his best guess of the pre-frontal cortex (MD system)
      },
author = {Dehaene, Stanislas},
publisher = {Penguin Books},
title = {{Reading in the brain}},
year = {2009}
}
@article{Dehaene2011,
abstract = {Reading systematically activates the left lateral occipitotemporal sulcus, at a site known as the visual word form area (VWFA). This site is reproducible across individuals/scripts, attuned to reading-specific processes, and partially selective for written strings relative to other categories such as line drawings. Lesions affecting the VWFA cause pure alexia, a selective deficit in word recognition. These findings must be reconciled with the fact that human genome evolution cannot have been influenced by such a recent and culturally variable activity as reading. Capitalizing on recent functional magnetic resonance imaging experiments, we provide strong corroborating evidence for the hypothesis that reading acquisition partially recycles a cortical territory evolved for object and face recognition, the prior properties of which influenced the form of writing systems.},
annote = {VWFA: strictly visual response
        
However, there appears to be a mixture of reading and non-reading functions for this region. Could this just be top-down signals from higher level language areas?
                  
neuron recycling hypothesis
- the brain cannot have evolved a dedicated mechanism for reading
-brain must use resources that evolved for another purpose
- it's not a tabula rasa, but prior constraints
- cultural form of writing must have evolved in accordance with the brain's learnability constraints, convering on a small set of symbol shapes that can be optimally learned
        
proposal:
- area is involved in extracting configs of object contours, which for patterns like "T", "L", "Y"
+ non-accidental properties, which are highly invariant across viewpoints
+ reading is speifically impaired when line configurations are deleted
+ VWFA overlaps with a subpart of the ventral stream that is active to line junctions
+ all of the world's writing systems maek use of similar junctions, with the frequency pattern of natuarl scences
        
This clarifies the vexing question of where the specialization comes from
+ lateralization of VWFA is correlated with the lateralization of spoke language processing
+ firt site to be invariant to case
+ also invariant to printed versus handwritten words
        
VWFA performs computations that are unique to reading learned sripts, not generic visual recognition
+ note: does this mean motor rep. might be better for new scripts?
        
Other forms of specialization
+ sensitive to bigram frequency
+ orthographic priming
+ distinguished between words and mirror images
        
General hiearchy of feature processing
        
VWFA has a higher activation for known rather than unknown scripts, although it is also active for line drawing
        
VWFA also appears to be a major site of literacy acquisition. 
+ with expertise, there is increased activation in the VWFA
+ there is also a decrease in activation with faces, houses, objects, etc.
        
For a new script, VWFA increases its response after just a few reading sessions
        
        
Can be active for braille
        
      },
author = {Dehaene, Stanislas and Cohen, Laurent},
doi = {10.1016/j.tics.2011.04.003},
file = {:Users/Brenden/Documents/Mendeley/Dehaene, Cohen - 2011 - The unique role of the visual word form area in reading.pdf:pdf},
issn = {1879-307X},
journal = {Trends in Cognitive Sciences},
keywords = {Brain,Brain Mapping,Brain: anatomy & histology,Brain: physiology,Diagnostic Imaging,Humans,Language,Neurons,Neurons: physiology,Reading,Visual Pathways,Vocabulary,handwriting,neural basis},
mendeley-tags = {handwriting,neural basis},
month = jun,
number = {6},
pages = {254--62},
pmid = {21592844},
publisher = {Elsevier Ltd},
title = {{The unique role of the visual word form area in reading.}},
volume = {15},
year = {2011}
}
@article{Dehaene2005,
abstract = {How is reading, a cultural invention, coded by neural populations in the human brain? The neural code for written words must be abstract, because we can recognize words regardless of their location, font and size. Yet it must also be exquisitely sensitive to letter identity and letter order. Most existing coding schemes are insufficiently invariant or incompatible with the constraints of the visual system. We propose a tentative neuronal model according to which part of the occipito-temporal 'what' pathway is tuned to writing and forms a hierarchy of local combination detectors sensitive to increasingly larger fragments of words. Our proposal can explain why the detection of 'open bigrams' (ordered pairs of letters) constitutes an important stage in visual word recognition.},
annote = {        ---
What is the level before the detection of words?        
        
Proposal for encoding: open bigrams
-- "TICS" is encoded by "TI","TC", etc. where the order of letters is maintained, but intervening letters are allowed
        
Another proposal:
-- detectors for local combinations of letters, like a `N one or two letters left of A'
-- This can look like "open bigrams", since the letter detectors themselves have some degree of translation invariance
                  
How are letters detected?        
-- increasingly more abstract features -- like a feature net
-- lines, combinations of lines, case-specific letter dectors, case-invariant, etc.
        
Is there an explosion of featuers?
-- Higher-levels do need lots of features, but they also have larger receptive fields
                  
How is this studied?        
-- you can use fMRI (adaptation) to see how different areas of the visual cortex respond to word strings. Thus, you can see where case-sensitivity arises, or bigram sensitivity, etc.
        
Also: mirror generalization. Many cells in visual cortex (like IT) respond to objects and their mirror image. If you train a monkey to identify a wire frame, a cell responsive to this will spontaneously generalize to the mirror. This could explain why many children write their names backwards.},
author = {Dehaene, Stanislas and Cohen, Laurent and Sigman, Mariano and Vinckier, Fabien},
file = {:Users/Brenden/Documents/Mendeley/Dehaene et al. - 2005 - The neural code for written words a proposal.pdf:pdf},
institution = {INSERM unit 562, Cognitive Neuroimaging, Service Hospitalier Frederic Joliot, CEA/DRM/DSV 4 Place du General Leclerc, 91401 Orsay cedex, France. dehaene@shfj.cea.fr},
journal = {Trends in Cognitive Sciences},
keywords = {embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
number = {7},
pages = {335--341},
pmid = {15951224},
publisher = {Elsevier},
title = {{The neural code for written words: a proposal.}},
volume = {9},
year = {2005}
}
@incollection{DeJong,
annote = {Main idea: substitute a knowledge base for the larget training sets needed by other machine learning systems
        
Pros:
- can learn from one example
- richly structured representaitons
        
Cons:
- Need an initial functional specification of the concept
- Does not work with the data in their raw form, and must have feature pre-processing
- Does it actually work on real examples? 
+ for all of the examples I have seen, the prior knowledge base has been hand-engineered to work for the toy example
-Does it account for graded category structures? 
- Only classical definitional concepts?
- Is the system robust? what if the rules don't prove the concept?
        
        
-------
Explanation based learning (EBL): acquiring general knowledge through analysis of a few specific episodes
        
thus, very relevant to one-shot learning
        
Uses very few examples (often one) to define the boundary of a concept
- concept is determined by a domain-theory-guided inspection
        
Concepts are proofs in a first-order calculus language, of how to go from object representations to "true or false" for the concept
        
Background knowledge is implemented as "theorems" that you can use to prove other things
        
Example:
- caveman views another cooking a drumstick on a stick over a fire
        
+ generalizes: knows he could do it too, not specific to this drumstuck, or this fire, etc.
        
There are very few truly creative advances made, and most people average less than one
+ EBL is will do the creative aspect, but simply try to understand the demonstration
        
similarity based learning: finding features to help classify examples
1) requires many examples
2) need for very little domain knowledge
This is the dominant paradigm in AI and cognitive science
Advantage: can be done in any domain
Disadvantage: you need many examples
        
Explanation based learning
        
EBL requires a functional specification of the concept:
a cup, means, you can drink from it
+ is this cheating?
        
EBL observers and example of the object, usually in the form of a semantic network with properties and object nodes
        
Goal: examine object in light of background knowledge, to try to learn a concept much more general than specific instance
        
Generalitzatinos could be done syntactically, or with regards to semantic too, and for EBL it is done ain a way that will never over-generalize (but can undergeneralize)
                  
Generalizing
                
Irrelevant feature elimination
-for cup, color and owner can be removed
        
Identity elimination
 - remove dependence on specific handles, and replace with variables
- "lifting", where concepts are defined by form, not identity
        
Operationality pruning
- if "liftable" is a feature of a cup, and there is a procedure for proving "liftable", we can replace the feature with the prcedure instead
+ this leads to greater genearlity
        
Structural generalization
More complex, structural changes, and requires a sub-hiearchy
- Disjunctive augmentation: 
Could replace "stable" featuer with a disjunction of two procedure for producing stability
- Temporal generalization
example provides one ordering, but there could be others
- Number generalization
If a tower contains three red blocks, the concept might also include four red blocks
+ difficult to formalize, because repeated structure in the network is not identical in each case
        
Various formulations, but they all have problems
        
Note: Also, I'm not sure how background knowledge works?
        
        
        
        What the formalisms miss- A single tough argument to a predicate, which cannot be proven, and derail on of these generalization operations
- so, something might be operational for some arguments but not al
+ would this sink all the predicates?
                  
Future directions
                
What exactly is operationality, and how do you compute it?
        
You would like domain-general inference, where you could plug in theoretical knowledge from any domain. But is this possible?
        
      },
author = {DeJong, Gerald},
booktitle = {Exploring Artificial Intelligence: Survey talks from the National Conferences on Artificial Intelligence},
keywords = {EBL,one-shot learning},
mendeley-tags = {EBL,one-shot learning},
pages = {45--81},
title = {{An introduction to explanation-based learning}},
year = {1988}
}
@article{Dejong1986,
annote = {Mitchell et al.'s EBL system:
        
-Learns sufficient conditions for being an example of a concept
- explanations are proof trees composed of horn-clause inference rules, which conclude with the example on the top
        
1) Goal concept: definition of concept in high-level properties, like a cup is an "open vessel" that is "stable" and "liftable"
        
2) Training example: Representation of a training example in lower level features
        
3) Domain theory: defines some of the high-level properties in terms of other properties
        
4) Operationality criterion: how the concept is represnted so it can be efficiently recognized
        
How do we make proof trees?
- goal regression: 
        
Problems: for most definitions of a concept cup, like liftable, drinkable, etc. a pail would also be listed, since you can do these thigns separately, but not together
        
      },
author = {Dejong, Gerald and Mooney, Raymound J},
file = {:Users/Brenden/Documents/Mendeley/Dejong, Mooney - 1986 - Explanation-Based Learning An Alternative View.pdf:pdf},
journal = {Machine Learning},
keywords = {EBL,abstract,adequately capture certain aspects,and kedar-cabelli presented a,approach to machine learning,classic AI,concept acquisition,development,explanation-based learning,for a number,framework for the explanation-based,in the last issue,keller,machine learning,of systems,of the systems under,of this journal mitchell,the framework does not,unifying,while it works well},
mendeley-tags = {EBL,classic AI},
pages = {145--176},
title = {{Explanation-Based Learning: An Alternative View}},
volume = {1},
year = {1986}
}
@article{Dempster1972,
author = {Dempster, A P},
journal = {Biometrics},
pages = {157--175},
title = {{Covariance Selection}},
volume = {28},
year = {1972}
}
@article{Dempster1977,
author = {Dempster, A P and Laird, N M and Rubin, D B},
file = {:Users/Brenden/Documents/Mendeley/Dempster, Laird, Rubin - 1977 - Maximum Likelihood from Incomplete Data via the EM Algorithm.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
number = {1},
pages = {1--38},
title = {{Maximum Likelihood from Incomplete Data via the EM Algorithm}},
volume = {39},
year = {1977}
}
@inproceedings{Deng2009,
author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, L},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR.2009.5206848},
file = {:Users/Brenden/Documents/Mendeley/Deng et al. - 2009 - ImageNet A large-scale hierarchical image database.pdf:pdf},
isbn = {978-1-4244-3992-8},
title = {{ImageNet: A large-scale hierarchical image database}},
year = {2009}
}
@article{dewar-xu10,
author = {Dewar, K and Xu, F},
file = {:Users/Brenden/Documents/Mendeley/Dewar, Xu - 2010 - Induction, overhypothesis, and the origin of abstract knowledge.pdf:pdf},
journal = {Psychological Science},
keywords = {attentional learning,one-shot learning,shape bias},
mendeley-tags = {attentional learning,one-shot learning,shape bias},
number = {12},
pages = {1871--1877},
title = {{Induction, overhypothesis, and the origin of abstract knowledge}},
volume = {21},
year = {2010}
}
@incollection{Dickinson2004,
annote = {People can recognize an object or scene even if all of it's visual featuers are different. How do we do this?

        
History of computer vision alternates between bringing images closer to our model representations, or bringing our representations closer to our images. 

        
We need to solve the hard proble of image (shape) abstraction.

        
Our current benchmarks aren't very helpful for diagonising the failure modes.

        
-------------
Can recognize an object or scene, even if they completely change at the level of local features
- local features, when grouped and then abstracted, do salient parts and configurations begin to emerge

        
- grouping of featuers together is necessary but not sufficient for categorization
- you might want to match image feature with model features, but then the model can be little more than just a collection of features

        
- this abstraction is the most challenging problem facing categorization researchers

        
avoiding the abstraction problem

        
in the 70's, people focused on generic 3-D shape representations
+ like generlized cylinders or geons

        
main challenge was the representational gap: difference between low-level features can can be reliably extracted and abstrcat nature of the model components
+ gap was closed by bring images closer to the models (reducing clutter, removing markings, etc.)
+ unsatisfying for obvious reasons

        
many important principles, now be re-discovered:
1) importance of shape
2) importance of viewpoint invariant, 3D shapes
3) importance of symmetry and non-accidental relations
4) shareable parts and relations to manage complexity
5) hierarhical representations (part/whole) hierachies
6) variable structure, in the number of parts, identities, attachments, etc.

        
Found more effective to build 3D models of the exemplars, rather than a the category level -- so one can actually fit the image

        
Another approach build highly-detailed 3D models, with detail at the level of images, which were created with a turnatble and a camera
+ nearest neighbor search in database, where each object has dense set of views
+ can recognize only exemplar objects

        
In the 2000s, re-discovered some of the principles of the 70s, like Fei Fei's scale-invariant part model for one-shot learning
+ moving closer to the image
+ however, we lost something, since today's models now have no chance at recognizing line drawings
+ can only recognize categories where exemplars share the same image-based (SIFT like) features

        
Hierarchical tree-based models based on parts, like a decomposition of a horse into image fragments
+ if we want to share parts, can we learn them, and how do we learn them so they are general enough to be useful?

        
Summary: we have moved images up the abstraction hierarchy, and moved models down to the image levee, in an effort to solve real problems
- images features cannot be so tightly coupled to model features if we want to make "real" progressf

        
Section: The abstraction of shape

        
Structural description models suffered from the problem that contours in the image don't necessarily correspond to contours of the models
- it is unrealistic to believe that the feature comprising these models could be directly observed in the image
- frameworks were abandoned because of their inability to recognize real images
- geons provide a powerful set of regularizing constraints when extract edge data, but they aren't used to help construct the edge features
   + treated more as a bottom-up pipeline

        
If you keep a large database of low-resolution object images, with enough models (like 80 million), you can get good performance by just covering the space densely enough

        
          
The abstraction of structure

        
        
- finding the primitives is only part of the problem, since the prim. configuration must also match the configuration of the correct model
- for most categories, part-structure is variable
+ acknowledged long ao, but it is very hard
+ AND/OR graph aproach, Zhu and Mumford (275), where a grammar provides a structural abstraction
- can you get hierarchy from part-based adjacnec graph?
+ have to solve a graph matching problem
+ compare with "lowest common abstraction"
+ graph-edit distance, spectral methods, etc. try to overcome the match image feature to model feature approach

        
          
segmentation, grouping and dthe role of models: beyond target recognition

        - segmentation algorithms, trying to incorporate prior knowledge, tend to bypass mid-level object knowledge and use entire objects... but this clearly doesn't scale
- attention seems to have been drawn away from learning generic parts and relations
+ however, some try to learn them from local image statistics, like HMAX or convolutional networks

        
          
expanding model score: objects to scences:

        
        
classic work on knowledge-based scene analysis, but very slow and specialized, and died off in early 90s

        
resurgence:
ie., Torallaba using scene context (global image features) as cues for recognition
          
- useful if object identity is ambiguous
          
- little work has tapped into general semantic knowledge, likt that present in large text corpora
          

        
        
          
managing search complexity: the case for 3D models
        

        
3D models, rather than a collection of 2D appearances, are coming back in fashion

        
          
identifying our shortcomings: the need for new benchmarks

        
        
Datasets do not systematically parameterize things like scale, rotation, etc. so it's hard to diagnose an algorithm's shortcomings

        
should have different test stuites, one for viewpoint, another illuminations etc.
- without this , we might be distrcted from focusing on the particular issues that need attention

        
          
Conclusion

        
original community's legacy from the 1970s
- rich object representations, with coarse 3D shapes for objets
- only worked for contribed scenes, since didn't have good image abstraction
- made a lot of progress on exemplar recognition, now wants to return to categorization

        
Exemplar-based apperancemodels are now trying to tackle mmore challenging categorization tasks, with better solution

        
But problem we still haven't solved: image (or shape) abstraction},
author = {Dickinson, Sven},
booktitle = {Object Categorization: Computer and Human Vision Perspectives},
editor = {Dickinson, S. and Schiele, B. and Tarr, M},
file = {:Users/Brenden/Documents/Mendeley/Dickinson - 2009 - The Evolution of Object Categorization and the Challenge of Image Abstraction.pdf:pdf},
keywords = {part-based models},
mendeley-tags = {part-based models},
pages = {1--58},
publisher = {Cambridge University Press},
title = {{The Evolution of Object Categorization and the Challenge of Image Abstraction}},
year = {2009}
}
@article{Diesendruck2003,
abstract = {Children tend to extend object names on the basis of sameness of shape, rather than size, color, or material-a tendency that has been dubbed the "shape bias." Is the shape bias the result of well-learned associations between words and objects? Or does it exist because of a general belief that shape is a good indicator of object category membership? The present three studies addressed this debate by exploring whether the shape bias is specific to naming. In Study 1, 3-year-olds showed the shape bias both when asked to extend a novel name and when asked to select an object of the same kind as a target object. Study 2 found the same shape bias when children were asked to generalize properties relevant to category membership. Study 3 replicated the findings from Study 1 with 2-year-olds. These findings suggest that the shape bias derives from children's beliefs about object kinds and is not the product of associative learning.},
author = {Diesendruck, Gil and Bloom, Paul},
file = {:Users/Brenden/Documents/Mendeley/Diesendruck, Bloom - 2003 - How specific is the shape bias.pdf:pdf},
issn = {0009-3920},
journal = {Child development},
keywords = {Association Learning,Child,Child Development,Female,Form Perception,Humans,Male,Preschool,Random Allocation,shape bias},
mendeley-tags = {shape bias},
number = {1},
pages = {168--78},
pmid = {12625443},
title = {{How specific is the shape bias?}},
volume = {74},
year = {2003}
}
@article{Doumas2008,
abstract = {Relational thinking plays a central role in human cognition. However, it is not known how children and adults acquire relational concepts and come to represent them in a form that is useful for the purposes of relational thinking (i.e., as structures that can be dynamically bound to arguments). The authors present a theory of how a psychologically and neurally plausible cognitive architecture can discover relational concepts from examples and represent them as explicit structures (predicates) that can take arguments (i.e., predicate them). The theory is instantiated as a computer program called DORA (Discovery Of Relations by Analogy). DORA is used to simulate the discovery of novel properties and relations, as well as a body of empirical phenomena from the domain of relational learning and the development of relational representations in children and adults.},
annote = {Relational concepts, like "above", "below", "whtin" must be learend
        
The same element must represent the relationship, and be able to engage in different bindings
        
Relational shift: match the objects of two relations by alginign the roles, not the objevts themselves (Gentner and Rattermann, 1991)
        
How can structure-based representations be learned from examples?
+ cited as significant limitation of structure-based accounts
        
Lots of work detecting featural invariatns, but what about relatoinal invariants?
                  
thesis: The article presents a theory of how structued, relational representations can be  learned from unstructure examples
        
        
      },
author = {Doumas, Leonidas A A and Hummel, John E and Sandhofer, Catherine M},
doi = {10.1037/0033-295X.115.1.1},
file = {:Users/Brenden/Documents/Mendeley/Doumas, Hummel, Sandhofer - 2008 - A theory of the discovery and predication of relational concepts.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Cognition,Humans,Learning,Models,Psychological,Psychological Theory},
month = jan,
number = {1},
pages = {1--43},
pmid = {18211183},
title = {{A theory of the discovery and predication of relational concepts.}},
volume = {115},
year = {2008}
}
@incollection{Duchi2008,
author = {Duchi, John and Gould, Stephen and Koller, Daphne},
booktitle = {Conference on Uncertainty in Artificial Intelligence (UAI 2008)},
file = {:Users/Brenden/Documents/Mendeley/Duchi, Gould, Koller - 2008 - Projected Subgradient Methods for Learning Sparse Gaussians.pdf:pdf},
keywords = {GGM,graphical models,sparsity},
mendeley-tags = {GGM,graphical models,sparsity},
title = {{Projected Subgradient Methods for Learning Sparse Gaussians}},
year = {2008}
}
@article{DueTrier1996,
annote = {Survey of single digit, off-line character recognition. What is the right set of features?
        
Generally you start with gray-level
1) You can convert to binary
2) You can also thin the character, so it is a thin as possible (one-pixel wide)
3) Or you can get the contours of the character
        
You may want some rotation, or skew-invariance, but not total invariance (upside 6 is a 9, or mirror images)
        
Ideas for recognition:
Template matching -- Have one, or a series, or prototype images for a character. Pick the one with highest accuracy.
Zoning -- Bin an image into regions. Then for each region, calculate the mean brightness
                  
Based on the character skeleton:
                
1) Templates will not work well, since character is so thin.
2) Can transform with affine functions
3) 
                  
              },
author = {{Due Trier}, O and Jain, A K and Taxt, T},
file = {:Users/Brenden/Documents/Mendeley/Due Trier, Jain, Taxt - 1996 - {Feature extraction methods for character recognition - A survey}.pdf:pdf},
journal = {Pattern Recognition},
keywords = {handwriting},
mendeley-tags = {handwriting},
number = {4},
pages = {641--662},
title = {{{Feature extraction methods for character recognition - A survey}}},
volume = {29},
year = {1996}
}
@article{Duncan2010,
abstract = {A common or multiple-demand (MD) pattern of frontal and parietal activity is associated with diverse cognitive demands, and with standard tests of fluid intelligence. In intelligent behaviour, goals are achieved by assembling a series of sub-tasks, creating structured mental programs. Single cell and functional magnetic resonance imaging (fMRI) data indicate a key role for MD cortex in defining and controlling the parts of such programs, with focus on the specific content of a current cognitive operation, rapid reorganization as mental focus is changed, and robust separation of successive task steps. Resembling the structured problem-solving of symbolic artificial intelligence, the mental programs of MD cortex appear central to intelligent thought and action.},
annote = {MD systems are undoubtedly involved in cognitive control. But specifically, planning multi-component behaviors.
        
---
Many cells in prefrontal cortex discriminate targets from nontargets. (up to 50%)
        
It can change targets very rapidly.
        
For different stages of a task, there can be completely different patterns of activity.
        
Sustained activity seems to reflect the total complexity of the currently maintained task plan. Activtiy increases with each new added rule.
        
      },
author = {Duncan, John},
doi = {10.1016/j.tics.2010.01.004},
file = {:Users/Brenden/Documents/Mendeley/Duncan - 2010 - The multiple-demand (MD) system of the primate brain mental programs for intelligent behaviour.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Animals,Brain,Brain: anatomy & histology,Brain: physiology,Cognition,Cognition: physiology,Executive Function,Executive Function: physiology,Frontal Lobe,Frontal Lobe: physiology,Humans,Intelligence,Intelligence: physiology,MD system,Magnetic Resonance Imaging,Neuropsychological Tests,Parietal Lobe,Parietal Lobe: physiology,Primates,Problem Solving,Problem Solving: physiology,Psychomotor Performance,Psychomotor Performance: physiology,User-Computer Interface},
mendeley-tags = {MD system},
month = apr,
number = {4},
pages = {172--9},
pmid = {20171926},
publisher = {Elsevier Ltd},
title = {{The multiple-demand (MD) system of the primate brain: mental programs for intelligent behaviour.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20171926},
volume = {14},
year = {2010}
}
@book{Duncan2010a,
annote = {Summary: The MD (multiple demand) system of the frontal and parietal lobes is at the heart of human intelligence. It assembles mental programs of thought. A program is a collection of cognitive enclosures (like innate release mechanisms) that combine to form complex action.
        
The basis for "g" and intelligence testing suggest the MD system might be are the core of g. Neural network models may be good at vision and associate learning, but they do not explain the sequential, structured nature of thought very naturally.
        
--
        
Ch 1
Around World War 2, there was a focus on studies of attention and information processing
-- Stroop
-- Cherry, with processing of two simultaneous speech messages
-- Wason; confirmation bias, it is very hard to compe up with the role "3 increasing numbers" (p. 18)
        
Ch 2
About Spearman's pioneering working in the early 1900s. "Intelligence" as a word has no true meaning, it's simply about what we call things, not about what it means in the world.
Spearman found that academic measures were strongly correlated with a basic ability to do perceptual judgments. 
Ravin's matrices is the task most strongly correlated with "g"
Competing theory is that the brain is a bunch of specialized modules, many of which are used for a given task. Thus, of course these correlated. But this doesn't explain why just Raven's matrices is so predictive.
        
Ch4 Making the link
Duncan was testing potential bus drivers on cognitive skills. The same subjects have trouble on embedded figure task, find it difficult to follow instructions. Theory was this is g, a function of the frontal lobes.
Luria made a similar discovery
Although control is distrubted with frontal lobe damage, many thought it doesn't affect IQ or intelligence. But many of these tests looked at crystalized intelligence
Duncan tested frontal lobe patients with high IQ. They scored poorly on Raven's matrices.
Multiple demand circuit involves lateral frontal and parietal regions
You have to lose a lot of frontal lobe before the effects are severe.
        
Ch5 The Demystification of Thought
Duncan argues for a role of the frontal lobes like traditional models in good old fashion AI. There is a goal, and the mind makes a plan to solve that goal, usually by breaking it into subgoals and excuting sub-plans. Thus this is a sequential, hiearchical organization of behavior.
Criticism of neural nets: explains vision and some tasks, but it does not explain the organization of executive behavior.
Flashes of insight are consistent with this type of planning theory
        
Ch 6 Up Close
This chapter describes results from single-cell recordings in PFC. They implement a form of short-term memory. 
-- People used to think there was a separation of "what" and "where" pathways in PFC. This is because PFC does everything you are looking for.
-- Earl Miller doubted this -- showed that the same cells code for target and location, when these two pieces of information are needed at different times
--PFC cells do whatever is needed, between 30% and 50% of them
-- Also true for cat/dog discrimination
-- Mental programs, rather than dedicated neurons, seem to be the brain's solution
        
Ch 7 The Box
PFC is necessary for task switching, or flexible behavior. Failures of this are seen in children or people with brain damage. But also might explain many of the heuristics and biases people show (Kaheneman and Tversky).
        
        
      },
author = {Duncan, John},
keywords = {MD system},
mendeley-tags = {MD system},
title = {{How intelligence happens}},
year = {2010}
}
@article{Duncan2000,
abstract = {Though many neuroscientific methods have been brought to bear in the search for functional specializations within prefrontal cortex, little consensus has emerged. To assess the contribution of functional neuroimaging, this article reviews patterns of frontal-lobe activation associated with a broad range of different cognitive demands, including aspects of perception, response selection, executive control, working memory, episodic memory and problem solving. The results show a striking regularity: for many demands, there is a similar recruitment of mid-dorsolateral, mid-ventrolateral and dorsal anterior cingulate cortex. Much of the remainder of frontal cortex, including most of the medial and orbital surfaces, is largely insensitive to these demands. Undoubtedly, these results provide strong evidence for regional specialization of function within prefrontal cortex. This specialization, however, takes an unexpected form: a specific frontal-lobe network that is consistently recruited for solution of diverse cognitive problems.},
annote = {MD project: frontal cortex seems to be involved in a diverse array of tasks. It seems to be modulated by something like executive demand, as evident in an easy/hard contrast in 5 tasks.
        
--
Despite decades of work, there is little evidence for functional specialization of the frontal cortex. This is both electrical recording and lesion studies.
        
Analysis 1: when testing a range if tasks, there is a clustering of activation in frontal cortex. But which studies do you include? And there is noise.
        
Analysis 2: systematic comparison of 5 tasks with easy/hard difficulty levels
        
1. Response conflict
-- Stroop like effects (not surprisal)
2. Task noverly
-- early phase of learning is harder (could be surprisal)
3. Working memory: number of items
(not surprisal)
4. Working memory: delay
(not surprisal)
5. Perceptual difficulty
(not surprisal)},
author = {Duncan, John and Owen, Adrian M},
file = {:Users/Brenden/Documents/Mendeley/Duncan, Owen - 2000 - Common regions of the human frontal lobe recruited by diverse cognitive demands.pdf:pdf},
issn = {0166-2236},
journal = {Trends in neurosciences},
keywords = {Animals,Attention,Attention: physiology,Brain Mapping,Cognition,Cognition: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Frontal Lobe,Frontal Lobe: physiology,Frontal Lobe: ultrastructure,Gyrus Cinguli,Gyrus Cinguli: physiology,Haplorhini,Haplorhini: physiology,Humans,MD system,Magnetic Resonance Imaging,Memory,Memory: physiology,Neuropsychological Tests,Perception,Perception: physiology,Prefrontal Cortex,Prefrontal Cortex: physiology,Prefrontal Cortex: ultrastructure,Psychomotor Performance,Psychomotor Performance: physiology,Semantics,Spatial Behavior,Spatial Behavior: physiology},
mendeley-tags = {MD system},
month = oct,
number = {10},
pages = {475--83},
pmid = {11006464},
title = {{Common regions of the human frontal lobe recruited by diverse cognitive demands.}},
volume = {23},
year = {2000}
}
@article{Durbin1987,
author = {Durbin, R and Willshaw, David},
file = {:Users/Brenden/Documents/Mendeley/Durbin, Willshaw - 1987 - An analogue approach to the travelling salesman problem using an elastic net method.pdf:pdf},
journal = {Nature},
keywords = {classic AI},
mendeley-tags = {classic AI},
pages = {689--691},
title = {{An analogue approach to the travelling salesman problem using an elastic net method}},
volume = {326},
year = {1987}
}
@article{EdelmanFlash1990,
annote = {Model of cursive handwriting recognition.
        
Handwriting is modeled as a spline, where the control points are usually easily detectable features (like corners and tops of loops). Matching is done between letters and their templates in control point space. 
        
Model summary
(1) Anchor point extraction -- done by tracing the image countour
(2) Stroke detection -- recognized by prototype alignment, using affince transformations
(3) Letter hypothesization -- potential instances of letters are detected
(4) Interpretation -- this assembles the best interpretation out of the set of all detected letters},
author = {Edelman, S and Flash, T and Ullman, S},
file = {:Users/Brenden/Documents/Mendeley/Edelman, Flash, Ullman - 1990 - Reading Cursive Handwriting by Alignment of Letter Prototypes.pdf:pdf},
journal = {International Journal of Computer Vision},
keywords = {handwriting,part-based models},
mendeley-tags = {handwriting,part-based models},
number = {3},
pages = {303--331},
title = {{Reading Cursive Handwriting by Alignment of Letter Prototypes}},
volume = {5},
year = {1990}
}
@article{Eden1962,
annote = {Early work on analysis-by-synthesis for pattern recognition
        
Perception by means of a simualtion, taking into account biological facts
        
Experiment 1: simualted handwriting by composing multiple, stroke-like curves. But with a markov model, it was too hard to capture long range dependencies
        
Experiment 2: sinusoilda description, with pair of opposing springs.},
author = {Eden, M},
file = {:Users/Brenden/Documents/Mendeley/Eden - 1962 - Handwriting and Pattern Recognition.pdf:pdf},
journal = {IRE Transactions on Information Theory},
keywords = {classic psychology,handwriting,part-based models},
mendeley-tags = {classic psychology,handwriting,part-based models},
pages = {160--166},
title = {{Handwriting and Pattern Recognition}},
year = {1962}
}
@article{Eimas2010,
author = {Eimas, Peter D and Quinn, Paul C},
file = {:Users/Brenden/Documents/Mendeley/Eimas, Quinn - 2010 - Studies on the Formation of Perceptually Based Basic-Level Categories in Young Infants Development.pdf:pdf},
journal = {Child Development},
number = {3},
pages = {903--917},
title = {{Studies on the Formation of Perceptually Based Basic-Level Categories in Young Infants Development}},
volume = {65},
year = {2010}
}
@article{Ekman1954,
author = {Ekman, Gosta},
journal = {Journal of Psychology: Interdisciplinary and Applied},
pages = {467--474},
title = {{Dimensions of color vision}},
volume = {38},
year = {1954}
}
@article{Eliasmith2012,
author = {Eliasmith, C. and Stewart, T. C. and Choo, X. and Bekolay, T. and DeWolf, T. and Tang, C. and Rasmussen, D.},
doi = {10.1126/science.1225266},
file = {:Users/Brenden/Documents/Mendeley/Eliasmith et al. - 2012 - A Large-Scale Model of the Functioning Brain(2).pdf:pdf;:Users/Brenden/Documents/Mendeley/Eliasmith et al. - 2012 - A Large-Scale Model of the Functioning Brain.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = nov,
number = {6111},
pages = {1202--1205},
title = {{A Large-Scale Model of the Functioning Brain}},
volume = {338},
year = {2012}
}
@article{Elidan2007,
annote = {Structure learning in Bayesian networks. 
        
When using linear Gaussian CPDs, it is easy to compute an "ideal parent" profile for a given node. You can then only evaluate parents for a node that are similar to the ideal. 
        
This also provides a mechanism for adding latent variables. If a bunch of nodes have a similar ideal parent, and there is no similar node in the dataset, then you can add a cluster connecting all of these.
        
Latent variables are proposed by doing hiearchical agglomerative clustering in the space of idea parents.},
author = {Elidan, Gal and Nachman, Iftach and Friedman, Nir},
file = {:Users/Brenden/Documents/Mendeley/Elidan, Nachman, Friedman - 2007 - “Ideal Parent” Structure Learning for Continuous Variable Bayesian Networks.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {GGM,bayesian networks,continuous variables,graphical models,hidden variables,structure learning},
mendeley-tags = {GGM,graphical models},
pages = {1799--1833},
title = {{“Ideal Parent” Structure Learning for Continuous Variable Bayesian Networks}},
volume = {8},
year = {2007}
}
@article{Embick2000,
abstract = {Despite numerous aphasia and functional imaging studies, the exact correlation between cortical language areas and subcomponents of the linguistic system has not been established. Here, we used functional MRI to identify cortical areas specifically involved in syntactic processing. An experimental design contrasted sentences containing grammatical errors with sentences containing spelling errors. The ungrammatical sentences produced more activation in cortical language areas than did the sentences with spelling errors, and the difference in activation was significantly greater in Broca's area than in Wernicke's area or in the angular gyrus/supramarginal gyrus. The present findings provide direct evidence of a syntactic specialization for Broca's area and establish the existence of distinct modules for our knowledge of language.},
author = {Embick, D and Marantz, a and Miyashita, Y and O'Neil, W and Sakai, K L},
doi = {10.1073/pnas.100098897},
file = {:Users/Brenden/Documents/Mendeley/Embick et al. - 2000 - A syntactic specialization for Broca's area.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Adult,Brain Mapping,Dominance, Cerebral,Female,Humans,Language,Magnetic Resonance Imaging,Male,Parietal Lobe,Parietal Lobe: physiology,Reading,Research Design,Temporal Lobe,Temporal Lobe: physiology},
month = may,
number = {11},
pages = {6150--4},
pmid = {10811887},
title = {{A syntactic specialization for Broca's area.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=18573&tool=pmcentrez&rendertype=abstract},
volume = {97},
year = {2000}
}
@article{Erdos1959,
author = {Erdos, Paul and Renyi, Alfred},
file = {:Users/Brenden/Documents/Mendeley/Erdos, Renyi - 1959 - On Random Graphs.pdf:pdf},
journal = {Publicationes Mathematicae},
keywords = {sparsity},
mendeley-tags = {sparsity},
pages = {290--297},
title = {{On Random Graphs}},
volume = {6},
year = {1959}
}
@article{Estes1986,
author = {Estes, WK},
file = {:Users/Brenden/Documents/Mendeley/Estes - 1986 - Array Models for Category Learning.pdf:pdf},
journal = {Cognitive psychology},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
pages = {500--549},
title = {{Array Models for Category Learning}},
volume = {549},
year = {1986}
}
@article{Falkenhainer1989,
author = {Falkenhainer, Brian and Forbus, Kenneth D. and Gentner, Dedre},
doi = {10.1016/0004-3702(89)90077-5},
file = {:Users/Brenden/Documents/Mendeley/Falkenhainer, Forbus, Gentner - 1989 - The structure-mapping engine Algorithm and examples.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
month = nov,
number = {1},
pages = {1--63},
title = {{The structure-mapping engine: Algorithm and examples}},
volume = {41},
year = {1989}
}
@article{Fares2009,
abstract = {Neuron morphology plays an important role in defining synaptic connectivity. Clearly, only pairs of neurons with closely positioned axonal and dendritic branches can be synaptically coupled. For excitatory neurons in the cerebral cortex, such axo-dendritic oppositions, termed potential synapses, must be bridged by dendritic spines to form synaptic connections. To explore the rules by which synaptic connections are formed within the constraints imposed by neuron morphology, we compared the distributions of the numbers of actual and potential synapses between pre- and postsynaptic neurons forming different laminar projections in rat barrel cortex. Quantitative comparison explicitly ruled out the hypothesis that individual synapses between neurons are formed independently of each other. Instead, the data are consistent with a cooperative scheme of synapse formation where multiple-synaptic connections between neurons are stabilized while neurons that do not establish a critical number of synapses are not likely to remain synaptically coupled.},
annote = {Do potential synapses become actual synapses at random? Actual connectivity, in contrast to the potential connectivity, is highly non-random (Fares and Stepanyants, 2009). If potential synapses become actual synapses at random, you would expect two cells to be connected by only 1 or 2 synapses. Instead, most functionally connected cells have many actual synapses between them (around 5). The authors fit this distribution by modeling whether two neurons will stay actually connected, f(N), given an initial number of actual connections N. There is a very sharp threshold for N around 4, meaning that if two cells lose a single connection (< 4) they become actually disconnected and lose their synapses. If they gain an actual connection over threshold (> 4), they become very stably connected. This reminds me of the discrete notion of edges in the sparse model, and it suggests cells have a mechanism to implement similar discrete connectivity choices.},
author = {Fares, Tarec and Stepanyants, Armen},
doi = {10.1073/pnas.0813265106},
file = {:Users/Brenden/Documents/Mendeley/Fares, Stepanyants - 2009 - Cooperative synapse formation in the neocortex.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Algorithms,Animals,Axons,Axons: physiology,Dendrites,Dendrites: physiology,Models,Neocortex,Neocortex: cytology,Neocortex: physiology,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Pyramidal Cells,Pyramidal Cells: physiology,Rats,Sprague-Dawley,Synapses,Synapses: physiology,Synaptic Potentials,Synaptic Potentials: physiology,sparsity,sparsity in the brain},
mendeley-tags = {sparsity,sparsity in the brain},
month = sep,
number = {38},
pages = {16463--8},
pmid = {19805321},
title = {{Cooperative synapse formation in the neocortex.}},
volume = {106},
year = {2009}
}
@article{Fedorenko2010,
abstract = {Previous neuroimaging research has identified a number of brain regions sensitive to different aspects of linguistic processing, but precise functional characterization of these regions has proven challenging. We hypothesize that clearer functional specificity may emerge if candidate language-sensitive regions are identified functionally within each subject individually, a method that has revealed striking functional specificity in visual cortex but that has rarely been applied to neuroimaging studies of language. This method enables pooling of data from corresponding functional regions across subjects rather than from corresponding locations in stereotaxic space (which may differ functionally because of the anatomical variability across subjects). However, it is far from obvious a priori that this method will work as it requires that multiple stringent conditions be met. Specifically, candidate language-sensitive brain regions must be identifiable functionally within individual subjects in a short scan, must be replicable within subjects and have clear correspondence across subjects, and must manifest key signatures of language processing (e.g., a higher response to sentences than nonword strings, whether visual or auditory). We show here that this method does indeed work: we identify 13 candidate language-sensitive regions that meet these criteria, each present in >or=80% of subjects individually. The selectivity of these regions is stronger using our method than when standard group analyses are conducted on the same data, suggesting that the future application of this method may reveal clearer functional specificity than has been evident in prior neuroimaging research on language.},
author = {Fedorenko, Evelina and Hsieh, Po-Jang and Nieto-Casta\~{n}\'{o}n, Alfonso and Whitfield-Gabrieli, Susan and Kanwisher, Nancy},
doi = {10.1152/jn.00032.2010},
file = {:Users/Brenden/Documents/Mendeley/Fedorenko et al. - 2010 - New method for fMRI investigations of language defining ROIs functionally in individual subjects.pdf:pdf},
issn = {1522-1598},
journal = {Journal of neurophysiology},
keywords = {Brain,Brain Mapping,Brain: blood supply,Brain: physiology,Functional Laterality,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods,Language,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Neuropsychological Tests,Oxygen,Oxygen: blood,Photic Stimulation,Reaction Time,Reaction Time: physiology,Reading,Reproducibility of Results,Time Factors},
month = aug,
number = {2},
pages = {1177--94},
pmid = {20410363},
title = {{New method for fMRI investigations of language: defining ROIs functionally in individual subjects.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2934923&tool=pmcentrez&rendertype=abstract},
volume = {104},
year = {2010}
}
@article{Fedorenko2010a,
author = {Fedorenko, The},
journal = {Language},
title = {{Defining language-sensitive regions functionally in individual subjects :}},
year = {2010}
}
@article{FeiFeiFergus2006,
annote = {        the "constellation model"        
        
One-shot learning by transfer learning. You do the hard work to learn a few categories with lots of examples, and transfer this knowledge to others.
        
---
You model the location and appearence of features in the image. 
        
Apperance: each feature is a point in a high-dimensional apperance space, modeled by a Gaussian
        
Shape: locations are in a scale and translation invariant space, relative to the left-most feature. Locations are also modeled by a high-dimensional Gaussian, so some classes can have constrained locations and others dont.
        
Priors on the shapes/appearance can be transferred from other object classes that you already know about.  For their experiments, they use a prior based on spotted cats, faces, and airplanes.
        
A major downside is that you must define the number of parts in the model (they used 4) in advance.
        
Mostly tested in detection scenario: does it contain an object, or is it just the background?
        
      },
author = {Fei-Fei, L and Fergus, R and Perona, P},
file = {:Users/Brenden/Documents/Mendeley/Fei-Fei, Fergus, Perona - 2006 - One-shot learning of object categories.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {4},
pages = {594--611},
title = {{One-shot learning of object categories}},
volume = {28},
year = {2006}
}
@article{Feldman2009,
abstract = {Discussions of the foundations of perceptual inference have often centered on 2 governing principles, the likelihood principle and the simplicity principle. Historically, these principles have usually been seen as opposed, but contemporary statistical (e.g., Bayesian) theory tends to see them as consistent, because for a variety of reasons simpler models (i.e., those with fewer dimensions or free parameters) make better predictors than more complex ones. In perception, many interpretation spaces are naturally hierarchical, meaning that they consist of a set of mutually embedded model classes of various levels of complexity, including simpler (lower dimensional) classes that are special cases of more complex ones. This article shows how such spaces can be regarded as algebraic structures, for example, as partial orders or lattices, with interpretations ordered in terms of dimensionality. The natural inference rule in such a space is a kind of simplicity rule: Among all interpretations qualitatively consistent with the image, draw the one that is lowest in the partial order, called the maximum-depth interpretation. This interpretation also maximizes the Bayesian posterior under certain simplifying assumptions, consistent with a unification of simplicity and likelihood principles. Moreover, the algebraic approach brings out the compositional structure inherent in such spaces, showing how perceptual interpretations are composed from a lexicon of primitive perceptual descriptors.},
annote = {Many are skeptical that we can perform optimal Bayesian computations in brains in real time.
        
Feldman argues that in many cases we may not have to -- we can ignore the quantative details. 
        
If the likleihood is flat (either the data is consistent or not), and the hypothesis can be organized into a lattice of more generic (each with equal prior), then inference can be simply the maximum-depth interpretation:
        
* Pick the simplest hypothsis that is consistent with the data.
        
This works out a Bayesian interpretation of Feldman's earlier lattice work
        
        
--------
Simplicity principle: choose the simplest interpretation consistent with the image
        
Likelihood principle: choose the most likely interpretation
        
Traditionally opposed, Bayesians see these as consistent.
                  
Hierarchices of candidate interpretations
                
Many consider Bayesian computations to be biologically unrealistic
        
But in some cases, the latent variable space is hierarchical
In Biedermans RBC, geons are special cases of each other - a straight brick is a special case of a curved brick
        
Others are non-accidental relations, liek parallel or coterminating lines
                  
implications for bayesian inference
                
Larger model classes always fit better.
+ Tenenbaum has explored Bayesian occam's razor for cognitive generalization
                  
The qualitative stance
                
We want a procedure that is rapid cmputation, yet gives a single unified answer (like MAP)
        
Qualtative stance: ignores quanitiative details of both prior and likelihood...treats them categorically
        
Only know that lines are parallel, and don't know the details of the angle
        
Likelihood just means whether or not the image is in the support (in A or not)
        
Since more generic models have a larger support, the since prinple favors simpler models
        
        prior
                
All model classes are equally likely, a priori.
                  
Bayes
                
This boils down to just choose the simplest configuration consistent with the image.
                  
Example
                
What generated the set of Gabor patches? Is it collinear or not?
        
Simple threshold on angle can decide which is collinear, and then map to an interpretation.
        
Bayesian analysis breaks into two terms:
- smoothness (deviation in chain)
- depth (score for chain increases linearly iwth number of steps)
        
Smoothness is quantitative, depth is qualitative
        
Rather than working out the computation, can could take the qualitative stance (and categorize the data based on the likelihood) and use the maximum-depth rule
        
---
        
With precise assumptions (priors) you might want to the quantiatively optimal inference.
        
But with partially correct assumptions, it might suffice to look at algebraic minization.},
author = {Feldman, Jacob},
doi = {10.1037/a0017144},
file = {:Users/Brenden/Documents/Mendeley/Feldman - 2009 - Bayes and the simplicity principle in perception.pdf:pdf},
issn = {0033-295X},
journal = {Psychological Review},
keywords = {Association Learning,Bayes Theorem,Depth Perception,Discrimination Learning,Humans,Judgment,Likelihood Functions,Models,Orientation,Probability Learning,Theoretical,Visual Perception,one-shot learning},
mendeley-tags = {one-shot learning},
month = oct,
number = {4},
pages = {875--87},
pmid = {19839688},
title = {{Bayes and the simplicity principle in perception.}},
volume = {116},
year = {2009}
}
@article{Feldman1997,
annote = {Early paper on one-shot learning. Formal account of how this type of learning is possible -- based on finding a manifold in a large space for which the object is maximally generic.
        
This theoretical count isn't fully operationalized, and doesn't make quantitative predictions
        
Category generation task: from 1 (or 3) examples, participants were asked to produce a new set of exemplars.
        
-----
        
How is one shot learning possible? Connectionist nets would just generalize around that example, and could never produce a multi-modal probability density from one example. You have no covariation with just one object, so this is a particular challenge.
        
To make up the difference, you must have strong prior knowledge.
        
Constraint: a subset of the larger object space
- expressed as functions that are smooth
Manifold: the sub-space defined by the constraint (like a curving 1d line in a 2d plane)
- this provides a very particular covariation relationship
        
Co-dimension: the new dimensionality of a particular constraint
        
Regularity lattice: defined by the intersection of constraints, which themselves are manifolds
        
Generic: the fewest restrictions on the space
        
Categorization hypothesis: objects are categorized by the regularity they obey.
        
How do you choose regularities?
- Generative model of objects: objects start with a null-structure, can then you can apply transformations to this structure
- The set of achievables by a particular transformation defines a regularity (manifold), like shearing, rescaling, translation, rotation, etc.
- starting with a null object, you can build up a lattice by applying transformations.
                  
Where do you place the object in the lattice?
principle of genericity:  points should be associated with categories for which they are maximally generic -- they don't fall within a lower node in the lattic
                  
where does the lattice come from?        
- You could use a complete lattice, but this would be computationally infeasible
- instead you can build it out from the bottom (the null object), adding levels as needed
                  
Experiments
                
You can test the lattice theory by looking at the probability distribution for the category.          
                
Show a participant one (or three) examples of a concept in a booklet. On the next page, they are asked to draw 6 more. 
        
Interestingly, the distributions are often multi-modal. This refelcts different elements in the lattice, which creates a mixture model
        
Each stimulus in coded, and the distribution across paritcipants is created by Gaussian kernels. Then it is fit with a mixture model, where k is chosen by model comparison.
        
Experiment 1: generic dot
- dot on a line, at 25% length
- people generalize strongly peaked at that length (like Shepard curve)
- but also a peak at the end (another lattice structure)
        
Experiment 2: non-generic dot
- dont near the end point
- people generalize sharply at the end point
        
Experient 3: three generic dots
- dots on a line, at every length uniformly across the subject population
- Similar to experiment 1, but more diffuse and another interesting peak at the midpoint in addition to the endpoint
        
Experiment 4: generic V (angle not at 90 degrees)
- peaks at the two angles shown across participants, and also at 90 degrees
        
Experiment 5: non-genric V (90 degrees)
- strong peak at 90 degrees
        
Experiment 6: three exampels of generic Vs
- similar results to experiment 4 but with a more diffuse pattern
        
Experiment 7: one example of generic dot on line, but varied over subjects. People seemed to like generic position between midpoint and endpoint.
                  
Discussion
                
People are suprisingly conssitent in their generalizations, even though this is occuring from just one example. Generiticity is providing this inductive leverage
        
Connectionist nets can't do this, and you could see how the lattice account could be extended for conceptual combination},
author = {Feldman, Jacob},
file = {:Users/Brenden/Documents/Mendeley/Feldman - 1997 - The structure of perceptual categories.pdf:pdf},
journal = {Journal of Mathematical Psychology},
keywords = {classic psychology,classics on concepts,one-shot learning},
mendeley-tags = {classic psychology,classics on concepts,one-shot learning},
pages = {145--170},
title = {{The structure of perceptual categories}},
volume = {41},
year = {1997}
}
@article{Feldman2006,
abstract = {Skeletal representations of shape have attracted enormous interest ever since their introduction by Blum [Blum H (1973) J Theor Biol 38:205-287], because of their potential to provide a compact, but meaningful, shape representation, suitable for both neural modeling and computational applications. But effective computation of the shape skeleton remains a notorious unsolved problem; existing approaches are extremely sensitive to noise and give counterintuitive results with simple shapes. In conventional approaches, the skeleton is defined by a geometric construction and computed by a deterministic procedure. We introduce a Bayesian probabilistic approach, in which a shape is assumed to have "grown" from a skeleton by a stochastic generative process. Bayesian estimation is used to identify the skeleton most likely to have produced the shape, i.e., that best "explains" it, called the maximum a posteriori skeleton. Even with natural shapes with substantial contour noise, this approach provides a robust skeletal representation whose branches correspond to the natural parts of the shape.},
annote = {Question: could we separate these variables into a "type-level" and a "token-level"?
- what would it look like to regenerate from the type-level?
+ can we just add gaussian noise to most of the selections?

        
------
Conventional approach to skeletons involves a deterministic procedure for computing skeletons.
- sensitive to noise

        
Here, they assume skeletons have grown using a stochastic generative process
+ provides more robust skeletal representations, with natural shape parts

        
Early work on medial axis transform (MAT)
- some evidence for neural representation
- agreement that "parts" must cross a medial axis
- algorithms are highly sensitive to noise

        
Bayesian estimation of the shape skeleton

        
- Shapes are filled regions
- Prior: Lines tend to be straight, and they have as few branches as possible
- Likelihood: Each segment has ribs, which have a characteristic length and Gaussian noise (also characteristic directio)

        
Inference: we find the MAP skeleton

        
This allows for uncertainty in the skeleton, and tends to remove suprious segments typical of thinning methods.

        
          
priors. 
- for each line, successive points are centered in a straight line, but can have an angular deiviation 
- axials branches sprout with a fixed probability (huh?) what does that mean? How is this a density?

        
          
likelihoods
        
- ribs sprout on both sides, approx. perpendicular to the axis, but with randomness in length and direction
- expected rib length is estimated from the shape, with Gaussian noise at the end
+ prior on rib lengths is exponential function, where slimmer regions are more likely than fatter ones

        
          
MAP skeleton
        
- MAP is also referred to as mimimum description length, since it is equivalent to the complexity of expressing the hypothesis in an optimal code

        
          
Algorithm
        
- points along the contour must be assigned to a skeletal point, suggesting an EM-like procedure for optimization
- rib length function is estimated by pooling ribs within a moving mask with a fixed width. Thus, the width can be different in different places along the axis
- over-segmented, and then non-root axies are subject to Bayesian posteiror ratio test (which is simply whether it improves the score or not ...its a greedy move)

        
          
Results

        
        
Much coarser skeletons, with fewer extraneous segments, are learned from their method, as compared to conventional MAT

        
Provides a Bayesian explanation for the well known dterminants of parts as the minima rule, where this falls out of the generative process

        
          
Discussion

        
        
shortomcing: it lacks an overt probabilist shape-generating model from the skeleton},
author = {Feldman, Jacob and Singh, Manish},
doi = {10.1073/pnas.0608811103},
file = {:Users/Brenden/Documents/Mendeley/Feldman, Singh - 2006 - Bayesian estimation of the shape skeleton.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Algorithms,Anatomic,Animals,Bayes Theorem,CogSci2013 Symposium,Computer Simulation,Humans,Models,Skeleton,part-based models},
mendeley-tags = {CogSci2013 Symposium,part-based models},
month = nov,
number = {47},
pages = {18014--9},
pmid = {17101989},
title = {{Bayesian estimation of the shape skeleton.}},
volume = {103},
year = {2006}
}
@inproceedings{Feldman2007,
address = {Austin, TX},
author = {Feldman, N H and Griffiths, T L},
booktitle = {{Proceedings of the 29th Annual Cognitive Science Society}},
editor = {McNamara, D S and Trafton, J G},
file = {:Users/Brenden/Documents/Mendeley/Feldman, Griffiths - 2007 - A rational account of the perceptual magnet effect.pdf:pdf},
pages = {257--262},
publisher = {Cognitive Science Society},
title = {{A rational account of the perceptual magnet effect}},
year = {2007}
}
@inproceedings{FeldmanGriffiths2009,
author = {Feldman, Naomi H and Griffiths, T L and Morgan, J L},
booktitle = {{Proceedings of the 31st Annual Conference of the Cognitive Science Society}},
file = {:Users/Brenden/Documents/Mendeley/Feldman, Griffiths, Morgan - 2009 - Learning phonetic categories by learning a lexicon.pdf:pdf},
keywords = {part-based models},
mendeley-tags = {part-based models},
title = {{Learning phonetic categories by learning a lexicon}},
year = {2009}
}
@article{Feldman2013,
abstract = {Infants segment words from fluent speech during the same period when they are learning phonetic categories, yet accounts of phonetic category acquisition typically ignore information about the words in which sounds appear. We use a Bayesian model to illustrate how feedback from segmented words might constrain phonetic category learning by providing information about which sounds occur together in words. Simulations demonstrate that word-level information can successfully disambiguate overlapping English vowel categories. Learning patterns in the model are shown to parallel human behavior from artificial language learning tasks. These findings point to a central role for the developing lexicon in phonetic category acquisition and provide a framework for incorporating top-down constraints into models of category learning. (PsycINFO Database Record (c) 2013 APA, all rights reserved).},
author = {Feldman, Naomi H and Griffiths, Thomas L and Goldwater, Sharon and Morgan, James L},
doi = {10.1037/a0034245},
file = {:Users/Brenden/Documents/Mendeley/Feldman et al. - 2013 - A role for the developing lexicon in phonetic category acquisition.pdf:pdf},
issn = {1939-1471},
journal = {Psychological review},
keywords = {part-based models,speech recognition},
mendeley-tags = {part-based models,speech recognition},
number = {4},
pages = {751--78},
pmid = {24219848},
title = {{A role for the developing lexicon in phonetic category acquisition.}},
volume = {120},
year = {2013}
}
@inproceedings{Feldman2010,
author = {Feldman, Naomi H and Myers, Emily and White, Katherine and Griffiths, Thomas and Morgan, James},
booktitle = {{Proceedings of the 35th Boston University Conference on Language Development}},
file = {:Users/Brenden/Documents/Mendeley/Feldman et al. - 2010 - Learners Use Word-Level Statistics in Phonetic Category Acquisition.pdf:pdf},
keywords = {part-based models},
mendeley-tags = {part-based models},
title = {{Learners Use Word-Level Statistics in Phonetic Category Acquisition}},
year = {2010}
}
@inproceedings{Felzenszwalb2008,
annote = {objects are modeled by parts in deformable configurations. However, "parts" are just grids of gradient histograms, and thus arnen't particularl structured
-------

        
difficult to get to work, and often out-performed by rigid templates

        
Model:
-- parts are filters that cover only smaller regions of objects

        
- HOG features (histogram of oriented gradient featuers)
- coarse features over entire window, and part-templates that can be moved with respect to the detection window
- histogram of gradients, where each pixel votes for the orientation of its gradient, with strength dependpent on the gradient magnitude
+ normalized with respect to global energy
- HOG feature pyramid by computing HOG features at each level

        
model with n parts, is defined by root filter (Fig .1b)
 and a set of n parts (1c), where each part has a center of the region it is in, a size, and a score for each possible position in that region (1d)
+ score of a placement of apart is the scor eof each filter plus a score for the position (relative to the root)
- parts are non-overlapping
- histogram features of a part define a prototype for that part, where location is allowed to vary
(also see Fig. 4 for learned models)

        
latent SVM:
- SVM with latent variables that are unobserved, like the part locations (valid palcements of root and part filters)

        
- choose 6 parts, and initialize them heuristically (to region with most positive energy)

        
At the time, beats many state-of-the-art systems on object detection for about half ot he objects tested},
author = {Felzenszwalb, Pedro and Mcallester, David and Ramanan, Deva},
booktitle = {Computer Vision and Pattern Recognition (CVPR)},
file = {:Users/Brenden/Documents/Mendeley/Felzenszwalb, Mcallester, Ramanan - 2008 - A Discriminatively Trained, Multiscale, Deformable Part Model.pdf:pdf},
keywords = {part-based models},
mendeley-tags = {part-based models},
title = {{A Discriminatively Trained, Multiscale, Deformable Part Model}},
year = {2008}
}
@article{Ferris1998,
author = {Ferris, Michael J and Palenik, Brian},
file = {:Users/Brenden/Documents/Mendeley/Ferris, Palenik - 1998 - Why people gesture when they speak.pdf:pdf},
journal = {Nature},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
pages = {228},
title = {{Why people gesture when they speak}},
volume = {396},
year = {1998}
}
@article{Finke1989,
annote = {Famous mental imagery experiment:
        
D + J = umbrella
        
Showed that mental images can undergo transformations -- are more "image-like" than previously thought},
author = {Finke, Ronald and Pinker, Steven and Farah, Martha J},
file = {:Users/Brenden/Documents/Mendeley/Finke, Pinker, Farah - 1989 - Reinterpreting Visual Patterns in Mental Imagery.pdf:pdf},
journal = {Cognitive Science},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
pages = {51--78},
title = {{Reinterpreting Visual Patterns in Mental Imagery}},
volume = {78},
year = {1989}
}
@article{Fischler1981,
author = {Fischler, Martin A and Bolles, Robert C},
file = {:Users/Brenden/Documents/Mendeley/Fischler, Bolles - 1981 - Random sample consensus a paradigm for model fitting with applications to image analysis and automated cartography.pdf:pdf},
journal = {Communications of the ACM},
keywords = {0,1,2,3,5,60,61,71,8,analysis,and phrases,automated cartography,camera calibration,classic AI,cr categories,determination,image matching,location,model fitting,scene},
mendeley-tags = {classic AI},
number = {6},
pages = {381--395},
title = {{Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography}},
volume = {24},
year = {1981}
}
@article{Fiser2002,
abstract = {The ability of humans to recognize a nearly unlimited number of unique visual objects must be based on a robust and efficient learning mechanism that extracts complex visual features from the environment. To determine whether statistically optimal representations of scenes are formed during early development, we used a habituation paradigm with 9-month-old infants and found that, by mere observation of multielement scenes, they become sensitive to the underlying statistical structure of those scenes. After exposure to a large number of scenes, infants paid more attention not only to element pairs that cooccurred more often as embedded elements in the scenes than other pairs, but also to pairs that had higher predictability (conditional probability) between the elements of the pair. These findings suggest that, similar to lower-level visual representations, infants learn higher-order visual features based on the statistical coherence of elements within the scenes, thereby allowing them to develop an efficient representation for further associative learning.},
annote = {Read Barlow's efficient coding work
Read Vuuilleumier ... Doaln 2002 Nature neuroscience
        
Infants can learn simple co-occurence statistics between shapes in simple visual scenes, as hypothesized by theories of vision
        
----
        
It has been hypothesized that the predictabliity of one element's appearance from another is important for perceiving the underlying structure of a scene (Barlow, Atick), but it has not been shown that infants are sensitive to it
        
        Structure of stimuli
                
12 base elements (colored shapes)
8 appear in pairs (either vertical or horizontal)
while others were noise items
        
Scenes are three elements in a 2 x 2 grid
        
16 possible scenes, with a base pair and a noisse element
        
viewed stream of scenes, where infants looked at each item until habituation, until an overall habituation criterion
        
each individual element was shown the same number of times, but base pairs appeared 4x more togethr than a base element and a noise element          
          
test phase        
two base pairs and two non-base pairs were seelcted randomly for each infant, and looking time was measured
                  
results        
there was a strong looking time preference for base pairs, compared to non-base pairs
        
another follow-up with reversed roles of particular elements, and got same result
        
however, predictability and "high co-occourence" (overal frequency) were confalted here. To tease these apart, they ran two more experiments
                  
Experiment 2
                
Looked longer at low-frequency base pairs than frequency-balanced non-base pairs, even though the co-occurence feqeuncy of the two test-pairs were equated
+ thus, they are not just counting without normalizing!
        
But this could be a low-frequency bias now of the elements
                  
Experiment 3        
        
Same setup, but test trials looked for any looking bias based on the single element frequencies
                  
results
                
no difference in looking time between high and low-frequency shapes 
                  
Discussion
                
Some models of high-level vision propose new complex features as conjunctions of subfeatures
        
may help explain difference between view-based and structural description accounts: if parts are consistent, then view-based is fine, if they are flexible, then SD model might be needed},
author = {Fiser, J\'{o}zsef and Aslin, Richard N},
doi = {10.1073/pnas.232472899},
file = {:Users/Brenden/Documents/Mendeley/Fiser, Aslin - 2002 - Statistical learning of new visual feature combinations by infants.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Association Learning,Child Psychology,Habituation,Humans,Infant,Pattern Recognition,Probability Theory,Psychophysiologic,Visual,classic psychology,statistical learning},
mendeley-tags = {classic psychology,statistical learning},
month = nov,
number = {24},
pages = {15822--6},
pmid = {12429858},
title = {{Statistical learning of new visual feature combinations by infants.}},
volume = {99},
year = {2002}
}
@article{Fiser2010,
abstract = {Human perception has recently been characterized as statistical inference based on noisy and ambiguous sensory inputs. Moreover, suitable neural representations of uncertainty have been identified that could underlie such probabilistic computations. In this review, we argue that learning an internal model of the sensory environment is another key aspect of the same statistical inference procedure and thus perception and learning need to be treated jointly. We review evidence for statistically optimal learning in humans and animals, and re-evaluate possible neural representations of uncertainty based on their potential to support statistically optimal learning. We propose that spontaneous activity can have a functional role in such representations leading to a new, sampling-based, framework of how the cortex represents information and uncertainty.},
annote = {Setup: probabilistic inference underlies perception and learning, but they are rarely studied together. This paper unifies them with prob. population codes.
        
Lots of examples of probabilistic inference: cue combination, Bayesian visual chunking
        
Doesn't say anything about neural representation.
-- Neural networks don't make strong, testable predictions at the neural level.
-- Sparse coding assume MAP estimates, but this throws away uncertainty, and is at odds with behavioral data. Uncertainty is key
-- Problem with propabilistic population codes: how do you do learning?
        
Their approach: sampling, where neural activity ( in a single cell) represents some value of a random variable. This is implicitly used in boltzmann machines, Helmholtz machines, etc. since a latent variable encodes a distribution on observed variables
        
Marginalization is easy -- you just look at some cells
Spontaneous activity is the prior distribution. 
-- This is supported by the fact that spontaneous activity looks a lot like evoked activity.  Spontaneous activity is structured, and given the high energy cost, it would be strange if it's noise.
--Also, this is priming, since it puts them in the right range. This might account for the rapid categorization cortex can do.
        
Future questions:
-- neural nets learned with MLE, but people do something more sophisticated (even model comparison). What is it?},
author = {Fiser, J\'{o}zsef and Berkes, Pietro and Orb\'{a}n, Gergo and Lengyel, M\'{a}t\'{e}},
doi = {10.1016/j.tics.2010.01.003},
file = {:Users/Brenden/Documents/Mendeley/Fiser et al. - 2010 - Statistically optimal perception and learning from behavior to neural representations.pdf:pdf},
issn = {1879-307X},
journal = {Trends in Cognitive Sciences},
keywords = {Animals,Bayesian perception,Cerebral Cortex,Humans,Learning,Models,Neurological,Perception,Statistical,neural coding},
mendeley-tags = {Bayesian perception,neural coding},
month = mar,
number = {3},
pages = {119--30},
pmid = {20153683},
title = {{Statistically optimal perception and learning: from behavior to neural representations.}},
volume = {14},
year = {2010}
}
@article{Hogans1985,
annote = {Motor planning is done by producing the "smoothest possible movement of the hand". This is called minmizing the magnitude of jerk.
        
--
        
      },
author = {Flash, Tamar and Hogans, Neville},
file = {:Users/Brenden/Documents/Mendeley/Flash, Hogans - 1985 - The Coordination of Arm Movements An Experimentally Confirmed Mathematical Model.pdf:pdf},
journal = {The Journal of Neuroscience},
keywords = {handwriting,program induction},
mendeley-tags = {handwriting,program induction},
number = {7},
pages = {1688--1703},
title = {{The Coordination of Arm Movements: An Experimentally Confirmed Mathematical Model}},
volume = {5},
year = {1985}
}
@article{Fleuret2011,
annote = {The authors study a visual categorization problem much like Bongard problems, where categories are defined by abstract rules (inside, between, etc.)
        
They find people learn these categories from a few examples, while machines take thousands or never learn them. They used simple local and global features, and SVMs and boosting for classification.
        
I completely agree with the point -- it's the general one-shot learning and rich representation point. But the modeling work is a little sad.},
author = {Fleuret, F. and Li, T. and Dubout, C. and Wampler, E. K. and Yantis, S. and Geman, D.},
doi = {10.1073/pnas.1109168108},
file = {:Users/Brenden/Documents/Mendeley/Fleuret et al. - 2011 - Comparing machines and humans on a visual categorization test.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {part-based models},
mendeley-tags = {part-based models},
month = oct,
number = {43},
pages = {17621--17625},
title = {{Comparing machines and humans on a visual categorization test}},
volume = {108},
year = {2011}
}
@article{Flowers2004,
abstract = {Brain imaging studies examining the component processes of reading using words, non-words, and letter strings frequently report task-related activity in the left extrastriate cortex. Processing of these linguistic materials involves varying degrees of semantic, phonological, and orthographic analysis that are sensitive to individual differences in reading skill and history. In contrast, single letter processing becomes automatized early in life and is not modulated by later linguistic experience to the same degree as are words. In this study, skilled readers attended to different aspects (single letters, symbols, and colors) of an identical stimulus set during separate sessions of functional magnetic resonance imaging (fMRI). Whereas activation in some portions of ventral extrastriate cortex was shared by attention to both alphabetic and non-alphabetic features, a letter-specific area was identified in a portion of left extrastriate cortex (Brodmann's Area 37), lateral to the visual word form area. Our results demonstrate that while minimizing activity related to word-level lexical properties, cortical responses to letter recognition can be isolated from figural and color characteristics of simple stimuli. The practical utility of this finding is discussed in terms of early identification of reading disability.},
author = {Flowers, D L and Jones, K and Noble, K and VanMeter, J and Zeffiro, T a and Wood, F B and Eden, G F},
doi = {10.1016/j.neuroimage.2003.10.002},
file = {:Users/Brenden/Documents/Mendeley/Flowers et al. - 2004 - Attention to single letters activates left extrastriate cortex.pdf:pdf},
issn = {1053-8119},
journal = {NeuroImage},
keywords = {Adolescent,Adult,Attention,Attention: physiology,Color Perception,Color Perception: physiology,Echo-Planar Imaging,Female,Humans,Magnetic Resonance Imaging,Male,Memory,Memory: physiology,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Reading,VWFA,Visual Cortex,Visual Cortex: physiology,handwriting},
mendeley-tags = {VWFA,handwriting},
month = mar,
number = {3},
pages = {829--39},
pmid = {15006649},
title = {{Attention to single letters activates left extrastriate cortex.}},
volume = {21},
year = {2004}
}
@article{Flusberg2011,
abstract = {Are objects that are more difficult to physically manipulate also more difficult to mentally manipulate? In our study, participants interacted with wooden objects modeled after the figures from Shepard and Metzler's (1971) classic mental rotation experiment. One pair of objects was easy to physically rotate while another pair was difficult. They then completed a standard mental rotation task on images of these objects. Participants were slower to mentally rotate objects that were harder to physically rotate when they engaged in motor imagery. Further, this cost accrued with increasing angles of rotation. We verified this was the result of motor imagery by showing that the costs can be eliminated by using a strictly visual imagery strategy (imagining the objects moving on their own). These results reveal a striking constraint imposed by our real-world motor experiences on mental imagery, and also demonstrate a way that we can overcome such constraints.},
annote = {Two sets of objects: one heavey and hard to rotate, another easier
        
Are objects that are more difficult to physically manipulate also more difficult to mentally manipulate?
-- seems to tie into simulation theory, like Pete's physics
        
Is imagination constrained or influenced by our actual physical experiences?
        
Experiment parts
1) physical rotation training
        
Objects were like Shepard and Metzler, and they were placed on a stand that they then rotated. For some objects, the device was filled with stand, making it more diffcult
4 objects, where color indicated the ease of physically rotating the object
        
Each object was manpiulated twice by the subjec
        
2) mental rotation task
        
Color photos of objects
        
Two objects shown: Either the same object or a mirror-reflected version 
- various degrees of rotation
        
Feedback was given after each trial
        
Instruction mainpulation
1) Imagine you are grasping the object with your hand and turning it..
2) Imagine it is moving by itself..
        
Results:
        
Participants remembered which colors were easier/harder to move
        
Standard rotation effect shows up
        
Significant rotation by imagery effect, where those with motor imagery were overall slower to mentally rotate the objects
        
Some weird statistics going on.. it doesnt look like the effect showed up initially. If you exclude participants who didn't rate the physical rotation difference as high as other, you get a stronger effect
        
Very small effect
        
Conclusion
        
to save time when you imagine redecorating your office, you can save time by imagining the couch moving by itself},
author = {Flusberg, Stephen J and Boroditsky, Lera},
doi = {10.3758/s13423-010-0024-2},
file = {:Users/Brenden/Documents/Mendeley/Flusberg, Boroditsky - 2011 - Are things that are hard to physically move also hard to imagine moving.pdf:pdf},
isbn = {1342301000242},
issn = {1531-5320},
journal = {Psychonomic bulletin \& review},
keywords = {Color Perception,Concept Formation,Female,Humans,Imagination,Male,Motion Perception,Orientation,Pattern Recognition,Psychomotor Performance,Reaction Time,Visual,Weight Perception,embodied cognition},
mendeley-tags = {embodied cognition},
number = {1},
pages = {158--64},
pmid = {21327358},
title = {{Are things that are hard to physically move also hard to imagine moving?}},
volume = {18},
year = {2011}
}
@book{Fodor1975,
annote = {Language of thought hypothesis (LOTH). Cognition is implemented in a mental language, that has both a syntax and semantics. The syntax, where symbols are manipulated through their formal features, is semantic preserving (like truth preserving). So formula are casusally connected in a way that preserves truth.
        
The crux of Fodor's (1975) argument is that the current paradigm in cognitive psychology assumes a LOTH. But other reasons include the productivity of thought (being able to think infinite thoughts from finite means) and systematcity of thought (if you understand "John loves mary" you understand "Mary love john).
        
Fodor also argues for a strong nativist position, where all concepts are innate in some sense (since you must be able to propose the "learned" hypothesis).
        
-----
        
speculative psychology: mixing psychology and philosophy. This has a long historical tradition, and it is unabashedly the approach of this book.
                  
Introduction
dismantling behaviorism
                
- even if a behaviorist claims that conditions for behavior can be elucidated as environmental stimuli, the cause can also be fully described by the internal states.
- Fodor gets rid of behaviorism to get to this views
                  
dismantling physical reductionism        
- sciences are not all collapsing into physics, which is perhaps the best argument that reductionism is not the best way to go
- a law in economics cannot have type-type redution to physics, since money can be a huge physical variety of things
- certainly there are non law-like relations between the physical properties of these things.
- there are also probably not kind-kind correspondences between neurological and mental states
- maybe the types at a higher level correspond to a disjunction of tokens at the lower-level
+ and thus laws at the higher-level must also be followed by some pair of physical things at the lower-level
- but in this case, neurology doesn't give us the thing that psychology requires
- and thus we can't dismiss cognitive psychology based on reductionism
                  
Main argument        
1) There must be a representational system for computation to be possible
2) A research strategy is elucidating this representational system
        
Choosing rational behavior (within an agent) requires a scheme of representing the options (and their probable consequences)
- no representations, no computations
- without representations, you can't generalize to new situations
- behaviorists have no good theory of "contemplated events"
        
- characterizing a LOT is a good part of what psychology must do
- concept learning, going beyond teh data, is not possible without a LOT
+ inherently involves hypothesis confirmation or rejection, and these hypotheses must be represented
+ in perception, what is represented is not purely couched in physical terms
- we need to bite the bullet and investigate what the LOT might look like
                  
Is LOT a natural language?        
- no, because non-verbal organisms (infants) can think
- UG itself (Chomsy) would have to be represented in some LOT
- you need to know some other language to acquire the semantic properties in a natural language
                  
how could there be a private language?
- danger of inifinite regress? you need a language to understand/learn that language?
+ solution: it is just a fact of the nervous system, innately provided
when you get something in natural language, you compile it in machine language -- you don't speak the language you compile in
- while private language may not have outward consistency, it has internal consistency
        
Claim:
organisms have some propositional attitude P iff there is come computational relation to some representation in the internal code
- relations between formula and propositional attitudes defines the character of thought
- determined by nervous system for LOT, which are conventions for natural language
                  
nativism argument        
- all thoughts must be thinkable in the original language (the basic one)          
- the basic language must be enough to express predicates of the candidate language L
(but learning L can also bootsrap off of initial learning in L, as a shortcut)
- in general, you cannot learn a language/logic with more power than one you already know (contrary to Piaget)
+ Piaget: failure of conservations (pour A into B, and B "has more"). Piaget explained this as a general lacking of "inverse relations." But Fodor claims they can then never be learned
- also, there is no sense of "learning a novel concept," because it must already be represented
- however airplanes can be conceived as a combination of previously learned parts, and a "mental chemistry" approach can serve us well here
                  
The structure of the internal code: linguistic evidence
- purpose here is to show this is not a metaphysical argument, and there are facts of the matter
- Chomsky's critique of "Verbal behavior". Language is not about stimulus/response (you can see the same stimulus and say different things). It has a structure independent of this.
- language: using messages to communicate an intuition from speaker to listner
- maybe studying the messages can tell us something about the language?
        
- different modalities can be compared, in some "non-linguistic" code (like is it rainy out?)
- messages (in natural language, NL) must provie appropriate format for input/output computation (it must contain the relative message in the LOT)
- there must be some concept that is modality independent (verbal + vision)
        
Main point: a theory of messages (language) is constrained by cognitive psychology and the LOT
                  
what does the LOT look like? language evidence        
- You could try to make a minimum set of words, by defining some words in terms of other (remove "bachelor" and replace with "unmarried man").
- if a definition can be substituated at some node in any sentence parse with that phrase/word, it is a good definition?
- so maybe we represent NL by a translation into defintions. But this doesn't work (Fodor gives eample of "only")
- also, if we represented things as definitions, there would be a correlation between how close they are to the definition when comprehending
- Main point: we don't represent things in terms of their definitions. The content and form of the LOT is an empirical question. NL cannot beasily be reducted by replacing words with defs. Maybe LOT is very muhc like a NL, in terms of complexity.
                  
psychological evidence        
- almost any data is relevant
- Broadbent filter paradigm. Lackner and Garret showed that processing in unattended channels can reach the highest level. 
- attention seems to be a very intelligent process
        
-information (syntax and/or semantics) retained from a sentence depends on what the instructions for the task are
- the input system gets modulated by goals (this modulation itself must be coded in the LOT)
- much more complex than associationism
                  
an image-like system?        
- it's possible that a language could be more "image-like", where the symbol actually resembles the referent
- but there is not way to represent "John is fat" vs. "John is total" vs. etc... from a picture of John?
- icons are not abstract enough for a LOT
- But imagery is real (Shpeard mental rotation), but images still need to be interpreted (like how the color on a map might denote sea floor dpeth)
                  
local summary        
- rational allocation of resources is critical
- hard to elucidate general principles in experiments, and psychology is hard
                  
Grand conclusion        
thinking: beliefs, desires, wants, actions are couched in an internal mental code (formula)
1) causal sequences of propositional attitudes are derivations in terms of the formula (a syntax?)
2) the assignments of formula should preserve semantic relations between propositions
        
But some propositions/thoughts can arise from outside the LOT system, like purely physiologically
- perception doesn't have mental causation, and is thus not "cognitive" by Fodor's standard
Putting one's watch on upside down, to remind you of something, is not the type of mental causation Fodor is talking about
- you need causation due to context},
author = {Fodor, Jerry A},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
publisher = {Harvard University Press},
title = {{The Language of Thought}},
year = {1975}
}
@book{Fodor1983,
address = {Cambridge, MA},
author = {Fodor, Jerry A},
publisher = {MIT Press},
title = {{The Modularity of Mind}},
year = {1983}
}
@article{Fodor1988,
annote = {appeals to a huge variety of different kinds of people
        
Two majors traditions in modern theorizing about the mind
- "eliminativist"
- "representationalists", where states of the mind which funtion to encode states of the world
        
PDP theorists often claim to be representationlists, where it is a theory about internal representation. It is important to make claims at the psyhological level.
        
Claims disagreement is not about explicitness of the rules. So what is it about?
        
Classical theories have causal and strutural relations at the level of semantically evaluable objets
-- they have a language of thought
-- representatinos have a combinatorial structure
+ for example, logical opreations P&Q therefore Q},
author = {Fodor, Jerry A and Pylyshyn, Zenon W},
file = {:Users/Brenden/Documents/Mendeley/Fodor, Pylyshyn - 1988 - Connectionism and cognitive architecture A critical analysis.pdf:pdf},
journal = {Cognition},
keywords = {classic psychology,connectionism},
mendeley-tags = {classic psychology,connectionism},
pages = {3--71},
title = {{Connectionism and cognitive architecture: A critical analysis}},
volume = {28},
year = {1988}
}
@article{Forbus1984,
annote = {Theory of processes -- how things effect eachother.
Are the paths of physical objects independent?
        
Liquids were primary motivation for qualitative process theroy
        
Processes are flows, motion, phase changes
        
Quantities, like differences in temperature, are important to describe processes. Differences in temperature can just be summarized by a sign.
                  
forbus talk, cogsci2012
          
- qualitative reasoning forms a bridge between perception and cognition
        
tasks with auto. qualitative representations
- geometric analogy
- Raven's matrices
- learning spatial prepositions
        
is it a good idea to leave a kettle on the stove for an hour?
- no, and you didn't need to know anything about the specifics of the water, all the hundreds of parameters
        
key ideas:
-quantize the continuous world for symbolic reasoning
- represent parital knowledge about the world
        
need a separate type of math for qual. reasoning
        
This provides a strong inductive bias on the space of possible representations
+ relations between entities and statems
+ not just a list of features
        
Learning concepts
during learning, you update the prior probability of a category
+ if it doesn't fit a category, you store the exemplar
        
Bayes bridge
- qualitative representations provide psychologically plausible language for hypotheses
- analgoical representation provides a good prior
        
      },
author = {Forbus, Kenneth D},
file = {:Users/Brenden/Documents/Mendeley/Forbus - 1984 - Qualitative Process Theory.pdf:pdf},
issn = {0169-2607},
journal = {Artificial Intelligence},
month = jun,
pages = {85--168},
pmid = {7956167},
title = {{Qualitative Process Theory}},
volume = {24},
year = {1984}
}
@article{Forbus2011,
annote = {Sketching is fascinating scientifically because it invovle, visual, spatial, and conceptual knowledge
        
CogSketch Goals
1) New research tool for cognitive scientists
2) platform for sketch-based educational software
                  
our hypothesis
                
Symbol recognition is a catalyst, but not a requirement. People aslo use language to label ink, etc. when sketching for otherh umans
        
CogSketch has other ways of linking ink to labels
        
"Open-domain sketch understanding": you can apply this to more than a restricted domain
                  
qualitative spatial representations:        
construct representations of segments, regions volumes etc. is key function of perception
                  
structure-mapping processes are used in visual reasoning        
qualitative representations provide visual and spatial structure, which is passed to analogical operations of matching, retrieval, and generalization
        
Use OpenCyc knowledge base, to help capture conceptual knowledge (relations, objects, etc.)
                  
raw input        
glyphs: sequence of polylines, which are the pen strokes
        
        ink processing        
- computes qualitative relations between two 2D shapes (disconnceted, edge-connected, partially overlapping)
                  
shape        
analysis of edges, including shape, length, alignment, etc.
+ detecing right angles, etc.
        
        analogical inference        
are two shapes the same, different, rotated/reflected 
+ computes an equivalence class of shapes, if needed
        
interactions with cocnept knwoeldge:
- cogsketch can create a list of potentail conceptial relations betwen pairs of entities
        
+ model has been used for solving geometric analogies
        
        spatial language learning
- used to learn in and on in English, using just a few examples of labeled spatial relations
                  
Education
                
Example
- "draw a fault on a geology map"
CogSketch can them compare the student's sketch to the teacher's
        
      },
author = {Forbus, Kenneth and Usher, Jeffrey and Lovett, Andrew and Lockwood, Kate and Wetzel, Jon},
doi = {10.1111/j.1756-8765.2011.01149.x},
file = {:Users/Brenden/Documents/Mendeley/Forbus et al. - 2011 - CogSketch Sketch Understanding for Cognitive Science Research and for Education.pdf:pdf},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {CogSci2013 Symposium,analogy,cognitive simulation,ing,qualitative reasoning,sketch understanding,spatial cognition,spatial reason-,visual reasoning},
mendeley-tags = {CogSci2013 Symposium},
month = oct,
number = {4},
pages = {648--666},
title = {{CogSketch: Sketch Understanding for Cognitive Science Research and for Education}},
volume = {3},
year = {2011}
}
@inproceedings{Foster2012,
annote = {A major challenge: finding a representation that is useful, in terms of predictive of reward
        
Questions:
1) How are relational concepts learned?
2) How do relation concepts evolve over time?
        
How do we model a hierachy of concepts?
        
- You represent objects, scenes with a set of relations
- You pick schemas, by finding commonalities between two scenes
- Relational consolidation: the strongest schemas become new concepts
        
There seems to be a one-shot jump to learning a schema -- since people are at chance in the previous trials
      },
author = {Foster, James M and Ca\~{n}as, Fabi\'{a}n and Jones, Matt},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Foster, Ca\~{n}as, Jones - 2012 - Learning Conceptual Hierarchies by Iterated Relational Consolidation.pdf:pdf},
keywords = {analogy,concept learning,induction,predication,refinement,relational consolidation,schema},
pages = {324--329},
title = {{Learning Conceptual Hierarchies by Iterated Relational Consolidation}},
year = {2012}
}
@article{Fox2008,
address = {New York, New York, USA},
author = {Fox, Emily B. and Sudderth, Erik B. and Jordan, Michael I. and Willsky, Alan S.},
doi = {10.1145/1390156.1390196},
file = {:Users/Brenden/Documents/Mendeley/Fox et al. - 2008 - An HDP-HMM for systems with state persistence.pdf:pdf},
isbn = {9781605582054},
journal = {Proceedings of the 25th international conference on Machine learning - ICML '08},
pages = {312--319},
publisher = {ACM Press},
title = {{An HDP-HMM for systems with state persistence}},
url = {http://portal.acm.org/citation.cfm?doid=1390156.1390196},
year = {2008}
}
@article{Frank2008,
abstract = {Does speaking a language without number words change the way speakers of that language perceive exact quantities? The Pirah\~{a} are an Amazonian tribe who have been previously studied for their limited numerical system [Gordon, P. (2004). Numerical cognition without words: Evidence from Amazonia. Science 306, 496-499]. We show that the Pirah\~{a} have no linguistic method whatsoever for expressing exact quantity, not even "one." Despite this lack, when retested on the matching tasks used by Gordon, Pirah\~{a} speakers were able to perform exact matches with large numbers of objects perfectly but, as previously reported, they were inaccurate on matching tasks involving memory. These results suggest that language for exact number is a cultural invention rather than a linguistic universal, and that number words do not change our underlying representations of number but instead are a cognitive technology for keeping track of the cardinality of large sets across time, space, and changes in modality.},
author = {Frank, Michael C and Everett, Daniel L and Fedorenko, Evelina and Gibson, Edward},
doi = {10.1016/j.cognition.2008.04.007},
file = {:Users/Brenden/Documents/Mendeley/Frank et al. - 2008 - Number as a cognitive technology evidence from Pirah\~{a} language and cognition.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Adult,Brazil,Cognition,Comprehension,Concept Formation,Discrimination Learning,Female,Humans,Judgment,Language,Male,Mathematics,Population Groups,Population Groups: psychology,Problem Solving,Psycholinguistics,Semantics,Vocabulary},
month = sep,
number = {3},
pages = {819--24},
pmid = {18547557},
title = {{Number as a cognitive technology: evidence from Pirah\~{a} language and cognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18547557},
volume = {108},
year = {2008}
}
@article{Frank2012,
author = {Frank, Michael C and Goodman, Noah D},
file = {:Users/Brenden/Documents/Mendeley/Frank, Goodman - 2012 - Predicting pragmatic reasoning in language games.pdf:pdf},
journal = {Science},
pages = {998},
title = {{Predicting pragmatic reasoning in language games}},
volume = {336},
year = {2012}
}
@article{Frank2009,
abstract = {Word learning is a "chicken and egg" problem. If a child could understand speakers' utterances, it would be easy to learn the meanings of individual words, and once a child knows what many words mean, it is easy to infer speakers' intended meanings. To the beginning learner, however, both individual word meanings and speakers' intentions are unknown. We describe a computational model of word learning that solves these two inference problems in parallel, rather than relying exclusively on either the inferred meanings of utterances or cross-situational word-meaning associations. We tested our model using annotated corpus data and found that it inferred pairings between words and object concepts with higher precision than comparison models. Moreover, as the result of making probabilistic inferences about speakers' intentions, our model explains a variety of behavioral phenomena described in the word-learning literature. These phenomena include mutual exclusivity, one-trial learning, cross-situational learning, the role of words in object individuation, and the use of inferred intentions to disambiguate reference.},
author = {Frank, Michael C and Goodman, Noah D and Tenenbaum, Joshua B},
doi = {10.1111/j.1467-9280.2009.02335.x},
file = {:Users/Brenden/Documents/Mendeley/Frank, Goodman, Tenenbaum - 2009 - Using speakers' referential intentions to model early cross-situational word learning.pdf:pdf},
issn = {1467-9280},
journal = {Psychological science},
keywords = {Association Learning,Humans,Intention,Language Development,Models, Psychological,Models, Statistical,Pattern Recognition, Visual,Social Environment,Speech Perception,Transfer (Psychology),Verbal Learning,Vocabulary},
month = may,
number = {5},
pages = {578--85},
pmid = {19389131},
title = {{Using speakers' referential intentions to model early cross-situational word learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19389131},
volume = {20},
year = {2009}
}
@article{Frey1991,
author = {Frey, Peter W and Slate, David J},
file = {:Users/Brenden/Documents/Mendeley/Frey, Slate - 1991 - Letter Recognition Using Holland-Style Adaptive Classifiers.pdf:pdf},
journal = {Machine Learning},
keywords = {and applying solution strategies,apportionment of credit,cases of familiar paradigms,category learning,difficult problems quickly and,effortlessly by categorizing com-,exemplar-based induction,fuzzy-match rule activation,h u m a,handwriting,n experts often solve,parallel rule-based systems,plex situations as special,that},
mendeley-tags = {handwriting},
number = {6},
pages = {161--182},
title = {{Letter Recognition Using Holland-Style Adaptive Classifiers}},
volume = {182},
year = {1991}
}
@article{Freyd1987,
author = {Freyd, J},
file = {:Users/Brenden/Documents/Mendeley/Freyd - 1987 - Dynamic Mental Representations.pdf:pdf},
journal = {Psychological Review},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
number = {4},
pages = {427--438},
title = {{Dynamic Mental Representations}},
volume = {94},
year = {1987}
}
@article{Freyd1983,
annote = {Participants observe characters being produced, either in method A or method B, where the direction of the strokes is changed. This influences recognition RT, where consistent distorted examples are recognized faster.
        
----
Most theories of letter-perception involve feature-analysis. But real systems must be tolerant to a range of distortions, caused by the writing process. 
        
Perhaps the perceiver produces a model of what he/she is seeing by following produciton rules (like the motor theory of speech perception)
        
Experiment:
Training: Participants saw characters drawn in real time, and learned to associate a number with each one. They saw one of two drawing methods.
Test: Asked to identify distorted versions of the same characters, in a manner consistent with the drawing method or not. These distortions were picked by hand.
        
Result: Each distortion is consistent with one drawing method versus another (like the last line is drawn up vs. down). 
        
There was no difference in overall error rate
        
There was a RT difference, whre inconsitent distortions are lower for recognition (by about 100-200 ms). This is regardless of distortion time (connecting and sloppy lines, connecting lines, sloppy lines)},
author = {Freyd, J},
file = {:Users/Brenden/Documents/Mendeley/Freyd - 1983 - Representing the dynamics of a static form.pdf:pdf},
journal = {Memory and Cognition},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
number = {4},
pages = {342--346},
title = {{Representing the dynamics of a static form}},
volume = {11},
year = {1983}
}
@article{Friederici2006,
abstract = {We used event-related functional magnetic resonance imaging to directly compare the hemodynamic responses associated with varying degrees of linguistic complexity with those engendered by the processing of ungrammatical utterances. We demonstrate a dissociation within the left inferior frontal cortex between the deep frontal operculum, which responds to syntactic violations, and a core region of Broca's area, that is, the inferior portion of the left pars opercularis in Brodmann area 44, the activation of which is modulated as a function of the complexity of well-formed sentences. The data demonstrate that different brain regions in the prefrontal cortex support distinct mechanisms in the mapping from a linguistic form onto meaning, thereby separating ungrammaticality from linguistic complexity.},
author = {Friederici, Angela D and Fiebach, Christian J and Schlesewsky, Matthias and Bornkessel, Ina D and von Cramon, D Yves},
doi = {10.1093/cercor/bhj106},
file = {:Users/Brenden/Documents/Mendeley/Friederici et al. - 2006 - Processing linguistic complexity and grammaticality in the left frontal cortex.pdf:pdf},
issn = {1047-3211},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {Adult,Behavior,Behavior: physiology,Brain Mapping,Frontal Lobe,Frontal Lobe: anatomy & histology,Frontal Lobe: physiology,Humans,Language,Linguistics,Magnetic Resonance Imaging,Male,Semantics,Speech Perception,Speech Perception: physiology},
month = dec,
number = {12},
pages = {1709--17},
pmid = {16400163},
title = {{Processing linguistic complexity and grammaticality in the left frontal cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16400163},
volume = {16},
year = {2006}
}
@inproceedings{Friedman1998,
author = {Friedman, Nir},
booktitle = {Fourteenth Conference on Uncertainty in Artificial Intelligence},
file = {:Users/Brenden/Documents/Mendeley/Friedman - 1998 - The Bayesian structural EM algorithm.pdf:pdf},
keywords = {graphical models},
mendeley-tags = {graphical models},
title = {{The Bayesian structural EM algorithm}},
year = {1998}
}
@article{Friedman1997,
annote = {This paper introduced structural EM. Structural EM was the first technique for structure learning with missing data. It extends regular EM by first performing the E-step, then update the structure, in addition to the parameters, in the M-step.
        
It is guarenteed to improve performance when using the BIC score (or some other penalized log-likelihood score) that only depends on the observed variables and parameters.},
author = {Friedman, Nir},
file = {:Users/Brenden/Documents/Mendeley/Friedman - 1997 - Learning Belief Networks in the Presence of Missing Values and Hidden Variables.pdf:pdf},
journal = {{Fourteenth International Conference on Machine Learning (ICML)}},
keywords = {graphical models},
mendeley-tags = {graphical models},
title = {{Learning Belief Networks in the Presence of Missing Values and Hidden Variables}},
year = {1997}
}
@article{Friston2005,
abstract = {This article concerns the nature of evoked brain responses and the principles underlying their generation. We start with the premise that the sensory brain has evolved to represent or infer the causes of changes in its sensory inputs. The problem of inference is well formulated in statistical terms. The statistical fundaments of inference may therefore afford important constraints on neuronal implementation. By formulating the original ideas of Helmholtz on perception, in terms of modern-day statistical theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts.It turns out that the problems of inferring the causes of sensory input (perceptual inference) and learning the relationship between input and cause (perceptual learning) can be resolved using exactly the same principle. Specifically, both inference and learning rest on minimizing the brain's free energy, as defined in statistical physics. Furthermore, inference and learning can proceed in a biologically plausible fashion. Cortical responses can be seen as the brain's attempt to minimize the free energy induced by a stimulus and thereby encode the most likely cause of that stimulus. Similarly, learning emerges from changes in synaptic efficacy that minimize the free energy, averaged over all stimuli encountered. The underlying scheme rests on empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organization and responses. The aim of this article is to encompass many apparently unrelated anatomical, physiological and psychophysical attributes of the brain within a single theoretical perspective. In terms of cortical architectures, the theoretical treatment predicts that sensory cortex should be arranged hierarchically, that connections should be reciprocal and that forward and backward connections should show a functional asymmetry (forward connections are driving, whereas backward connections are both driving and modulatory). In terms of synaptic physiology, it predicts associative plasticity and, for dynamic models, spike-timing-dependent plasticity. In terms of electrophysiology, it accounts for classical and extra classical receptive field effects and long-latency or endogenous components of evoked cortical responses. It predicts the attenuation of responses encoding prediction error with perceptual learning and explains many phenomena such as repetition suppression, mismatch negativity (MMN) and the P300 in electroencephalography. In psychophysical terms, it accounts for the behavioural correlates of these physiological phenomena, for example, priming and global precedence. The final focus of this article is on perceptual learning as measured with the MMN and the implications for empirical studies of coupling among cortical areas using evoked sensory responses.},
annote = {        cortical organization        
        
Overall cortical rule: cells with the same function are grouped together in space (e.g., colmns of cortex)
        
forward/backwards distinction.
- forward connections are more topographically organized
- backwards connections show abundant axonal bifurcation and are more diffuse topographically
        
theory
+ forward conections promulgate sensroy information
        
Stopped at Page 13 of 23
+ backwards connections implement context effects.
++ backwards connections have NMDA receptors, with slower time constants, allowing more enduring context effects
        
- backwards connections can skip levels, while forward genrealyl do not
        
        Representational inference and learning
                
        Brain is faced with a problem of inverting a non-linear generatie model. Linear generative models overlap causes in a transparent way, but usually multiple causes (objects) interact in complex ways (with occlusions)
        
      EM algorithm for learning and inference. E-step is the inference step, and M-step is the learning step.
        
Free energy formulation of EM, where you have a lower-bound on the marginal likelihood of the data.
        
E-step increases the bound with respect to a distribution Q, which is the expectation of the latent causes
        
M-step increase the bound with respect to the unknonw parameters
        
Inference and learning work in exactly the same way: minimize the free energy. This is effectively the same as minimizing surprise about the sensory inputs encountered.
                  
predictive coding
                
minimizing prediction error
- backwards connections play the role a prior, whcih helps for ill-posed problems
                  
hierarchical models
                
data at the upper level is the prior on the lower level
        
You can do EM for the entire hierarchical model at once.
                  
Implications for cortical infrastructure
          
        1) Hierarhcial organization
This permits a biological plausible implementation, since connetions driving inference only need to run between neighbouring levels
        
2) Reciprocal connections (forward and lateral) must be reciprocated. This is consistent with anatomical observations
        
3) Backwards connections need to be modulatory (non-linear), while forward connections do not. Backwards projections are consisntent with this (NMDA receptors).
        
4) Plasticity - complicated prediction here...
                  
Implications for coritcal physiology
                
minimizing free energy produces very realistic receptive fields, like those in Olshausen and Field (1996)},
author = {Friston, Karl},
doi = {10.1098/rstb.2005.1622},
file = {:Users/Brenden/Documents/Mendeley/Friston - 2005 - A theory of cortical responses.pdf:pdf},
issn = {0962-8436},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Biophysical Phenomena,Biophysics,Cerebral Cortex,Cerebral Cortex: anatomy & histology,Cerebral Cortex: physiology,Electrophysiology,Humans,Interneurons,Interneurons: cytology,Interneurons: physiology,Learning,Learning: physiology,Models,Neurological,Perception,Perception: physiology,Statistical,Synapses,Synapses: physiology},
month = apr,
number = {1456},
pages = {815--36},
pmid = {15937014},
title = {{A theory of cortical responses.}},
volume = {360},
year = {2005}
}
@article{Friston2010,
abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories - optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
author = {Friston, Karl},
doi = {10.1038/nrn2787},
file = {:Users/Brenden/Documents/Mendeley/Friston - 2010 - The free-energy principle a unified brain theory.pdf:pdf},
issn = {1471-0048},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Brain,Brain: physiology,Cognition,Cognition: physiology,Humans,Learning,Learning: physiology,Nerve Net,Nerve Net: physiology,Perception,Perception: physiology,Psychological Theory},
month = feb,
number = {2},
pages = {127--38},
pmid = {20068583},
publisher = {Nature Publishing Group},
title = {{The free-energy principle: a unified brain theory?}},
volume = {11},
year = {2010}
}
@article{Friston2003,
abstract = {This article is about how the brain data mines its sensory inputs. There are several architectural principles of functional brain anatomy that have emerged from careful anatomic and physiologic studies over the past century. These principles are considered in the light of representational learning to see if they could have been predicted a priori on the basis of purely theoretical considerations. We first review the organisation of hierarchical sensory cortices, paying special attention to the distinction between forward and backward connections. We then review various approaches to representational learning as special cases of generative models, starting with supervised learning and ending with learning based upon empirical Bayes. The latter predicts many features, such as a hierarchical cortical system, prevalent top-down backward influences and functional asymmetries between forward and backward connections that are seen in the real brain. The key points made in article are: (i). hierarchical generative models enable the learning of empirical priors and eschew prior assumptions about the causes of sensory input that are inherent in non-hierarchical models. These assumptions are necessary for learning schemes based on information theory and efficient or sparse coding, but are not necessary in a hierarchical context. Critically, the anatomical infrastructure that may implement generative models in the brain is hierarchical. Furthermore, learning based on empirical Bayes can proceed in a biologically plausible way. (ii). The second point is that backward connections are essential if the processes generating inputs cannot be inverted, or the inversion cannot be parameterised. Because these processes involve many-to-one mappings, are non-linear and dynamic in nature, they are generally non-invertible. This enforces an explicit parameterisation of generative models (i.e. backward connections) to afford recognition and suggests that forward architectures, on their own, are not sufficient for perception. (iii). Finally, non-linearities in generative models, mediated by backward connections, require these connections to be modulatory, so that representations in higher cortical levels can interact to predict responses in lower levels. This is important in relation to functional asymmetries in forward and backward connections that have been demonstrated empirically.},
author = {Friston, Karl},
doi = {10.1016/j.neunet.2003.06.005},
file = {:Users/Brenden/Documents/Mendeley/Friston - 2003 - Learning and inference in the brain.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks},
keywords = {Bayes Theorem,Brain,Brain: physiology,Learning,Learning: physiology,Neural Networks (Computer)},
month = nov,
number = {9},
pages = {1325--52},
pmid = {14622888},
title = {{Learning and inference in the brain.}},
volume = {16},
year = {2003}
}
@book{Fu1974,
annote = {http://books.google.com/books?id=-lENKsb5khIC&pg=PR3&lpg=PR3&dq=Syntactic+methods+in+pattern+recognition&source=bl&ots=9iSAllzO6g&sig=aWY_lFM086DFGJpKWg1klDGYWRs&hl=en&sa=X&ei=y8whT67iN8zI0AHs0PWFCQ&ved=0CC8Q6AEwAQ#v=onepage&q&f=false},
author = {Fu, King Sun},
keywords = {part-based models,program induction},
mendeley-tags = {part-based models,program induction},
title = {{Syntactic methods in pattern recognition}},
year = {1974}
}
@article{Fukushima1980,
author = {Fukushima, Kunihiko},
file = {:Users/Brenden/Documents/Mendeley/Fukushima - 1980 - Neocognitron A self-organizing neural network model for a mechanism of pattern recognition unaffectedby shift in position.pdf:pdf},
journal = {Biological Cybernetics},
pages = {193--202},
title = {{Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffectedby shift in position}},
volume = {36},
year = {1980}
}
@article{Galantucci2006,
annote = {Three claims of motor theory:
        
(1) speech is special
(2) perceiving speech is perceiving gestures
(3) motor system is recruited for perceiving speech
        
The third is the most important, and this paper provides a number of great examples of it.
        
---
        
Original motivation:
-- failure of automatic reading system that codes word with arbitrary phonemes. People couldn't perceive this quickly. What was different about speech? Coarticulation.
-- Early emphasis on learned associations. 
-- Then, it was a module in Fodor's sense. Supported by the duplex phenomenon. A sound is perceived two ways at once.
        
(1) Speech is special. (false)
-- Speech is not the only auditory sound that tries to perceive distal stimuli. Plus, duplex perception can be replicated when slamming doors.
-- Also, other domains recruit the motor system.
-- It's not clear if there is hardware dedicated to just speech.
        
(2) Perceiving speech is perceiving gestures (probably true)
-- McGurk effect, where gestures influence how speech is perceived
        
(3) Speech perception activates motor systems
-- Differences in perception between individuals mirror production differences
-- used as a mechanism in frogs to perceive songs, but only by those of genetic matches
-- bird song production areas are sensitivty to acoustic simtuli
-- Shiffar and Freyd -- apparent motion follows biological constraints
-- 2/3 power law of motion, where velocities are slower the more curved the motion. Perception of motion is sensitivet to this law.
-- Knoblich and Prinz (2001) -- people can categorize trajectories drawn by themselves vs. others
-- mirror neurons
-- Prinz (1997) event codes, as a common-coding principle. This is in contrast with the more conventional view that formarts are incommensurate and must be translated. Actions are coded in terms of the effects they produce in the world. Evidence by stimulus-response compatiblity effects.
-- People are worse at happy/sad discrimination with a pen in their mouth, which prevents facial mimicry (Niedenthal, Brauer,... 2001)},
author = {Galantucci, Bruno and Fowler, Carol and Turvey, M T},
file = {:Users/Brenden/Documents/Mendeley/Galantucci, Fowler, Turvey - 2006 - The motor theory of speech perception reviewed.pdf:pdf},
journal = {Psychonomic Bulletin and Review},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
number = {3},
pages = {361--377},
title = {{The motor theory of speech perception reviewed}},
volume = {13},
year = {2006}
}
@misc{Garcia1966,
abstract = {Beginning with Darwin's work in the 1870s,Foundations of Animal Behaviorselects the most important works from the discipline's first hundred yearsforty-four classic papersand presents them in facsimile, tracing the development of the field. These papers are classics because they either founded a line of investigation, established a basic method, or provided a new approach to an important research question.The papers are divided into six sections, each introduced by prominent researchers. Sections one and two cover the origins and history of the field and the emergence of basic methods and approaches. They provide a background for sections three through six, which focus on development and learning; neural and hormonal mechanisms of behavior; sensory processes, orientation, and communication; and the evolution of behavior.This outstanding collection will serve as the basis for undergraduate and graduate seminars and as a reference for researchers in animal behavior, whether they focus on ethology, behavioral ecology, comparative psychology, or anthropology.Published in association with the Animal Behavior Society},
author = {Garcia, J and Koelling, R A},
booktitle = {Psychonomic Science},
chapter = {19},
editor = {Drickamer, Lee C},
isbn = {0226354563},
number = {3},
pages = {123--124},
publisher = {University of Chicago Press},
title = {{Relation of cue to consequence in avoidance learning}},
url = {http://books.google.com/books?hl=en&amp;lr=&amp;id=14uLkgB73RcC&amp;oi=fnd&amp;pg=PA374&amp;dq=relation+of+cue+to+consequence+in+avoidance+learning&amp;ots=LX0bz_SFdE&amp;sig=R7Fmf_UmQziNaG2ZYL-EVTKjdiw},
volume = {4},
year = {1966}
}
@article{Gauthier2000,
abstract = {Expertise with unfamiliar objects ('greebles') recruits face-selective areas in the fusiform gyrus (FFA) and occipital lobe (OFA). Here we extend this finding to other homogeneous categories. Bird and car experts were tested with functional magnetic resonance imaging during tasks with faces, familiar objects, cars and birds. Homogeneous categories activated the FFA more than familiar objects. Moreover, the right FFA and OFA showed significant expertise effects. An independent behavioral test of expertise predicted relative activation in the right FFA for birds versus cars within each group. The results suggest that level of categorization and expertise, rather than superficial properties of objects, determine the specialization of the FFA.},
author = {Gauthier, I and Skudlarski, P and Gore, J C and Anderson, A W},
doi = {10.1038/72140},
file = {:Users/Brenden/Documents/Mendeley/Gauthier et al. - 2000 - Expertise for cars and birds recruits brain areas involved in face recognition.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Adult,Animals,Automobiles,Birds,Brain Mapping,Data Display,Face,Humans,Magnetic Resonance Imaging,Male,Occipital Lobe,Occipital Lobe: physiology,Pattern Recognition,Photic Stimulation,Professional Competence,Task Performance and Analysis,Temporal Lobe,Temporal Lobe: physiology,Visual,Visual: physiology,classic psychology,perceptual expertise},
mendeley-tags = {classic psychology,perceptual expertise},
month = feb,
number = {2},
pages = {191--7},
pmid = {10649576},
title = {{Expertise for cars and birds recruits brain areas involved in face recognition}},
volume = {3},
year = {2000}
}
@article{Gauthier1999,
abstract = {Part of the ventral temporal lobe is thought to be critical for face perception, but what determines this specialization remains unknown. We present evidence that expertise recruits the fusiform gyrus 'face area'. Functional magnetic resonance imaging (fMRI) was used to measure changes associated with increasing expertise in brain areas selected for their face preference. Acquisition of expertise with novel objects (greebles) led to increased activation in the right hemisphere face areas for matching of upright greebles as compared to matching inverted greebles. The same areas were also more activated in experts than in novices during passive viewing of greebles. Expertise seems to be one factor that leads to specialization in the face area.},
annote = {Are faces special?
- inversion is more detrimetal
        
Subjects learned "greebles" such that they were as fast at categorizing at the individual level when compared to the family level. At least 7 hours of training
        
localizer task: viewing faces vs. viewing non-face objects
        
Prediction: greebles in block 3 would have as high a response as faces, when comparing upright vs inverted greebles
        
This was significant, but with a lot of residual. The way they are doing statistics, and why they are testing upright/inverted contrast rather than just straightfoward activation -- is confusing to me. What is this sum of t-values, I guess its all pixels in the ROI?
        
Task: sequential matching, where they performed same/different identity judgements 
- stimuli were either all upright or all inversted in a block
        
Also, there seems to be more activation for greebles after training, rather than displaced activation
                  
passive viewing task        
comparing faces, objects, and greebles, there was an interaction for whether or not they were a greeble expert, in terms of overall activation in FFA
        
Training procedure greebles are different than the ones during test, claims they want to reduce learning effect.
aLso, in scanning sessions are with one "family" at a time, and the individuals changed during test
        
Nancy's complaint:
Scanning is only done with one family of greebles, while training was with many famililies},
author = {Gauthier, I and Tarr, M J and Anderson, a W and Skudlarski, P and Gore, J C},
doi = {10.1038/9224},
file = {:Users/Brenden/Documents/Mendeley/Gauthier et al. - 1999 - Activation of the middle fusiform 'face area' increases with expertise in recognizing novel objects.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Adult,Face,Female,Humans,Magnetic Resonance Imaging,Male,Neurophysiological,Neurophysiological: physiology,Pattern Recognition,Recruitment,Temporal Lobe,Temporal Lobe: physiology,Visual,Visual: physiology,classic psychology,perceptual expertise},
mendeley-tags = {classic psychology,perceptual expertise},
month = jun,
number = {6},
pages = {568--73},
pmid = {10448223},
title = {{Activation of the middle fusiform 'face area' increases with expertise in recognizing novel objects.}},
volume = {2},
year = {1999}
}
@article{Geisler2001,
abstract = {The human brain manages to correctly interpret almost every visual image it receives from the environment. Underlying this ability are contour grouping mechanisms that appropriately link local edge elements into global contours. Although a general view of how the brain achieves effective contour grouping has emerged, there have been a number of different specific proposals and few successes at quantitatively predicting performance. These previous proposals have been developed largely by intuition and computational trial and error. A more principled approach is to begin with an examination of the statistical properties of contours that exist in natural images, because it is these statistics that drove the evolution of the grouping mechanisms. Here we report measurements of both absolute and Bayesian edge co-occurrence statistics in natural images, as well as human performance for detecting natural-shaped contours in complex backgrounds. We find that contour detection performance is quantitatively predicted by a local grouping rule derived directly from the co-occurrence statistics, in combination with a very simple integration rule (a transitivity rule) that links the locally grouped contour elements into longer contours.},
author = {Geisler, W S and Perry, J S and Super, B J and Gallogly, D P},
file = {:Users/Brenden/Documents/Mendeley/Geisler et al. - 2001 - Edge co-occurrence in natural images predicts contour grouping performance.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Bayes Theorem,Computer-Assisted,Female,Form Perception,Form Perception: physiology,Gestalt Theory,Humans,Image Processing,Male,Mathematical Computing,Psychophysics},
month = mar,
number = {6},
pages = {711--24},
pmid = {11248261},
title = {{Edge co-occurrence in natural images predicts contour grouping performance.}},
volume = {41},
year = {2001}
}
@article{Geisler2008,
abstract = {The environments in which we live and the tasks we must perform to survive and reproduce have shaped the design of our perceptual systems through evolution and experience. Therefore, direct measurement of the statistical regularities in natural environments (scenes) has great potential value for advancing our understanding of visual perception. This review begins with a general discussion of the natural scene statistics approach, of the different kinds of statistics that can be measured, and of some existing measurement techniques. This is followed by a summary of the natural scene statistics measured over the past 20 years. Finally, there is a summary of the hypotheses, models, and experiments that have emerged from the analysis of natural scene statistics.},
annote = {Since the perceptual system is adapted to the environment, we can learn about the perceptual system by measuring the environment.
        
This is in contrast to the traditional approach to perception, where a scientist develops and tests an informal hypothesis.
        
--
        
Example with eyes:
animals that avoid prey have them on opposite sides of head
animals that hunt have them in front, to maximize binocular vision
        
Read about efficient coding (Barlow, 1961)
        
Reasons for ideal observed models:
-- helps you understand the task
-- comparison for human performance
-- often reduces to simple decision rules 
Comment: but only for low-level perception
        
The number of samples needed to estimate a distribution increases rapidly as the number of dimensions increase ("the curse of dimensionality")
        
Within-domain statistics:
-- the relationship between luminance and contrast
-- color: marginal distributions of color responses + luminance are Gaussian in natural images
-- for spatial scales, amplitude spectra fall approximately as 1/f. Thus high frequencies have lower amplitudes. Also, this leads to scale invariance, where zooming in or out has roughly the same spectrum. There are strong dependencies between filter responses
        
Between-domain statistics:
Do two edges belong to the same or different physical contours?
--If contrast polarity is the same and cocircular, it is the same contour
-- If contrast polarity is different and not coricular, it is a different contour
Range information and binocular disparity
        
Predictions:
--Histogram equalization. Neurons should divide up distribution into equal sized bins, so prevent neurons from becoming over/under saturated. They do seem to behave this way, with respect to the distribution of luminance
-- Olshausen and Field. Field suggested that V1 filters respond strongly but sparsely (1987). With an optimization algorithm, they recovered V1 filters from natural images.
-- Predicting saccades as reducing total uncertainty about the contrast at every location in the image
-- Simple image statistics can discriminate between leaves, shadow boundaries, and surface markings with reasonably high accuracy},
author = {Geisler, Wilson S},
doi = {10.1146/annurev.psych.58.110405.085632},
file = {:Users/Brenden/Documents/Mendeley/Geisler - 2008 - Visual perception and the statistical properties of natural scenes.pdf:pdf},
issn = {0066-4308},
journal = {Annual Review of Psychology},
keywords = {Bayes Theorem,Bayesian perception,Color Perception,Color Perception: physiology,Data Interpretation,Eye Movements,Eye Movements: physiology,Humans,Motion Perception,Motion Perception: physiology,Space Perception,Space Perception: physiology,Statistical,Visual Perception,Visual Perception: physiology},
mendeley-tags = {Bayesian perception},
month = jan,
number = {August 2007},
pages = {167--92},
pmid = {17705683},
title = {{Visual perception and the statistical properties of natural scenes.}},
volume = {59},
year = {2008}
}
@article{Geisler1989,
abstract = {Visual stimuli contain a limited amount of information that could potentially be used to perform a given visual task. At successive stages of visual processing, some of this information is lost and some is transmitted to higher stages. This article describes a new analysis, based on the concept of the ideal observer in signal detection theory, that allows one to trace the flow of discrimination information through the initial physiological stages of visual processing, for arbitrary spatio-chromatic stimuli. This ideal-observer analysis provides a rigorous means of measuring the information content of visual stimuli and of assessing the contribution of specific physiological mechanisms to discrimination performance. Here, the analysis is developed for the physiological mechanisms up to the level of the photoreceptor. It is shown that many psychophysical phenomena previously attributed to neural mechanisms may be explained by variations in the information content of the stimuli and by preneural mechanisms.},
author = {Geisler, Wilson S},
file = {:Users/Brenden/Documents/Mendeley/Geisler - 1989 - Sequential ideal-observer analysis of visual discriminations.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Attention,Attention: physiology,Bayesian perception,Discrimination Learning,Discrimination Learning: physiology,Form Perception,Form Perception: physiology,Humans,Orientation,Orientation: physiology,Pattern Recognition,Psychophysics,Visual,Visual Pathways,Visual Pathways: physiology,Visual: physiology},
mendeley-tags = {Bayesian perception},
month = apr,
number = {2},
pages = {267--314},
pmid = {2652171},
title = {{Sequential ideal-observer analysis of visual discriminations.}},
volume = {96},
year = {1989}
}
@article{Geisler2011,
abstract = {An ideal observer is a hypothetical device that performs optimally in a perceptual task given the available information. The theory of ideal observers has proven to be a powerful and useful tool in vision research, which has been applied to a wide range of problems. Here I first summarize the basic concepts and logic of ideal observer analysis and then briefly describe applications in a number of different areas, including pattern detection, discrimination and estimation, perceptual grouping, shape, depth and motion perception and visual attention, with an emphasis on recent applications. Given recent advances in mathematical statistics, in computational power, and in techniques for measuring behavioral performance, neural activity and natural scene statistics, it seems certain that ideal observer theory will play an ever increasing role in basic and applied areas of vision science.},
author = {Geisler, Wilson S},
file = {:Users/Brenden/Documents/Mendeley/Geisler - 2011 - Contributions of ideal observer theory to vision research.pdf:pdf},
institution = {Center for Perceptual Systems and Department of Psychology, University of Texas at Austin, United States. geisler@psy.utexas.edu},
journal = {Vision Research},
keywords = {Bayesian perception},
mendeley-tags = {Bayesian perception},
number = {7},
pages = {771--781},
publisher = {Elsevier Ltd},
title = {{Contributions of ideal observer theory to vision research.}},
volume = {51},
year = {2011}
}
@book{Gelman2004,
author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Rubin, Donalid B},
edition = {2},
publisher = {Chapman and Hall/CRC},
title = {{Bayesian Data Analysis}},
year = {2004}
}
@article{Gelman1990,
author = {Gelman, R},
doi = {10.1016/0364-0213(90)90027-T},
file = {:Users/Brenden/Documents/Mendeley/Gelman - 1990 - First principles organize attention to and learning about relevant data Number and the animate-inanimate distinction as examples.PDF:PDF},
issn = {03640213},
journal = {Cognitive Science},
month = mar,
number = {1},
pages = {79--106},
title = {{First principles organize attention to and learning about relevant data: Number and the animate-inanimate distinction as examples}},
volume = {14},
year = {1990}
}
@article{Geman1992,
annote = {How does this relate to learning rich representations from just a few examples? Should rich representations be harder to learn in general?
        
Yes, but it depends on what the prior is on the rich representation.
                  
regression problems:For a fixed size dataset with n points,
the expected square error, across all possible datasets, can be decomposed into two terms:
                  
bias: the difference between the expected function predictions across datasets and the true function
                  
variance: the variance of the expected function, compared to its mean, across datasets
        
---
Famous paper about over-fitting and under-fitting.
        
The bias/variance dilemma:
incorrect models have high bias
truly model-free inference has high variance
        
The focus should be on the right "representations" for learning.
        
non-parametric: no particular decisinom boundary/class model is assumed in advance. They can be characterized by consistency, since they arrive at the right answer in the limit of infinite data.
----
If you have too simple a model, is it stable across datasets, but it underfits.
        
If you have too complex a model, it is not stable across datasets, and it generalizes poorly.
        
Non-parametric models are generally consistent, in that they converge in the limit of infinite data. But they are very crude with just a few data points. With parametric models, even if the true model is outside the class, it might peform better.
        
There are successes of non-parametric methods
(CART partioning method for multi-class classification)
        
Credit-card fraud has large datasets, so it makes sense to try non-parametric methods.
--
        
Mathematics:
        This is formulated for a regression problem, where we want to predict some continuous variable
        
For a fixed size dataset with n points,
the expected square error, across all possible datasets, can be decomposed into two terms:
                  
bias: the difference between the expected function predictions across datasets and the true function
                  
variance: the variance of the expected function, compared to its mean, across datasets
        
When solving a regression problem with a neural network, how big of a network should you use? If you have one hidden unit, you'll have huge bias. With many hidden units, you'll have huge variance.
        
With splines, you attempt to keep some higher-order derivative of the function below a certain value. This value is the regulaization parameter, and has a similar function as the number of hidden units.
        
Neural networks are supposed to discover rules for you-- rather than engineering them by hand -- but at the price of high variance. 
                  
dedicated machines are harder to build but easier to train        
        
tested three-non-parametric methods
        
k-Nearest neighbor: With k=N, you have high bias but little variance. With k=1, you have high variance. Best algorithm is probably in the middle
        
parzen-window or kernel estimator: combine responses of all points, with amoutn determined by the kernel. bias/variance governed by bandwith
        
for feedforward networks, the number of hidden units might control bias/variacne
        
Experiment:
X drawn in 2D rectangle, where y={1,0} depending on whether the point falls above or below a sinusoid
        
You can approximate bias and variance by sampling many datasets
        
Without noise, 2-NN did the best. With noise, higher-order NN was the best (like 10)
        
With neural net, in determinstic task, there was an advantage for more hidden units. In the noisy task, there was an advantage for very few hidden units (2)
        
With neural networks, you see "early stopping" -- where the total error on the test set starts to increase as you keep training. Here, variance is going up while bias is going down.
        
--- 
Practical strategies:
        
cross-validation: this works really well! despite a lack of theory
        
Can neural nets solve problems that are supposed to require real "intelligence"? The question boils down to whether you can expect a big enough training set
        
This is really a bias/variance dillema, becaues you can't approach perfect performance in any practical sense.
        
If pressed, the authors believe it is unlikely to get a good bias/variance tradeoff with non-parametric methods and finite data
        
Neural nets acheive consistency -- but so what? This tells us little about what to do.
        
Children can learn a new word in just one example. Does this disprove the previous analysis? You must purposefully introduce bias. And the bias must be harmless for the problem at hand. -- the bias must be designed for each problem.
        
the study of pre-wired designs, like for vision or adutiion, might be much more to the point -- that neurally inspired non-parametric inference.
        
To say the neural nets have the right "bias'  of real brains just because they are "brain-like" seems very far fetched.
        
another experiment: with a graph-matching metric between handwritten characters, you have much better performance
                  
Finding the right biases is the substantial problem in neural modeling, not finding the most general architecture.      },
author = {Geman, Stuart and Bienenstock, Elie and Doursat, Rene},
file = {:Users/Brenden/Documents/Mendeley/Geman, Bienenstock, Doursat - 1992 - Neural Networks and the BiasVariance Dilemma.pdf:pdf},
journal = {Neural Computation},
keywords = {classic AI,neural networks},
mendeley-tags = {classic AI,neural networks},
pages = {1--58},
title = {{Neural Networks and the Bias/Variance Dilemma}},
volume = {4},
year = {1992}
}
@article{Gentner1983,
annote = {Similarity, as defined by Tversky, has little to say about what makes a good analogy
        
How do you map one domain into another?
        
1) Discard attributes of objects
2) Try to prserve relations
3) In trying to decide "which" relations are preserved, choose systems of relations (relations on relations)
        
        
Two kinds of comparisoins:
literal statements - includes relatoins and object properties
analgoeis - relations, but not attributres, are mapped
        
By this analysis, the contrast between a literal statement and an analogy is a continuum.
        
      },
author = {Gentner, Dedre},
doi = {10.1016/S0364-0213(83)80009-3},
file = {:Users/Brenden/Documents/Mendeley/Gentner - 1983 - Structure-Mapping A Theoretical Framework for Analogy.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
month = jun,
number = {2},
pages = {155--170},
title = {{Structure-Mapping: A Theoretical Framework for Analogy}},
volume = {7},
year = {1983}
}
@inproceedings{Ghahramani2005,
annote = {Problem:
        
see a few positive examples of a set. Try to complete the rest of the set.
        
clustering-on-demand: forming a cluster once some information about the membership has been revealed.
                  
model        
-We observed some D_c as belonging to a latent class
- want to measure p(x|D_c) for new examples x, 
- score is defined by dividing likelihood over P(x), which normalizes for items that are likely everywhere
        
You can re-write this in various forms, and you may want to integrate out your uncertainty about the parameters of each class.
        
under certain types of models, this can be computed with a simple sparse matrix multiplication.
        
For instance, each dat point is a binary vector, with unknown element probabilities.
                  
results        
        
people tend to prefer the retrieval results to google sets, as determiend in a study.},
author = {Ghahramani, Zoubin and Heller, Katherine A},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:Users/Brenden/Documents/Mendeley/Ghahramani, Heller - 2005 - Bayesian Sets.pdf:pdf},
keywords = {classic AI},
mendeley-tags = {classic AI},
title = {{Bayesian Sets}},
year = {2005}
}
@inproceedings{Gibson2010,
author = {Gibson, B and Zhu, X and Rogers, T and Kalish, C and Harrison, J},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
title = {{Humans learn using manifolds, reluctantly}},
volume = {24},
year = {2010}
}
@article{Gibson2013,
abstract = {Most empirical work in human categorization has studied learning in either fully supervised or fully unsupervised scenarios. Most real-world learning scenarios, however, are semi-supervised: Learners receive a great deal of unlabeled information from the world, coupled with occasional experiences in which items are directly labeled by a knowledgeable source. A large body of work in machine learning has investigated how learning can exploit both labeled and unlabeled data provided to a learner. Using equivalences between models found in human categorization and machine learning research, we explain how these semi-supervised techniques can be applied to human learning. A series of experiments are described which show that semi-supervised learning models prove useful for explaining human behavior when exposed to both labeled and unlabeled data. We then discuss some machine learning models that do not have familiar human categorization counterparts. Finally, we discuss some challenges yet to be addressed in the use of semi-supervised models for modeling human categorization.},
author = {Gibson, Bryan R and Rogers, Timothy T and Zhu, Xiaojin},
doi = {10.1111/tops.12010},
file = {:Users/Brenden/Documents/Mendeley/Gibson, Rogers, Zhu - 2013 - Human semi-supervised learning.pdf:pdf},
issn = {1756-8765},
journal = {Topics in Cognitive Sciencenitive science},
keywords = {Artificial Intelligence,Classification,Concept Formation,Decision Making,Empirical Research,Humans,Knowledge of Results (Psychology),Learning,Models,Probability,Psychological,Statistical,Statistical Distributions,semi-supervised learning},
mendeley-tags = {semi-supervised learning},
number = {1},
pages = {132--72},
pmid = {23335577},
title = {{Human semi-supervised learning.}},
volume = {5},
year = {2013}
}
@article{Gibson2006,
author = {Gibson, E},
doi = {10.1016/j.jml.2005.12.005},
file = {:Users/Brenden/Documents/Mendeley/Gibson - 2006 - The interaction of top–down and bottom–up statistics in the resolution of syntactic category ambiguity☆.pdf:pdf},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {frequency,sentence comprehension,statistical language processing,synactic category disambiguation},
month = apr,
number = {3},
pages = {363--388},
title = {{The interaction of top–down and bottom–up statistics in the resolution of syntactic category ambiguity☆}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0749596X0500149X},
volume = {54},
year = {2006}
}
@article{Gilet2011,
abstract = {In this paper, we study the collaboration of perception and action representations involved in cursive letter recognition and production. We propose a mathematical formulation for the whole perception-action loop, based on probabilistic modeling and bayesian inference, which we call the Bayesian Action-Perception (BAP) model. Being a model of both perception and action processes, the purpose of this model is to study the interaction of these processes. More precisely, the model includes a feedback loop from motor production, which implements an internal simulation of movement. Motor knowledge can therefore be involved during perception tasks. In this paper, we formally define the BAP model and show how it solves the following six varied cognitive tasks using bayesian inference: i) letter recognition (purely sensory), ii) writer recognition, iii) letter production (with different effectors), iv) copying of trajectories, v) copying of letters, and vi) letter recognition (with internal simulation of movements). We present computer simulations of each of these cognitive tasks, and discuss experimental predictions and theoretical developments.},
annote = {They don't model parsing because:
a) they do online character recognition with (x,y,t) data
b) they use cursive characters so there are no pen lifts
        
They don't do one-shot learning:
In their dataset, they have 4 people draw each Latin character 40 times. For classification, they use 35 training examples per class to get above 90% correct. But if the model tries to generalize to a new writer it hasn't been trained on, it is about 50% correct.
        
The biggest difference is that they don't have a single generative model of characters - from an internal motor representation to data. They describe their model as "algorithmic", using "Bayes' rule to combine various representations." They do have a "production module" that is like a generative model from motor to data, but then they have a separate "perception module" that starts with the data and has a CPD on an internal representation. Then they have a third "simulation module" that takes the unexecuted output of the production module and can re-recognize it if desired (huh?). So, the model has arrows running in seemingly all directions, sprinkled with some questionable uses of Bayes' rule. 
        
I do think there was a good paper hiding in here. They just need to collapse everything into one generative model, and then their other "modules" are more-or-less serving as a bottom-up inference procedure.
-----------------
Differences with HBPL:
        
+There is not parsing problem, because
- they deal with online charcter recognition        
- have cursive characters, where you don't lift the pen
+There is not a generative model from motor program to image
+ Use about 35 training examples, per person, to do within-person classification. Accuracy is very poor for new people (50% correct)
+ Some questionable uses of Bayes' rule are mixed in here too
        
Their model is "Bayesian" and defines a joint probability distribution, but it is not using a generative model of characters in the natural way
- Letter -> internal motor representation -> trajectory
        
But rather than inverting this generative process for perception, they have a duplicate generative process that goes from trajectory -> internal perceptual represeiation -> letter. What should be inference, they define a forward process instead
        
--
                  
Introduction        
        
Few studies have looked at reading and writing as intimately linked.
        
most studies of motor control are open-loop, wheren you don't change commands depending on what you have done so far
models that use strictly image-analysis are not viable models of peopel
        
Bayesian model        
They want to apply model to lots of tasks (both recognition, generation, copying) [similar to HBPL].
        
Use online letter recognition.
        
Assumes there are separate visual and production representations, but they are encoded in the same space.
        
You can use different effectors to produce the production.
                  
Bayesian model
                
-Prior on letter P(L) and writer P(W)
-internal representation P(C | L,W)
- visual rep. P(V|c)
- perceptual rep. P(P|c)
        
There are two distint, inter-linked internal representations: one visual and one motor
- but they use the same space and same encoding, but can be activated differently
        
P(CV | L,W) P(CP | L,W) P(V|CV) P(P|CP)
        
Also, we can add an effector model P(E|P), which transforms the general space to a particualr effect
                  
representation        
need a representation that can be used for both perception and production
+ HMM features would not be useful guides for generation
+ some models can be very hard to invert
        
- set of via poitns, placed at places of zero x or y derivative
- via points are recorded as positions and velocities (4 values for each via point, up to 16 via points per trajectory)
+ markov assumption, where current position only depends on the last
- this is the internal "C" representation, for vision and production
        
Since there is interactions between perception/motor, those two internal representations are tied together
+ but this is not Bayesian?
+ we don't want them duplicated, so they can have different representations, one for perception and one for drawing
++Now, somehow, we had added yet another path, from the generaeted trajectory in the motor path to a siulated trajcetroy to an internal representaiton, which uses the same distribution as the perception path
        
finally, we have switches, that decide which part of the model is active (what?)
        
Movement generation as an open loop, since the movements are short.
                  
Perception model
                
Takes a pen trajectory, and extracts the via points (attaching them to pauses in x and y)
                  
Action model
                
It is well-known that visual feedback during movement execution plays a role. It's a closed loop. 
Note: with HBPL, We get a bit of this, by defining relations on strokes and depend on previous strokes
        
draw between via points, and use a minimum acceleration model. 
        
Thus, via points is how the visual and action models have the same representation
                  
Effector        
We can model effector control separately, like with joints on a robotic arm
                  
internal simulation model
                
IS the same as the perception model, where we take the generated motor trajectory, and turn it through perception
                  
Inference for recognition:        
        
Want to compute P(L | C), where  C was computed bottom-up from the via points. 
        
        
Then, with a letter model, we can compute the probability of the via points
P(C_t+1 | C_t, L), from markov process
                  
Data
                
Collected about 40 examples for each character from 4 writers
                  
Paramter fitting
                
Need to estimate P(C_t+1 | C_t, L), 
for each writer, using their 40 examples          
                
Via points are represented as discretized continuous space, with 41 integer values for position and 7 values for speed
        
Also, the parameters were smoothed to neighbors, allowing for better generalization
                  
Letter Classification
                
35 examples from each person as training
5 examples for testing
I believe this is witin a single writer
        
within-writer          
        94% correct
        
between-writer
93% correct
        
new-writer
50% correct
                  
Recognizing writer
                
35 training exampler per person per letter
        
For any given letter, who wrote it?
        
Only 80% correct for 4 people
                  
Writing letters        
        
Given the ltter and person, what are the arm accelerations used to draw?
        
They call this "inference", because they marginalize over the internal represenation, to compute the distributin on just join angles
        
(why wouldnt you just forward sample here?)
        
+ this is what they do!! very strange.
                  
Tasks that require both branches of the model        
                  
copying trajectories (we don't know letter)        
        
seems it does an okay job of this. I have no idea what inference problem they are really solving here
        
P(joints | trajectory) 
        
I think they just extract via points, and reconstruct from there
                  
copying ltters        
        
don't you have to sum over the internal representation here? 
        
Well, no, since we extract via points, compare them to the letter model.
        
Once we sample a letter, we re-draw the via ppoints, and then draw a new letter
                  
reuslts:        
you can copy a letter from one handwriting style to another
        
interesting to see if young children, pre-literate, are more liky trajectory copying, while development leeds to letter copying
                  
reading letters using internal simulation movements
                
Here, the entire model is activated, during the recognition of letters from trajecotires          
                
Instead of drawing the letter, instead of executing the trajectory copying, it is fed into an internal simulation
        
Thus, you get the entire loop? what??
        
Inference
First: run perception part
Then: generate trajectory, and pass it back to the internal simulator, which extract a letter again. This is compared to the letter representation model with memorized letter represenations
        
I guess this is only compared once?
                  
reuslts
                
classification rates are about the same as before, with just the perception module
        
but, if you have cases where the trajectory data is incomplete, they found examples where completing the trajectory results in a different classifications afterwards
+ this is interesting, but is it just a few cases? Do they also go the other way?
        
It is hard to say aynthing principled is going on here
                  
future directions
                
offlinel etter recognition would be harder, but knowing movements could be very beneficial for learning the concepts (our point)
        
claims it is an algorithmic model, using Bayes rule to combine different representations
+ they don't have an overall generative model
        
they want to know if you can collapse all their represenations? YES!!! you can},
author = {Gilet, Estelle and Diard, Julien and Bessi\`{e}re, Pierre},
doi = {10.1371/journal.pone.0020387},
file = {:Users/Brenden/Documents/Mendeley/Gilet, Diard, Bessi\`{e}re - 2011 - Bayesian action-perception computational model interaction of production and recognition of cursive let.pdf:pdf},
issn = {1932-6203},
journal = {{PloS ONE}},
keywords = {Bayes Theorem,Computer Simulation,Handwriting,Humans,Learning,Learning: physiology,Movement,Online Systems,Pattern Recognition,Reading,Robotics,Semantics,Visual,Visual: physiology,handwriting,part-based models},
mendeley-tags = {handwriting,part-based models},
number = {6},
pmid = {21674043},
title = {{Bayesian action-perception computational model: interaction of production and recognition of cursive letters.}},
volume = {6},
year = {2011}
}
@article{Glass2003,
annote = {Most speech recognizers divide the input into fixed-length "frames" of 10 ms. Then, a phoneme segment is some continguous subset of those frames
        
THe MIT approach: possible segments are a path through a graph, where you can model an utterance with different sequence of phonemes (replacing blocks, rather than individual elements)
- each segment is a single fixed-length feature vector, rather than having one per frame
        
Conditional independence is rarely true between individual frames, but it is more reasonable between subsequent segments.
        
near-miss modeling: model segments as either "phones" or "non-phones". Also model some phones as "near-misses" which are similar to phones we know but not great matches
        
Can also separeately model landmarks, or feature at the transition between phones (or even within a phone). These also augment the data space
        
Processing the eraw wafeform
- Somethine liek a Fourier transform
- whiten the data
- acoustic model is mixture of diagonal gaussians
        
Results:
generally, landmarks and segments do better than just one
      },
author = {Glass, James R},
doi = {10.1016/S0885-2308(03)00006-8},
file = {:Users/Brenden/Documents/Mendeley/Glass - 2003 - A probabilistic framework for segment-based speech recognition.pdf:pdf},
issn = {08852308},
journal = {Computer Speech & Language},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
month = apr,
pages = {137--152},
title = {{A probabilistic framework for segment-based speech recognition}},
volume = {17},
year = {2003}
}
@article{Gluck1988,
abstract = {We used adaptive network theory to extend the Rescorla-Wagner (1972) least mean squares (LMS) model of associative learning to phenomena of human learning and judgment. In three experiments subjects learned to categorize hypothetical patients with particular symptom patterns as having certain diseases. When one disease is far more likely than another, the model predicts that subjects will substantially overestimate the diagnosticity of the more valid symptom for the rare disease. The results of Experiments 1 and 2 provide clear support for this prediction in contradistinction to predictions from probability matching, exemplar retrieval, or simple prototype learning models. Experiment 3 contrasted the adaptive network model with one predicting pattern-probability matching when patients always had four symptoms (chosen from four opponent pairs) rather than the presence or absence of each of four symptoms, as in Experiment 1. The results again support the Rescorla-Wagner LMS learning rule as embedded within an adaptive network model.},
annote = {Extended Rescola-Wagner theory to a model that contain the pairwise interaction terms, not just the individual input dimensions},
author = {Gluck, M A and Bower, G H},
file = {:Users/Brenden/Documents/Mendeley/Gluck, Bower - 1988 - From Conditioning to Category Learning An Adaptive Network Model.pdf:pdf},
issn = {0096-3445},
journal = {Journal of Experimental Psychology: General},
keywords = {Association Learning,Diagnosis,Feedback,Humans,Microcomputers,Probability Learning,classic psychology,neural networks},
mendeley-tags = {classic psychology,neural networks},
month = sep,
number = {3},
pages = {227--47},
pmid = {2971760},
title = {{From Conditioning to Category Learning: An Adaptive Network Model}},
volume = {117},
year = {1988}
}
@article{Godden1975,
author = {Godden, D R and Baddeley, A D},
file = {:Users/Brenden/Documents/Mendeley/Godden, Baddeley - 1975 - Context-dependent memory in two natural environments On land and underwater.pdf:pdf},
journal = {British Journal of Psychologyi},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {3},
pages = {325--331},
title = {{Context-dependent memory in two natural environments: On land and underwater}},
volume = {66},
year = {1975}
}
@article{Gold2007,
abstract = {The study of decision making spans such varied fields as neuroscience, psychology, economics, statistics, political science, and computer science. Despite this diversity of applications, most decisions share common elements including deliberation and commitment. Here we evaluate recent progress in understanding how these basic elements of decision formation are implemented in the brain. We focus on simple decisions that can be studied in the laboratory but emphasize general principles likely to extend to other settings.},
annote = {---
Talk by Michael Shadlen, Oct 4
"Believing and Time: A neural mechanism for decision making"
        
!. reasoning from reliable and less reliable cues
        
-experiments with extra-cellular recording
- LIP cells
+ spatially selective, persistent activity from when the stimulus comes on a a particular location to when the eye focus gets there
        
Prob. categorization task (weather prediction
+ combinations of shapes changes whether which target is more likely to have a reward (left or right). But even if you pick the right one, its only 2/3 to 1/3
+ four possible shapes, each changes the probability (like features)
        
claim: no such thing as probability matching? just onise in the brain... what is the different?
        
the monkey learns this, and learns that different shapes have different probabilities
        
As the shapes come on one by one, an LIP cell, with the target in its receptibe field, fires proportionally to the log-likelihood ratio of picking that target over the  other
+ it increments and decrements its sum online, like a running sum
        
Is the brain doing sequential probability ratio tests?
(for each piece of evidence, evaluating the log-likelihood in favor of each hypothesis)
        
You can get similar effects in tasks where the monkey decides when to go, rather than a fixed response time. So he can see as many shapes as he wants
        
Firing rate of individual cells looks like accumlated evidence
        
When the monkey makes the choice inside the response field, it seems to do something different, and then "initiates the response field"
        
decision terminates on a threshold of log-likelihood
                  
2. decision confidence ('degree of belief')
                
Firing strength of LIP neurons, when seeing random dot patterns, is correlated with strength of evidence
        
(I guess it's not necessarily log-likelihood though, that was the previous study)
        
Neurons in MT respond relatively consistent across the trial, where LIP neurons seem to ramp up.
+ It looks like LIP is taking 20-40 samples before deciding, on average
+ you can tell because MT auto-correlation is pretty short
+ stimulus provides a constant amount of evidence, no reason to look in different parts of the screen, 
        
Can model with drift-diffusion model
        
You can have an experiment where there is a 3rd option, which gives a smlal "sure ting reward"
- He seems to be able to monitor internal uncertainy, and choose the 3rd option at just the right time
        
You can use the passage of time as a trick to marginalize over the strength of the movement... hmmm?
        
LIP connects sensory to motor areas
        
Thinks that abstract decision/thought as buildling on the same mechansisms of more basic perceptual decisiosn
        
        
        
        
        
        
        
      },
author = {Gold, Joshua I and Shadlen, Michael N},
doi = {10.1146/annurev.neuro.29.051605.113038},
file = {:Users/Brenden/Documents/Mendeley/Gold, Shadlen - 2007 - The neural basis of decision making.pdf:pdf},
issn = {0147-006X},
journal = {Annual review of neuroscience},
keywords = {Animals,Brain,Brain: anatomy & histology,Brain: physiology,Cognition,Cognition: physiology,Decision Making,Decision Making: physiology,Humans,Models,Movement,Movement: physiology,Neurological,Perception,Perception: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Psychophysics,Volition,Volition: physiology,classic psychology},
mendeley-tags = {classic psychology},
month = jan,
pages = {535--74},
pmid = {17600525},
title = {{The neural basis of decision making.}},
volume = {30},
year = {2007}
}
@article{Goldstone1994,
author = {Goldstone, R K},
journal = {Journal of Experimental Psychology: General},
number = {2},
pages = {178--200},
publisher = {Journal},
title = {{Influences of Categorization on Perceptual Discrimination}},
volume = {123},
year = {1994}
}
@article{Goldstone1998,
author = {Goldstone, R K},
journal = {Annual Review of Psychology},
pages = {585--612},
title = {{Perceptual learning}},
volume = {49},
year = {1998}
}
@incollection{Goldstone2003,
annote = {- Can't learn without constraints
        
- Some have argued for composition, like parts and relations (Biderman, Hummel, etc.)
+ but typically, these parts are fixed and learned in advance        
        
Could these parts be learned?
        
EM algorithm for factorial learning (Zoubin) can find independent components that can be used to create complex stimuli.
                  
Varities of perceptual learninbg
                
Is is perceptual or cocneptal? Lots of evidence that it is at the very early stages (auditory cortex cells are turned to often repeated sounds, Merzenich finger stiching, etc.)
                  
imprinting        
unsuperivsed learning, something about the stimulus is memorized
                  
unitization        
perceptual units combine, that are useulf or categorization
- learn configural patterns
        
Goldstone (2000) experiment. Mountainous stimulus, where you had to look at all 5 segments in order to classify it into the right cateogry. BUt there is only one stimulus that you need
- Do you develop a unitized whole for this stimulus?
        
you get much faster over 1.5 hours of training, and not when you only need to look at one region. Also, order of region is important
        
...
                  
dimension differentation
                
dimensions that are psychologically fused become separate and isolated
- perhaps training on two fused dimensions, in an orthognal way, might make them more separate?
        
Can use face morphs to create arbitrary dimensions. Learn 1 categorization judgement. tHen learn a second, which is shifted by 45 degrees( where the old was partially relevant) or 90 degrees wher ehte old is irrelevant
                  
reconciling unitization and dimension differentiation
                
** Palmer (1977) look at quantiative model of part naturlness
        
Pevtzow and Goldstone:  shown distortions of 4 stimuli, where the categorization rule differed in two groups. Afterwads, people did part-whole judgments.
+ diagonisticity of the part was a significant factor in the part/whole judgmets
                  
the categorization network
                
        
        
      },
author = {Goldstone, R L},
booktitle = {Perceptual organization in vision: Behavioral and neural perspectives},
file = {:Users/Brenden/Documents/Mendeley/Goldstone - 2003 - Learning to Perceive While Perceiving to Learn.pdf:pdf},
keywords = {handwriting,part-based models},
mendeley-tags = {handwriting,part-based models},
pages = {233--278},
title = {{Learning to Perceive While Perceiving to Learn}},
year = {2003}
}
@article{Goldstone1998a,
abstract = {Work in philosophy and psychology has argued for a dissociation between perceptually-based similarity and higher-level rules in conceptual thought. Although such a dissociation may be justified at times, our goal is to illustrate ways in which conceptual processing is grounded in perception, both for perceptual similarity and abstract rules. We discuss the advantages, power and influences of perceptually-based representations. First, many of the properties associated with amodal symbol systems can be achieved with perceptually-based systems as well (e.g. productivity). Second, relatively raw perceptual representations are powerful because they can implicitly represent properties in an analog fashion. Third, perception naturally provides impressions of overall similarity, exactly the type of similarity useful for establishing many common categories. Fourth, perceptual similarity is not static but becomes tuned over time to conceptual demands. Fifth, the original motivation or basis for sophisticated cognition is often less sophisticated perceptual similarity. Sixth, perceptual simulation occurs even in conceptual tasks that have no explicit perceptual demands. Parallels between perceptual and conceptual processes suggest that many mechanisms typically associated with abstract thought are also present in perception, and that perceptual processes provide useful mechanisms that may be co-opted by abstract thought.},
author = {Goldstone, R L and Barsalou, L W},
file = {:Users/Brenden/Documents/Mendeley/Goldstone, Barsalou - 1998 - Reuniting perception and conception.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Association Learning,Concept Formation,Humans,Perception,Problem-Based Learning,Symbolism,Thinking,classic psychology},
mendeley-tags = {classic psychology},
month = jan,
number = {2-3},
pages = {231--62},
pmid = {9557384},
title = {{Reuniting perception and conception.}},
volume = {65},
year = {1998}
}
@article{Goldstone2010,
abstract = {The contributions to this special issue on cognitive development collectively propose ways in which learning involves developing constraints that shape subsequent learning. A learning system must be constrained to learn efficiently, but some of these constraints are themselves learnable. To know how something will behave, a learner must know what kind of thing it is. Although this has led previous researchers to argue for domain-specific constraints that are tied to different kinds/domains, an exciting possibility is that kinds/domains themselves can be learned. General cognitive constraints, when combined with rich inputs, can establish domains, rather than these domains necessarily preexisting prior to learning. Knowledge is structured and richly differentiated, but its "skeleton" must not always be preestablished. Instead, the skeleton may be adapted to fit patterns of co-occurrence, task requirements, and goals. Finally, we argue that for models of development to demonstrate genuine cognitive novelty, it will be helpful for them to move beyond highly preprocessed and symbolic encodings that limit flexibility. We consider two physical models that learn to make tone discriminations. They are mechanistic models that preserve rich spatial, perceptual, dynamic, and concrete information, allowing them to form surprising new classes of hypotheses and encodings.},
annote = {1990 Cognitive Science issue:
the mind is a "swiss army knife", Cosmides and Tooby 1992
- Spelke: objects follow smooth trajectories in space and time
- Markman: needs constraints on word meaning (mutual exclusitvity)
+ whole object, taxonomic rather than thematic
- Keil: ontological knowledge is a tree. Predicates must apply to an entire sub-tree , thus prevneting "M" structures. If things can have fear but cannot be 2 hours long, and other things can be 2 hours long but cannot fear, you cant have still other things that both fear and last 2 hours long
        
This article: it's possible that many of those constraints are learned, and this doesn't make them any less powerful
- Wouldn't have a "A" detector or a "cow" detector hard-wried
                  
Learning overhypotheses        
        
Kemp et al. You could infer that "all animals have a characteristic number of legs", from that fact that storks have two, worms have none, beetles have six,e tc.
        
Powerful ability to learn struture in environemt, 
ignoring some features (via selection)
and create compact representations (via compression)
[see Sustain, which does both]
        
Another way, C-learning, or coordinate learning, where the things you learn is developed by other people (like language)
                  
Skeletons
                
Metaphor for constraints, ,first principels, where knowledge must hang off of it?
Can those skeletons be learned?
        
Even with tennis players, there skeletons adapt over type.
        
Neural gas model
Rogers and McClelland
                  
getting physical about constraint learning
                
Often, models that do this have pre-procesed and symbloci inpufts
Kemp's model (learning causal models) receives people, events, etc. as given types
+ can you have new types of entiteis?
        
in rogers and mcclelland, singles nodes represent "canaries", "can" , "fly"
+ not connected to the real world by perceptual system
        
        
        
      },
author = {Goldstone, Robert L and Landy, David},
doi = {10.1111/j.1551-6709.2010.01131.x},
file = {:Users/Brenden/Documents/Mendeley/Goldstone, Landy - 2010 - Domain-creating constraints.pdf:pdf},
issn = {1551-6709},
journal = {Cognitive science},
keywords = {classic psychology,cognitive development,constraints,domain-specificity,embodi-,inference,learning,ment,novelty,perception},
mendeley-tags = {classic psychology},
month = sep,
number = {7},
pages = {1357--77},
pmid = {21564250},
title = {{Domain-creating constraints}},
volume = {34},
year = {2010}
}
@article{Goldwater2009,
abstract = {Since the experiments of Saffran et al. [Saffran, J., Aslin, R., & Newport, E. (1996). Statistical learning in 8-month-old infants. Science, 274, 1926-1928], there has been a great deal of interest in the question of how statistical regularities in the speech stream might be used by infants to begin to identify individual words. In this work, we use computational modeling to explore the effects of different assumptions the learner might make regarding the nature of words--in particular, how these assumptions affect the kinds of words that are segmented from a corpus of transcribed child-directed speech. We develop several models within a Bayesian ideal observer framework, and use them to examine the consequences of assuming either that words are independent units, or units that help to predict other units. We show through empirical and theoretical results that the assumption of independence causes the learner to undersegment the corpus, with many two- and three-word sequences (e.g. what's that, do you, in the house) misidentified as individual words. In contrast, when the learner assumes that words are predictive, the resulting segmentation is far more accurate. These results indicate that taking context into account is important for a statistical word segmentation strategy to be successful, and raise the possibility that even young infants may be able to exploit more subtle statistical patterns than have usually been considered.},
annote = {Saffran et al. : infants track predictability of next sylabble (or phoneme) from the previous ones
- used to segment word boundaries
- seem to be one of the earliest cluse that infants are sensitivte to
        
They examine learning from natural, rather than artificial, language input
        
They find the model initially over-segments, when not enough words
        
Data
- words are strong together as a sequence of characters, and you must figure out the segmentation
        
MLE
- doesn't really make sense because it would treat the document as one big word
- 
        
Generative unigram model:
- decide if a word is novel, if so, generate a new lexical form
- a new lexical form generates "phoneme symbols" from some base distribution
        
Used CHILDRES database, when phoneme transcriptions
        
Use a DP on new words},
author = {Goldwater, Sharon and Griffiths, Thomas L and Johnson, Mark},
doi = {10.1016/j.cognition.2009.03.008},
file = {:Users/Brenden/Documents/Mendeley/Goldwater, Griffiths, Johnson - 2009 - A Bayesian framework for word segmentation exploring the effects of context.pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
keywords = {Algorithms,Bayes Theorem,Data Interpretation,Humans,Language Development,Models,Psychological,Speech Perception,Speech Perception: physiology,Statistical,classic psychology,speech recognition},
mendeley-tags = {classic psychology,speech recognition},
month = jul,
number = {1},
pages = {21--54},
pmid = {19409539},
publisher = {Elsevier B.V.},
title = {{A Bayesian framework for word segmentation: exploring the effects of context.}},
volume = {112},
year = {2009}
}
@article{Goodman2008,
author = {Goodman, Noah D and Mansinghka, Vikash K and Roy, Daniel M and Bonawitz, Keith and Tenenbaum, Joshua B},
file = {:Users/Brenden/Documents/Mendeley/Goodman et al. - 2008 - Church A language for generative models.pdf:pdf},
journal = {{Uncertainty in Artificial Intelligence}},
keywords = {program induction},
mendeley-tags = {program induction},
title = {{Church: A language for generative models}},
year = {2008}
}
@inproceedings{Goodman2,
annote = {Scalar implicature: should you same "some of the apples are red" or "all of them are red"
                  
experiment 1:
                
If the speaker doesn't know the color of one apple (it is in a bag), and the listener knows he can't see one, then "some of the aplpes are red" now includes the possibility that all of them are
        
[the scalar implicature is canceled in the partial access conditions]
                  
experiment 2:
                
"I have looked at 2 of the 3 letters. One of the letters has checks inside."
        
The model now thinks there is little probability of all 3 letters having the check.
        
The model fits about 0.95 (just 2 parameters, meaning how optimal are people when choosing their actions)
        
So, no simple story works where you just turn off pragmatics when  you have partial access.
        
conclusions
- language understanding as an inference, based on intuitive theory of speaking as an action
        
      },
author = {Goodman, Noah D and Stuhlmuller, Andreas},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Goodman, Stuhlmuller - 2 - Knowledge and implicature Modeling language understanding as social cognition.pdf:pdf},
pages = {390--395},
title = {{Knowledge and implicature: Modeling language understanding as social cognition}},
year = {2}
}
@article{Goodman2008a,
abstract = {This article proposes a new model of human concept learning that provides a rational analysis of learning feature-based concepts. This model is built upon Bayesian inference for a grammatically structured hypothesis space-a concept language of logical rules. This article compares the model predictions to human generalization judgments in several well-known category learning experiments, and finds good agreement for both average and individual participant generalizations. This article further investigates judgments for a broad set of 7-feature concepts-a more natural setting in several ways-and again finds that the model explains human performance.},
annote = {Concepts are definitions in first order logic, which are inferred by probabilistic inference. This can capture graded effects, even though the underlying representations are discrete and rigid.
        
Criticism: doesn't this suffer from many of the problems of the classical theory of concepts? What is a chair? What is a game? No single definition can really cut it
        
----
Three themes about concepts:
        
1) Mental representations used to discriminate between objects/events
        
2) Concepts are learned inductively
        
3) Concepts are compositional
        
Literature review:
- Bruner et al. looked at learning determinstic concepts, but not relaly inductive
- prototype, exemplars etc. don't say anything about composition
- RULEX is not flexible enough
        
Proposal
- combine power of logic/generative grammar with probabilistic inference
- use context-free grammars as a prior on concepts
- graded effects can rise out of mixtures of determinsitic representations under uncertainty
- ideal learner is commited to "a" correct definition for each conept, there is rarely enough information to specify it.
+ COMMENT: But -- what about the critcisms of the classical theory of concepts -- what is the definition of a chair?
        
Concepts are expressions in disjunctive normal form
+ uniform prior over production probabilities
+ noise, such that a formula may not always label things properly
        
Fit to both aggregate performance on concept learning experiments (percent of participants to generalize for a test example)
        
Also, fit to the distribution of individual subject response patterns to test stimuli. This does quite well, but so does RULEX
      },
author = {Goodman, Noah D and Tenenbaum, Joshua B and Feldman, Jacob and Griffiths, Thomas L},
doi = {10.1080/03640210701802071},
file = {:Users/Brenden/Documents/Mendeley/Goodman et al. - 2008 - A rational analysis of rule-based concept learning.pdf:pdf},
issn = {0364-0213},
journal = {Cognitive science},
keywords = {classics on concepts},
mendeley-tags = {classics on concepts},
month = jan,
number = {1},
pages = {108--54},
pmid = {21635333},
title = {{A rational analysis of rule-based concept learning.}},
volume = {32},
year = {2008}
}
@article{Goodnow1973b,
annote = {Hebrew writing: is read and written right-to-left rather than left-to-right (like English). How does this affect copying performance?
        
There is little differnece in starting location, and left-to-right behavior for the simple shapes tested. Although the instructions for drawing Hebrew characters does not obey a strong left-to-right constraint. There is a marked difference in the direction of drawing circles, and whether a vertical line is drawn first.`
        
        
---
        
Four different age groups: pre-school (4-5 yr) to adults were studied.
        
Design:
given two booklet, copied shape from one booklet to another.
        
Results:
                  
similar developmental trajectory        
- start at left
- start at top
- draw all horizontals left-to-right
- draw all verticals down
                  
different developmental trajectroy        
- start with a vertical line (weaker for israeli)
- threading (weaker for israeli)
- circles (counter-clockwise for Americans, clockwise for Israel)
- for a triangle, start at top and come down left side (strong for Americans, opposite for Israeli)
                  
teaching of drawing instructions        
- in Isreal, if there is no top horizontal, you may be instructed to start from the right.
                  
sex differences        
girls in both cutlures display an earlier rise in starting consistency and an increase of threading.
                  
Discussion        
Any notion of "natural" must be put in a cultural context. For instance, drawing a "O" clockwise feels unnatural. But Israeli children have no trouble.},
author = {Goodnow, Jacqueline J and Friedman, S L and Bernbaum, M and Lehman, E. B.},
file = {:Users/Brenden/Documents/Mendeley/Goodnow et al. - 1973 - Direction and sequence in copying The effect of learning to write in English and Hebrew.pdf:pdf},
journal = {Journal of Cross-Cultural Psychology},
keywords = {embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
number = {3},
pages = {263--282},
title = {{Direction and sequence in copying: The effect of learning to write in English and Hebrew}},
volume = {4},
year = {1973}
}
@article{Goodnow1973,
annote = {Asked children (of various ages) and adults to copy simple drawings. They investigated the underlying laws that govern this copying, including where the pen starts, and which direction lines are usually drawn in.
        
They emphasize that drawing is more cognitive the previously thought. While there are changes in the strength of the rules over time, and in general towards more orderly drawings in adults, there are some odd u-shaped trends which aren't discussed.
        
All subjects wer eright handed
        
Rules from experiment 1:
        
Rules:
1. Start at the leftmost point
2. Start at the topmost point
3. Start with a vertical line
4. Start at apex and come down the left oblique
5. Draw all horiz. lines left to right
6. Draw all vert. lines top to bottom
7. Thread, i.e, draw with a continuous line
        
Experiment 2. Analysis of error. They did a more controlled study of characters like "d" and "b" with young kids. They found children are more likely to regularize "d" to "b", conforming to the left to right rule. This is like over-regularizing speech.},
author = {Goodnow, Jacqueline J and Levine, Rochelle A},
file = {:Users/Brenden/Documents/Mendeley/Goodnow, Levine - 1973 - ``The Grammar of Action Sequence and syntax in childen's copying.pdf:pdf},
journal = {Cognitive Psychology},
keywords = {handwriting,program induction},
mendeley-tags = {handwriting,program induction},
number = {1},
pages = {82--98},
title = {{``The Grammar of Action": Sequence and syntax in childen's copying}},
volume = {4},
year = {1973}
}
@article{Gopnik2004,
abstract = {The authors outline a cognitive and computational account of causal learning in children. They propose that children use specialized cognitive systems that allow them to recover an accurate "causal map" of the world: an abstract, coherent, learned representation of the causal relations among events. This kind of knowledge can be perspicuously understood in terms of the formalism of directed graphical causal models, or Bayes nets. Children's causal learning and inference may involve computations similar to those for learning causal Bayes nets and for predicting with them. Experimental results suggest that 2- to 4-year-old children construct new causal maps and that their learning is consistent with the Bayes net formalism.},
annote = {        Introduction
                
Developmental psychologists know a lot about time course of development, but much less about representations and mechanisms
        
Knowing about causal knowledge allows us to intervene on the world
        
Work on causality has taken place in context of "theory theory"
        
Causal map: representation of causal knowlege
- can be learned from correlational evidene as well as interventions
        
Causal learning does not just invovle Rescorla-Wagner rule
                  
The causal inverse problem
                
World is 3D, only seen in 2D, use regularities and assumptions to recover latent structure
        
      },
author = {Gopnik, Alison and Glymour, Clark and Sobel, David M and Schulz, Laura E and Kushnir, Tamar and Danks, David},
doi = {10.1037/0033-295X.111.1.3},
file = {:Users/Brenden/Documents/Mendeley/Gopnik et al. - 2004 - A theory of causal learning in children causal maps and Bayes nets.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Adult,Association Learning,Bayes Theorem,Child,Child Development,Discrimination Learning,Female,Humans,Male,Markov Chains,Models,Motion Perception,Pattern Recognition,Preschool,Probability Learning,Problem Solving,Statistical,Visual,causal reasoning,classic psychology},
mendeley-tags = {causal reasoning,classic psychology},
number = {1},
pages = {3--32},
pmid = {14756583},
title = {{A theory of causal learning in children: causal maps and Bayes nets.}},
volume = {111},
year = {2004}
}
@book{Gopnik1997,
address = {Cambridge, MA},
author = {Gopnik, Alison and Meltzoff, Andrew N},
keywords = {conceptual change,theory theory},
mendeley-tags = {conceptual change,theory theory},
publisher = {MIT Press},
title = {{Words, Thoughts, and Theories}},
year = {1997}
}
@article{Gopnik2004a,
abstract = {Research suggests that by the age of five, children have extensive causal knowledge, in the form of intuitive theories. The crucial question for developmental cognitive science is how young children are able to learn causal structure from evidence. Recently, researchers in computer science and statistics have developed representations (causal Bayes nets) and learning algorithms to infer causal structure from evidence. Here we explore evidence suggesting that infants and children have the prerequisites for making causal inferences consistent with causal Bayes net learning algorithms. Specifically, we look at infants and children's ability to learn from evidence in the form of conditional probabilities, interventions and combinations of the two.},
author = {Gopnik, Alison and Schulz, Laura},
doi = {10.1016/j.tics.2004.06.005},
file = {:Users/Brenden/Documents/Mendeley/Gopnik, Schulz - 2004 - Mechanisms of theory formation in young children.pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Bayes Theorem,Child,Child Development,Child Development: physiology,Cognition,Cognition: physiology,Concept Formation,Concept Formation: physiology,Humans,Learning,Learning: physiology,Markov Chains,Preschool,causal reasoning,theory theory},
mendeley-tags = {causal reasoning,theory theory},
month = aug,
number = {8},
pages = {371--7},
pmid = {15335464},
title = {{Mechanisms of theory formation in young children.}},
volume = {8},
year = {2004}
}
@article{Graf2007,
author = {{Graf Estes}, K and Evans, J L and Alibali, M W and Saffran, J R},
journal = {Psychological Science},
number = {3},
pages = {254--260},
title = {{Can Infants Map Meaning to Newly Segmented Words?}},
volume = {18},
year = {2007}
}
@article{GraingerRey2008,
author = {Grainger, J and Rey, A and Dufau, S},
file = {:Users/Brenden/Documents/Mendeley/Grainger, Rey, Dufau - 2008 - Letter perception from pixels to pandemonium.pdf:pdf},
journal = {Trends in Cognitive Sciences},
keywords = {handwriting,part-based models},
mendeley-tags = {handwriting,part-based models},
number = {10},
pages = {381--387},
title = {{Letter perception: from pixels to pandemonium}},
volume = {12},
year = {2008}
}
@url{GrantBoyd2009,
author = {Grant, M and Boyd, S},
title = {{{CVX}: Matlab software for disciplined convex programming}},
url = {http://stanford.edu/$\sim$boyd/cvx}
}
@article{Green2003,
abstract = {As video-game playing has become a ubiquitous activity in today's society, it is worth considering its potential consequences on perceptual and motor skills. It is well known that exposing an organism to an altered visual environment often results in modification of the visual system of the organism. The field of perceptual learning provides many examples of training-induced increases in performance. But perceptual learning, when it occurs, tends to be specific to the trained task; that is, generalization to new tasks is rarely found. Here we show, by contrast, that action-video-game playing is capable of altering a range of visual skills. Four experiments establish changes in different aspects of visual attention in habitual video-game players as compared with non-video-game players. In a fifth experiment, non-players trained on an action video game show marked improvement from their pre-training abilities, thereby establishing the role of playing in this effect.},
annote = {Video games seem to increase various cognitive abilities, particularly related to multi-tasking and attention allocation

        
It may help skills relevant to jobs, like if you are an air-traffic controller, it isn't a general improvment in cognitive ability (like general problem solving and reasoning)

        
------
Compared video game players (VGS) vs. non-video game players (NVGS)

        
Task 1: flanker compatiblity effect

        
Identify a shape as a square/diamond in a ring, where the distractor was either the same or different
- facilitation effect when distractor is the same
- this diminishes as the task gets harder, but not so much for video game players
(flanker task is supposed to measure "left over attention")

        
Task 2: enumeration task

        
how many squares are shown in a brief display?

        
NVGS seemed to have an automatic process for a small number, and a slower serial counting process for a larger number of items

        
Results: slope of the line ins th esame, but VGS are better at each number of squares

        
Task 3: Attention improvements outside the VG zone (0-5 deg ) of fixation?
- measure of attentional resources and their spatial distribution
- indicate which spoke a target appeared, with varying degrees of ecentricity
+ video game player were much better at all levels of eccentricity

        
Task 4: attentional blink
- inability to detect a second target right after a first one
+ this is cross-modal efect
+ letter shown every 100 ms
- huge increase in performance regarding attentional blin, where accuracy is almost 20% better

        
          
traininng experiment
        
(could have been general population differences)
- perhaps people with better ability played video games more, or they are quicker at motor tasks and thus have more time for visual processing

        
procedure: 1 hr per day for 10 days playing Medal of Honor
- control group was trained on Tetris (visuo-motor training), but does not distribute/switch attention around field
- also, controls for test-retest

        
big improvments in all three tasks, even with only 10 days of training

        
          
participants: 
        
all subjects were male, and between ages 18-23},
author = {Green, C Shawn and Bavelier, Daphne},
doi = {10.1038/nature01647},
file = {:Users/Brenden/Documents/Mendeley/Green, Bavelier - 2003 - Action video game modifies visual selective attention.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {Adolescent,Adult,Attention,Attention: physiology,Female,Humans,Learning,Learning: physiology,Male,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Space Perception,Space Perception: physiology,Video Games},
month = may,
number = {6939},
pages = {534--7},
pmid = {12774121},
title = {{Action video game modifies visual selective attention.}},
volume = {423},
year = {2003}
}
@article{Green1995,
annote = {Introduced an MCMC method for Bayesian model comparison.
        
You can define a mixture model, where the mixture components are defined on different spaces. Reversible Jump MCMC provides a way to sample from this distribution, where the time spent in a mixing component, in the stationary distribution, is proportional to its probability .
        
      },
author = {Green, Peter J},
file = {:Users/Brenden/Documents/Mendeley/Green - 1995 - Reversible Jump Markov Chain Monte Carlo Computation and Bayesian Model Determination.pdf:pdf},
journal = {Biometrika},
keywords = {classic AI,mcmc},
mendeley-tags = {classic AI,mcmc},
number = {4},
pages = {711--732},
title = {{Reversible Jump Markov Chain Monte Carlo Computation and Bayesian Model Determination}},
volume = {82},
year = {1995}
}
@incollection{Griffiths2008,
address = {Oxford},
author = {Griffiths, T L and Sanborn, A N and Canini, K R and Navarro, D J},
booktitle = {The probabilistic mind: Prospects for rational models of cognition},
editor = {Oaksford, M and Chater, N},
file = {:Users/Brenden/Documents/Mendeley/Griffiths et al. - 2008 - Categorization as nonparametric Bayesian density estimation.pdf:pdf},
publisher = {Oxford University Press},
title = {{Categorization as nonparametric Bayesian density estimation}},
year = {2008}
}
@article{Griffiths2010a,
abstract = {Cognitive science aims to reverse-engineer the mind, and many of the engineering challenges the mind faces involve induction. The probabilistic approach to modeling cognition begins by identifying ideal solutions to these inductive problems. Mental processes are then modeled using algorithms for approximating these solutions, and neural processes are viewed as mechanisms for implementing these algorithms, with the result being a top-down analysis of cognition starting with the function of cognitive processes. Typical connectionist models, by contrast, follow a bottom-up approach, beginning with a characterization of neural mechanisms and exploring what macro-level functional phenomena might emerge. We argue that the top-down approach yields greater flexibility for exploring the representations and inductive biases that underlie human cognition.},
annote = {        From Duplicate 1 (                           Probabilistic models of cognition: exploring representations and inductive biases.                         - Griffiths, Thomas L; Chater, Nick; Kemp, Charles; Perfors, Amy; Tenenbaum, Joshua B )
                
        
        
        From Duplicate 2 (                           Probabilistic models of cognition: exploring representations and inductive biases.                         - Griffiths, Thomas L; Chater, Nick; Kemp, Charles; Perfors, Amy; Tenenbaum, Joshua B )
                
        
        
      },
author = {Griffiths, Thomas L and Chater, Nick and Kemp, Charles and Perfors, Amy and Tenenbaum, Joshua B},
doi = {10.1016/j.tics.2010.05.004},
file = {:Users/Brenden/Documents/Mendeley/Griffiths et al. - 2010 - Probabilistic models of cognition exploring representations and inductive biases.pdf:pdf;:Users/Brenden/Documents/Mendeley/Griffiths et al. - 2010 - Probabilistic models of cognition exploring representations and inductive biases(2).pdf:pdf},
issn = {1879-307X},
journal = {Trends in Cognitive Sciences},
keywords = {Bias (Epidemiology),Brain,Brain: physiology,Cognition,Cognition: physiology,Humans,Models,Predictive Value of Tests,Probability,Psychological,connectionism},
mendeley-tags = {connectionism},
month = aug,
number = {8},
pages = {357--64},
pmid = {20576465},
publisher = {Elsevier Ltd},
title = {{Probabilistic models of cognition: exploring representations and inductive biases.}},
volume = {14},
year = {2010}
}
@article{Griffiths2008a,
abstract = {Many of the problems studied in cognitive science are inductive problems, requiring people to evaluate hypotheses in the light of data. The key to solving these problems successfully is having the right inductive biases-assumptions about the world that make it possible to choose between hypotheses that are equally consistent with the observed data. This article explores a novel experimental method for identifying the biases that guide human inductive inferences. The idea behind this method is simple: This article uses the responses produced by a participant on one trial to generate the stimuli that either they or another participant will see on the next. A formal analysis of this "iterated learning" procedure, based on the assumption that the learners are Bayesian agents, predicts that it should reveal the inductive biases of these learners, as expressed in a prior probability distribution over hypotheses. This article presents a series of experiments using stimuli based on a well-studied set of category structures, demonstrating that iterated learning can be used to reveal the inductive biases of human learners.},
annote = {Used iterated learning on Shepard, Holland, Jenkins task. Participants received a set of positive examples (data), and then different hypotheses about the complete set of positive examples and were asked to choose. This eliminated memory demands.
        
The original results replicated, largely, except that type VI problems were easier than many others (3-5). This may be because of reduced memory demands. This would contradict Feldman's logic story.},
author = {Griffiths, Thomas L and Christian, Brian R and Kalish, Michael L},
doi = {10.1080/03640210701801974},
file = {:Users/Brenden/Documents/Mendeley/Griffiths, Christian, Kalish - 2008 - Using category structures to test iterated learning as a method for identifying inductive biases.pdf:pdf},
issn = {0364-0213},
journal = {Cognitive Science},
keywords = {bayesian inference,induction,iterated learning,mathematical modeling,statistics},
month = jan,
number = {1},
pages = {68--107},
pmid = {21635332},
title = {{Using category structures to test iterated learning as a method for identifying inductive biases.}},
volume = {32},
year = {2008}
}
@article{Griffiths2011,
author = {Griffiths, Thomas L and Ghahramani, Zoubin},
file = {:Users/Brenden/Documents/Mendeley/Griffiths, Ghahramani - 2011 - The Indian Buffet Process An Introduction and Review.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {beta process,chinese,exchangeable distributions,latent variable models,markov chain monte carlo,non-parametric Bayes,nonparametric bayes,restaurant processes,sparse binary matrices},
mendeley-tags = {non-parametric Bayes},
pages = {1185--1224},
title = {{The Indian Buffet Process: An Introduction and Review}},
volume = {12},
year = {2011}
}
@article{Griffiths2006,
abstract = {Human perception and memory are often explained as optimal statistical inferences that are informed by accurate prior probabilities. In contrast, cognitive judgments are usually viewed as following error-prone heuristics that are insensitive to priors. We examined the optimality of human cognition in a more realistic context than typical laboratory studies, asking people to make predictions about the duration or extent of everyday phenomena such as human life spans and the box-office take of movies. Our results suggest that everyday cognitive judgments follow the same optimal statistical principles as perception and memory, and reveal a close correspondence between people's implicit probabilistic models and the statistics of the world.},
author = {Griffiths, Thomas L and Tenenbaum, Joshua B},
doi = {10.1111/j.1467-9280.2006.01780.x},
file = {:Users/Brenden/Documents/Mendeley/Griffiths, Tenenbaum - 2006 - Optimal predictions in everyday cognition.pdf:pdf},
issn = {0956-7976},
journal = {Psychological science},
keywords = {Cognition,Forecasting,Humans,Memory,Models, Statistical,Perception,Psychology,Psychology: statistics & numerical data},
month = sep,
number = {9},
pages = {767--73},
pmid = {16984293},
title = {{Optimal predictions in everyday cognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16984293},
volume = {17},
year = {2006}
}
@article{Griffiths2007,
abstract = {People's reactions to coincidences are often cited as an illustration of the irrationality of human reasoning about chance. We argue that coincidences may be better understood in terms of rational statistical inference, based on their functional role in processes of causal discovery and theory revision. We present a formal definition of coincidences in the context of a Bayesian framework for causal induction: a coincidence is an event that provides support for an alternative to a currently favored causal theory, but not necessarily enough support to accept that alternative in light of its low prior probability. We test the qualitative and quantitative predictions of this account through a series of experiments that examine the transition from coincidence to evidence, the correspondence between the strength of coincidences and the statistical support for causal structure, and the relationship between causes and coincidences. Our results indicate that people can accurately assess the strength of coincidences, suggesting that irrational conclusions drawn from coincidences are the consequence of overestimation of the plausibility of novel causal forces. We discuss the implications of our account for understanding the role of coincidences in theory change.},
annote = {Evaluated Bayesian model selection, as a means of deciding whether a pattern is random or not. It generally produces a tight fit.
        
Domains of coincidence:
        
coin flips: is it random, or someone influencing it by psychokinesis
space: is it random, or targeted bombing (also cover story with Lemur colony)
dates: is it random, or targeted in a small interval (birthdays or shipping days)
        
Relevance to MD project: does the MD region detect these coincidences, and become active when they are violated?
        
----
        
Coincidence is not just low probability (unlikely event). Lots of events have low probability. It's causal support instead.
        
Experiment 1: counts of "heads" and "tails." Either sex of a rat after injection of a drug, or someone influencing a coin flip through mental powers. Bayes' factors are a good predictor, and people seem sensitivty to prior probabilities. 
        
Experiment 2: spatial patterns of German bombing of London. Model was uniform random noise and noice + a Gaussian cluster. The correlation between log-Bayes' factor and subject ratings was very high.
        
Experiment 3: birthday problem. Same deal with one dimension, cluster + noise. Again a very good fit
        
Experiment 4 & 5: explicitly ask about the probability of a hidden cause.
        
This ability to detect coincidences may play a role in theory change (a la Kuhn), one of the biggest problems in theory theory},
author = {Griffiths, Thomas L and Tenenbaum, Joshua B},
doi = {10.1016/j.cognition.2006.03.004},
file = {:Users/Brenden/Documents/Mendeley/Griffiths, Tenenbaum - 2007 - From mere coincidences to meaningful discoveries.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Bayes Theorem,Humans,Life Change Events,MD system,Models,Probability,Psychological,Semantics,perceptual grouping},
mendeley-tags = {MD system,perceptual grouping},
month = may,
number = {2},
pages = {180--226},
pmid = {16678145},
title = {{From mere coincidences to meaningful discoveries.}},
volume = {103},
year = {2007}
}
@article{Grill-Spector2004,
abstract = {The function of the fusiform face area (FFA), a face-selective region in human extrastriate cortex, is a matter of active debate. Here we measured the correlation between FFA activity measured by functional magnetic resonance imaging (fMRI) and behavioral outcomes in perceptual tasks to determine the role of the FFA in the detection and within-category identification of faces and objects. Our data show that FFA activation is correlated on a trial-by-trial basis with both detecting the presence of faces and identifying specific faces. However, for most non-face objects (including cars seen by car experts), within-category identification performance was correlated with activation in other regions of the ventral occipitotemporal cortex, not the FFA. These results indicate that the FFA is involved in both detection and identification of faces, but that it has little involvement in within-category identification of non-face objects (including objects of expertise).},
annote = {Activity in FFA was correalted on a trial by trial basis when trying to identify a specific, within-category taget in images (a particular face or a particular type of bird)
        
Stimuli were either another example of that specific categry, and example of the more general category, or not an object (texture). Participants were asked to specify which of these was the case.
        
Could compare:
- when participants correctly identified the object
- detected an object but didn't know what it was (a detection hit)
- did not detect an object at all (a detectino miss)
        
BOLD response in FFA for faces was strongest for the identification hit, then the correct detection, then the detection miss
        
Not so for other categories, except for birds (maybe because they have faces?)
        
When they tested car experts in this task, there was NOT a similar response for cars. In fact, there was no correlation between FFA response for cars as a function of expertise
        
Expertise is quantified by d-prime on the behavioral detection task
      },
author = {Grill-Spector, Kalanit and Knouf, Nicholas and Kanwisher, Nancy},
doi = {10.1038/nn1224},
file = {:Users/Brenden/Documents/Mendeley/Grill-Spector, Knouf, Kanwisher - 2004 - The fusiform face area subserves face perception, not generic within-category identification.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Adult,Analysis of Variance,Attention,Brain Mapping,Cerebral Cortex,Cerebral Cortex: anatomy & histology,Cerebral Cortex: blood supply,Cerebral Cortex: physiology,Data Display,Data Display: supply & distribution,Discrimination (Psychology),Face,Face: physiology,Female,Functional Laterality,Humans,Image Processing, Computer-Assisted,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,Middle Aged,Photic Stimulation,Photic Stimulation: methods,Psychomotor Performance,Psychomotor Performance: physiology,Time Factors,Visual Perception,Visual Perception: physiology},
month = may,
number = {5},
pages = {555--62},
pmid = {15077112},
title = {{The fusiform face area subserves face perception, not generic within-category identification.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15077112},
volume = {7},
year = {2004}
}
@article{Grodner,
author = {Grodner, Daniel and Klein, Natalie M and Carbary, Kathleen M and Tanenhaus, Michael K},
file = {:Users/Brenden/Documents/Mendeley/Grodner et al. - Unknown - Rapid interpretation of pragmatic “ some ”.pdf:pdf},
number = {610},
title = {{Rapid interpretation of pragmatic “ some ”}}
}
@inproceedings{Grosse2012,
author = {Grosse, R and Salakhutdinov, R and Freeman, William T and Tenenbaum, Joshua B},
booktitle = {Uncertainty in Artificial Intelligence},
file = {:Users/Brenden/Documents/Mendeley/Grosse et al. - 2012 - Exploiting compositionality to explore a large space of model structures.pdf:pdf},
title = {{Exploiting compositionality to explore a large space of model structures}},
url = {http://arxiv.org/abs/1210.4856},
year = {2012}
}
@article{Grush2004,
abstract = {The emulation theory of representation is developed and explored as a framework that can revealingly synthesize a wide variety of representational functions of the brain. The framework is based on constructs from control theory (forward models) and signal processing (Kalman filters). The idea is that in addition to simply engaging with the body and environment, the brain constructs neural circuits that act as models of the body and environment. During overt sensorimotor engagement, these models are driven by efference copies in parallel with the body and environment, in order to provide expectations of the sensory feedback, and to enhance and process sensory information. These models can also be run off-line in order to produce imagery, estimate outcomes of different actions, and evaluate and develop motor plans. The framework is initially developed within the context of motor control, where it has been shown that inner models running in parallel with the body can reduce the effects of feedback delay problems. The same mechanisms can account for motor imagery as the off-line driving of the emulator via efference copies. The framework is extended to account for visual imagery as the off-line driving of an emulator of the motor-visual loop. I also show how such systems can provide for amodal spatial imagery. Perception, including visual perception, results from such models being used to form expectations of, and to interpret, sensory input. I close by briefly outlining other cognitive functions that might also be synthesized within this framework, including reasoning, theory of mind phenomena, and language.},
annote = {Related to Bayesian cognitive science, in that you define a forward model, and also can invert it when given a goal state. Otherwise, it is not particularly clear.},
author = {Grush, Rick},
file = {:Users/Brenden/Documents/Mendeley/Grush - 2004 - The emulation theory of representation Motor control, imagery, and perception.pdf:pdf},
issn = {0140-525X},
journal = {Behavioral and Brain Sciences},
keywords = {Brain,Brain: physiology,Environment,Humans,Imagination,Language,Models,Perception,Psychomotor Performance,Psychomotor Performance: physiology,Psychophysiology,Theoretical,Visual Perception,embodied cognition},
mendeley-tags = {embodied cognition},
month = jun,
number = {3},
pages = {377--96; discussion 396--442},
pmid = {15736871},
title = {{The emulation theory of representation: Motor control, imagery, and perception}},
volume = {27},
year = {2004}
}
@inproceedings{Guath2013,
annote = {Learning to regulate eletricity usuage by monitoring cost
        
Feed-forward learning (why would they choose this name?)
        
Conditions
1) Regression: map continuous usage continuous cost
2) Rank-order: usage to rank-order cost
3) Causal: manipulate variables and observe cost changes
4) Feedback: 120 days in the house, where you get a detailed bill after each day detailing  ohw much you spent and what each appliance cost
        
Experiment:
maximize utility, givne a fixed energy budget
        
Utility is a linear weighted sum over the appliances, where the terms are the ratio of actualy to max use, where a power a_i controls the rate of dimishing returns
        
Pre-test: contorl house for 30 days
        
Training: 
in metric condition, they learn to map usage to cost for each appliance
        
rank-order: which is more, using this for this long or this for this long?
        
causal: presented witha  slider bar
        
Metric seemed to do the best.
        
Also, asked to generalize to another task with a different budget, and now the feedback condition does the best
        
        Discussion:        
        
People already have strong prior knowledge about how much these things cost, especially since prices were designed to be realistic
        
Performance in metric condition is impressive, since people never got feedback about the total cost of the house
        
Rank order condition did poorly},
author = {Guath, Mona and Juslin, Peter and Millroth, Philip},
booktitle = {Proceedings of the 35th Annual Meeting of the Cognitive Science Society (CogSci2013)},
file = {:Users/Brenden/Documents/Mendeley/Guath, Juslin, Millroth - 2013 - Is Feedforward Learning more Efficient than Feedback Learning in Smart Meters of Electricity Consumptio.pdf:pdf},
pages = {519--524},
title = {{Is Feedforward Learning more Efficient than Feedback Learning in Smart Meters of Electricity Consumption ?}},
year = {2013}
}
@article{Gureckis2004,
author = {Gureckis, T M and Love, B C},
file = {:Users/Brenden/Documents/Mendeley/Gureckis, Love - 2004 - Common Mechanisms in Infant and Adult Category Learning.pdf:pdf},
journal = {Infancy},
number = {2},
pages = {173--198},
title = {{Common Mechanisms in Infant and Adult Category Learning}},
volume = {5},
year = {2004}
}
@article{Gureckis2003,
author = {Gureckis, T M and Love, B C},
journal = {International Journal of Pattern Recognition and Artificial Intelligence},
number = {5},
pages = {885--901},
title = {{Human unsupervised and supervised learning as a quantitative distinction}},
volume = {17},
year = {2003}
}
@inproceedings{Gureckis2002,
author = {Gureckis, T M and Love, B C},
booktitle = {Proceedings of the Cognitive Science Society},
pages = {399--404},
title = {{Who says models can only do what you tell them? Unsupervised category learning data, fits, and predictions}},
year = {2002}
}
@article{Gureckis2012,
annote = {Summary: self-directed sampling is not just a secial case of passive learning with a choice step. It can be qualitatively different
        
Example: Xu and Tenenbau, where self-directed learning hinders generalization
        
--------
Introduction
        
- almost all concept learning studies are passive
- cross-fertilization from machine learning, cognitive science, cognitive neuroscience, and education
        
Example: child flips through a book, and asks for the name of an animal
- studying with flash cards
        
Category learning: almost always passive
causal learning: establishing cause, by intervnetion, is an active move
- Bonawitz: interventions are planned specfically with the intention of acquiring useful causal structure
        
Yoked experiments: good way to isolate the factor of choice
- but makes task less engaging
        
Biased data gathering leads to many phenomena: risk averison, etc.
        
People often decide how to memorize things in a way that optimizes performance, in terms of studying only easy items if time is limited
- but people cram for tests, which is sub-optimal
        
Xu and Tenenbaum:
- same examples given by teacher, or chosen by student
- sharper generalization in "strong sampling' case
+ Interesting, because here the active learning is WORSE!
        
Idea: Why does active learning lead to improved performance in some cases, but worse performance in others? I guess it depends on what the baseline is (random objects, or items from concept)
        
Discussion: self-directed sampling is not just a secial case of passive learning with a choice step. It can be qualitatively different
                  
Machine learning
                
Weakness of approaches: if you start with a bad hypothesis, and pick bad data, it can be reinforcing (confirmation bias)
        
Steyvers: human interventions in causal learning wre found to decrease entropy over the space of possible causal models
        
Reinforcement learing can modle optimal explore-exploit strategies
        
Is it true that Bayesian models don't make different predictions for self-directed sampling?
        
Main question: when does self-directed learning succeed, and when does it fail?
      },
author = {Gureckis, T. M. and Markant, D. B.},
doi = {10.1177/1745691612454304},
file = {:Users/Brenden/Documents/Mendeley/Gureckis, Markant - 2012 - Self-Directed Learning A Cognitive and Computational Perspective.pdf:pdf},
issn = {1745-6916},
journal = {Perspectives on Psychological Science},
keywords = {active learning,and,environment,intervention-based causal learning,machine learning,of presentation is not,self-directed learning,self-regulated study,some information is provided,the timing and sequence,to us by the,under our},
month = sep,
number = {5},
pages = {464--481},
title = {{Self-Directed Learning: A Cognitive and Computational Perspective}},
url = {http://pps.sagepub.com/lookup/doi/10.1177/1745691612454304},
volume = {7},
year = {2012}
}
@article{Guyon1991,
annote = {Time Delay Neural Net (convolution in time) applied to the problem of character recognition
        
Performs better than a similar system trained only on static images.
        
------
On-line recognition, meaning the trajectory information is used
        
General approach:
highly-engineered features, with simple classifier with no domain knowledge
        
Neural nets allow for a single trainable system
        
Touch terminal to collect letters
        
Found that neural nets that incorporate time information perform better than off-line recognition
        
Order of the sequence contains more information than exact timing
                  
pre-processing
        resampling, centering, and rescaling greatly reduce meaningless variability
- very poor performance when training on raw data
- resampled at regular spaced points along traj. (linear interp)
        
re-scaling preserved aspect ratio
        
local angle information is added to rep.
- direction infromation
- curvature
        
intermediate rep.
sequence of frames with position, direction, curve components
                  
neural network
                
Time Delay Neural Networ (Hinton and Lang)
TDNN
        
feedforward
- local receptive fields
-convolutional
- time scale gets coarser on successive levels
        
Decision at each time n is based on the last m time steps
- convolution in spirit, even though non-linear
        
Next layer only has 1/3 of the time points, where each layer is sensitive to progressively more of the input field
        
        results
                
about a 4% error rate on held-out examples
        
It also makes mistakes when recognition characters written in an unusual way
        
      },
author = {Guyon, I and Albrecht, P and LeCun, Y and Denker, J and Hubbard, W},
file = {:Users/Brenden/Documents/Mendeley/Guyon et al. - 1991 - Design of neural network character recognized for a touch terminal.pdf:pdf},
journal = {Pattern Recognition},
keywords = {handwriting},
mendeley-tags = {handwriting},
number = {2},
pages = {105--119},
title = {{Design of neural network character recognized for a touch terminal}},
volume = {24},
year = {1991}
}
@inproceedings{Hammer2012,
annote = {Attentional learning: one way to do rapid generalization
        
Experiment
        
two conditoins: high-low saliency of categories 
stimuli: weird frog-like creatures
        
Results:
With high saliecny (easy to discrminate), there is no difference betwen high informationa nd low-information conditions
        
with low saliency, there is an advnatage of high information. concluslion: thi sinvovles "constructing" the right hypotheses. This becomes much harder of the examples are a little ambiguous
        
Maybe different learning mechanisms can be engaged in the same category learning structure, but it depends on the examples and the context.
        
kjljk},
author = {Hammer, Rubi and Sloutsky, Vladimir and Grill-Spector, Kalanit},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Hammer, Sloutsky, Grill-Spector - 2012 - The Interplay between Feature-Saliency and Feedback Information in Visual Category Learning Tasks.pdf:pdf},
keywords = {attentional learning,feature-saliency,feedback information,perceptual learning,visual category learning},
pages = {420--425},
title = {{The Interplay between Feature-Saliency and Feedback Information in Visual Category Learning Tasks}},
volume = {1},
year = {2012}
}
@article{Hardy,
author = {Hardy, Joseph L and Sarakar, Kunal and Kellent, Gregory and Scanlon, Michael},
file = {:Users/Brenden/Documents/Mendeley/Hardy et al. - Unknown - Enhancing visual attention and working memory with a Web-based cognitive training program.pdf:pdf},
journal = {Mensa Research Journal},
number = {2},
pages = {13--20},
title = {{Enhancing visual attention and working memory with a Web-based cognitive training program}},
volume = {42}
}
@inproceedings{Harel2006,
author = {Harel, Jonathan and Koch, Christof and Perona, Pietro},
booktitle = {Advances in Neural Information Processing Systems},
file = {:Users/Brenden/Documents/Mendeley/Harel, Koch, Perona - 2006 - Graph-Based Visual Saliency.pdf:pdf},
title = {{Graph-Based Visual Saliency}},
year = {2006}
}
@article{Harlow1949,
annote = {introduced the term "learning how to learn efficiently"
- showed the monkeys, and children, get better at learning similar (although simple) tasks over time 

        
Tasks:
- always pick a particular object
- always pick object 1, then random switch to picking object 2
- always pick an object, then switch at some point to pick a position

        
Harlow's monkeys: see if monkey had preference for wire mother (with food) or cloth mother, after being reared without a mother, and they choose to stay with the cloth one, and just leaving for feeding

        
-----
normal learning situations are repeated many times in similar form
- not just a single situation, but multiple related learing problems

        
Task: two objects, one with food underneath and another without

        
344 tasks with different pairs of stimuli
- first 32 problem with 50 trials
- second 200 problems for 6 trials
last 112 problems for 9 trials

        
The monkeys "learn how to learn"
- they get faster at learning each problem, as evident when you block the tasks

        
also tried it with "operated monkeys' with extensive unilateral coritcal lesions

        
Also tried it with children, and similar transfer

        

        massive effect
        
also, in the last 56 discriminations, 1 trial brings the animals close to perfect performance (onl 3 percent short)

        
discrimination reversal training:
- show the moneky a few trials, then reverse the response (until the end)
- when plotting the percent correct on the reversal trials, there is a big transfer effect

        
hypothesis driven, one-trial like learning only occured at the end of a progressive, gradual learning process

        
Also, training does not turn the monkey into an automata -- but rather an increased capacitiy to adapt (as shown in the reverrse learing condition)

        
another task: first n trials respond to specific object, next 10 resepond to specific position
- this is learned over problems as well
- again, almost immediate shift at the right trial after 42-56 problems solved

        
Discussion
- experience is genreally studied in isolated habits, rather than in the wild},
author = {Harlow, H F},
file = {:Users/Brenden/Documents/Mendeley/Harlow - 1949 - The.&cit%3Apub=Psychological+Review&cit%3Avol=56&cit%3Aiss=1&cit%3Apg=51&cit%3Adate=Jan+1949&ic=true&cit%3Aprod=PsycARTICLES:&cit%3Apub=Psychological+Review&cit%3Avol=56&cit%3Aiss=1&cit%3Apg=51&cit%3Adate=Jan+1949&ic=true&cit%3Aprod=PsycARTICLES},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Learning,classic psychology,one-shot learning},
mendeley-tags = {classic psychology,one-shot learning},
month = jan,
number = {1},
pages = {51--65},
pmid = {18124807},
title = {{The formation of learning sets}},
volume = {56},
year = {1949}
}
@incollection{Harnad1987,
address = {New York},
author = {Harnad, S},
booktitle = {Categorical Perception: The Groundwork of Cognition},
chapter = {1},
editor = {Harnad, S},
publisher = {Cambridge University Press},
title = {{Psychophysical and cognitive aspects of categorical perception: A critical overview}},
year = {1987}
}
@article{Harris1998,
annote = {Minimum jerk model: there is no principled explanation why the nervous system should have evolved top optimize this quantity (change in acceleration)
        
Proporsal: minimizing variance of eye or arm's position (final position), is the quantity being optimized
        
If noise was independent of control signal, the movement would be done as fast as possible
        
However, they assume that noise in neural control increases with level of signal. This imposes a speed/accuracy trade-off.
        
      },
author = {Harris, CM and Wolpert, DM},
file = {:Users/Brenden/Documents/Mendeley/Harris, Wolpert - 1998 - Signal-dependent noise determines motor planning.pdf:pdf},
journal = {Nature},
number = {August},
pages = {780--785},
title = {{Signal-dependent noise determines motor planning}},
url = {http://www.nature.com/nature/journal/v394/n6695/abs/394780a0.html},
volume = {394},
year = {1998}
}
@article{Hauk2004,
abstract = {Since the early days of research into language and the brain, word meaning was assumed to be processed in specific brain regions, which most modern neuroscientists localize to the left temporal lobe. Here we use event-related fMRI to show that action words referring to face, arm, or leg actions (e.g., to lick, pick, or kick), when presented in a passive reading task, differentially activated areas along the motor strip that either were directly adjacent to or overlapped with areas activated by actual movement of the tongue, fingers, or feet. These results demonstrate that the referential meaning of action words has a correlate in the somatotopic activation of motor and premotor cortex. This rules out a unified "meaning center" in the human brain and supports a dynamic view according to which words are processed by distributed neuronal assemblies with cortical topographies that reflect word semantics.},
author = {Hauk, Olaf and Johnsrude, Ingrid and Pulverm\"{u}ller, Friedemann},
file = {:Users/Brenden/Documents/Mendeley/Hauk, Johnsrude, Pulverm\"{u}ller - 2004 - Somatotopic representation of action words in human motor and premotor cortex.pdf:pdf},
issn = {0896-6273},
journal = {Neuron},
keywords = {Adult,Brain Mapping,Cerebrovascular Circulation,Cerebrovascular Circulation: physiology,Computer-Assisted,Fingers,Fingers: physiology,Foot,Foot: physiology,Functional Laterality,Functional Laterality: physiology,Humans,Image Processing,Language,Magnetic Resonance Imaging,Male,Motor Cortex,Motor Cortex: blood supply,Motor Cortex: physiology,Movement,Movement: physiology,Psycholinguistics,Tongue,Tongue: physiology,embodied cognition},
mendeley-tags = {embodied cognition},
month = jan,
number = {2},
pages = {301--7},
pmid = {14741110},
title = {{Somatotopic representation of action words in human motor and premotor cortex.}},
volume = {41},
year = {2004}
}
@article{Hayes2009,
abstract = {These three experiments examined how people make property inferences about exemplars whose category membership is uncertain. Participants were shown two categories and a novel exemplar with a feature that indicated that the exemplar was more likely to belong to one category (target) than to the other (nontarget). Participants then made categorization decisions and property inferences about the novel exemplar. In some conditions, property inferences could be made only by considering both target and nontarget categories. In other conditions, predictions could be based on both categories or on the target category alone. Consistent with previous studies (e.g., Murphy & Ross, 1994, 2005), we found that many people made predictions based only on consideration of the target category. However, the prevalence of such single-category reasoning was greatly reduced by highlighting the costs of neglecting nontarget alternatives and by asking for inferences before categorization decisions. The results suggest that previous work may have exaggerated the prevalence of single-category reasoning and that people may be more flexible in their use of multiple categories in property inference than has been previously recognized.},
annote = {Re-evaluation of Ross and Murphy
        
It's possible that you need to make inferences about a property before you make the cateogrization
(hear russling in the woods, it it dangerous?)
        
It is possible that people are neglecting uncertainty, in that they don't see how failing to propagate uncertainty hurts you later (Tversky and Kaneman)
        
Murphy suggests there is a sort of "argmax" when making predictions aftewards
        
Perhaps this can be influenced by other factors? Like how important the alterantives cateogires are?
        
Experiment 1:
Alterantive category was a disease that was "Serious and potentially fatal". 
        
Also, had a condition where the single-category rule would not make a clear prediction, but incorporating other categories would
        
Results:
When forced to look beyond the single category to make a clear predictoin, people were able to do this.
        
When you had an option of single or multiple, people often chose single. But this could be shifted quite substnatially through the instruction manipulation.
        
But the instructions were presented right before test, indicating a possible demand effect.
        
Experiment 2: replicated finding of Experiment 1, with instructions presented at the begining
        
Experiment 3: what if you just asked for the predictions before categorization, rather than the order way around?
        
Lagnado and Shanks (2003) found a version of this, and called it the "commitment heuristic"
Although Murphy and Ross tested this, they had a relatively small difference in probabilities (10%) to shoot for
                  
Experiment 3: Question order was manipulated within-subects
        
This order manipualtion makes a difference, but STILL, at most 50% of the predictions are based on the multiple category rule
                  
Discussion
                
Thus, there can be changing strategories, but the Rational model provides no explanation that can help explain the shifts
        
      },
author = {Hayes, Brett K and Newell, Ben R},
doi = {10.3758/MC.37.6.730},
file = {:Users/Brenden/Documents/Mendeley/Hayes, Newell - 2009 - Induction with uncertain categories When do people consider the category alternatives.pdf:pdf},
issn = {0090-502X},
journal = {Memory & cognition},
keywords = {Adult,Association Learning,Classification,Classification: methods,Decision Making,Diagnosis,Differential,Female,Generalization (Psychology),Humans,Male,Probability Learning,Uncertainty,feature prediction},
mendeley-tags = {feature prediction},
month = sep,
number = {6},
pages = {730--43},
pmid = {19679854},
title = {{Induction with uncertain categories: When do people consider the category alternatives?}},
volume = {37},
year = {2009}
}
@article{Hayes2008,
author = {Hayes, Bruce and Wilson, Colin},
doi = {10.1162/ling.2008.39.3.379},
file = {:Users/Brenden/Documents/Mendeley/Hayes, Wilson - 2008 - A Maximum Entropy Model of Phonotactics and Phonotactic Learning.pdf:pdf},
issn = {0024-3892},
journal = {Linguistic Inquiry},
keywords = {learnability,maximum entropy,onsets,phonotactics},
month = jul,
number = {3},
pages = {379--440},
title = {{A Maximum Entropy Model of Phonotactics and Phonotactic Learning}},
volume = {39},
year = {2008}
}
@inproceedings{Heisele2001,
author = {Heisele, Bernd and Serre, Thomas and Pontil, Massimiliano and Vetter, Thomas and Poggio, Tomaso},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:Users/Brenden/Documents/Mendeley/Heisele et al. - 2001 - Categorization by Learning and Combining Object Parts.pdf:pdf},
title = {{Categorization by Learning and Combining Object Parts}},
year = {2001}
}
@incollection{Heit1998,
author = {Heit, Evan},
booktitle = {Rational Models of Cognition},
editor = {Oaksford, M. and Chater, Nick},
file = {:Users/Brenden/Documents/Mendeley/Heit - 1998 - A Bayesian analysis of some forms of inductive reasoning.pdf:pdf},
keywords = {property induction},
mendeley-tags = {property induction},
number = {024},
pages = {248--274},
publisher = {Oxford University Press},
title = {{A Bayesian analysis of some forms of inductive reasoning}},
year = {1998}
}
@article{Heit2000,
abstract = {This paper reviews the main psychological phenomena of inductive reasoning, covering 25 years of experimental and model-based research, in particular addressing four questions. First, what makes a case or event generalizable to other cases? Second, what makes a set of cases generalizable? Third, what makes a property or predicate projectable? Fourth, how do psychological models of induction address these results? The key results in inductive reasoning are outlined, and several recent models, including a new Bayesian account, are evaluated with respect to these results. In addition, future directions for experimental and model-based work are proposed.},
annote = {How do people project information from known cases to unknown cases?
        
seminal work by Rips (1975):
-premise/conclusion similarity plays a role
-premise typicality is important
-conclusion typicality is not important
        
Nisbett et al. (1983)
- Barratos tribe, where one member is either (brown/obsese)
- these different properties have different effects
        
Carey (1985)
- dogs to humans much weaker than humans to dogs
- children consider humans to be very typical, so this makes sense
- sensitivity to similarity increases with age
- seems to reflect a maturing conception of things in the living world
        
Osherson et al. (1990) documend a set of important phenomena
- premise/conclusion simlairty
- premise typicality effect
- more specific conclusion categories are stronger
- inclusion fallacy: stronger with "all birds" as a conclusion thatn "ostriches"},
author = {Heit, Evan},
file = {:Users/Brenden/Documents/Mendeley/Heit - 2000 - Properties of inductive reasoning.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic Bulletin and Review},
keywords = {Adult,Bayes Theorem,Child,Generalization (Psychology),Humans,Logic,Models,Probability Learning,Psychological,Set (Psychology),property induction},
mendeley-tags = {property induction},
month = dec,
number = {4},
pages = {569--92},
pmid = {11206199},
title = {{Properties of inductive reasoning.}},
volume = {7},
year = {2000}
}
@inproceedings{Herlau2012,
author = {Herlau, Tue and M\o rup, Morten and Schmidt, Mikkel N and Hansen, Lars Kai},
booktitle = {Cognitive Information Processing (CIP)},
file = {:Users/Brenden/Documents/Mendeley/Herlau et al. - 2012 - Detecting hierarchical structure in networks.pdf:pdf},
keywords = {essentialism},
mendeley-tags = {essentialism},
title = {{Detecting hierarchical structure in networks}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6232913},
year = {2012}
}
@article{Hinton1995,
abstract = {An unsupervised learning algorithm for a multilayer network of stochastic neurons is described. Bottom-up "recognition" connections convert the input into representations in successive hidden layers, and top-down "generative" connections reconstruct the representation in one layer from the representation in the layer above. In the "wake" phase, neurons are driven by recognition connections, and generative connections are adapted to increase the probability that they would reconstruct the correct activity vector in the layer below. In the "sleep" phase, neurons are driven by generative connections, and recognition connections are adapted to increase the probability that they would produce the correct activity vector in the layer above.},
annote = {Wake phase -- train the generative weights to better-produce the input data
        
Sleep phase -- train the recognition weights to better-produce the fantasty data. Although this uses fantasy data rather than real data, which is bad early on, it can be useful as the generative model improves.
        
This is a generative model, which is capable of fast perceptual inference by the recognition weights.
        
The object function minimizes the cost of describing the input vector givent he hidden states, marginalizing over the possible hidden states
        
Although the recognition weights are factorial in each forward pass, this causes the model to restrict it's generative capacity to be of a similar form, limiting the damage.},
author = {Hinton, G E and Dayan, P and Frey, B J and Neal, R M},
file = {:Users/Brenden/Documents/Mendeley/Hinton et al. - 1995 - The wake-sleep algorithm for unsupervised neural networks.pdf:pdf},
issn = {0036-8075},
journal = {Science},
keywords = {Algorithms,Neural Networks (Computer),Probability,Stochastic Processes,neural networks},
mendeley-tags = {neural networks},
month = may,
number = {5214},
pages = {1158--61},
pmid = {7761831},
title = {{The "wake-sleep" algorithm for unsupervised neural networks.}},
volume = {268},
year = {1995}
}
@inproceedings{HintonNair2006,
annote = {Digit recognition by inferring motor progams.
        
The generative model is two pairs of opposing springs, at right angles, where the stiffness of the springs controls the movement of a pen. This pen generates ink.
        
This is a hand-coded computer program, so learning in this model is accomplished by two neural networks:
1) A recognition network that takes an image and outputs the motor program
2) A generative network, that inputs a motor program and outputs an image
        
A recognition network is trained for each class, starting with a single hand-coded program and building an island of competence around it by adding noise. 
        
This produces pretty good motor programs for new images, but they can be improved by a local closed-loop search. The generative network accomplishes this, and one is trained for each class. Iterative imporvement is done by generating an image and then back-propagating the error.
        
Classification: rather than just using the sum of squares (which treats errors as independent), you can model the residuals with PCA. During classification, you project the residuals into the hyper-plane for each class, and see which is the closest to the hyperplane. All of these projection scores, plus the sum of squres (20 scores), as used as inputs to a classifer 
        
Also, PCA model is learned from the trajectories of digits in it's own class. This servers as a prior, so digit models can't contort themselves in weird ways.
                  
Dicussion        
You can do just as well by training a single neural network, and then modeling the motor program ouptut for each class with PCA. 
        
This is suprising, because the reconstructions are much worse. But it works as well for classification.
        
      },
author = {Hinton, G E and Nair, V},
booktitle = {{Advances in Neural Information Processing Systems 19}},
file = {:Users/Brenden/Documents/Mendeley/Hinton, Nair - 2006 - Inferring motor programs from images of handwritten digits.pdf:pdf},
keywords = {handwriting,program induction},
mendeley-tags = {handwriting,program induction},
title = {{Inferring motor programs from images of handwritten digits.}},
year = {2006}
}
@article{Hinton2006,
abstract = {High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such "autoencoder" networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.},
author = {Hinton, G E and Salakhutdinov, R R},
doi = {10.1126/science.1127647},
file = {:Users/Brenden/Documents/Mendeley/Hinton, Salakhutdinov - 2006 - Reducing the dimensionality of data with neural networks(2).pdf:pdf;:Users/Brenden/Documents/Mendeley/Hinton, Salakhutdinov - 2006 - Reducing the dimensionality of data with neural networks.pdf:pdf},
issn = {1095-9203},
journal = {Science},
keywords = {deep learning},
mendeley-tags = {deep learning},
month = jul,
number = {5786},
pages = {504--7},
pmid = {16873662},
title = {{Reducing the dimensionality of data with neural networks.}},
volume = {313},
year = {2006}
}
@article{Hinton2002,
abstract = {It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual "expert" models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called "contrastive divergence" whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data.},
annote = {Radically different type of mixture models.
        
Additive mixture models are more like "or", where the data has to come from at least one of the components.
        
A mixture of experts is more like an "and" function. Each expert can specify something specific about the data (shape, particular features, etc.)
        
This is accomplished by having several weak generative models of the data, and making the real likelihood the product of them all
        
This means that sampling in the forward direction is difficult
- note, however, an importance sampler could be a decent approximation
But inference in the other direction is often easier.
        
In an RBM or the mixture of gaussians model described in the paper, inferring the hidden states is relatively easy.
        
Note: while the paper talks about this in general, I am either misunderstanding or it is poorly written. I don't think the latent variables are conditionally independent given the data, since the normalizing constant of the likelihood is a function of the two latent varibles in general. 
        
      },
author = {Hinton, Geoffrey E},
doi = {10.1162/089976602760128018},
file = {:Users/Brenden/Documents/Mendeley/Hinton - 2002 - Training products of experts by minimizing contrastive divergence.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
month = aug,
number = {8},
pages = {1771--800},
pmid = {12180402},
title = {{Training products of experts by minimizing contrastive divergence.}},
volume = {14},
year = {2002}
}
@article{Hinton2012,
annote = {TIMIT: 630 speakers (different dialects) each reading 10 sentences.  It includes time-aligned orthographic, phonetic, and word transcriptions

        
Each phone is modeled by a number of different "triphone" HMMs that take into account the phones on either side

        
Each triphone HMM has 3 states, and allows only upper-diagonal transitions. You can train these with labeled, time-aligned input data

        
Thus, a word-based HMM is the concatenation of the triphone HMMs

        
Targets are obatined by using a baseline GMM-HMM system to produce a forced alignment (of HMM states to input windows, I assume)

        
The raw input to the DNN is a sequence of frames (perhaps 5)

        
It is important to have a good basline model, since the GMM-HMM systems create the initial labeled data fro the DNN

        
--
Most acoustic models using HMMs and GMMs, but GMMs are not very good at modeling high-dimensional data that fall on a low-dimensional manifold

        
Stacked RBMs: we can compute the marginal distribution on the visible units, which of course depends on a prior on hidden variables

        
We can improve the model by replacing this prior with something better, like the aggregate posterior over hidden with the fixed p(h|v) model. This is exactly what the next RBM in the stack is trained to mdoel

        
After the unsupervised training, the network is trained to predict an HMM state (for an optimized HMM model), given the acoustic input. This can then be converted into an entire predcited sequence using viterbi alignment.

        

        
Timit results:
-obtain about 20% error (state of the art) on phone recognition task

        
Switchboard:
300 hours of training data

        
On most taks, GMMs are much worse with the same amount of data, but GMMs can approach the same performance with more data

        
Other ways to use deep learning:
- train an auto-encoder on the raw features, and train the GMM-HMM on that},
author = {Hinton, Geoffrey E and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and Kingsbury, Brian},
file = {:Users/Brenden/Documents/Mendeley/Hinton et al. - 2012 - Deep neural networks for acoustic modeling in speech recognition.pdf:pdf},
journal = {IEEE Signal Processing Magazine},
keywords = {deep learning,part-based models,speech recognition},
mendeley-tags = {deep learning,part-based models,speech recognition},
pages = {82--97},
title = {{Deep neural networks for acoustic modeling in speech recognition}},
year = {2012}
}
@article{Hinton1995a,
annote = {For each digit class, they fit a mixture of linear auto-encoders. Classification picks the model with the best reconstruction error.
        
---
Rather than fitting to labels, train an autoencoder, and see which auto-encoder fits the best
        
Model: 
-- autoencoders with linear hidden units
-- barely worse, great computational advantages, since it is equivalent to PCA
-- but one will not be enough, so they fit a mixture of PCAs with EM
        
Results:
error of about 5% on digit classification.
If you look at reconstructions of a 2, with a 0 model, it looks circular},
author = {Hinton, Geoffrey E and Revow, M and Dayan, P},
file = {:Users/Brenden/Documents/Mendeley/Hinton, Revow, Dayan - 1995 - Recognizing Handwritten Digits Using Mixtures of Linear Models.pdf:pdf},
journal = {{Advances in Neural Information Processing Systems }},
keywords = {handwriting},
mendeley-tags = {handwriting},
pages = {1015--1022},
title = {{Recognizing Handwritten Digits Using Mixtures of Linear Models}},
year = {1995}
}
@article{Hoffman1984,
annote = {Thesis: the visual system decomposes shapes into parts, and it does so by exploting rules that define part boundaries. 
        
The main rule is this: when two objects interpenetrate, there is always a concavitiy. 
        
--
        
Why are parts important? The overall shape is often occluded, but parts can help recognition. Spatial relations amongst parts, this helps decouple the configural properties with the shape. We also want parts that are useful for recognition. 
        
Transversality: when two shapes interpenetrate, they always meet in a contour of concave discontintuity of their tangent planes (tangent at the point of penetration)
        
For generic shapes, you want lines of principal curvature (max), when traced along the shape. The minima rule then divides the surace into parts, based on the loci of minima of each principal curve
        
You don't need a menu of parts shapes for defining parts.
        
Is it computable? (in theory, maybe not in practice) -- Marr and Poggio's levels
        
This explains visual illusions, where sqiggly lines in a figure can alternate between moutains and valleys. This also accounts for the two-face or a face illusion, where concavitiy and convexity alternate},
author = {Hoffman, D D and Richards, W A},
file = {:Users/Brenden/Documents/Mendeley/Hoffman, Richards - 1984 - Parts of recognition.pdf:pdf},
journal = {Cognition},
keywords = {classic AI,classic psychology},
mendeley-tags = {classic AI,classic psychology},
pages = {65--96},
title = {{Parts of recognition}},
volume = {18},
year = {1984}
}
@incollection{Hofstadter2001,
author = {Hofstadter, Douglas R},
booktitle = {The analogical mind},
file = {:Users/Brenden/Documents/Mendeley/Hofstadter - 2001 - Analogy as the core of cognition.pdf:pdf},
pages = {116--144},
title = {{Analogy as the core of cognition}},
year = {2001}
}
@article{Hofstadter1978,
author = {Hofstadter, Douglas R},
file = {:Users/Brenden/Documents/Mendeley/Hofstadter - 1978 - Emergent Letter Perception Implementing the Role Hypothesis.pdf:pdf},
title = {{Emergent Letter Perception: Implementing the Role Hypothesis}},
year = {1978}
}
@article{Holden2010,
abstract = {Memories for spatial locations often show systematic errors toward the central value of the surrounding region. This bias has been explained using a Bayesian model in which fine-grained and categorical information are combined (Huttenlocher, Hedges, & Duncan, 1991). However, experiments testing this model have largely used locations contained in simple geometric shapes. Use of this paradigm raises 2 issues. First, do results generalize to the complex natural world? Second, what types of information might be used to segment complex spaces into constituent categories? Experiment 1 addressed the 1st question by showing a bias toward prototypical values in memory for spatial locations in complex natural scenes. Experiment 2 addressed the 2nd question by manipulating the availability of basic visual cues (using color negatives) or of semantic information about the scene (using inverted images). Error patterns suggest that both perceptual and conceptual information are involved in segmentation. The possible neurological foundations of location memory of this kind are discussed.},
annote = {People think Reno is east of San Diego, because Nevada is East of California
- shows category and metric information
        
Bayesian models are a way of combingin multiple cues, based on reliabliity 
+ suitable for combining fine-grained and coarse information (CAM)
        
Does the CAM model work for natural complex spaces? 
                  
Experiment 1        
Natural scenes, where categories were labeled by other participants or generated from segmentation aglorithm
        
Prestend two landscapes, than got two responses. This taxes memory, so you can get more bias
        
Computed the average error for each location, which incorporates both the size and direction of error (add errors, than divide by total length of summed vector)
        
Compute a mean error for each subject, and test whether this distribution is different than uniformly distributed around the circle
                  
Experiment 2: manipulated image information, like turning it upsdiedown or reading color negative
                  
results        
for negatives vs canonical, people errored in the right, but more strongly in the cannonical
        
for canonical vs. upside-down, people errer in both lengtha dn direction 
                  
Discussion
                
It is hard to predict the inversion effect with the Dynamic field theory model, since it claims categorie are defined relative to axes
+ thus, categorization depends on semantic information brought ot the task},
author = {Holden, Mark P and Curby, Kim M and Newcombe, Nora S and Shipley, Thomas F},
doi = {10.1037/a0019293},
file = {:Users/Brenden/Documents/Mendeley/Holden et al. - 2010 - A category adjustment approach to memory for spatial location in natural scenes.pdf:pdf},
issn = {1939-1285},
journal = {Journal of experimental psychology. Learning, memory, and cognition},
keywords = {Attention,Attention: physiology,Computer-Assisted,Concept Formation,Concept Formation: physiology,Cues,Environment,Female,Humans,Image Processing,Male,Mental Recall,Mental Recall: physiology,Orientation,Orientation: physiology,Photic Stimulation,Space Perception,Space Perception: physiology,Spatial Behavior,Spatial Behavior: physiology,Visual Perception,Visual Perception: physiology,Young Adult,spatial reasoning},
mendeley-tags = {spatial reasoning},
month = may,
number = {3},
pages = {590--604},
pmid = {20438259},
title = {{A category adjustment approach to memory for spatial location in natural scenes.}},
volume = {36},
year = {2010}
}
@article{Hollerbach1981,
author = {Hollerbach, John M},
file = {:Users/Brenden/Documents/Mendeley/Hollerbach - 1981 - An Oscillation Theory of Handwriting.pdf:pdf},
journal = {Biological Cybernetics},
keywords = {handwriting,part-based models,program induction},
mendeley-tags = {handwriting,part-based models,program induction},
number = {2},
pages = {139--156},
title = {{An Oscillation Theory of Handwriting}},
volume = {39},
year = {1981}
}
@article{Hommel2001,
abstract = {Traditional approaches to human information processing tend to deal with perception and action planning in isolation, so that an adequate account of the perception-action interface is still missing. On the perceptual side, the dominant cognitive view largely underestimates, and thus fails to account for, the impact of action-related processes on both the processing of perceptual information and on perceptual learning. On the action side, most approaches conceive of action planning as a mere continuation of stimulus processing, thus failing to account for the goal-directedness of even the simplest reaction in an experimental task. We propose a new framework for a more adequate theoretical treatment of perception and action planning, in which perceptual contents and action plans are coded in a common representational medium by feature codes with distal reference. Perceived events (perceptions) and to-be-produced events (actions) are equally represented by integrated, task-tuned networks of feature codes--cognitive structures we call event codes. We give an overview of evidence from a wide variety of empirical domains, such as spatial stimulus-response compatibility, sensorimotor synchronization, and ideomotor action, showing that our main assumptions are well supported by the data.},
annote = {perceptions and ations are equally reperestned by integrated, task-tuned networks of feature codes -- called event codes
        
Evidence for a common code:
-- there is a shared reference frame between perception and action, otherwise, how could action coordinate with perception for catching a ball?
-- mirror neurons
-- Freyd studies
-- Vivani's biological movement },
author = {Hommel, B and M\"{u}sseler, J and Aschersleben, G and Prinz, W},
file = {:Users/Brenden/Documents/Mendeley/Hommel et al. - 2001 - The Theory of Event Coding (TEC) a framework for perception and action planning.pdf:pdf},
issn = {0140-525X},
journal = {Behavioral and Brain Sciences},
keywords = {Cognition,Evoked Potentials,Humans,Memory,Memory: physiology,Mental Processes,Models,Perception,Theoretical,embodied cognition},
mendeley-tags = {embodied cognition},
month = oct,
number = {5},
pages = {849--78; discussion 878--937},
pmid = {12239891},
title = {{The Theory of Event Coding (TEC): a framework for perception and action planning.}},
volume = {24},
year = {2001}
}
@inproceedings{Horowitz2012,
annote = {Learning from word choices
        
We can learn more from a single utterance than its truth content
        
" I can't find my left shoe" implies that you have your right shoe
        
Given an adjective as the only cue to contrast, are children sensitive to that information?
        
Experiment 1:
        
"This is a [tall/red] glorp" -- implies that there also may be shorter glorps
        
Adults tend (80%) to generalize in the implied direction
        
Experiment 2:
        
Can adults use this information if it is more subtle?
        
        
Experiment 3:
Are they sensitive to other types of adjective categories?
+ texure/height, width/height, pattern/height
All of these adjectives seem to work
        
Discussion:
This may facilitate inferential learning from others
+ increases common groupd between others
        
[note: how is this not just a general pragmatic effect? Is this new?]
        
Experiment 4: Are preschoolers sensitive to adjective information to infer contrast dimensions?
        
Younger 4s: huge bias for matching by color
+ 
        
older 4s: there is much less of a bias
+ more evidence of using the adjective information (although a small effect)
        
Experiment 5: Why a color bias?
        
        
      },
author = {Horowitz, Alexandra and Frank, Michael C},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Horowitz, Frank - 2012 - Learning from speaker word choice by assuming adjectives are informative.pdf:pdf},
keywords = {adjectives,language development,pragmatics},
pages = {473--478},
title = {{Learning from speaker word choice by assuming adjectives are informative}},
year = {2012}
}
@article{Hu1996,
annote = {Really good paper on HMMs for handwriting recognition.
        
Top level--stochastic word grammar
Mid level --letters are a sequence of strokes, captured by a left-to-right HMM
Low level -- strokes are a sequence of features, captured by a another left-to-right HMM
        
Strokes are shared across characters, but this is done manually. 
        
--------
left-to-right HMM: whre you start at state 1 for a character, and then move to 2, etc. You can do this with or without state skipping
        
How do you break writing into HMMs?
-- word level
-- character level (still shared structure(
-- stroke level
        
Here, they use stroks, and a letter is a concatenation of several stroke models. But a priori, you define how many strokes per character, and which are shared
        
Characters are now left to right HMMs over stroke models. Characters are then embedded in a grammar network, which define words, CFGs, etc.
        
Decoding -- inference with viterbi algorithm
Training -- inference, parameter restimatino, inference,... repeat like EM
        
Results: produces reasonable segmentation of words into strokes, but much of this is built in
        
Features: should be invariant to common image deformations. They choose tangent lines, or ratio of atngents
        
Results: trained on 10 writers, then tested on other writers.
-- Each stroke was a single state.
        
Accuracy was about 5% error
        
        
      },
author = {Hu, Jianying and Brown, Michael K},
file = {:Users/Brenden/Documents/Mendeley/Hu, Brown - 1996 - HMM Based On-Line Handwriting Recognition.pdf:pdf},
journal = {{IEEE Transactions of Pattern Analysis and Machine Intelligence}},
keywords = {handwriting},
mendeley-tags = {handwriting},
number = {10},
pages = {1039--1045},
title = {{HMM Based On-Line Handwriting Recognition}},
volume = {18},
year = {1996}
}
@article{Huettel2002,
abstract = {We demonstrate that regions within human prefrontal cortex develop moment-to-moment models for patterns of events occurring in the sensory environment. Subjects viewed a random binary sequence of images, each presented singly and each requiring a different button press response. Patterns occurred by chance within the presented series of images. Using functional magnetic resonance imaging (fMRI), we identified activity evoked by viewing a stimulus that interrupted a pattern. Prefrontal activation was evoked by violations of both repeating and alternating patterns, and the amplitude of this activation increased with increasing pattern length. Violations of repeating patterns, but not of alternating patterns, activated the basal ganglia.},
annote = {The prefrontal cortex is active during the violation of sequential patterns. This included ABABAB sequences and AAAAA sequences, even though sequences were random and subjects knew that. Thus, PFC pattern detection seems to be obligatory.
        
There is a beautiful parametric relationship between how big the violation is and the bold response.
        
---
People extract patterns automatically. They have expectations about what is coming next.
        
PFC may be central to dynamic prediction. It is implicated in processing low-probability stimuli, but this does not demonstrate sensitivity to local context.
        
Experiment:
Subjects saw sequence of A's and B's randomly intermixed. Looked for repeating and alternating patterns.
        
Response time shows sensitivity to these violations, particularly repeating stimuli.
        
Subjects know the sequence is random, so this is automatic processing.
        
Voxels in PFC active for one violation were also active for the other.
        
Parametric effect that is larger for longer sequences.
        
Large correlation (r=.9) with response time
        
In the basal ganglion, there was activation for violation of repeating structure, but not alternating. Perhaps the basal ganglion is involved in changing response modes, not general pattern structure.},
author = {Huettel, Scott a and Mack, Peter B and McCarthy, Gregory},
doi = {10.1038/nn841},
file = {:Users/Brenden/Documents/Mendeley/Huettel, Mack, McCarthy - 2002 - Perceiving patterns in random series dynamic processing of sequence in prefrontal cortex.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Adolescent,Adult,Basal Ganglia,Basal Ganglia: anatomy & histology,Basal Ganglia: physiology,Behavior,Behavior: physiology,Brain Mapping,Female,Humans,MD system,Magnetic Resonance Imaging,Male,Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,Prefrontal Cortex,Prefrontal Cortex: anatomy & histology,Prefrontal Cortex: physiology,Reaction Time,Reaction Time: physiology,Visual,Visual: physiology},
mendeley-tags = {MD system},
month = may,
number = {5},
pages = {485--90},
pmid = {11941373},
title = {{Perceiving patterns in random series: dynamic processing of sequence in prefrontal cortex.}},
volume = {5},
year = {2002}
}
@article{Association1920,
annote = {URL: http://books.google.com/books?id=-cNMAAAAYAAJ&pg=PA1&lpg=PA1&dq=Quantitative+Aspects+of+the+Evolution+of+Concepts&source=bl&ots=f2AveZA_ch&sig=qls_iw3d9tXUr-546HcqBFm6viM&hl=en&ei=yv43TpqqLc600AHV3KyyAw&sa=X&oi=book_result&ct=result&resnum=6&ved=0CEUQ6AEwBQ#v=onepage&q&f=false
        
        Introduction
                
It is difficult to reproduce all of the context in which concepts ("learning abstractions") learned in real environments
        
Child who touches a flame may not want to touch a lightbulb
        
Herbart's view of concepts:
"Lastly the significant element common to all experiences is deliberately sought out, found, and formulated in language"
- Herbart seems to be describing a necessary and sufficient view, formulated in natural language
        
But Hull claims that it can be more implicit, and there may be no verbalization of the concept at the end (how do you describe exactly what a dog is?) 
        
Previous studies involved looking at a group of elements, and trying to pick out (or verbally describe) a common element or try. It wasn't an artificial learning task in the usual sense, and it ignores the role of language
        
Hull wants to develop a better method for studying concepts
                  
Experiment 1: Order effects        
        
How much easier is it to first learning simpler to more complex examples, rather than the reverse?
                  
Method        
144 Chinese characters, adapted when necessary
        
Each "concept" was a motify present in many examples, where the examples differed in complexity. These motifs were like certain strokes
        
12 concepts total
        
Exposure time of five seconds
- each exposure must require a reaction from the subject
- test packs for testing evaluation of learning
+ also, can measure how long it takes to learn the training packs
        
Each pack varied on a spectrum of how obscured the defining element was
Two conditions
- complex to simple
- simple to complex
        
        
        
        
      },
author = {Hull, Clark},
file = {:Users/Brenden/Documents/Mendeley/Hull - 1920 - Quantitative aspects of the evolution of concepts.pdf:pdf},
publisher = {American Psychological Association},
title = {{Quantitative aspects of the evolution of concepts}},
volume = {XXVIII},
year = {1920}
}
@article{Hummel1992,
abstract = {Given a single view of an object, humans can readily recognize that object from other views that preserve the parts in the original view. Empirical evidence suggests that this capacity reflects the activation of a viewpoint-invariant structural description specifying the object's parts and the relations among them. This article presents a neural network that generates such a description. Structural description is made possible through a solution to the dynamic binding problem: Temporary conjunctions of attributes (parts and relations) are represented by synchronized oscillatory activity among independent units representing those attributes. Specifically, the model uses synchrony (a) to parse images into their constituent parts, (b) to bind together the attributes of a part, and (c) to bind the relations to the parts to which they apply. Because it conjoins independent units temporarily, dynamic binding allows tremendous economy of representation and permits the representation to reflect the attribute structure of the shapes represented.},
annote = {Neural network implementation of structural description model of object recognition.
        
The sub-components of objects are Biederman's geons. A neural network starts with edges and detects geons. To bind geons together with relations, etc., invovles sychronous firing of the units},
author = {Hummel, J E and Biederman, I},
file = {:Users/Brenden/Documents/Mendeley/Hummel, Biederman - 1992 - Dynamic binding in a neural network for shape recognition.pdf:pdf},
issn = {0033-295X},
journal = {Psychological Review},
keywords = {Depth Perception,Depth Perception: physiology,Discrimination Learning,Discrimination Learning: physiology,Form Perception,Form Perception: physiology,Humans,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurons,Neurons: physiology,Orientation,Orientation: physiology},
month = jul,
number = {3},
pages = {480--517},
pmid = {1502274},
title = {{Dynamic binding in a neural network for shape recognition.}},
volume = {99},
year = {1992}
}
@article{Hung2005,
abstract = {Understanding the brain computations leading to object recognition requires quantitative characterization of the information represented in inferior temporal (IT) cortex. We used a biologically plausible, classifier-based readout technique to investigate the neural coding of selectivity and invariance at the IT population level. The activity of small neuronal populations (approximately 100 randomly selected cells) over very short time intervals (as small as 12.5 milliseconds) contained unexpectedly accurate and robust information about both object "identity" and "category." This information generalized over a range of object positions and scales, even for novel objects. Coarse information about position and scale could also be read out from the same population.},
annote = {This paper:
        
have awake monkey fixate, show images of objects
        
record exta-cellular from neurons, over time, when seeing the objects
        
For n neurons, create an n dimensional vector which is the average firing rate
        
IT population supports good real-time performacne, from a few exampes, much better than early visual cortex (but how many examples did they use?)
        
----
Jim Dicarlo's tutorial on visual object recognition
        
What are tasks people are better than machines?
object recognition
scene understanding
walking...
        
Jim thinks we can move object recognition over pretty soon
        
works with rhesus monkey
        
Each layer v1, v4, IT) has a retinotopic map
Takes about 100 ms to get to IT
        
We want a "explicit" representaiton of object shape, that we can achieve from just a few examples
- and with a good enough representation, you can just use a linear classifier to do identification
        
Comparisions he will make today
1) Monkey neurons vs. Human behavior
2) Machines vs. Monkey neurons
3) Machines vs. Monkey neurons/Human behavior
        
Does spike rate in IT fully explain human object recognition?
- maybe rate code isn't sufficient?
- there could be specialized regions of IT?
        
Method:
- define object recognition (OR) tasks, test people on them
- then record from monkey IT on same tasks, and use decoders to predict performance
        
Task:
- 3D models rendered, controlling position, size, orientation
- placed on uncorrelated backgrounds, since many computer vision systems were cheating by picking up the background correlatins
        
Peopel are better at basic level tasks, rather than sub-ordinate
        
recording in monkeys: arrays of 96 electrodes, 3 clusters of electrodes
        
Create mean response to an image, averaged over reptitions, and over time during the display of that imgae
- can get a response vector for each image
        
Linear classifer trained on the IT response
- linear 100+ binary classificaiton task, and predict d-prime
- how many training examples per task?
+ 100 training images per category
- but people don't need this many to learn a new class!
        
There is a correlation of 0.91, and V4 doesn't correlate very well (r=0.5)
        
how would it do if you get a totally new object, is there enough signal in there?
- could you do hierarchical bayes, to figure out which features are important, and match based on that?
        
Machines vs monkey neurons
- you can do well on caltech101, with just v1 like features
- on their task, models don't do well
        
Model
- convolution net, with pooling and normalziation
- 3 layers
- neuroscience inspired these convolutional models... hmmm, does the brain do convolution?
- some way of optimizing architectural parameters in a modular ways
        
Top level of model can fit neurons in IT, using linear regression
- explains about 50% of variance, which is much better than all previous models, and also earlier layers of the same model
        
Can compare similarity matrices for objects
(like Kriesgorte)
- monkey IT has nice block diagonal structure, where V4 doesn't have this
        
HMO (thier model) correlates well (r=0.7) with monkey IT
        
Model explains a lot of variance at single unit and population level
- even the intermediate levels match quite well with lower-level regions on the visual hierarchy
        
Do other deep learning models predict the IT response as well?
+ other models, like Fergus's and Hinton's, do quite well
        
Machines vs. IT neurons
        
Hinton machine is very good at their task (rendered objects), near human performance
        
They all explain about half the variane in the IT neurons
        
Models were inspired by brains for a long time, now the mdoels are providing hypotheses for understanding the brain
        
      },
author = {Hung, Chou P and Kreiman, Gabriel and Poggio, Tomaso and DiCarlo, James J},
doi = {10.1126/science.1117593},
file = {:Users/Brenden/Documents/Mendeley/Hung et al. - 2005 - Fast readout of object identity from macaque inferior temporal cortex.pdf:pdf},
issn = {1095-9203},
journal = {Science},
keywords = {Action Potentials,Animals,Brain Mapping,Macaca mulatta,Neurons,Neurons: physiology,Psychomotor Performance,Recognition (Psychology),Temporal Lobe,Temporal Lobe: physiology,Time Factors,Visual Perception},
month = nov,
number = {5749},
pages = {863--6},
pmid = {16272124},
title = {{Fast readout of object identity from macaque inferior temporal cortex.}},
volume = {310},
year = {2005}
}
@article{Huttenlocher1993,
author = {Huttenlocher, Daniel P and Klanderman, Gregory A and Rucklidge, William J},
file = {:Users/Brenden/Documents/Mendeley/Huttenlocher, Klanderman, Rucklidge - 1993 - Comparing Images Using the Hausdorff Distance.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {computer vision},
number = {9},
pages = {850--63},
title = {{Comparing Images Using the Hausdorff Distance}},
volume = {15},
year = {1993}
}
@article{Huttenlocher1991,
annote = {Category adjustment model for spatial memory tasks. It seems pretty close to Bayesian... but they present their analysis in a very non-standard way
        
You could analyze it as data is generated from category, pertrubed by noise to create memory trace, and you want to reconstruct the original stimulus. Which would lead to shrinkage, like the perceptual magnet effect
        
--------
People's reports are often reconstructions, if there is category information
        
model: judgements have two influences
- category information
- metric information relating it to the category
        
fits better with prototype rather than exemplar models of categoriziation
        
Model
- prototype value of each category
                  
Bias        
- assume memory is normally distributed around the correct value
- there could be boundaries, and there is some bias in the Recollection (R) associated with truncation of uncertainty at the boundary
                  
Prototype        
P is prototype location, which itself is randomly distributed and uncertain (also normal?)
        
Recollection is a convex combination of the memory and the prototype
        
R = lambda*M + (1-lambda)P
        
lambda is a function of (sigma_p / sigma_m), which might be optimal if it is the square of this ratio. Bt it doesn't say how this is computed
        
If the recollection is far from the category prototype, biasing it towards the prototype might improve accuracy
                  
applying the model
                
there are reports of bias in the literature, but here the model explains it by combinbing two different types of unbiased information? 
+ do I get this?
                  
bias in cirle map        
when reporting the location of a dot in a circle, there is a bias towards reporting it closer to the circumference line, except when right at the line
        
thus, there is an outward bias because coding is more exact there, where it is uncertain in the middle of a cricle
        
inexactness in the fine-grained representation leads to more bias, and this noise may not be uniform across the stimulus space
                  
Experiment1
                
Dot appeared in a circle, and then reconstructed from memroy afterwards
        
results:
consistent with polar coordinates, where you get elongated noise due to error in the angle far out in the circle, and more circular noise closer to the center
        
radial location is independent as you go towards end of circle
- angular location gets noiser as you go towards end
- error were independent
        
prototype effect:
Within each quadrant, estimates of angle are biased away from the actual dot location in a direction towards the center of each quadrant
        
strong support that people use prototypes
        
radial bias: near center of circle, you get an outward bias. This gets weaker as you go further outward
+prototype may be near circumfrance
        
They estimate that the bias produces more accurate estimates, meaning that knowing and using the category provided useful information
                  
Experiment 3:        
presented more datapoints near the quandrant boundaries
                  
Experiment 4 (memory under noise):        
Presented a distractor task after the presentation but before the memory task, hoping to increase noise
+ within subjects, wehre only some trials had a distractor task
                  
results:        
prototypes is given more weight in constructing responses when the memor ytrace is uncertain, where there is a stronger bias
                  
Discussion
                
Dots in a cirle has two types of information
fine-grained: polar coordinates, where the radial measurement is judged in terms of boundary
coarse grain- quandrant location, which showed up in both the raidal and angular bias
        
more straightfoward to express as a prototype model rather than an exemplar model
        
shows how you can get systematic biases in reporting stimulus values even when the memory is unbiased, which might explain Weber's law},
author = {Huttenlocher, Janellen and Hedges, Larry V and Duncan, Susan},
file = {:Users/Brenden/Documents/Mendeley/Huttenlocher, Hedges, Duncan - 1991 - Categories and Particulars Prototype Effects in Estimating Spatial Location.pdf:pdf},
journal = {Psychological Review},
keywords = {classic psychology,spatial reasoning},
mendeley-tags = {classic psychology,spatial reasoning},
number = {3},
pages = {352--376},
title = {{Categories and Particulars: Prototype Effects in Estimating Spatial Location}},
volume = {98},
year = {1991}
}
@unpublished{Hwang2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1110.5667v1},
author = {Hwang, Irvin and Stuhlmueller, Andreas and Goodman, Noah D},
eprint = {arXiv:1110.5667v1},
file = {:Users/Brenden/Documents/Mendeley/Hwang, Stuhlmueller, Goodman - 2011 - Inducing Probabilistic Programs by Bayesian Program Merging.pdf:pdf},
keywords = {CogSci2013 Symposium,program induction},
mendeley-tags = {CogSci2013 Symposium,program induction},
title = {{Inducing Probabilistic Programs by Bayesian Program Merging}},
year = {2011}
}
@book{Inhelder1964,
address = {London},
annote = {        General thoughts on Piaget        
        
Piaget is famous for stage-like theory of development. His general stages did not hold up to scrutiny, but this was an important idea.
        
To read: Chapters 2-8, on classification
        
        Introduction:
                
Two main topics:
development of categorization and seriation
        
Categorization: treating a set of objects as the same
        
Seriation: treating a set of objects as ordered, as in they can be sorted
        
Neither depend on language, since they can develop, to some extent, before language. 
        
Just knowing "all," "some", or "bigger than" does not lead to the right concepts, since they can be interpreted in the perceptual-graphica schema or the logical schema.
        
                  
Part 1: Classification
          
Part 2: Seriation
                
Does not develop much before 7 or 8-- in the abstract sense. But can build on perception.
        
Initial abilities are perceptual: A child can build a tower by using the bigger blocks at the bottom, but this is strongly perception-based
        
Sticks are arranged from long to short, and may be non-linear changes in length. When asked to compare two sets of pairs, younger children (5-7) needs to re-measure, but older children use the shape of the parabola traced by the lineup (p248)
        
Addition experiment:
        
Bars of various length are given. When a new object is added to the set, younger children compare it to all others in a disordered way. At 7-8 years old, they only need to compare to the shortest, then the next, understanding transitivity.
        
However, at 5-6, children can draw the shape that a set of items would trace if they were ordered, before they can order them
        
Development
Stage 1 (4-5 years): Children cannot order the bars initially, there are many chunks of ordered subsets
Stage 2 (5-6 years): Can order them correctly after trial and error, but cannot generalize to new objects well. Also, drawing performance gets the general shape correct.
Stage 3 (start at 7-8 years): Children generalize to new objects properly. Once they realize that if X is larger than 2, they don't need to check if it is also larger than 1.
                  
Multiple seriation
          
        Domain has two comparative relations:
lighter and larger
        
Children are asked to order everything in a 2D matrix.          
                
Stage 1: no seriation
Stage 2: seriation of only one dimension
Stage 3: seriation in both dimensions (age 7-8)
        
Seriation in 2D is harder than 1D, but 2D can help classification (but why? -- don't understand yet)
                  
Conclusion        
        
Over development, children's behavior in classification and seriation tend to more closely resemble the logical-mathematical laws. Why is this the case?
        
This is how Piaget tends to think, domain general, as opposed to later work on domain specificity (Carey, Spelke, etc.)
        
Overall claim that logical operations: <,>,= are the same for seriation and classification, although they are used differently. And the abilities come online at roughly the same time      
        
Classification: Initially, classes are just the extension (perceptual, graphic). The critical problem is the coordination of intention and extension. It's not how they arise, but how they become differenitated in the child.
        
My comments: It is important to understand whether Piaget's results on logical operations in classification is still relevant, given modern resemblance theories of concepts},
author = {Inhelder, Barbel and Piaget, Jean},
publisher = {Routledge \& Kegan Paul},
title = {{The Early Growth of Logic in the Child}},
year = {1964}
}
@article{Intraub1989,
abstract = {We report a picture-memory phenomenon in which subjects' recall and recognition of photographed scenes reveal a pronounced extension of the pictures' boundaries. After viewing 20 pictures for 15 s each, 37 undergraduates exhibited this striking distortion; 95% of their drawings included information that had not been physically present but that would have been likely to have existed just outside the camera's field of view (Experiment 1). To determine if boundary extension is limited to recall and drawing ability, Experiment 2 tested recognition memory for boundaries. Eighty-five undergraduates rated targets and distractors on a boundary-placement scale. Subjects rated target pictures as being closer up than before and frequently mistook extended-boundary distractors as targets. Results are discussed in terms of picture comprehension and memory. In addition to its theoretical value, discovery of the phenomenon demonstrates the importance of more widespread use of open-ended tests in picture-memory methodology.},
annote = {-- our insight into the pictorial representation is hindered by just using recognition tasks
-- drawing produces much more information
-- image schemas seem to be invovled, in that we can extrapolate far beyond the bounadries of the image frame
                  
Experiment 1:        
Participants saw 20 scenes, each of which had a main object or cluster in a natural bakground
-- photographs were close-ups
-- edge was labeled "edge of slide" on booklet
-- participants listened to a 35-min lectures, and then they were asked to draw some of the photos
        
Result:
consistently extended the boundary outside the original frame.
On 95% of trials, the boundary was extended.
                  
Experiment 2:        
Also included a recognition test, where participants rated how the boundary might have changed compared to the orignal. AGain, the bias is in the same direction
                  
Conclusion        
      },
author = {Intraub, H and Richardson, M},
file = {:Users/Brenden/Documents/Mendeley/Intraub, Richardson - 1989 - Wide-angle memories of close-up scenes.pdf:pdf},
issn = {0278-7393},
journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
keywords = {Adult,Attention,Distance Perception,Form Perception,Humans,Imagination,Memory,Mental Recall,Orientation,Pattern Recognition,Perceptual Masking,Size Perception,Visual,Visual Fields,classic psychology},
mendeley-tags = {classic psychology},
month = mar,
number = {2},
pages = {179--87},
pmid = {2522508},
title = {{Wide-angle memories of close-up scenes.}},
volume = {15},
year = {1989}
}
@article{Itti1998,
author = {Itti, Laurent and Koch, Christof and Niebur, Ernst},
file = {:Users/Brenden/Documents/Mendeley/Itti, Koch, Niebur - 1998 - A Model of Saliency-Based Visual Attention for Rapid Scene Analysis.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligencen},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {11},
pages = {1254--1259},
title = {{A Model of Saliency-Based Visual Attention for Rapid Scene Analysis}},
volume = {20},
year = {1998}
}
@article{Jacobs2009,
abstract = {A fundamental question in neuroscience concerns how the human brain represents perceptual and conceptual information. Traditionally, researchers probed this issue by identifying single neurons that increased their firing rate when an animal encountered certain stimuli. Here we provide evidence of a complementary scheme in which gamma-band (25-128 Hz) electrocorticographic (ECoG) activity -- a phenomenon involving large groups of neurons -- encodes the active cognitive representation. We analyzed intracranial brain recordings from neurosurgical patients while they studied lists of visually presented letters and found that the amplitude of gamma-band activity encoded the identity of the current letter. These letter-specific patterns occurred during periods of overall increased gamma amplitude and were linked to the phase of simultaneous theta (4-8 Hz) oscillations. In occipital cortex, these patterns sometimes reflected the shape of the viewed letter, but, in other brain regions, this phenomenon was not related to letter form. Our findings show that gamma-band activity encodes a range of perceptual and conceptual information, suggesting that ECoG recordings can reveal neural correlates of specific human cognitive representations.},
author = {Jacobs, Joshua and Kahana, Michael J},
doi = {10.1523/JNEUROSCI.2187-09.2009},
file = {:Users/Brenden/Documents/Mendeley/Jacobs, Kahana - 2009 - Neural representations of individual stimuli in humans revealed by gamma-band electrocorticographic activity.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience},
keywords = {Brain,Brain: physiology,Electroencephalography,Electroencephalography: methods,Humans,Neurons,Neurons: physiology,Photic Stimulation,Photic Stimulation: methods,Psychomotor Performance,Psychomotor Performance: physiology},
month = aug,
number = {33},
pages = {10203--14},
pmid = {19692595},
title = {{Neural representations of individual stimuli in humans revealed by gamma-band electrocorticographic activity.}},
volume = {29},
year = {2009}
}
@article{Jacobs2010,
abstract = {Finding our way in spatial environments is an essential part of daily life. How do we come to possess this sense of direction? Extensive research points to the hippocampus and entorhinal cortex (EC) as key neural structures underlying spatial navigation. To better understand this system, we examined recordings of single-neuron activity from neurosurgical patients playing a virtual-navigation video game. In addition to place cells, which encode the current virtual location, we describe a unique cell type, EC path cells, the activity of which indicates whether the patient is taking a clockwise or counterclockwise path around the virtual square road. We find that many EC path cells exhibit this directional activity throughout the environment, in contrast to hippocampal neurons, which primarily encode information about specific locations. More broadly, these findings support the hypothesis that EC encodes general properties of the current context (e.g., location or direction) that are used by hippocampus to build unique representations reflecting combinations of these properties.},
annote = {Talk Jan 28
        
electrophysiological representation of specific cognitive states
        
+ intractable seizues, only procedure is to remove brain region. Implanted electrodes in  the brain, and they sit in hospital. Can run studies int he meantime
        
Two types of work:
- recognition memory
- spatial navigation
        
Electrocorticography (ECoG)
each electrode 400,000 neurons
- also microelectrodes that can be inserted into deep parts of the brain
        
Penfield (1938) found temporal-lobe stimulation caused memory recall
- stimulation caused inhibition
- why does inhibition cause memory recall?
        
Patient: stimulating a particular electrode made them recall somethingabout high-school
        
Asked them questions about high school (person/nonperson) and other non-highschool question (person/nonperson)
        
ECoG signals
- theta and gamma waves
- also, broadband ECoG signals power in my frequencies
        
Was there a diference in ECoG activity, at each electrode, between high-school and non-highschool questions?
- yes, the same electrode shows up , when answering questions or through stimulation (he reports high-school memory here)
        
Gamma activity actually DECREASES in this electrode when it is processing high-school information
        
Seems to represent "high school"-ness (Norma and O'Reilly), abstract rep. in neocortex
        
Letters (Jacobs & kahana, 2009)
Sternberg memory paradigm
        
- duration of signals is the factor that changes
+ this was in visual cortex
+ many letters have initial spike, but duration changes
+ Have cortical columns that respond to particular letters, or small sets of letters
        
pre-motor cortex responds to abstract representatin of letters, regardless of font size or font
(Jacobs, ..., 2011)
        
Experiment: for a given site, rank it by the amount of response to letters
+ get repetition suppression for seeing the same letter twice, but only for the most common letters
                  
Spatial navigation
                
in entorhinal cortex and hippocampus
        
had people pretend to be taxi-cab drivers
        
hippocampal place cell: represents a certain part ofthe map, but in a direction-specific manner
        
Also have a cell that seems to represent "clock-wise" movement
        
grid cells: individual neurons are representing an array of locations, spaced out in a grid
+ there are grid cells in entorhinal cortex
+ they are most prominent in entorhinal cortex
- also foudn some in hippocampus and the cingulate cortex
        
        entorhinal: more course rep.
hippocampus: more sparse, location-specific representation
                
        
      },
author = {Jacobs, Joshua and Kahana, Michael J and Ekstrom, Arne D and Mollison, Matthew V and Fried, Itzhak},
doi = {10.1073/pnas.0911213107},
file = {:Users/Brenden/Documents/Mendeley/Jacobs et al. - 2010 - A sense of direction in human entorhinal cortex.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Entorhinal Cortex,Entorhinal Cortex: physiology,Entorhinal Cortex: surgery,Hippocampus,Hippocampus: physiology,Humans,Space Perception,Video Games},
month = apr,
number = {14},
pages = {6487--92},
pmid = {20308554},
title = {{A sense of direction in human entorhinal cortex.}},
volume = {107},
year = {2010}
}
@article{Jacobs1991,
annote = {Have many connectionist networks, each responsible for a small portion of the training data. You then have a gating network that decides which network shoudl be used for each training example.
        
Previous work used linear combinations of experts, which resulted in strong copuling between them.
        
Instead, they make a stochastic decision about which expert to use for each example. This makes each responsible for the entire training example
        
gating network receives the same input, and outputs the probability of choosing each, as a softmax
        
        results:        
discriminating 4 different vowel categories
        
captured mixture of experts (very simple linear functions) with full backpropagation networks
        
mixture of experts converged faster, probably due to only have one layer},
author = {Jacobs, Robert a. and Jordan, Michael I. and Nowlan, Steven J. and Hinton, Geoffrey E.},
doi = {10.1162/neco.1991.3.1.79},
file = {:Users/Brenden/Documents/Mendeley/Jacobs et al. - 1991 - Adaptive Mixtures of Local Experts.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {classic AI},
mendeley-tags = {classic AI},
month = feb,
number = {1},
pages = {79--87},
title = {{Adaptive Mixtures of Local Experts}},
volume = {3},
year = {1991}
}
@article{Jain1997,
annote = {Attempts to match an unknown image against a databse of known images, using deformable templates. It attempts to match the pixels, while using the smallest possible transformation.
        
Someting like this could work from just a few training examples. Similar to Revow et al., and also Miller
        
        
---
Similar to the Revow et al. spline deformation model
        
Deformations are parameterized by an infinite set of basis functions, which look like sine/cosine waves
        
Dissimilarity is how well the template fits, and how much deformation is needed
-- Prior on deformation: Gaussian centered on 0 for each basis coefficient
--Likelihood based on similar edges
        
Using this as a distance measure, multi-dimensional scaling does a good job separating the classes
        
Performance is in the high 90's on NIST. To reduce computational burden, you can just take a few good prototypes, rather than full nearest neighbor},
author = {Jain, Anil K and Zongker, Douglas},
file = {:Users/Brenden/Documents/Mendeley/Jain, Zongker - 1997 - Representation and Recognition of Handwritten Digits Using Deformable Templates.pdf:pdf},
journal = {{IEEE Transactions of Pattern Analysis and Machine Intelligence}},
keywords = {classic AI,handwriting},
mendeley-tags = {classic AI,handwriting},
number = {12},
pages = {1386--1391},
title = {{Representation and Recognition of Handwritten Digits Using Deformable Templates}},
volume = {19},
year = {1997}
}
@article{Jain2004,
annote = {        Problem        
Gibbs-sampling can easily get stuck when clustering, by duplicating clusters
        
This paper shows how to use MH moves to split/merge clusters. This is done intelligently by using gibbs sampling as an inner-loop, to get intelligence splits.
        
It's relevant more broadly, showing how gibbs sampling can be integrated with MH proposals. If you have a block of correlated variables, you can use an MH propsoal for one (or a few), and use gibbs sampling to clean up the rest -- before the final proposal. Computing these probabilities can be complicated, but you can make it a valid mcmc proposal.
                  
Important: comment on mixing kernels        
When mixing or chooseing between MH kernels, "the proposal probability CAN BE calculated for just the proposal distribution that was chosen, rather than summing over all possible proposal distributions" (p162) Both lead to valid sampelrs, but the latter is much more complicated.
                  
first version (not efficient)
                
This uses a MH proposal          
                
Select two data points at random
1) if they are in the same cluster, propose splitting the clusters randomly
2) if they are in different clusters, propose combining them into a cluster
                  
second version
          
step one, getting a launch state        
1) pick data points i and j
2) regardless of whether or not they are in the same cluster, assign each to a new cluster
3)  randomly assign the datapoints to one cluster or the other
2) second: do several scans of restricted gibbs sampling, where you can reassign just these datapoints to one cluster or the other
                  
if i and j were in the same clusters,        
now that you have the launch state,
compute the split state with one more restrictred iteration of gibbs sampling. The proposal probability is then just the transition probability from the launch state, to the final proposed state, csplit. This is a product of all the conditional distributions in the last gibbs update
                  
if i and j were in different clusters,        
You merge the two clusters. You can then compute the reverse probability by using the (hypothetical) gibbs sampling transition probability from the launch state, to the original split configuration c        
        
        other issues        
You can combine split/merge with traditional gibbs sampling, to get a combination of major and minor updates
                  
results        
when the data is high-dimensional and the classification problem is difficult, split-merge, combined with gibbs cleanup, is much more effective than standard gibbs
                  
future directions        
For blocks of correlated variables, it should be propose new values for some variables in the block, and then using restricted Gibbs sampling to update the other variables.
        
It should be possible to compute a suitable acceptance probability then.},
author = {Jain, Sonia and Neal, Radford M},
doi = {10.1198/1061860043001},
file = {:Users/Brenden/Documents/Mendeley/Jain, Neal - 2004 - A Split-Merge Markov Chain Monte Carlo Procedure for the Dirichlet Process Mixture Model.pdf:pdf},
isbn = {1061860043001},
issn = {1061-8600},
journal = {Journal of Computational and Graphical Statistics},
keywords = {classic AI,gibbs sampler,hastings algorithm,latent class analysis,metropolis},
mendeley-tags = {classic AI},
month = mar,
number = {1},
pages = {158--182},
title = {{A Split-Merge Markov Chain Monte Carlo Procedure for the Dirichlet Process Mixture Model}},
volume = {13},
year = {2004}
}
@article{JakelScholkopf2009,
author = {J\"{a}kel, Frank and Scholk\"{o}pf, B and Wichmann, F A},
journal = {Trends in Cognitive Science},
number = {9},
title = {{Does Cognitive Science Need Kernels?}},
volume = {13},
year = {2009}
}
@article{James2009,
abstract = {Functional specialization in the brain is considered a hallmark of efficient processing. It is therefore not surprising that there are brain areas specialized for processing letters. To better understand the causes of functional specialization for letters, we explore the emergence of this pattern of response in the ventral processing stream through a training paradigm. Previously, we hypothesized that the specialized response pattern seen during letter perception may be due in part to our experience in writing letters. The work presented here investigates whether or not this aspect of letter processing-the integration of sensorimotor systems through writing-leads to functional specialization in the visual system. To test this idea, we investigated whether or not different types of experiences with letter-like stimuli ("pseudoletters") led to functional specialization similar to that which exists for letters. Neural activation patterns were measured using functional magnetic resonance imaging (fMRI) before and after three different types of training sessions. Participants were trained to recognize pseudoletters by writing, typing, or purely visual practice. Results suggested that only after writing practice did neural activation patterns to pseudoletters resemble patterns seen for letters. That is, neural activation in the left fusiform and dorsal precentral gyrus was greater when participants viewed pseudoletters than other, similar stimuli but only after writing experience. Neural activation also increased after typing practice in the right fusiform and left precentral gyrus, suggesting that in some areas, any motor experience may change visual processing. The results of this experiment suggest an intimate interaction among perceptual and motor systems during pseudoletter perception that may be extended to everyday letter perception.},
annote = {Only learning to write, rather than recognize, new characters changes the functional specialization of visual cortex in an area near the VWFA
        
------------
- functional specialization is the hallmark of efficient processing, so it's not surprise that it should exist for letters (faces, places, body parts)
- why is the letter area placed where it is? 
+ one hypothesis is eccentricity bias
+ however, it requires a coarser level of analysis than does faces processing.
        
Hypothesis: the letter area may refelct sensorimotor integration that is required when we learn to write letters. Motor programs might be stored with the visual information -- and they may serve to augment visual information.
+ this is supported by activity in motor/premotor regions
+ lots of other evidence for perceptual/motor interaction
+  evidence from patient with damage to motor areas, than cannot write and has trouble identifying letters (Anderson, Damasio,  Damasio, 1990)
        
Method:
compare writing, typing, and visual-only experience on visual "pseudoletters", and see how this effects the neural processing
        
1) initial scan
2) two training sessions, and behavioral testing
3) final scan to look at post-training brain
        
Scanner task:
1) one-back matching task, regardless of font or orientation
        
Training task:
1) writing condition: asked to copy pseudoletters
2) typing condition: find and type the pseudoletter presented on the screen
3) visual condiion: look at the stimulus and memorize its form
        
All participants were notified they would be tested on the stimuli after training. One task did not appear to take longer than any other.
        
Testing task:
1) Is the target stimulus (shown first) presented in an array of characters below? A measure of learning that does not require explicit recognition.
2) same/different task with brief sequential presentation
+ font or orientation could change
3) old/new recognition test
        
For each test type, there was no significant difference in the test performances. There was an effect of learning in each group though.
        
fMRI results:
Compare activation of trained vs. untrained pseudoletters for before and after training
        
- left posterior fusiform gyrus: there was a large increase in activity for trained psuedoletters vs. untrained pseudoletters ONLY IN THE MOTOR GROUP.
- same found in left dorsal precentral gyrus
-  left inferior occipital gyrus: same effect found in both the motor and typing group
- right posteiror fusiform gyrus: large effect of typing, of the same form
        
Summary: left posterior fusiform and left dorsal precentral gyrus, showed greater activation for trained pseudoletters over untrained ones, compared before/after training. These are the same regions that have previously been found to respond to letter perception (James & Gauthier, 2006).
        
Discussion: fMRI results should be considered in light of the null behavioral results. Their results support that motor experience is important for the development of functional specialization
        
Theory that children learn from printed characters, but when they produce characters they perceive the motor variability. This may serve to augment the visual processing by broadening the visual-motor representaiton.},
author = {James, Karin H and Atwood, Thea P},
doi = {10.1080/02643290802425914},
file = {:Users/Brenden/Documents/Mendeley/James, Atwood - 2009 - The role of sensorimotor learning in the perception of letter-like forms tracking the causes of neural specializa.pdf:pdf},
issn = {1464-0627},
journal = {Cognitive Neuropsychology},
keywords = {Adult,Analysis of Variance,Brain Mapping,Cerebral Cortex,Cerebral Cortex: blood supply,Cerebral Cortex: physiology,Computer-Assisted,Computer-Assisted: methods,Female,Functional Laterality,Functional Laterality: physiology,Humans,Image Processing,Learning,Learning: physiology,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,Oxygen,Oxygen: blood,Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,Reaction Time,Reaction Time: physiology,Visual,Visual: physiology,Young Adult,handwriting,neural basis},
mendeley-tags = {handwriting,neural basis},
month = feb,
number = {1},
pages = {91--110},
pmid = {18830859},
title = {{The role of sensorimotor learning in the perception of letter-like forms: tracking the causes of neural specialization for letters.}},
volume = {26},
year = {2009}
}
@article{James2006,
abstract = {Behavioral, neuropsychological and neuroimaging research suggest a distributed network that is recruited when we interact with letters. For the first time, we combine several letter processing tasks in a single experiment to study why letters seem to engage such disparate processing areas. Using fMRI, we investigate how the brain responds to letters using tasks that should recruit systems for letter perception, letter writing, letter copying and letter imagery. We describe a network of five cortical regions including the left fusiform gyrus, two left pre-central areas, left cuneus and the left inferior frontal gyrus that are all selectively engaged during a 1-back matching paradigm with letters. Our results suggest involvement of these regions to different extents in different tasks. However, the regions also form an integrated network such that letter perception also engages motor regions while writing recruits letter-specific visual regions as well. We suggest that this distributed network is a direct result of our sensory-motor interactions with letters.},
annote = {        From Duplicate 1 (                   Letter processing automatically recruits a sensory-motor brain network.                 - James, Karin H; Gauthier, Isabel )
                
Supporting these results, \citeA{JamesGauthier2006} looked at the ROI from \citeA{LongcampAnton2003} when participants viewed letters, faces, and objects in a 1-back task. They found this region responded stronger to letters, when compared to faces or objects. 
Left premotor area (BA6) 
active for letters > faces
and letters > objects.
        
Task: 1-back matching
Stimuli: letters, faces, objects
        
ROI was that found in Longcamp
-
        
 Also found this srea is active for drawing more generally, which they claim is inconsistent with Longcamp who did not find activity for drawing pseudoletters. But Loncamp 2003 says they did get activity for drawing pseudoletters.
        
        From Duplicate 2 (                   Letter processing automatically recruits a sensory-motor brain network                 - James, K; Gauthier, I )
                
        
        
      },
author = {James, Karin H and Gauthier, Isabel},
file = {:Users/Brenden/Documents/Mendeley/James, Gauthier - 2006 - Letter processing automatically recruits a sensory-motor brain network(2).pdf:pdf},
institution = {Department of Psychological and Brain Sciences, Indiana University, 1101 E. 10th Street, Bloomington, IN 47405, USA. khjames@indiana.edu},
journal = {Neuropsychologia},
keywords = {embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
number = {14},
pages = {2937--2949},
pmid = {16920164},
title = {{Letter processing automatically recruits a sensory-motor brain network.}},
volume = {44},
year = {2006}
}
@article{James2009a,
abstract = {The effect of writing on the concurrent visual perception of letters was investigated in a series of studies using an interference paradigm. Participants drew shapes and letters while simultaneously visually identifying letters and shapes embedded in noise. Experiments 1-3 demonstrated that letter perception, but not the perception of shapes, was affected by motor interference. This suggests a strong link between the perception of letters and the neural substrates engaged during writing. The overlap both in category (letter vs. shape) and in the perceptual similarity of the features (straight vs. curvy) of the seen and drawn items determined the amount of interference. Experiment 4 demonstrated that intentional production of letters is not necessary for the interference to occur, because passive movement of the hand in the shape of letters also interfered with letter perception. When passive movements were used, however, only the category of the drawn items (letters vs. shapes), but not the perceptual similarity, had an influence, suggesting that motor representations for letters may selectively influence visual perception of letters through proprioceptive feedback, with an additional influence of perceptual similarity that depends on motor programs.},
annote = {        relevance to motor program induction model:  This suggests that the neural imaging results, showing activation in motor areas for static letters, is not epihenomenal. Motor processes seem to be playing an role in letter perception, where motor interference can be highly specific (drawing curved letters intereferences with perceiging curved letters, rather than straight ones)
        
However, drawing shapes doesn't interference much with perceiving letters, and perceiving shapes doesn't get much interference. Does this mean this system is totally different for novel characters?
        
Not so fast, because their shapes are rather complex (heart, clover, square, etc.). This could still be tried with simple characters from other alphabets
        
---
        
Summary:
Writing impairs reading. Participants were tested on letter identification under noise. 
        
drawing curvey vs straight items: curvey items interferes with pereiving curvey letters, and likewise for stright
drawing letters vs. shapes: the effect is stronger  drawing for letters
        
even when a participant is yoked to an experimenter, and thus is just passively drawing, there are interference effects. But it is not highly specfic, where the curvey/straight dimension isn't highly specific in the interference
        
perceiving shapes does not show much interference. However, writing letters does seem to interfere somewhat with perceiving curvy shapes.
                
However, their shapes are not a whole lot like novel handwritten characters.          
          
---
          
Introduction        
Idea that people's perception of the wolrd is reliant on motor interactions with their environment
        
interference effect: ongoing actions influence current perceptions
+ left arrow target interfers with left keypress
+ holding a heavy object influences perception          
          
        priming/facilitation effects: 
+ perception of biological motion is faciliated by prior performance of it
+ motor systems are engaged in the visual perception of objects with strong motor associations
+ true for skilled piano players hearing notes          
                
main case: letters
- do not automatically afford action without experience -- you need to be trained to some respect. (Is this true?)
        
Main questions
1) Can motor processes influence the interaction with the static forms? facilitatory or inhibitory?
2) Does the interference reflect specific motor experience? Does the content have to match?          
          
Experient 1:        Seeing shapes        
- Participats identified letters visually, embedded in noise (H,N,K [straight] and G,D,U [curvy])
- Simulataneously, they had to draw either letters or shapes.
- noise was adjusted to 75% correct for each subject
        
Drawing task: draw pairs of letters ( or shapes) in alternation. Told these letters would be analyzed, although they weren't.
        
Results:
Task was letter identification
- First recorded performance in a baseline recognition task.
- Then practiced writing task
-Then did both together
        
Main effects:
 that writing letters interferes more than writing shapes. 
        
But more intersetingly, there is an intercation, where writing straight items [lettres and shapes] hurts the identification of straight letters, and drawing curvy items hurts seeing curvy letters
        
Trend towards three-way interaction (I assume letters more than shapes?)
        
Support idea of shared neural processes. The coolest effect is the specificity of perceiving straight letters is harmed by drawing straight letters. But could have also been due to sub-vocalization.
        
        Experiment 2: Perceigin letters under interference
                
- Made perception task only involving letters with straight segments, or curvy segments. [HFICOU]
- drew eithr S,V,t,8,circle,triangle,cross
- Also, only wrote one item over and over, and they varied how similar the item was to the letters being perceived. There is a nice parameteric relationship here, as shown in the amount of interference.
        
main effect: writing letters interfered more than drawing shapes
interaction: congruent curvature (straight vs. curverd) had stronger interferenece, as before
three-way intercation; congruent curvature in the same domain was strongest
        
when drawn item is exactly the same as the perceived one, little interference exists (like drawing a 0 when preceiving an "O")
        
less possibility for rehersal, since people just drew one shape. also it wouldn't mediate the effect of similarity effect
                  
Experiment 3:
                
Partitipants perceived both letters and shapes in noise -- maybe letters interfere with any type of perceptual task?
        
Yes, the data looked the same as the previous tasks for perceiving letters. But little interference at all when perceiving shapes. Interference might depend on extensive experience writing letters. 
        
Maybe the motor system is not engaged automatically for shapes, just letters? [their speculation]
        
However, their shapres aren't very "character-like" -- star, heart, clover, etc.
        
idea: can we run an interference task, when learning to categorize novel letters?
                  
Experiment 4: Yoked experimenter and subject, so the subject passively draws.
                  
no main effect of writing condition (active vs. passive) on perception!
        
Letter writing produces intereference, but shape writing does little (same as previous experiments, even in passive condition)
                  
BUT writing curved/straight does not specifically interfere with curved/straight perception. Thus, some aspect of intentional writing is important.
        
        General        Discussion        
        
- activity of motor cortex during letter perception is not epiphenomenal. It seems to play an active role
- the systems are so closely linked that writing and perception can interfere with eachother, and they do so in highly specific ways (based on shared perceptual features)},
author = {James, Karin H and Gauthier, Isabel},
doi = {10.1037/a0015836},
file = {:Users/Brenden/Documents/Mendeley/James, Gauthier - 2009 - When writing impairs reading letter perception's susceptibility to motor interference.pdf:pdf},
issn = {0096-3445},
journal = {Journal of Experimental Psychology: General},
keywords = {Attention,Discrimination (Psychology),Female,Field Dependence-Independence,Humans,Male,Pattern Recognition,Psychomotor Performance,Reading,Visual,Writing,Young Adult,embodied cognition,handwriting,neural basis},
mendeley-tags = {embodied cognition,handwriting,neural basis},
month = aug,
number = {3},
pages = {416--31},
pmid = {19653799},
title = {{When writing impairs reading: letter perception's susceptibility to motor interference.}},
volume = {138},
year = {2009}
}
@article{James2005,
abstract = {One would expect that a lifetime of experience recognizing letters would have an important influence on the visual system. Surprisingly, there is limited evidence of a specific neural response to letters over visual control stimuli. We measured brain activation during a sequential matching task using isolated characters (Roman letters, digits, and Chinese characters) and strings of characters. We localized the visual word form area (VWFA) by contrasting the response to pseudowords against that for letter strings, but this region did not show any other sign of visual specialization for letters. In addition, a left fusiform area posterior to the VWFA was selective for letter strings, whereas a more anterior left fusiform region showed selectivity for single letters. The results of different analyses using both large regions of interest and inspections of individual patterns of response reveal a dissociation between selectivity for letter strings and selectivity for single letters. The results suggest that reading experience fine-tunes visual representations at different levels of processing. An important conclusion is that the processing of nonpronounceable letter strings cannot be assumed to be equivalent to single-letter perception.},
author = {James, Karin H and James, Thomas W and Jobard, Gael and Wong, Alan C N and Gauthier, Isabel},
file = {:Users/Brenden/Documents/Mendeley/James et al. - 2005 - Letter processing in the visual system different activation patterns for single letters and strings.pdf:pdf},
issn = {1530-7026},
journal = {Cognitive, affective \& behavioral neuroscience},
keywords = {Adult,Attention,Attention: physiology,Brain Mapping,Cerebral Cortex,Cerebral Cortex: physiology,Computer-Assisted,Female,Humans,Image Processing,Language,Magnetic Resonance Imaging,Male,Pattern Recognition,Reading,VWFA,Visual,Visual: physiology,handwriting},
mendeley-tags = {VWFA,handwriting},
month = dec,
number = {4},
pages = {452--66},
pmid = {16541814},
title = {{Letter processing in the visual system: different activation patterns for single letters and strings.}},
volume = {5},
year = {2005}
}
@article{James2010,
abstract = {Since Broca's studies on language processing, cortical functional specialization has been considered to be integral to efficient neural processing. A fundamental question in cognitive neuroscience concerns the type of learning that is required for functional specialization to develop. To address this issue with respect to the development of neural specialization for letters, we used functional magnetic resonance imaging (fMRI) to compare brain activation patterns in pre-school children before and after different letter-learning conditions: a sensori-motor group practised printing letters during the learning phase, while the control group practised visual recognition. Results demonstrated an overall left-hemisphere bias for processing letters in these pre-literate participants, but, more interestingly, showed enhanced blood oxygen-level-dependent activation in the visual association cortex during letter perception only after sensori-motor (printing) learning. It is concluded that sensori-motor experience augments processing in the visual system of pre-school children. The change of activation in these neural circuits provides important evidence that 'learning-by-doing' can lay the foundation for, and potentially strengthen, the neural systems used for visual letter recognition.},
annote = {        Check out Portwood, developmental dyspraxia, where motor impairment hurts letter recognition.        
        
Thesis: letter-specialization in cortex is a result of sensori-motor experience, not simply visual experience
        
Both in left posterior fusiform (near VWFA)
and left anterior fusiform (closer to a "letter area", James et al. 2005) only acquired significant activation after motor experience with letters. Not just visual experience.
        
----
Children learn to write letters before they can read words, sometimes 3-4 years beforehand
        
Why do we have specialization for letteres?
Hypothesis: it is due to sensori-motor experience with letters.
        
James & Atwood (2009) greater activation to studied pseudo-letters than unstudied pseudo-letters in left fusiform gyrus. This was true for adults learning to write them, but not just visual experience.
        
Task: there was no task just passive viewing of the characters by the children in the scanner
        
Training session:
Children were read a story, with certain words (that used a set of tested letters) were bolded. Afterwards, children either idenitified these letters in a force-choice task (A) or wrote these letters (B). Both groups were given feedback regarding accuracy. There were multiple training sessions over weeks.
        
Writing training: they copied the letters, and given feedback on the writing accuracy.
        
Participants: 4-5 year olds
        
Use a ROI defined as the left fusiform gyrus, from past work. Did not use a localizer, since they assumed the control group would have little activity there.
                  
results:        
        
Before training, left fusiform gyrus was engaged more during letter perception than other stimuli (shapes and psuedoletters). Thus, even before children learn to read, the brain achieves left-hemi dominance for print. But they know alphabet, can print name etc.
        
But there were a large increase in activity only after sensori-motor training.  This was for letters, but not for shapes and pseudoletters.        
        
Thre was no difference after just the visual training.
        
Similar results for left posterior, and anterior, fusiform regions
        
Weaker result for right anterior fusiform gyrus (although still significant)
        
VWFA seems like a visual perceptual area, but it does not change response for visual-only experience. 
        
Alternative explanation could be attention differences, but there were no behavioral signatures.
        
However, the experimental group showed a slight improvement in behavioral preformance.
        
Discussion:
        
Shapes and pseudoletters provide good controls, because pseudoletters have the same featuers and shapes are highly famililar.
        
Instead, it has something to do with learning to write letters, that leads to functional specificity.
        
- embodied cognition has been studied by a wide variety of fields
- Montessori method: teaching children how to draw letters is important},
author = {James, Karin Harman},
doi = {10.1111/j.1467-7687.2009.00883.x},
file = {:Users/Brenden/Documents/Mendeley/James - 2010 - Sensori-motor experience leads to changes in visual processing in the developing brain.pdf:pdf},
issn = {1467-7687},
journal = {Developmental science},
keywords = {Brain,Brain: blood supply,Brain: growth & development,Child,Female,Functional Laterality,Functional Laterality: physiology,Humans,Language Development,Learning,Learning: physiology,Magnetic Resonance Imaging,Male,Preschool,Reading,Visual Cortex,Visual Cortex: blood supply,Visual Cortex: growth & development,Visual Perception,Visual Perception: physiology,handwriting,neural basis},
mendeley-tags = {handwriting,neural basis},
month = mar,
number = {2},
pages = {279--88},
pmid = {20136924},
title = {{Sensori-motor experience leads to changes in visual processing in the developing brain.}},
volume = {13},
year = {2010}
}
@article{James2012,
author = {James, KH and Engelhardt, Laura},
file = {:Users/Brenden/Documents/Mendeley/James, Engelhardt - 2012 - The effects of handwriting experience on functional brain development in pre-literate children.pdf:pdf},
journal = {Trends in Neuroscience and Education},
title = {{The effects of handwriting experience on functional brain development in pre-literate children}},
url = {http://www.sciencedirect.com/science/article/pii/S2211949312000038},
year = {2012}
}
@misc{Janak2012,
abstract = {Talk on Sept 20, MIT Colloq.},
annote = {Shows you can manipulate rat behavior by stimulating dopamine regions with optogentics.
        
This region corresponds to the error prediction signal for "model-free" reinforcement learning.
        
        
-----
Lab: interested in how cues are associated with rewards. 
+ people want to know where to seek out natural rewards
+ is this the hardest problem this is relevant to?
        
prediction error = actual reward - predicted reward
(rescola wagner rule? sutton & barto)
        
dopamine neurons correspond closely with this reward signal (Schultz)
        
If you give animals dopamine inhibitor, it inhibits learning
        
But people haven't shown a direct causal relationship.
        
using optogenetics, they can selectively target these dopamine neruons
        
Simple experiment: pair CS and US, reward with a random stimulus
+ dopamine neurons respond to CS stimulus, as expected
+ response is lost over the course of learning
        
Method: stimulate dopamine cells, which can cause artifical learning or prevent the decrement of learning
        
Block effect: A+, then AX+, no learning to X
control starts with B+ instead
        
Waelti (2001). Showed that dopamine neurons behave like the reward signal expected during the block paradigm
        
By stimulating dopamine during AX+ pair, can you make a strong response to X by itself? (mitigate the blocking effect)
        
Results: Big response to X on its own, due to stimulation
        
New experient: switch out sucrose for water... so there should be a decrease in response. What happens when you stimulate dopamine cells though?
        
Results: yes, you can get inhibition of excition, by zapping the cells at the time of expected reward
Control group received stimulation outside the critical interval
                  
part 2
                
model-free learning (habitual ) vs.
model-based learning (goal-directed)
        
Give rats a lever, have food come (but lever doesn't matter, its just the indicator)
- some rats track the lever
- some rats go straight to the location of the food
        
Only in lever traers, did you get the classic error-prediction dopamine pattern (Flagell, nature, 2011?)
        
(but this is kinda of a lame version of reinforcement learning)
        
With inhibition stimulation, you can prevent rats from giong to the lever. Instead, they are going to the reward location more often. Thus, they are goal tracking (can learn predictive relationship)
        
      },
author = {Janak, Patricia H},
title = {{Establishing causal roles for dopamine neurons in learning}},
year = {2012}
}
@article{Jenkins1990,
author = {Jenkins, W M and Merzenich, M M and Ochs, M T and Allard, T and Gu\'{\i}c-Robles, E},
journal = {Journal of Neurophysiology},
number = {1},
pages = {82--104},
title = {{Functional reorganization of primary somatosensory cortex in adult owl monkeys after behaviorally controlled tactile stimulation}},
volume = {63},
year = {1990}
}
@inproceedings{Jern2009,
annote = {--Category generation: sampling new examples from a category, or creating entirely new categories
        
--This is not a task that most models of categorization can do, (unless they are Bayesian)
        
 -------
        
Stimuli were circles with 4 slots. Slots were paired (across the circle), such that a pair of letters is sampled and then plugged into those slots. Different letters occur for each of the pairs.
        
Subjects saw 8 examples, and then they were asked to generate 3 more. Their responses fit a Bayesian model.
        
The model
1) Samples uniformly on the space of all partitions into slots (each letter could be independent, or all from the same group)
2) Each group is defined by a dirichlet (over all possible permutations of simples that can fill this slot)
3) Examples are sampled from a multi-nomial
        
In two experiments, people and the model tend to agree on what samples are likely.},
author = {Jern, Alan and Kemp, Charles},
booktitle = {Proceedings of the 31st Annual Conference of the Cognitive Science Society},
file = {:Users/Brenden/Documents/Mendeley/Jern, Kemp - 2009 - Category Generation.pdf:pdf},
keywords = {bayesian modeling,category generation,category learning,generative,models},
title = {{Category Generation}},
year = {2009}
}
@article{Jern2013,
abstract = {People are capable of imagining and generating new category exemplars and categories. This ability has not been addressed by previous models of categorization, most of which focus on classifying category exemplars rather than generating them. We develop a formal account of exemplar and category generation which proposes that category knowledge is represented by probability distributions over exemplars and categories, and that new exemplars and categories are generated by sampling from these distributions. This sampling account of generation is evaluated in two pairs of behavioral experiments. In the first pair of experiments, participants were asked to generate novel exemplars of a category. In the second pair of experiments, participants were asked to generate a novel category after observing exemplars from several related categories. The results suggest that generation is influenced by both structural and distributional properties of the observed categories, and we argue that our data are better explained by the sampling account than by several alternative approaches.},
annote = {classification is only one of many ways people use knowlege of categories:
        
- For example, category knowledge is used for feature inference (Yamauchi & Markman, 2000; Yamauchi & Yu, 2008), problem solv- ing (Ross, 1999), causal reasoning (Rehder, 2003; Rehder & Kim, 2006), and explanation (Lombrozo, 2009; Williams & Lombrozo, 2010).
        
        
computational basis for creativity?
        
4 experminets that look at how people generate new exemplars, and now categories from related cateogires
- generative model provides better account than other approaches
        
        
------
most models of categorization only deal with classification, not generation or other abilities
        
paper discusses generating new exemplars of a category, and generating new categories from related categories
        
generating new things is a common human activity: 
- chefs create new dishes by combining new ingredients
- designers create new everything
- children an produce new and imaginary examples
        
        
Since categories come in hierarchies, new instances can be generated at any level of the hierachy
        
theory: this involves sampling from a distribution, of exemplars or categories
        
sampling: neural plaausible and explains psychological effects
        
Other examples of generation
- Letter spirit, where you can generate other letters ina coherent font
- Deep belief nets 
- work in creative cognition
+ Ward asked participants to draw animals from another planet, so category knowledge constraints how people generate new things
        
This paper offers an explicit computational account
                  
sampling account of exemplar and category generation
          
        category knowlege is used for manyt higns, and a complete account would need to look at all th eways this knowledge is used
        
x - exemplar
y - label
        
You can perform classification with a generative model, or model conditional den. directly
        
exemplar generation ois an extreme form of feature inference, where you don't know any of the features
- feature inference often draws on richer knowledge than classification
        
generating a new sonnet is much richer than simply classifying something as one
        
Two steps:
1) learn category representation
2) predict new instance
        
You can do this with model averaging, or choosing a single good estimate of the parameters
        
category generation )
- you can generate a new salad category, and then sample an example from it
- people readily detect shared structure across categories, like the shape bias, and people can use this knowledge to generate new categories
                  
alternatives
          
        most discriminative models dont have a mechanism for this
        
- exemplar models
"copy and tewak" account, which is a basic approach proposed by many like Barsalou and Ward
- might be equivalent to bayesian model if cateogires are clusters in a similairty space, but otherwise it is not
        
decision bound models
- without additional assumptions, it makes no preidctions
        
rule-based models
- RULEX learns representations with "wildcard" features that are uninformative, and it could start by filling in those features
        
        Exp 1: exemplar generation
                
present people with observed cateogry exemplars, and ask them to generate a new exemplar
        
exemplars are generated by filling four feature positions with capital leatures
        
generative process: partiion features into ellipitical "slots", where slots tended to have different distribution of Letters which appear in them
- kind of like visual chunking
- after slots are chosen (forming category),  exemplars are chosen by replacing letters in those categories
        
alternatives
rule-based model: limited to a uniform distirbutin on observed letters within a slot (no gradedness)
independent feature- graded, but no notion of slots
        
procedure: participants saw stimuli on index cards, left in front of them, and told they were genmore of flu virus
+ which other exemplars are likely, that are different?
- afterwards, they ratedd other new genomes
- 3 conditions, with differen category structures
- participants were shown half of the 16 possible stimuli
        
results: model predicts that the 8 valid exemplars are the 8 most likely ones
- but also the model and people put a lot of probability mass on invalid exemplars?
        
when people drew their exemplars, 77% drew them in a way consistent with the model's sampling process
                  
Exp 2: probabilistic exemplar generation
                
From previous experiment, it's not clear whether people sampled from prob. dist. over parts, rather than just enumerated the other famiiliar pairs
        
Method: same category structures, except one part in each slot appeared 3 times, two parts apeartd twice, and one part appeared onces
        
results:
- models predicts the different relative fequncies now
        
again, most people with tablets created the responses in the expected order
        
also, both experiments, there was a large minority of participants who either failed to learn category stuructre or disregarded it
        
other models
structure sampling, or sampling randomly and then allowing all exemplars over a threshold, doesn't predict gradiations
- copy and tweak model: in this experiment, just changing a single letter can result in invalid responses
                  
Experiment 3: category generation
          
        LEarned two categories of crystals, and then asked to generate a novel third category
        
two dimensions are correlated within each category, where the sampling-based model predicts that people generate a new cateogory that preserves these correlations
- lenght and saturation are correlated (either positivel or negatively), and all categories had same correlation
        
categories are gaussian, where we have a hierarhcial bayesian model with hyper-parameters
        
after see two existing categories, they were asked to generate a new one with six exemplars
        
3 conditions:
- positive correlation
- negative correlation
- no correlation
                  
results        
1) model makes prediction about a fairly strong correlation, and people seem to follow that
        
2) with independent categories, the model predictions are basically flat
        
also makes predictions about the variance along the different dimensions
        
why didn't they try other model comparisions?          
          
Experiment 4: restricted category generation
                
participants could have duplicated an existing category, and then duplicated one of the examples to get around this problem
        
here, they were restricted to just one half of the length dimension (they had to use a new region of the stimulus space)
                  
results        
        
inferences were not quite as consistent, but still predicted by the hierarchical sampling model
                  
genreal discussion: a successfull mechanistic account must go beyond the assumption that exemplras are generated independently
- people looked for "representative" samples of the category, not just IID ones that might overlap
        
copy-and-tweak model cannot account for data in experiment 4
        
category knowlege is used for all sorts of things, like problem solivng, causal reasoning, and explanation
        
most existing approaches to categorization are discriminative
- generative models natrually handle feature inference
- "ideal categories" are better handled by discriminative models... since the "best diet food" do not fall near the mean, since it has zero claories
        
Ward tasks may be best handled by generative models, sine you need to condition on some features
        
computational basis of creativitiy?          
              },
author = {Jern, Alan and Kemp, Charles},
doi = {10.1016/j.cogpsych.2012.09.003},
file = {:Users/Brenden/Documents/Mendeley/Jern, Kemp - 2013 - A probabilistic account of exemplar and category generation.pdf:pdf},
issn = {1095-5623},
journal = {Cognitive psychology},
keywords = {Concept Formation,Humans,Models,Pattern Recognition,Probability,Psychological,Visual,exemplar generation},
mendeley-tags = {exemplar generation},
month = mar,
number = {1},
pages = {85--125},
pmid = {23108001},
title = {{A probabilistic account of exemplar and category generation.}},
volume = {66},
year = {2013}
}
@inproceedings{Jia2013,
author = {Jia, Yangqing and Abbott, Joshua and Austerweil, Joseph and Griffiths, Thomas and Darrell, Trevor},
booktitle = {Advances in Neural Information Processing Systems 26},
file = {:Users/Brenden/Documents/Mendeley/Jia et al. - 2013 - Visual Concept Learning Combining Machine Vision and Bayesian Generalization on Concept Hierarchies.pdf:pdf},
keywords = {one-shot learning},
mendeley-tags = {one-shot learning},
title = {{Visual Concept Learning: Combining Machine Vision and Bayesian Generalization on Concept Hierarchies}},
year = {2013}
}
@inproceedings{Johnson,
annote = {PCFGs: choose rewrite roles independently at random
        
adaptor grammars: weaken the independence assumptions made in PCFGs
        
re-write rules, using adaptors, can be extended like they have been extended in the past
                  
PCFGs
                
A CFG associates with each symbol a set of trees assocaited wtih all possible continuations, defined recurisvely, with the appropriate start symbol
        
Terminal symbols are just the singleton tree
        
a PCFG has a probability distribution associated with each re-write rule
        
Each sub-tree is generated independenlty from its distribution, which is the assumption that adaptor grammars relax
                  
Pitman-Yor process        
        
a = 0, reduces to DP
a = 1, reduces to just the base distribution
        
You can define an adapator grammar with general non-parametric models at each decision, not just DP or PYor
                  
Pitman-Yor adaptor grammars        
        
Each non-terminal node has a Pitman-Yor process instead of a standard discrete distribution for each of the re-write options
- thus, rich get richer
        
But doesn't this lead to most of the sharing occuring at the top level of the adapotr grammar?
        
Exampels
        
- simple DP over discrete distribution, (monkeys using type-weriter model)},
author = {Johnson, Mark and Griffiths, Thomas L and Goldwater, Sharon},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:Users/Brenden/Documents/Mendeley/Johnson, Griffiths, Goldwater - 2006 - Adaptor Grammars A Framework for Specifying Compositional Nonparametric Bayesian Models.pdf:pdf},
title = {{Adaptor Grammars: A Framework for Specifying Compositional Nonparametric Bayesian Models}},
year = {2006}
}
@book{Johnson2001,
address = {New York, NY},
annote = {This book is about how rich organization can emerge from simpler elements.
        
Overall: it's not-academic, and not particularly well written.
        
Examples: 
-- ant colonies (p.1)
-- organization of Manchester England (p. 35)
-- genetic algorithms (p. 58)
-- human body built of cells (p. 84)
-- WWW (p. 113)
-- news cycles (p. 136)
-- Slashdot moderation (p. 153)
-- Sim City / Video games (p. 180)
-- Selfridge's Pandemonium model},
author = {Johnson, Steven},
publisher = {Scribner},
title = {{Emergence}},
year = {2001}
}
@article{Johnson2013,
author = {Johnson, V. E.},
doi = {10.1073/pnas.1313476110},
file = {:Users/Brenden/Documents/Mendeley/Johnson - 2013 - Revised standards for statistical evidence.pdf:pdf},
isbn = {1313476110},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {statistics},
mendeley-tags = {statistics},
title = {{Revised standards for statistical evidence}},
volume = {2013},
year = {2013}
}
@article{Johson-Laird1980,
annote = {        SUMMARY        
        
How do we evaluate syllogisms? Or how do we think of what conclusions to draw, after viewing a set of premises? Logic does not tell us what to infer, only whether or not a statement is true
                  
theory:        
We construct a mental model of the objects in the domain, in a way consistent with the premises. This leads to conclusions, which we then try to think of counter-models for.
        
        
-----
Introduction
        
Does cognitive science exist?
- opinion: experimental psychology, and AI will not succeed on their own in understanding the mind
        
Should not just be people of different backgrounds happen to work on the same problems.
        
mental models, motivated by:
- the form of mental representation
- processes underlying ordinary reasoning
- meaning of words
        
A robot, with a model of a table, can know where it is -- even without sensors
        
Logic is not psychology
- from a simple syllogism, we are likely to draw some conclusions, but not other exactly valid ones
- logic is not a model of inference, and it's not just "peformance limitations"
                  
theories of syllogistic inference
                
atmosphere theory: the premises predipose certain conclusions by creating an atmosphere
- if premises are negative, conclusion likely negative
- if a premise contains a particular quanitifer (some), the conclusion will likely contain a particular. Otherwise, universal (all, none0
        
these principles capture the bias, but don't tell us the mental processes
        
some syllogisms people claim don't lead to any conclusions.
        
Laird goes over some failed examples of formal logical theories.
                  
a theory of syllogistic inference        
- shoudl account for biases, systematic mistakes
- should work for all quanitifiers
- developmental story
                  
manipulating mental models
          
** logical prinicples can say whether a conclusion is valid, but it doesnt tell you which conclusions to draw
        
procedure:
- start with a set of objets in the logical domain
- assign them to roles, based on first premise
- try to form as many identities as possible
- get a conclusion
- check for logical validity
(you can reformulate conclusion, and then check validity again, etc.)
                  
results        
figural effect: there is an asymmetry, based on the order of introducing the objects
- if the heuristic leads to a correct conclusion, it was right 80% of the time, as opposed to if it doesn't (46%)
        
- can accomdate all types of quantifiers
        
similar to the notion of models in logic, but in logic inference should apply to all possible models. Here, we might be talking about just one.
        
- there are no rules of inference. Just, model checking. But it can be compatible with logical inference.
+ but may fail, if they don't do enough destructive tests
++ might explain some of the origins of logic
        
        meaning and mental models        
        
if semantic meaning can be forumlated as logical postulates, we need infinitely many rules, in some cases
        
for spatial relatoins, it would take a huge number of logical rules to specify inferences you can make regarding right, left, transitivety etc.
        
Much simpler to create a spatial model, and place objects in a way that satisfy the premises
                  
images, propositions, and mental models        
        
debate regarding the status of mental imagery (Kosslyn vs. Phylysyn)
+ continuous vs. discrete
        
the mapping from propositional representation to mental model is not an invertible function. Thus, this is a distinct theory from propositional representations
                  
the characteristics of mental models
                
propositional representations are a description, which is true or false with respect to the world
+ or a mental model of the world
        
images have a property of arbitrariness -- you cannot form an image of a triangle in general
+ much them same with mental models
        
(check out Miller, Galanter, & Pribram, 1960)
                  
experimental evidence
                
it was easier to draw spatial relations, if the objects arrived in an order where it is easy to construct the mental model
        
if you have to create two mental models, and combine them, you will be less accurate (this is shown to be true experimentally)
                  
conclusion
                
explains the necessity of continuity of reference when reading passages. You need to be able to update your mental model on fhte fly
        
much of logical reasoning comes out of this -- because any model constructed will lead to the right conclusion
        
formal logic may have arisen by failing to carry out test procedures for inferences
        
it's important to make a distinction between the program you wrote, and the theory it is supposed to model
        
Need to integrate both experimental and computer programming -- reality and consistency},
author = {Johson-Laird, P N},
doi = {10.1207/s15516709cog0401_4},
file = {:Users/Brenden/Documents/Mendeley/Johson-Laird - 1980 - Mental Models in Cognitive Science.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
month = jan,
number = {1},
pages = {71--115},
title = {{Mental Models in Cognitive Science}},
volume = {4},
year = {1980}
}
@article{Jones2011,
annote = {There are advancements in frameworks, particularly mathematical frameworks, that relate to science

        
But we shouldn't confuse this with theoretical progress -- what is Bayesian modeling doing?

        
Fundamentalists: researchers who don't move beyond rational analysis, just want to say people are optimal

        
Enlightened Bayesian: integrates rational with process level, tests multiple models

        
Connectionism was more useful for its mechanistic commitments, and constraints, rather than what it can and can't learn

        
Claim: Bayesian models eschew mechanism, so they do little explanatory work},
author = {Jones, Matt and Love, Bradley C.},
doi = {10.1017/S0140525X10003134},
file = {:Users/Brenden/Documents/Mendeley/Jones, Love - 2011 - Bayesian Fundamentalism or Enlightenment On the explanatory status and theoretical contributions of Bayesian models.pdf:pdf},
issn = {0140-525X},
journal = {Behavioral and Brain Sciences},
keywords = {bayesian modeling,cognitive processing,levels of analysis,rational analysis,representation},
month = aug,
number = {04},
pages = {169--188},
title = {{Bayesian Fundamentalism or Enlightenment? On the explanatory status and theoretical contributions of Bayesian models of cognition}},
volume = {34},
year = {2011}
}
@article{Jones1991,
author = {Jones, SS and Smith, LB and Landau, B},
file = {:Users/Brenden/Documents/Mendeley/Jones, Smith, Landau - 1991 - Object properties and knowledge in early lexical learning.pdf:pdf},
journal = {Child development},
keywords = {shape bias},
mendeley-tags = {shape bias},
title = {{Object properties and knowledge in early lexical learning}},
year = {1991}
}
@article{Jones2002,
author = {Jones, Susan S. and Smith, Linda B.},
doi = {10.1111/1467-7687.00224},
file = {:Users/Brenden/Documents/Mendeley/Jones, Smith - 2002 - How children know the relevant properties for generalizing object names.pdf:pdf},
issn = {1363755X},
journal = {Developmental Science},
keywords = {shape bias,word learning},
mendeley-tags = {shape bias,word learning},
month = may,
number = {2},
pages = {219--232},
title = {{How children know the relevant properties for generalizing object names}},
volume = {5},
year = {2002}
}
@article{Julesz1986,
author = {Julesz, B},
file = {:Users/Brenden/Documents/Mendeley/Julesz - 1986 - Biological Cybernetics.pdf:pdf},
journal = {Biological Cybernetics},
keywords = {part-based models},
mendeley-tags = {part-based models},
pages = {245--251},
title = {{Biological Cybernetics}},
volume = {54},
year = {1986}
}
@article{Julesz1981,
annote = {Textons are the elementary units of texture perception
        
Textons:  basic elements of pre-attentive preception -- local features that yield texture discrimination
        
--
Are textures perceived locally or globally? How do we notice there are two different surfaces?
        
First order statistics: the probabiltiy of white vs. black for a texture
        
Second order statistics: the probability that endpoints of dipoles, at all orientations and lengths, will fall on a particular color (both on black, or white and black)
- dipoles are basically line segments        
        
N-th order: same thing with n-gons
(triangles, 4-gons, etc.)
        
People are not able to discriminate textures higher than 2nd order, when presented globally. Locally, after attention, they are easier to discriminate.
        
Textons: special, local features that enable texture discrimination at the pre-attentive level
        
Textons include:
closure, connectivity, granularity
color, elongated blobs and their terminators},
author = {Julesz, Bela},
file = {:Users/Brenden/Documents/Mendeley/Julesz - 1981 - Textons, the elements of texture perception, and their interactions.pdf:pdf},
journal = {Nature},
keywords = {part-based models},
mendeley-tags = {part-based models},
pages = {91--97},
title = {{Textons, the elements of texture perception, and their interactions}},
volume = {290},
year = {1981}
}
@article{Juni2012,
annote = {Study that shows people effectively integrate information from more than two cues. However, they do so sub-optimally
        
---
Where is the best place to drill? 7 cues drawn from Gaussian centered at this place, with different variances
        
Cues were ordered from most to least reliable, or the reverse
        
Differences from typical setup
- precision of cues must be learned over experience
- The noise isn't sensory, but it is experimental manipulation
- optimal integration
        
Comparison model:
- treat all cues equally
- use only the best cue
        
People did not converge on optimal weights
        
There was a linear trend in the weights, depending on the upward of downward condition. Thus, they were not assigning equal weight
        
Also, people's estimates were better than the single most precise cue
        
People integrate at least three cues, which is the first demonstration they know of of more than two cues
        
We can rule out arguments of primarcy of recency
                  
Discussion
                
cue integration can be "effective", without meeting the standard of "optimal" -- meaning it is better than just one cue
      },
author = {Juni, Mordechai Z and Gureckis, Todd M and Maloney, Laurence T},
doi = {10.1167/12.8.12.Introduction},
file = {:Users/Brenden/Documents/Mendeley/Juni, Gureckis, Maloney - 2012 - Effective integration of serially presented stochastic cues.pdf:pdf},
journal = {Journal of Vision},
keywords = {cue combination,cue integration,effective cue integration,learning cue precisions,sequential integration,stochastic cues,visual},
mendeley-tags = {cue combination},
number = {8},
pages = {1--16},
title = {{Effective integration of serially presented stochastic cues}},
volume = {12},
year = {2012}
}
@article{Juni2010,
abstract = {We developed a method analogous to classification images that allowed us to measure the influence that each dot in a dot cluster had on observers' estimates of the center of the cluster. In Experiment 1, we investigated whether observers employ a robust estimator when estimating the centers of dot clusters that were drawn from a single distribution. Most observers' fitted influences did not differ significantly from that predicted by a center-of-gravity (COG) estimator. Such an estimator is not robust. In Experiments 2 and 3, we considered an alternative approach to the problem of robust estimation, based on source separation, that makes use of the visual system's ability to segment visual data. The observers' task was to estimate the center of one distribution when viewing complex dot clusters that were drawn from a mixture of two distributions. We compared human performance to that of an ideal observer that separated the cluster into two sources through a maximum likelihood algorithm and based its estimates of location using the dots it assigned to just one of the two sources. The results suggest that robust methods employed by the visual system are closely tied to mechanisms of perceptual segmentation.},
annote = {Stimuli are a dot cluster. How does the visual system estimate the center?
        
Mean (Center of gravity,COG) estimates are not robust to outliers. If stimuli are drawn from a student T, then you should use a more robust estimator like the median. What do people do?
        
Experiment 1: 
        
Two alternative forced choice, is mean of cluster to left or right of reference lines.
        
Stimuli were drawn from either a Gaussian or a Student T. You would expect the COG to be non-robust on the T. However, most subjects were indistinguishable from the COG from either distribution.
        
Maybe the visual system can segment the signal from the noise?
        
Experiment 2:
Same types of stimuli, except the stimulus is produced by superimposing Gaussian and uniform noise.
        
Participants were shown how sitmuli were constructed. Then asked whether mean of Gaussian cluster was to the left or right of reference points.
 People are fit well by a MLE model that separates the noise and the signal.
        
However, they assume the number of dots assigned to either mixture component is fixed. They should be integrating over some uncertainty there.
        
Experiment 3: Same deal, except instead of uniform noise, there is a small additional cluster added. People seem to be a little worse in the case compared to the MLE.},
author = {Juni, Mordechai Z and Singh, Manish and Maloney, Laurence T},
doi = {10.1167/10.14.2},
file = {:Users/Brenden/Documents/Mendeley/Juni, Singh, Maloney - 2010 - Robust visual estimation as source separation.pdf:pdf},
issn = {1534-7362},
journal = {Journal of vision},
keywords = {Form Perception,Form Perception: physiology,Humans,Linear Models,Models,Neurological,Normal Distribution,Orientation,Orientation: physiology,Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,Psychometrics,Visual,Visual: physiology,perceptual grouping},
language = {en},
mendeley-tags = {perceptual grouping},
month = jan,
number = {14},
pages = {2},
pmid = {21131562},
publisher = {Association for Research in Vision and Ophthalmology},
title = {{Robust visual estimation as source separation.}},
volume = {10},
year = {2010}
}
@inproceedings{Kachergis2012,
annote = {How much of language learning can we explain with associative learning?
        
Skinner tried this, but maybe before his time.
        
Cross-situational learning can help (two objects and two words)
        
Many models of word learning have no order effects. But people show highlighting, with symmetrical training but not the same result.
        
highlighting},
author = {Kachergis, George},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Kachergis - 2012 - Learning nouns with domain-general associative learning mechanisms.pdf:pdf},
title = {{Learning nouns with domain-general associative learning mechanisms}},
year = {2012}
}
@article{Kahneman1979,
annote = {Curve: concave in positive direction, convex in negative direction. Slope is steeper in negative.
        
Reason why we wouldn't see a large risky negative gamble, is because we over-weight low probability evenets
        
Loss aversion: losing $100 hurts more than the negative value of gaining $100
        
        
        
----
Very classic work criticizing the classic economic agent model of decision making.
        
People evaluate the relative gains and losses, with steeper curve for losses
        
Classic examples by Allais, where the responses for two choices are inconsistent with expected utility theory
        
Risk aversion in the positive domain implies risk seeking in the negative domain.
        
Expected utility theory implies that people should want to pay for probabilistic insurance, where there is some chance that the insurance won't cover any of the damages.
                  
clearly inconsistent with utility theory:        
A two-stage game should be the same as a one-stage game with lower probabilities. But this is not the case. This violates the notion that the prospects are determiend solely by the probabilities of the final states.
                  
prospect theory
- people perceive gains and losses, rather than the final states of the wealth or welfare
+ compared to some reference point
- decompose sure components from risky components
- discard components that are shared by the offered prospects
        
V -- overall value (expected value)
\pi -- each probability is re-weighted by a non-linear transform
v(.)  -- reflects subjective value of that outcome, defined relative to a reference point
        
Then you compute the expected value, based on V
You have the same form as expected utility theory, but values are attached to changes rather than final states
                  
value function        
Value function generally takes an argument that varies based on current assests. But this is generally stable, so we can assume it just has one argument which is the change in state in most cases
        
Value function for positive changes in convtex, following the basic psychophysical principal (Weber's law)
                  
probability weighting function        
they do not following probability axioms, and they are not degrees of belief
        
not well-behaved near the endpoints
        
convex near the middle range (with less sensitivity than the endpoints)
        
Example of playing Russian roulette -- how much would you pay to remove one bullet? It depends how many bullets are in there... you would pay a lot more to remove 1 of 1 or 1 of 6, rather than 1 of 4, for instance
        
This shows that probability does not have a linear weight.},
author = {Kahneman, D and Tversky, Amos},
file = {:Users/Brenden/Documents/Mendeley/Kahneman, Tversky - 1979 - Prospect Theory An Analysis of Decision under Risk.pdf:pdf},
journal = {Econometrica},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {2},
pages = {263--292},
title = {{Prospect Theory: An Analysis of Decision under Risk}},
volume = {47},
year = {1979}
}
@article{Kalisman2005,
abstract = {The neocortex has a high capacity for plasticity. To understand the full scope of this capacity, it is essential to know how neurons choose particular partners to form synaptic connections. By using multineuron whole-cell recordings and confocal microscopy we found that axons of layer V neocortical pyramidal neurons do not preferentially project toward the dendrites of particular neighboring pyramidal neurons; instead, axons promiscuously touch all neighboring dendrites without any bias. Functional synaptic coupling of a small fraction of these neurons is, however, correlated with the existence of synaptic boutons at existing touch sites. These data provide the first direct experimental evidence for a tabula rasa-like structural matrix between neocortical pyramidal neurons and suggests that pre- and postsynaptic interactions shape the conversion between touches and synapses to form specific functional microcircuits. These data also indicate that the local neocortical microcircuit has the potential to be differently rewired without the need for remodeling axonal or dendritic arbors.},
annote = {There's a distinction between a potential synapse and actual synapse. A potential synapse is where the axon and dendrite of two cells are very close and could form a synapse if they wanted to. A potential synapse is necessary, but not sufficient, for an actual synapse. The interesting finding is that the potential synaptic matrix of excitatory cells in the same layer (and column) is a "tabula rasa" (Kalisman et al., 2005). Any two cells in this circuit have at least one, and likely many, potential synapses. To an extent this is also true between layers of the same column. Like the sparse model, any two units can functionally connect, a priori. But actual functional connectivity is highly sparse (estimated at 15% in Kalisman et al.).},
author = {Kalisman, Nir and Silberberg, Gilad and Markram, Henry},
doi = {10.1073/pnas.0407088102},
file = {:Users/Brenden/Documents/Mendeley/Kalisman, Silberberg, Markram - 2005 - The neocortical microcircuit as a tabula rasa.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Animals,Axons,Axons: ultrastructure,Confocal,Dendrites,Dendrites: ultrastructure,Electrophysiology,Imaging,Microscopy,Neocortex,Neocortex: cytology,Neocortex: physiology,Nerve Regeneration,Neurons,Neurons: physiology,Rats,Synapses,Three-Dimensional,Wistar,sparsity,sparsity in the brain},
mendeley-tags = {sparsity,sparsity in the brain},
month = jan,
number = {3},
pages = {880--5},
pmid = {15630093},
title = {{The neocortical microcircuit as a tabula rasa.}},
volume = {102},
year = {2005}
}
@article{Kalogerakis2012,
annote = {Generating new objects in a domain, after seeing about 100 training examples in a wide variety of styles
- it is hard to see if teh generalization is non-trivial, but the approach does seem flexible enough

        
However, it seems like it can successfully model part and style variability in a domain of complex real objects

        
video:
http://people.cs.umass.edu/$\sim$kalo/papers/ShapeSynthesis/ShapeSynthesis.mov

        
----
Generating compelling 3D content takes a long time, and designers would benefit from automatic tools to do so
- this paper focuses on the generative model, rather than the computer vision application

        
structure variability can be high in complex domains, where parts are differnet in office chairs vs. dining chairs

        

        
Previous work often doesn't capture latent causes
- check out "inverse procedural modeling", which is most often applied to individual concepts
- here, they learn latent variables to represent variability in object categories

        
          
probabilistic model
        

        
- model is trained on a set of compatibly segmented shapes
+ not all exemplars need to have the same parts
+ however, compatible components need to be identified as such (all stabilizers need to be labeled stabilizer)

        
random variables
-   root R: controls overall object shape
- for each component L, there is a latent variable that aims to represent the styles of that component (learned from data)
- each component can then generate continuous and discrete features
+ continuous features include curvature, shape, scale
+ discrete feature incode adjacency information

        
continuos feature include a 3D scale vector for the oriented bounding box, histogram of principal curves, "lightfied" features compressed with PCA
          

          
example
        
You can capture correlations amongst object parts, such that there are two types of tables: rectangular tables have four lergs, and ciruclar tables have one split leg
- can have lateral edge, such that features of a table top influence features of th leg (so you can't have a narrow leg on a wide table)

        
CPDs for disrete variables
- with one parent, just a table
- with more than one, use a sigmoid CPD

        
CPDs for continuous
- conditiona linear multivariate gaussain
- where random variables from parents can influence the mean, but not cov.

        
Structure learning: find G that has maximum posterior prob., where likelihood of the marginal likelihood
- greedy search, where you start with just a single mixture component, and increase it gradually 
+ then do the same for the domain size, and iterate
+ after number of components and domain size are dcided, we search over possible lateral edges
+ use EM algorithm to maximmize MAP score

        

        5 shape synthesis

        
        
Model can be used to synthesize new object exemplars
          

        
        
TWo stages
1) enumreate high-probability instances
2) optimize placement of copmonents

        
5.1 synthesizing a set of components
- sets of components can be found through forward sampling
+ though not suitable for evluating all instantiaons with non-trivial probability, so they enumerate the ordered set in some fancy way
+ continuous variables are just set to previous instantiations that were seen in the training set... the density is not modeled (like DP mem)

        
5.2 optmizing compoent placement
- components have slots, which store the category label of compoentns it can be attahed to
- these are learned from the training set, based on finding points of contact between parts
+ a chair seat has two lots for front legs and two slots for back elgs (also have symmetry inforation), which are a property of the seat
- coarse initial placement that puts it near the right slot
( which is actually modeled with a density)
- further refinement of attachments, that aligns all parts at thier poit of contact
+ did some further smoothing at points of connection

        
          
Applications

          
shape database amplificaiton 
        
given database of labeled objects, train model and synthesize all instantiatons of the model that have non-triila probability
+ optimize resulting objects
+ reject instances that are very simlar to shapes in the input datset (with just a threshold)

        
          
constrained shape synthesis
        
user may want to syntheisze objects with partiuclar components 
+ interactive interface for visually specifiny constraints

        
          
Evaluation
        
dataset of 3D models, which was segmented using technique from previous paper, and assited with manual labeling

        
          
generalizaiton. How well does the model generalize? We want plausible new instances.
+ evaluted by held-out likelihood of some examples (80/20 trainig test splits)
+ but hard to judge visiually?
- find that various components are important, and it out-performs a model without latent variables

        
experiment: particpnats were asked to choose which of two objects was more plausible, either from the shape database, from their model, or from a flat model
- particpants preferred their model, but this doesn't really demonstrate whether the examples were compelling and new

        
latent structure in shapes looks very inutivie, in terms of disecting chairs into multiple styles

        
          
Discussion

        
        
Needed help in creating labeled database, which is tedious

        
Only learns linear correlations between component features

        
Placement of components is heuristic, and does not optimize the intersection between components

        
Interesting to model correaltions between discrete structural variability with continuous variailibty},
author = {Kalogerakis, Evangelos and Chaudhuri, Siddhartha and Koller, Daphne and Koltun, Vladlen},
doi = {10.1145/2185520.2335406},
file = {:Users/Brenden/Documents/Mendeley/Kalogerakis et al. - 2012 - A probabilistic model for component-based shape synthesis.pdf:pdf},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {cal models,data-driven 3d modeling,machine learning,part-based models,probabilistic graphi-,probabilistic graphical models,shape structure,shape synthesis},
mendeley-tags = {part-based models},
month = jul,
number = {4},
title = {{A probabilistic model for component-based shape synthesis}},
volume = {31},
year = {2012}
}
@article{Kandel2011,
abstract = {This study examined the theoretical controversy on the impact of syllables and bigrams in handwriting production. French children and adults wrote words on a digitizer so that we could collect data on the local, online processing of handwriting production. The words differed in the position of the lowest frequency bigram. In one condition, it coincided with the word's syllable boundary. In the other condition, it was located before the syllable boundary. The results yielded higher movement durations at the position where the low-frequency bigram coincided with the syllable boundary compared to where the low-frequency bigram appeared before the syllable boundary. Syllable-oriented strategies failed with the presence of a very low-frequency bigram within the initial syllable. Further analysis showed that children in grades 3 and 4 privileged syllable-oriented programming strategies. The production times of children in grade 4 were also affected by syllable frequency and, to a lesser extent, bigram frequency. The adults writing durations were modulated by bigram frequency. Therefore, both bigrams and syllables regulate handwriting production although the influence of bigrams was stronger in adults than children. In the light of these results, we propose a psycholinguistic model of handwriting production. (PsycINFO Database Record (c) 2011 APA, all rights reserved).},
author = {Kandel, Sonia and Peereman, Ronald and Grosjacques, G\'{e}raldine and Fayol, Michel},
doi = {10.1037/a0023094},
file = {:Users/Brenden/Documents/Mendeley/Kandel et al. - 2011 - For a psycholinguistic model of handwriting production Testing the syllable-bigram controversy.pdf:pdf},
issn = {1939-1277},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {1952,adults,as,bigram frequency,cf,children,handwriting,if it was a,into chunks,jenkins,letter after the other,letters,letters of a word,mere linear sequence of,not just producing one,russel,syllable,the,to,we tend to group,writing a word is},
month = apr,
number = {4},
pages = {1310 --1322},
pmid = {21500939},
title = {{For a psycholinguistic model of handwriting production: Testing the syllable-bigram controversy.}},
volume = {37},
year = {2011}
}
@article{Kanwisher1997,
abstract = {Using functional magnetic resonance imaging (fMRI), we found an area in the fusiform gyrus in 12 of the 15 subjects tested that was significantly more active when the subjects viewed faces than when they viewed assorted common objects. This face activation was used to define a specific region of interest individually for each subject, within which several new tests of face specificity were run. In each of five subjects tested, the predefined candidate "face area" also responded significantly more strongly to passive viewing of (1) intact than scrambled two-tone faces, (2) full front-view face photos than front-view photos of houses, and (in a different set of five subjects) (3) three-quarter-view face photos (with hair concealed) than photos of human hands; it also responded more strongly during (4) a consecutive matching task performed on three-quarter-view faces versus hands. Our technique of running multiple tests applied to the same region defined functionally within individual subjects provides a solution to two common problems in functional imaging: (1) the requirement to correct for multiple statistical comparisons and (2) the inevitable ambiguity in the interpretation of any study in which only two or three conditions are compared. Our data allow us to reject alternative accounts of the function of the fusiform face area (area "FF") that appeal to visual attention, subordinate-level classification, or general processing of any animate or human forms, demonstrating that this region is selectively involved in the perception of faces.},
author = {Kanwisher, N and McDermott, J and Chun, Marvin M},
chapter = {4302},
doi = {10.1098/Rstb.2006.1934},
file = {:Users/Brenden/Documents/Mendeley/Kanwisher, McDermott, Chun - 1997 - The fusiform face area a module in human extrastriate cortex specialized for face perception.pdf:pdf},
institution = {Department of Psychology, Harvard University, Cambridge, Massachusetts 02138, USA.},
issn = {02706474},
journal = {Journal of Neuroscience},
keywords = {adult,classic psychology,discrimination learning,discrimination learning physiology,face,female,functional laterality,functional laterality physiology,humans,magnetic resonance imaging,male,pattern recognition,visual,visual cortex,visual cortex physiology,visual pathways,visual pathways physiology,visual perception,visual perception physiology,visual physiology},
mendeley-tags = {classic psychology},
number = {11},
pages = {4302--11},
pmid = {9151747},
publisher = {Soc Neuroscience},
title = {{The fusiform face area: a module in human extrastriate cortex specialized for face perception.}},
volume = {17},
year = {1997}
}
@article{Kanwisher2010,
abstract = {Is the human mind/brain composed of a set of highly specialized components, each carrying out a specific aspect of human cognition, or is it more of a general-purpose device, in which each component participates in a wide variety of cognitive processes? For nearly two centuries, proponents of specialized organs or modules of the mind and brain--from the phrenologists to Broca to Chomsky and Fodor--have jousted with the proponents of distributed cognitive and neural processing--from Flourens to Lashley to McClelland and Rumelhart. I argue here that research using functional MRI is beginning to answer this long-standing question with new clarity and precision by indicating that at least a few specific aspects of cognition are implemented in brain regions that are highly specialized for that process alone. Cortical regions have been identified that are specialized not only for basic sensory and motor processes but also for the high-level perceptual analysis of faces, places, bodies, visually presented words, and even for the very abstract cognitive function of thinking about another person's thoughts. I further consider the as-yet unanswered questions of how much of the mind and brain are made up of these functionally specialized components and how they arise developmentally.},
author = {Kanwisher, Nancy},
doi = {10.1073/pnas.1005062107},
file = {:Users/Brenden/Documents/Mendeley/Kanwisher - 2010 - Functional specificity in the human brain a window into the functional architecture of the mind.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Algorithms,Brain,Brain Mapping,Brain: anatomy & histology,Brain: physiology,Cognition,Cognition: physiology,Face,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Models,Nerve Net,Nerve Net: physiology,Neural Pathways,Neural Pathways: physiology,Neurological,Perception,classic psychology},
mendeley-tags = {classic psychology},
month = jun,
number = {25},
pages = {11163--70},
pmid = {20484679},
title = {{Functional specificity in the human brain: a window into the functional architecture of the mind.}},
volume = {107},
year = {2010}
}
@article{Katayama,
author = {Katayama, Susumu},
file = {:Users/Brenden/Documents/Mendeley/Katayama - Unknown - Systematic Search for Lambda Expressions.pdf:pdf},
number = {985},
pages = {111--126},
title = {{Systematic Search for Lambda Expressions}},
volume = {81}
}
@inproceedings{KatzGoodman2008,
author = {Katz, Y and Goodman, N D and Kersting, K and Kemp, C and Tenenbaum, J B},
booktitle = {Proceedings of the Thirtieth Annual Conference of the Cognitive Science Society},
title = {{Modeling Semantic Cognition as Logical Dimensionality Reduction}},
year = {2008}
}
@inproceedings{Kearns1999,
annote = {Planning when the state space is too large
        
Algorithm does not scale with the number of states, but rather with look-ahead time
        
Planning algorithm, which is a policy, but it takes non-trivial computation at each state
        
From a given state, you stochastically roll-out all possible paths that you can take, taking "C" samples from each state/action pair, for a given depth. The leaf nodes are considered obsorving states. This defines a "sub-MDP," which is a sub-set of the lager MDP
        
Cab speed it up by recognizing repeated states in the tree, and collapsing these sub-trees. This can be exact for determinstic MDPS (how??)
      },
author = {Kearns, Michael and Mansour, Yishay and Ng, Andrew Y},
booktitle = {IJ-CAI},
file = {:Users/Brenden/Documents/Mendeley/Kearns, Mansour, Ng - 1999 - A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov Decision Processes.pdf:pdf},
keywords = {planning},
mendeley-tags = {planning},
title = {{A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov Decision Processes}},
year = {1999}
}
@article{Kelso1998,
abstract = {That animals and humans can accomplish the same goal using different effectors and different goals using the same effectors attests to the remarkable flexibility of the central nervous system. This phenomenon has been termed 'motor equivalence', an example being the writing of a name with a pencil held between the toes or teeth. The idea of motor equivalence has reappeared because single-cell studies in monkeys have shown that parameters of voluntary movement (such as direction) may be specified in the brain, relegating muscle activation to spinal interneuronal systems. Using a novel experimental paradigms and a full-head SQUID (for superconducting quantum interference device) array to record magnetic fields corresponding to ongoing brain activity, we demonstrate: (1), a robust relationship between time-dependent activity in sensorimotor cortex and movement velocity, independent of explicit task requirements; and (2) neural activations that are specific to task demands alone. It appears, therefore, that signatures of motor equivalence in humans may be found in dynamic patterns of cortical activity.},
author = {Kelso, J a and Fuchs, A and Lancaster, R and Holroyd, T and Cheyne, D and Weinberg, H},
doi = {10.1038/33922},
file = {:Users/Brenden/Documents/Mendeley/Kelso et al. - 1998 - Dynamic cortical activity in the human brain reveals motor equivalence.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {Brain,Brain Mapping,Brain: physiology,Humans,Magnetics,Motor Cortex,Motor Cortex: physiology,Psychomotor Performance,Somatosensory Cortex,Somatosensory Cortex: physiology,handwriting,motor equivalence},
mendeley-tags = {handwriting,motor equivalence},
month = apr,
number = {6678},
pages = {814--8},
pmid = {9572140},
title = {{Dynamic cortical activity in the human brain reveals motor equivalence.}},
volume = {392},
year = {1998}
}
@article{KempPerfors2007,
annote = {Overhypotheses: inductive contraints that help learning
- M-constraint
-shape bias
-Spelke objects
        
Connectionist models might be able to learn overhypotehses, but they are difficult to analyze
                  
Example:        
If you get bags full of just white or black marbles, and you get a new bag with just one black marble, what do the rest look like?
        
Bags are modeled with a paremter of a benouli, which have a beta prior that is shared across of the bags 
bernouli has two parameters: 
alpha: concentration
beta: proportion of weights
                  
Example: skin color vs. obesity for ilsanders
                
Can learn to treat different features different, by fitting separate models for each feature          
          
Shape bias:        
training data based on Smith et al., where you get four classes of objects that only share the shape feature
        
This requires to model each dimension as a multinomial distribution, so you can have many novel shapes and colors. They choose 10 options for each.
        
The also make quantitative predictions about the generalization, which matches well with childern's inferences
        
In the marbles example, for a fixed number of marbles, the best way to teach the "consistnet bags" hypothesis is to have as many bags of two observations as possible
        
Learning can be faster at level two than leve 1, whihc is fdifferent than buttom-up approache to learning over-hypotheses. you can be uncertain about any given bag, but certain about the hyperparameters
        
I don't see how they go from: 
- simple binary data for marbles in bags
- a set of multinomials for objects, where tehre is a set for each type of featuer, and each feature has its own set of values
        
They must be treating features independently... I don't know how else they are doing this},
author = {Kemp, C and Perfors, A and Tenenbaum, J B},
file = {:Users/Brenden/Documents/Mendeley/Kemp, Perfors, Tenenbaum - 2007 - Learning overhypotheses with hierarchical {B}ayesian models.pdf:pdf},
journal = {Developmental Science},
number = {3},
pages = {307--321},
title = {{Learning overhypotheses with hierarchical {B}ayesian models}},
volume = {10},
year = {2007}
}
@article{Kemp2012,
annote = {        General
                
There are many types of concepts that can be learned. Concepts including a single object, multiple objects, relations between objects, features and relatoins, etc.
        
The main goal is to explore this space of possibilites, and develop a computational approach that can learn concepts from all of these different forms.
        
Kemp proposes using a variant first-order logic, with quanitifcation over objects. This is in general easier than quantification over features.
        
He shows experiments with learning boolean concepts across single/multiple object concepts. Relational concepts. Different types of features. Kinship concepts, etc.
        
-------
Goal is to have a single model that can learn conepts of many different forms (relational between multiple objects, single objects, additive features, substitutive features etc.)
        
Goals are to map out the universe of possibilities, collect data, and propose a unified modeling approach.
        
It is difficult to develop connectionist models that apply to all domains in this universe. 
        
hypothesis: concepts are represented in a compositional language, like predicate logic
        
How does this go beyond Feldman (2000)?
- relies on quanitifcation and relations
- qualitatively different domains
        
concept: function that picks out a subset of objects in a domain... comment: but does this allow for graded members
        
systems
Systems have objects, these objects have featuers and can participate in relations.
        
concepts (key: compositional structure)
pick out a subset of objects in this system.
compositional structure is the key motivation for the model being considered: you can have a category "elidgible for a free drink" that is defined based on features of which booth people visited.
        
You can have concepts like robbery, which cinclude relatoins between objects like the their, victim, the goods (or armed roberies, that pick out items in the robberies set)
        
additive features ("has a mustach") vs.
subsitutive features (red or yellow, has to be one or the toher)
        
extension: objects in the world that belong the concept
intension: the mental representation
        
concept types
        
Uses a SHJ-like analysis to identify qualitatively unique concept types. 
        
If you have 1 objects, 3 sub features, or 3 objects 1 additive features...you can construct two classes of stimuli based on that famous cube. But there are different numbers of qualitative types for each domain, depending on how you could describe it in first order logic.
        
        
the approach
1) objects, features, relatoins are basic elements
2) conceptual elements can be bound together into compound objets or systems
        
description length hypothesis:
minimum length in description language determines its ease of learning
        
Allows us to compare merits of various description languages: including propositional logic and varieties of predicate logic
        
Hypothesis: first-order logic with quantification over objects (although, this is at best a rough approximation),
Alternatives: quantification over features, or quantification over both
Thus, the hypothesis is that it is naturally easier to quantify over objects than features
        
specifics
- nested quantifiers are assumed to refer to different objects
- complexity: one place liters (features) have a weight of 1, relations have 2
- makes no processing claims
        
This is motivated by a bias, that infants have, for counting Spelke-objects over other things, like colors
        
other accounts        
similarity models: have difficulty accounting for concepts that require quantification
        
Any successes should be attributed to rule-based models more generally, not just this one (most can be extended to quantification)
        
experiments        
11 different domains
        
Feature-based domains related to SHJ
        
1 object, 3 SF (substitutive features)
3 objects, 3 SF
3 objets, 1 AF (additive feature)
1 objects, 3 AF
3 objects, 3 AF
        
Certain items in these types, which can be described by quantification over features or objects, can be used to test what type of quantification is better
        
Feature based domains related to SHJ
        
experiment design
- participants saw all the items on the screen, and in the "learning phase" they are provided with a braoder or not
- memory phase: new order, must sort items into the red group and blue group
- if they make an error, they return to the learning phase
-when they succeed, they proceed to the description phase, where they describe the concept       
        
Each participant was assigned to a single domain (30,3SF), for example
- each participant learned all 10 concepts
        
Tested (3O,3SF), (3O,1AF), (1O,3AF), (3O,3AF)
        
(3O,3SF) vs (1O,3AF) 
Is interesting contrast because the structure is identical, since only one feature applies to each of the three objects
        
(3O,1AF) vs. (3O,3AF)
With 1AF, you can quantify over objects, say like "they all have the feature"
But with the other domain, you can't, since each feature only applies to one object.
But if you add a feature like "has its characteristic pattern", then they are structurally identical
        
Series of predictions:
1) Two domains that quantify over objects (30,1AF) and (30,3AF) will be easier than domains that don't support that (much lower complexities)
2) Predicts that domains that support quantification over features (1O,3AF) will be harder
        
results 
not possible to directly compare speed of learning across domains, since they were not normalized for perceptual complexity
        
In the 3 object domains, type 10, which is equivalent to SHJ type 6, is not the hardest to learn\ldots as predicted by the logic model
        
written descriptions provide evidence that people were quantifying over objects.
        
Of the models, OQ model is broadly compatible with the main differences that emerge in learning time.
        
Misses that type 2 is easier than type 3 -- where the classic explanation is that type 3 needs to use all 3 features, but type 2 can ignore one (explained by selective attention)
+ but, a more complete model would use a shorter description for rules that have repeated symbols
        
Also, people seem to be sensitive to global propreties of considering all the items together, where people were not
        
IT is clear that these different domains are not isomorphic, as predicted by the logic account.
        
Also, people seem to represent number in a more elegant way than using logic -- so we need some cognitively natural representation of number
        
Boolean concepts
        
Uses Feldman's (2000) data, where they extended the SHJ (10,3SF) domains to (1O,4SF) and also varied the number of positive examples.
        
The mental model's approach has the best results so far on this dataset.
        
OQ model does not perform well, unless two other strategies are allowed:
- memorize the positive examples instead of writing rule
- learn the negative examples, if there are fewer of them
        
Ternary features
        
Data collected by Lee and Navarro
9 objects, and substitutive features with 3 values
        
Results:
        
Explains the data about as well as the algebraic complexity approach of Aitkin and Feldman, if not better
        
Relations
        
Simple domain with 3 objects, one relation
        
Type SHJ 6 problem is easier to learn than 3-5
        
A social network is "balanced" if people who like each other share the same opinions about the other people in the network
        
Crockett, who found type 6 was easier due to balance, took this as evidence for domain-specific reasoning
        
But, type 6 can be described as "networks with either 3 links or one link". Indeed, this is predict was born out in Experiment one with (30, 1AF). 
        
Relations and quantification
        
Compared relations, where you have people and food, and relations indicate whether the person likes the food
        
Compares 3o x 2o relations vs. 6o x 1o relations, where one would expect that features could capture the second but not the first.
        
Control conditions, where concepts in the 3o x 2o condition have no simple relational description or not. Here the binary values for the 3o x 2o relations are permuted.
        
Items in experiment were similar to figures, where a graph was shown.
        
results
        
again, the model was allowed to encode the complement of the set instead
        
The model fits beautifully by using relations, where there is a major difference between the 3 x 2 and the 6 x 1 conditions. The paired controls were much easier if they had a relational description in 3 x 2, but not so in the 6 x 1 condition.
        
This suggests that people relied on quantifiers over relational descriptions.
        
Kemp 2008. 
        
Learning the structure of graphs -- asked people to subjective rate complexity This, and learning time, correlate well with description length complexity.
        
kinship
        
Given a family tree, you could partition nodes with a binary concept. Which concepts are easy to learn? (mother, father, grandparents, etc. are concepts)
        
Kemp and Reiger showed that Kinship categories across languages have a nearoptima tradeoff between utility and description length
        
Discussion
        
OQ accounted best for the data, explaining why people found it easy to learn concepts that can be described with quantifiers.
        
All concept learning models take features/relations as primitives\ldots need some pre-processing. Why not view the 3 objects as a single object, perhaps submerged with 3 humps? clearly, people didn't think about it in this way.
        
Future directions
        
Continuous features?
        
Combining with likelihood (sampling process) to build a proper probabilistic model?
- can this account for when people inferred non-minimal rules? (Medin, 1987)
        
Process models
- Account for variation across participants? Sampling rules based on proability?
        
QUESTION: what about goodness judgements? Examples are not clear cut in/out of the concept
        
        
        
        
      },
author = {Kemp, Charles},
doi = {10.1037/a0029347},
file = {:Users/Brenden/Documents/Mendeley/Kemp - 2012 - Exploring the Conceptual Universe.pdf:pdf},
issn = {1939-1471},
journal = {Psychological Review},
keywords = {CogSci2013 Symposium,classic psychology,compositionality,concept learning,conceptual complexity,minimum description length},
mendeley-tags = {CogSci2013 Symposium,classic psychology},
title = {{Exploring the Conceptual Universe}},
year = {2012}
}
@phdthesis{Kemp2007,
author = {Kemp, Charles},
file = {:Users/Brenden/Documents/Mendeley/Kemp - 2007 - The acquisition of inductive constraints.pdf:pdf},
school = {MIT},
title = {{The acquisition of inductive constraints}},
type = {Ph.D. Thesis},
year = {2007}
}
@inproceedings{Kemp2005,
annote = {Similarity might be thought of as "arising from the same generative process." This is judging objects by their causal history, rather than just features.
        
Medin and Ortony: "surface features are frequently constrainted by... the deeper, more central parts of objects"
        
This doesn't yield all kinds of similarity judgments, but hopefully an important class of them.
        
Similarity is the log-likelihood ratio that:
-numerator: they belong to the same hypothesis
-denomenator: they belong to different hypotheses
        
This equation is difficult to calculate, so they replace it with the MAP values. 
NOTE: shows one approximation to integral
                  
feature model:
- rederives tversky's model from a generative approach, where features are benoulli and drawn from a beta distribution
- gives rational interpretation to Tversky
                  
results:
                
Force choiced experiment. Which of two strings is more similar to a prototype?          
                
Experiments with strings generated from HMMs. Then, given forced choice task between one with simple transformatinos, and one generated from the same HMM.
        
HMM model was fit using EM algorithm to calculate MAP parameter values.
      },
author = {Kemp, Charles and Bernstein, Aaron and Tenenbaum, Joshua B},
booktitle = {Proceedings of the 27th Annual Conference of the Cognitive Science Society},
file = {:Users/Brenden/Documents/Mendeley/Kemp, Bernstein, Tenenbaum - 2005 - A Generative Theory of Similarity.pdf:pdf},
keywords = {a,a fertilized egg into,an adult,an animal grows from,computational theory,every object is the,generative processes,outcome of a generative,process,similarity},
title = {{A Generative Theory of Similarity}},
year = {2005}
}
@article{Kemp2008b,
annote = {Datasets are given by binary relations R(a,b) which are observed for some entites. 
        
        
Theory: A set of laws, as expressed in modified first order logic
        
Model: Specifies the extension of each predicate, in a way that is consistent with the theory
        
Data: Some subset of these extensions, as specified by the model, are given as data. Thus there are multiple models consistent with the data.},
author = {Kemp, Charles and Goodman, Noah D and Tenenbaum, Joshua B},
file = {:Users/Brenden/Documents/Mendeley/Kemp, Goodman, Tenenbaum - 2008 - Theory Acquisition and the Language of Thought.pdf:pdf},
journal = {{Proceedings of the 30th Annual Cognitive Science Society (CogSci)}},
keywords = {conceptual change,logic},
mendeley-tags = {conceptual change,logic},
title = {{Theory Acquisition and the Language of Thought}},
year = {2008}
}
@inproceedings{Kemp2009a,
annote = {Learning of rich representations (Kemp says "schemas") from just a single example, but with a simple artificial task
        
---
        
Stimuli were cards with very simple objects, with two parts that varied in size, position, etc. Concepts were defined as relations between cards.
        
Experiment 1: Participants saw 3 cards in a set, and then saw two sets and was asked to say which is a better fit. Also, they were asked to generate another 3 card group.
        
The fit between the model and subjects is excellent.
        
Experiment 2: participants saw just one set, and were asked to generate another.},
author = {Kemp, Charles and Jern, Alan},
booktitle = {{Advances in Neural Information Processing Systems 22}},
file = {:Users/Brenden/Documents/Mendeley/Kemp, Jern - 2009 - Abstraction and relational learning.pdf:pdf},
keywords = {logic,one-shot learning},
mendeley-tags = {logic,one-shot learning},
title = {{Abstraction and relational learning}},
year = {2009}
}
@inproceedings{KempPerfors2004,
author = {Kemp, Charles and Perfors, Amy and Tenenbaum, Joshua B},
booktitle = {Proceedings of the Twenty-Sixth Annual Conference of the Cognitive Science Society},
title = {{Learning domain structures}},
year = {2004}
}
@article{Kemp2012a,
abstract = {Languages vary in their systems of kinship categories, but the scope of possible variation appears to be constrained. Previous accounts of kin classification have often emphasized constraints that are specific to the domain of kinship and are not derived from general principles. Here, we propose an account that is founded on two domain-general principles: Good systems of categories are simple, and they enable informative communication. We show computationally that kin classification systems in the world's languages achieve a near-optimal trade-off between these two competing principles. We also show that our account explains several specific constraints on kin classification proposed previously. Because the principles of simplicity and informativeness are also relevant to other semantic domains, the trade-off between them may provide a domain-general foundation for variation in category systems across languages.},
author = {Kemp, Charles and Regier, Terry},
doi = {10.1126/science.1218811},
file = {:Users/Brenden/Documents/Mendeley/Kemp, Regier - 2012 - Kinship Categories Across Languages Reflect General Communicative Principles.pdf:pdf},
issn = {1095-9203},
journal = {Science},
keywords = {Communication,Cross-Cultural Comparison,Family,Female,Humans,Language,Linguistics,Male,Semantics,Terminology as Topic,Vocabulary},
month = may,
number = {6084},
pages = {1049--54},
pmid = {22628658},
title = {{Kinship Categories Across Languages Reflect General Communicative Principles}},
volume = {336},
year = {2012}
}
@article{Kemp2009,
abstract = {Everyday inductive inferences are often guided by rich background knowledge. Formal models of induction should aim to incorporate this knowledge and should explain how different kinds of knowledge lead to the distinctive patterns of reasoning found in different inductive contexts. This article presents a Bayesian framework that attempts to meet both goals and describes corrected 4 applications of the framework: a taxonomic model, a spatial model, a threshold model, and a causal model. Each model makes probabilistic inferences about the extensions of novel properties, but the priors for the 4 models are defined over different kinds of structures that capture different relationships between the categories in a domain. The framework therefore shows how statistical inference can operate over structured background knowledge, and the authors argue that this interaction between structure and statistics is critical for explaining the power and flexibility of human reasoning.},
author = {Kemp, Charles and Tenenbaum, Joshua B},
file = {:Users/Brenden/Documents/Mendeley/Kemp, Tenenbaum - 2009 - Structured statistical models of inductive reasoning.pdf:pdf},
institution = {Department of Psychology, Carnegie Mellon University. ckemp@cmu.edu},
journal = {Psychological Review},
keywords = {property induction},
mendeley-tags = {property induction},
number = {1},
pages = {20--58},
pmid = {19159147},
publisher = {American Psychological Association},
title = {{Structured statistical models of inductive reasoning.}},
volume = {116},
year = {2009}
}
@article{Kemp2008,
abstract = {Algorithms for finding structure in data have become increasingly important both as tools for scientific data analysis and as models of human learning, yet they suffer from a critical limitation. Scientists discover qualitatively new forms of structure in observed data: For instance, Linnaeus recognized the hierarchical organization of biological species, and Mendeleev recognized the periodic structure of the chemical elements. Analogous insights play a pivotal role in cognitive development: Children discover that object category labels can be organized into hierarchies, friendship networks are organized into cliques, and comparative relations (e.g., "bigger than" or "better than") respect a transitive order. Standard algorithms, however, can only learn structures of a single form that must be specified in advance: For instance, algorithms for hierarchical clustering create tree structures, whereas algorithms for dimensionality-reduction create low-dimensional spaces. Here, we present a computational model that learns structures of many different forms and that discovers which form is best for a given dataset. The model makes probabilistic inferences over a space of graph grammars representing trees, linear orders, multidimensional spaces, rings, dominance hierarchies, cliques, and other forms and successfully discovers the underlying structure of a variety of physical, biological, and social domains. Our approach brings structure learning methods closer to human abilities and may lead to a deeper computational understanding of cognitive development.},
author = {Kemp, Charles and Tenenbaum, Joshua B},
doi = {10.1073/pnas.0802631105},
file = {:Users/Brenden/Documents/Mendeley/Kemp, Tenenbaum - 2008 - The discovery of structural form(2).pdf:pdf;:Users/Brenden/Documents/Mendeley/Kemp, Tenenbaum - 2008 - The discovery of structural form.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Algorithms,Data Interpretation,Humans,Learning,Learning: physiology,Models,Research Design,Statistical,Theoretical,conceptual change,graphical models},
mendeley-tags = {conceptual change,graphical models},
month = aug,
number = {31},
pages = {10687--92},
pmid = {18669663},
title = {{The discovery of structural form.}},
volume = {105},
year = {2008}
}
@inproceedings{Kemp2006,
annote = {Is it possible to learn a richer hierarchy than just a flat clustering of objects and features? This seems non-obvious, since there is no relationship between each draw specifying the relation strength
        
Has this been thought of as a model of learning essences, or why certain features are bundled together by a type of latent cause?
                  
----
Infinite relational model:
                
Will sort an object/feature matrix into block structure          
                
Arbitrary relations, taking objects of several possible types, are modeled by clustering objects in each type with a CRP
        
Tables in CRP determine how strongly the relation appear in that bloc
        
----
        
Objects (multiple types allowed), such as x, y,z
Relations  R(x,y) or R(x,x) or R(x,x,z) that can have arbitrary number of arguments
        
Objects are drawn from a CRP, over "classes", where the probability of a relation is determined soley by the class of each object
        
This probability is drawn from a beta distribution
                  
Example 1:        
Object vs. Features (two types of objects), where R(o,f) determines which object has which feature
        
Ends up co-clustering objects and features
                  
Example 2:        
Database of semantic knowledge
        
R: t1 x t1 x t2, for t1 is the set of conetps and t2 is the set of binary predicatres
        
concpets were like mammal, disease, etc.
        
The model uncvoers latent classes like organimsms, chemicals, biological functions, diseass etc.
- also classes of predicates
                  
Learning kinship systems
                
t1: set of 104 individuals
t2: complex set of kinships terms
        
R: t1 x t1 x t2},
author = {Kemp, Charles and Tenenbaum, Joshua B and Griffiths, Thomas L and Yamada, T and Ueda, N},
booktitle = {Proceedings of the 21st National Conference on Artificial Intelligence},
file = {:Users/Brenden/Documents/Mendeley/Kemp et al. - 2006 - Learning Systems of Concepts with an Infinite Relational Model.pdf:pdf},
keywords = {classic AI},
mendeley-tags = {classic AI},
title = {{Learning Systems of Concepts with an Infinite Relational Model}},
year = {2006}
}
@article{Kemp2010,
abstract = {Concept learning is challenging in part because the meanings of many concepts depend on their relationships to other concepts. Learning these concepts in isolation can be difficult, but we present a model that discovers entire systems of related concepts. These systems can be viewed as simple theories that specify the concepts that exist in a domain, and the laws or principles that relate these concepts. We apply our model to several real-world problems, including learning the structure of kinship systems and learning ontologies. We also compare its predictions to data collected in two behavioral experiments. Experiment 1 shows that our model helps to explain how simple theories are acquired and used for inductive inference. Experiment 2 suggests that our model provides a better account of theory discovery than a more traditional alternative that focuses on features rather than relations.},
annote = {Meaning of concepts depend part on their relations to other concepts
        
      },
author = {Kemp, Charles and Tenenbaum, Joshua B and Niyogi, Sourabh and Griffiths, Thomas L},
file = {:Users/Brenden/Documents/Mendeley/Kemp et al. - 2010 - A probabilistic model of theory formation.pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
keywords = {Algorithms,Bayes Theorem,Concept Formation,Humans,Learning,Learning: physiology,Mental Processes,Mental Processes: physiology,Models,Statistical},
month = feb,
number = {2},
pages = {165--96},
publisher = {Elsevier B.V.},
title = {{A probabilistic model of theory formation}},
volume = {114},
year = {2010}
}
@inproceedings{Kemp,
annote = {Sylabel modeling
        
For german, build in hard phonotactics contraints on syllables
        
- then you can augment this by learning the state - to-state transitions
        
They get about 18% correct using the augmented model
        
Also, can get about the same accuracy without as much a priori knowledge of the phonotactics},
author = {Kemp, T. and Jusek, A.},
booktitle = {International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings},
doi = {10.1109/ICASSP.1996.541150},
file = {:Users/Brenden/Documents/Mendeley/Kemp, Jusek - Unknown - Modelling unknown words in spotaneous speech.pdf:pdf},
isbn = {0-7803-3192-3},
pages = {530--533},
publisher = {Ieee},
title = {{Modelling unknown words in spotaneous speech}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=541150},
volume = {1}
}
@article{Kersten2004,
abstract = {We perceive the shapes and material properties of objects quickly and reliably despite the complexity and objective ambiguities of natural images. Typical images are highly complex because they consist of many objects embedded in background clutter. Moreover, the image features of an object are extremely variable and ambiguous owing to the effects of projection, occlusion, background clutter, and illumination. The very success of everyday vision implies neural mechanisms, yet to be understood, that discount irrelevant information and organize ambiguous or noisy local image features into objects and surfaces. Recent work in Bayesian theories of visual perception has shown how complexity may be managed and ambiguity resolved through the task-dependent, probabilistic integration of prior object knowledge with image features.},
author = {Kersten, Daniel and Mamassian, Pascal and Yuille, Alan},
doi = {10.1146/annurev.psych.55.090902.142005},
file = {:Users/Brenden/Documents/Mendeley/Kersten, Mamassian, Yuille - 2004 - Object perception as Bayesian inference.pdf:pdf},
issn = {0066-4308},
journal = {Annual review of psychology},
keywords = {Bayes Theorem,Decision Making,Humans,Learning,Psychological Theory,Psychophysics,Visual Perception,Visual Perception: physiology,feature prediction},
mendeley-tags = {feature prediction},
month = jan,
pages = {271--304},
pmid = {14744217},
title = {{Object perception as Bayesian inference.}},
volume = {55},
year = {2004}
}
@inproceedings{Khan2011,
author = {Khan, Faisal and Zhu, Xiaojin and Mutlu, Bilge},
booktitle = {Advances in Neural Information Processing Systems 25},
file = {:Users/Brenden/Documents/Mendeley/Khan, Zhu, Mutlu - 2011 - How Do Humans Teach On Curriculum Learning and Teaching Dimension.pdf:pdf},
keywords = {active learning,rational teaching},
mendeley-tags = {active learning,rational teaching},
pages = {1--9},
title = {{How Do Humans Teach: On Curriculum Learning and Teaching Dimension}},
year = {2011}
}
@article{Kidd2012,
annote = {Trend towards rational decision making in many domains
        
Here they show results in delay-of-gratification task
        
Why do children fail at the marshmellow task, after an average of 5 minutes?
- could be deficiency in self-control
        
Longer wait times correlate with greater self-confident, better interpersonal skills, SAT, substance abuse, many other positive life outcomes
        
Children with absent father prefer immediate, lesser rewards
                  
Experiment
                
Children observe either a reliable or an unreliable exerpimenter
        
While poor self-control in children is well-document, there is little work on the origin of failure
        
Choice 1
Art supply room, where child was given broken crayons. Told exeperimenter would return with better ones
+ child waited for 2.5 mins
+ either I'm sorry, I made a mistake, we don't have others
+ or reliable condition
        
Choice 2
Same thing, but with stickers
        
Marshamllow task:
- Stay here, and wiat for me to go get more marshmallos from the other room - you can have two instead
- or eat 1 right now
        
Wait for 15 minutes to elapse
        
        
        
      },
author = {Kidd, Celeste and Palmeri, Holly and Aslin, Richard N},
file = {:Users/Brenden/Documents/Mendeley/Kidd, Palmeri, Aslin - 2012 - Rational snacking Young children’s decision-making on the marshmallow task is moderated by beliefs ab(2).pdf:pdf},
journal = {Cognition},
title = {{Rational snacking: Young children’s decision-making on the marshmallow task is moderated by beliefs about environmental reliability}},
year = {2012}
}
@inproceedings{Kievit-Kylar2011,
author = {Kievit-Kylar, Brent and Jones, Michael N},
booktitle = {{Proceedings of the 33rd Annual Cognitive Science Conference}},
file = {:Users/Brenden/Documents/Mendeley/Kievit-Kylar, Jones - 2011 - The Semantic Pictionary Project Property Pictionary.pdf:pdf},
keywords = {one-shot learning,part-based models},
mendeley-tags = {one-shot learning,part-based models},
title = {{The Semantic Pictionary Project Property Pictionary}},
year = {2011}
}
@article{Kim2012,
author = {Kim, Su Yeong and Wang, Yijie and Orozco-Lapray, Diana and Shen, Yishan and Murtuza, Mohammed},
doi = {10.1037/a0030612},
file = {:Users/Brenden/Documents/Mendeley/Kim et al. - 2012 - Does “Tiger Parenting” Exist Parenting Profiles of Chinese Americans and Adolescent Developmental Outcomes.pdf:pdf},
issn = {1948-1993},
journal = {Asian American Journal of Psychology},
keywords = {adolescent adjustment,chinese,parenting profiles,tiger parenting},
number = {1},
pages = {7--18},
title = {{Does “Tiger Parenting” Exist? Parenting Profiles of Chinese Americans and Adolescent Developmental Outcomes.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0030612},
volume = {4},
year = {2012}
}
@article{Knoblich2001,
abstract = {Five experiments addressed the question of whether individuals can distinguish between self-generated and other-generated actions when seeing their visual effects. Each experiment consisted of a recording session in which participants drew familiar and unfamiliar characters without receiving visual feedback and a recognition session in which they provided self-or-other judgments (SOJs) to indicate whether a kinematic display reproduced the visual effects of their own actions. The main results were that self-generated and other-generated drawing can be distinguished, that the familiarity of character shapes does not influence the accuracy of SOJs, and that velocity information is crucial for the identification of self-generated drawing. The ability to determine authorship from kinematic displays of drawing provides evidence for the contribution of action-planning structures to perception.},
annote = {Is the perception of dynamic characters embodied? Test of "common coding" approach to perception and action. Actions are coded in terms of the perceivable effects they should generate.
        
--
Drawing was on WACOM tablet, which sampled in constant temporal frequency
        
Experiment 1:
Participants were instructed to draw novel characters in a paritcular manner. But pilot study ensured these characters had a consistent parse. In fact, many unfamiliar characters had a consistent parse.
        
Recording and recognition session occured 1 week apart. Tarjectoreis were scaled to a fixd size. Drawing procedure ensured that the character was copeid with fedility. 
        
On each trial (of 159), the peson saw two displays -- one was them, one was someonese else.
        
Subjects drew a bunch of characters, without visual feedback, and after being instructued how to draw the characters. When viewing the trajectories a week later, they had to say "self or other" 
        
Results:
They were .59 correct overall, and slightly higher for familiar comapred unfamiliar characters (n.s.).
        
No difference for multiple segments.
        
But due to the different base rates, perhaps they did some statistical learning on the fly.
        
Experiment 2: maybe it was perceptual learning? But people don't seem to be able to do supervised classification for which trajcetory belongs to which person.
        
Experiment 3: The trajectories were not time-noralized. If you normalize the time, you get about the same recognition performance.
        
Experiment 4: The temporal component of the kinematics is necessary condition for self-recognition. IT is not just the overall shape of the trajectory. To test this, they made all trajectories with a constant velocity. 
        
Experiment 5: Scaled each self-trajectory to a particular other trajectory.
        
After-analysis: people were more accurate at identifying character with loops or corners, over a straight line. There was no significant difference for old versus new characters.
                  
discussion:        
the kinematics at end-point trajecotires enables individuals to judge self vs. other'
        
this is enabled by the structures involved in action planning.Comment: But perhaps even these can be inferred from the static trace?
        
comment: should have run this for the static characters!!},
author = {Knoblich, G\"{u}nther and Prinz, Wolfgang},
file = {:Users/Brenden/Documents/Mendeley/Knoblich, Prinz - 2001 - Recognition of self-generated actions from kinematic displays of drawing.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
keywords = {embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
number = {2},
pages = {456--465},
title = {{Recognition of self-generated actions from kinematic displays of drawing}},
volume = {27},
year = {2001}
}
@article{Knoblich2002,
abstract = {Does the action system contribute to action perception? Recent evidence suggests that actions are simulated while being observed. Given that the planning and simulating system are the same only when one observes one's own actions, it might be easier to predict the future outcomes of actions when one has carried them out oneself earlier on. In order to test this hypothesis, three experiments were conducted in which participants observed parts of earlier self- and other-produced trajectories and judged whether another stroke would follow or not. When the trajectories were produced without constraints, participants accomplished this task only for self-produced trajectories. When the trajectories were produced under narrow constraints, the predictions were equally accurate for self- and for other-generated trajectories. These results support the action simulation assumption. The more the actions that one observes resemble the way one would carry them out oneself, the more accurate the simulation.},
author = {Knoblich, Gunther and Seigerschmidt, Eva and Flach, R\"{u}diger and Prinz, Wolfgang},
file = {:Users/Brenden/Documents/Mendeley/Knoblich et al. - 2002 - Authorship effects in the prediction of handwriting strokes evidence for action simulation during action perception.pdf:pdf},
institution = {Max Plank Institute for Psychological Research, Munich, Germany. knoblich@mpipf-muenchen.mpg.de},
journal = {Quarterly Journal of Experimental Psychology},
keywords = {embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
number = {3},
pages = {1027--1046},
pmid = {12188508},
title = {{Authorship effects in the prediction of handwriting strokes: evidence for action simulation during action perception.}},
volume = {55},
year = {2002}
}
@inproceedings{Kocsis,
author = {Kocsis, Levente and Szepesv, Csaba},
booktitle = {15th European Conference on Machine Learning},
file = {:Users/Brenden/Documents/Mendeley/Kocsis, Szepesv - 2006 - Bandit based Monte-Carlo Planning.pdf:pdf},
keywords = {inverse optimal control},
mendeley-tags = {inverse optimal control},
title = {{Bandit based Monte-Carlo Planning}},
year = {2006}
}
@article{Kohonen1982,
author = {Kohonen, T},
journal = {Biological Cybernetics},
pages = {59--69},
title = {{Self-organized formation of topologically correct feature maps}},
volume = {43},
year = {1982}
}
@book{Koller2009,
author = {Koller, D and Friedman, N},
publisher = {MIT Press},
title = {{Probabilistic Graphical Models}},
year = {2009}
}
@article{Koopman,
author = {Koopman, Pieter and Plasmeijer, Rinus},
file = {:Users/Brenden/Documents/Mendeley/Koopman, Plasmeijer - Unknown - Systematic Synthesis of Functions.pdf:pdf},
pages = {35--55},
title = {{Systematic Synthesis of Functions}}
}
@article{Kording2004,
abstract = {When we learn a new motor skill, such as playing an approaching tennis ball, both our sensors and the task possess variability. Our sensors provide imperfect information about the ball's velocity, so we can only estimate it. Combining information from multiple modalities can reduce the error in this estimate. On a longer time scale, not all velocities are a priori equally probable, and over the course of a match there will be a probability distribution of velocities. According to bayesian theory, an optimal estimate results from combining information about the distribution of velocities-the prior-with evidence from sensory feedback. As uncertainty increases, when playing in fog or at dusk, the system should increasingly rely on prior knowledge. To use a bayesian strategy, the brain would need to represent the prior distribution and the level of uncertainty in the sensory feedback. Here we control the statistical variations of a new sensorimotor task and manipulate the uncertainty of the sensory feedback. We show that subjects internally represent both the statistical distribution of the task and their sensory uncertainty, combining them in a manner consistent with a performance-optimizing bayesian process. The central nervous system therefore employs probabilistic models during sensorimotor learning.},
author = {K\"{o}rding, Konrad P and Wolpert, Daniel M},
doi = {10.1038/nature02169},
file = {:Users/Brenden/Documents/Mendeley/K\"{o}rding, Wolpert - 2004 - Bayesian integration in sensorimotor learning.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
keywords = {Bayes Theorem,Bayesian perception,Brain,Brain: physiology,Feedback,Female,Fingers,Fingers: physiology,Humans,Learning,Learning: physiology,Male,Motor Skills,Motor Skills: physiology,Movement,Normal Distribution,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology},
mendeley-tags = {Bayesian perception},
month = jan,
number = {6971},
pages = {244--7},
pmid = {14724638},
title = {{Bayesian integration in sensorimotor learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14724638},
volume = {427},
year = {2004}
}
@article{Kosslyn1978,
abstract = {Four experiments demonstrated that more time is required to scan further distances across visual images, even when the same amount of material falls between the initial focus point and the target. Not only did times systematically increase with distance but subjectively larger images required more time to scan than did subjectively smaller ones. Finally, when subjects were not asked to base all judgments on examination of their images, the distance between an initial focus point and a target did not affect reaction times.},
annote = {        Experiment 2: the famous one
                
- Map with locations on it (hut, lake, etc.)
- Participants looked at map, drew it from memory, and repeated until each location was drawn accurately in terms of position
- Then, they were asked to imagine a speck traveling between locations, and to press a button when they got there.
        
There was a linear relationship between distance and reaction time.},
author = {Kosslyn, S M and Ball, T M and Reiser, B J},
file = {:Users/Brenden/Documents/Mendeley/Kosslyn, Ball, Reiser - 1978 - Visual images preserve metric spatial information evidence from studies of image scanning.pdf:pdf},
issn = {0096-1523},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
keywords = {Distance Perception,Form Perception,Humans,Imagination,Reaction Time,Size Perception,Visual Perception,classic psychology},
mendeley-tags = {classic psychology},
month = feb,
number = {1},
pages = {47--60},
pmid = {627850},
title = {{Visual images preserve metric spatial information: evidence from studies of image scanning.}},
volume = {4},
year = {1978}
}
@inproceedings{Krishnapuram2004,
annote = {Shape recognition by a probabilistic template model.
        
Shapes can undergo an affine transformation, and then ink is generated as uniform samples from the contour of the shape.
        
Bayesian model comparison can detect the most efficient way to parse images.
        
      },
author = {Krishnapuram, Balaji and Bishop, Christopher M and Szummer, Martin},
booktitle = {Ninth International Workshop on Frontiers in Handwriting Recognition},
file = {:Users/Brenden/Documents/Mendeley/Krishnapuram, Bishop, Szummer - 2004 - Generative Models and Bayesian Model Comparison for Shape Recognition.pdf:pdf},
number = {1},
pages = {20 -- 25},
title = {{Generative Models and Bayesian Model Comparison for Shape Recognition}},
year = {2004}
}
@phdthesis{Krizhevsky2009,
author = {Krizhevsky, Alex},
school = {Unviersity of Toronto},
title = {{Learning multiple layers of features from tiny images}},
year = {2009}
}
@inproceedings{Krizhevsky2012,
annote = {ground-breaking paper that produced a huge gain on the challenging ImageNet task

        
General aspects of architecture:
- 5 convolutional layers
- non-saturating neurons
- efficient GPU implementation
- dropout

        
They use activation patterns on the last hidden layer to probe image similarity, using Euclidean distance, which is how we test one-shot learning (provides some support for this idea).

        
Main results on 1000 classses with 1000 images each, but 

        
------------
convolutional nets make strong, and mostly correct, assumptions about images, and they are easier to train because they have far fewer parameters (and theoretical performance should be just a little worse)
+ but convnets have been expensive to train on such a large dataset, until recently

        
removing any convolutional layer decreased performance, so this suggests they may not be over-fitting

        
5-6 days to train

        
          
imagenet

        
        
1000 images each of 1000 categories

        
since system requires a constant dimensional image,  , 256 x 256, it was cropped down so the shortest side was 256, and then cropped out the central patch

        
          
architecture

          
recitfied linear units (ReLU)
        
- f(x) = max(0,x) is the activation function, where 0

        
- much faster to train tahn saturating non-linearities (several times faster, like 7x in their demo)
- they may not make a different for overfitting, but on a large dataset, faster training can make a big difference

        
          
GPUS

        
        
- trained on two of them, since all the training examples don't fit on one
- can read and write from eachother's memory directly
- units are split on both GPUs
- type of "column" like architecture, where the next layer only takes input from the previous layer for units on that gpu

        
          
local response normalization

          
- ReLUs do not require input normalization to prevent them from saturating
- however, local normalization aids generalization
- lateral inhibition across the same image location in different kernel maps

        
          
overlappling pools
        
pooling units overalp, which slighlty reduces overfitting

        
          
overall architeture
        
- two column architecture
- the first five layers are convolutional, wwith 3 max-pooling layers, while there are two densely connected hidden layers (4096 neurons each)

        
          
Reducing overfitting

        
        
60 million paramters
          
data augmentation
        
- computationally free, since they are computed on CPU while GPU is training
1) extract random patches (of almost the same size, to produce translation) and horizontal reflections
- without this scheme, the network suffers from substantial over-fitting
2) change color intensity and illumination of image, using PCA (drops error rate by 1%)

        
          
dropout
- model combination can reduce test errors
efficient version of model combination, dropout, where you set the output of each hidden neuron to 0 with prob. 0.5
- at test time, you use all neurons and multiply outputs by 0.5, which is an approximation to the geometric mean produced by exponentially-many dropout netowkrs

        
          
details of learning
        
- btach size of 128
- momenutm of 0.9
- weight decay of 0.0005 (this was important). it is not merely a regularizer, it helps with training error
- weights were zero-mean Gaussian with sd 0.01
- biases init to 1 to some layers (accelerate early laearning)
- divide learning rate by 10 after the validation error stopped changing (started at 0.01), reduces 3 times
- roughly 90 cycles through the training set of 1.2 millioin images, which took 5-6 days

        
          
Results

        
        
ILSVRC-2010
(imagenet with 1000 cateogires)
17% error rate for top-5, and 37.5% for top-1
- reduced top-5 error rate by about 11%, which was a sparse-coding approach

        
ImageNet (2009)
- 10,000 categories, where top-5 erorr rate is about 40%

        
          
Qualitative evaluations

        
        
- kernels on one GPU were color agonistic, while kernels on the othe were color specific
+ this type of specialization always occured
- often very reasonable mistakes, when theya re made

        
You can probe a networks visual knowlege by looking at feature activations in the last hidden layer, before the softmax (like we are doing currently)

        
          
Discussion

        
        
Entirely supervised approach that achieves record-breaking results, and performance degrades if a single covolutional layer is removed

        
No unsupervised pre-training, but it might help, especially if the network is made larger without more labeled data

        
Many orders of magnitude to go before matching the IT pathway in the human visual system},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {{Advances in Neural Information Processing Systems 25}},
file = {:Users/Brenden/Documents/Mendeley/Krizhevsky, Sutskever, Hinton - 2012 - ImageNet Classification with Deep Convolutional Neural Networks.pdf:pdf},
keywords = {classic AI,deep learning},
mendeley-tags = {classic AI,deep learning},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
year = {2012}
}
@inproceedings{Kronrod2012,
author = {Kronrod, Yakov and Coppess, Emily and Feldman, Naomi H},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Kronrod, Coppess, Feldman - 2012 - A Unified Model of Categorical Effects in Consonant and Vowel Perception.pdf:pdf},
keywords = {bayesian modeling,categorical perception,computational linguistics,different categories being easier,of speech sounds,perceptual magnet effect,phonetic categories influence perception,to,with stimuli belonging to},
pages = {629--634},
title = {{A Unified Model of Categorical Effects in Consonant and Vowel Perception}},
year = {2012}
}
@inproceedings{Kuehne2000,
author = {Kuehne, Sven E and Forbus, Kenneth D and Gentner, Dedre and Quinn, Bryan},
booktitle = {Proceedings of the 22nd Annual Conference of the Cognitive Science Society},
file = {:Users/Brenden/Documents/Mendeley/Kuehne et al. - 2000 - SEQL Category learning as progressive abstraction using structure mapping.pdf:pdf},
keywords = {analogy,one-shot learning},
mendeley-tags = {analogy,one-shot learning},
title = {{SEQL : Category learning as progressive abstraction using structure mapping}},
year = {2000}
}
@article{Kuhl2006,
author = {Kuhl, P K and Stevens, E and Hayashi, A and Deguchi, T and Kiritani, S and Iverson, P},
journal = {Developmental Science},
number = {2},
pages = {F13--F21},
title = {{Infants show a facilitation effect for native language phonetic perception between 6 and 12 months}},
volume = {9},
year = {2006}
}
@article{Kuhn2011,
abstract = {While neural signatures of breaches of expectancy and their immediate effects have been investigated, thus far, temporally more remote effects have been neglected. The present fMRI study explored neural correlates of temporally remote destabilization of prediction following rare breaches of expectancy with a mean delay of 14 s. We hypothesized temporally remote destabilization to be reflected either in an attenuation of areas related to long-term memory or in an increase of lateral fronto-parietal loops related to the encoding of new stimuli. Monitoring a deterministic 24-digit sequence, subjects were asked to indicate occasional sequential omissions by key press. Temporally remote destabilization of prediction was expected to be revealed by contrasting sequential events whose equivalent was omitted in the preceding sequential run n-1 (destabilized events) with sequential events without such history (nondestabilized events). Temporally remote destabilization of prediction was reflected in an attenuation of activity in the dorsal frontomedian cortex (Brodmann Area (BA) 9) bilaterally. Moreover, activation of the left medial BA 9 was enhanced by contrasting nondestabilized events with breaches. The decrease of dorsal frontomedian activation in the case of destabilized events might be interpreted as a top-down modulation on perception causing a less expectation-restricted encoding of the current stimulus and hence enabling the adaptation of expectation and prediction in the long run. Hum Brain Mapp, 2011. © 2011 Wiley-Liss, Inc.},
annote = {Interested in surprisal, but with more interesting temporal dynamics than typically studied.
        
Subjects got a sequence like:
        
123 123 765 765 234 234 987 987
        
If the first 234 was missing, it was an undestabilized even. If the second 234 was missing, it was a destablized event. 
        
Subjects had to respond when they noticed a deviation fo the sequence, which they had memorized before the experiment.
        
Activity in BA9, BA10, BA8 favorted the nondestablized event},
author = {K\"{u}hn, Anne B and Schubotz, Ricarda I},
doi = {10.1002/hbm.21325},
file = {:Users/Brenden/Documents/Mendeley/K\"{u}hn, Schubotz - 2011 - Temporally remote destabilization of prediction after rare breaches of expectancy.pdf:pdf},
issn = {1097-0193},
journal = {Human brain mapping},
keywords = {MD system,adaptation of,dorsal frontomedian cortex,long-term memory,prediction,sequential event structure,top-down control},
mendeley-tags = {MD system},
month = jun,
pmid = {21674697},
title = {{Temporally remote destabilization of prediction after rare breaches of expectancy.}},
volume = {000},
year = {2011}
}
@book{Kuhn1962,
address = {Chicago, IL},
annote = {Main idea: science does not proceed by falsification in Popper's sense. Instead, there are revolutions, where one paradigm displaces another.
        
Paradigms, as used in Kuhn, are typically "universally" accepted. Feuding schools of thought are not really paradigms until one wins.
        
Scientists accept paradigms because they no longer need to study from first principles, after accepting the doctrine.
There is no grand goal of science -- we aren't getting closer to the "truth"
        
Examples of paradigm shifts:
        
Physical optics
S1 Light is particles (Newton)
S2 Light is waves
S3 Light is both
        
Conceptual change is a fundamental change in the concepts that compose a theory.
        
Examples of conceptual change:
-- Phlogiston theory of burning displaced by oxygen
-- Copernicus proposes that the earth revolves around the sun
-- Theory of relativity displaces Newton
-- Galileo's theory of motion displaces impetus theory/Aristotle (p. 123)
-- Dalton's modern chemistry collapsed a mixture/compound distinction that no longer exists. They defined a compound as combining that gives off heat,light, etc. while mixtures can be separeted. But there were intermediate cases (p. 130-134)
        
Anomaly and the emergence of scientific theories
                
Anomalies in a paradigm are regarded as failures of the scientist or are ignored, until they start to build up and form a crisis.
                  
Crisis and the emergence of scientific theories
                
There are often proposals for the next paradigm, but none of them stick unless the current paradigm is in crisis.
                  
The response to crisis
                
The first anomalous data usually has little impact, because there is no theory to take it's place. Rejecting the current theory would be rejecting science.
        
Often, the new theory is not present at first, but comes all at once to someone in the middle of the night.
                  
The Nature and Necessity of revolutions
                
Normal science is not possible without paradigms -- a way to pose a question and interpret results. When there is a time of conflict, people argue circularly from their paradigm. 
Note -- but this doesn't have to be circular. It could be hiearchical Bayes
        
        Revolutions as changes in world view        
The same exact experiments are viewed differently, depending on the paradigm. 
        
There is a great example of two chemists talking past eachother about whether compounds formed 1 to 1 proportions, because they have the wrong compound/mixture distinction (p. 132)
        
        The invisibility of revolutions        
Textbooks try to create a narrative of past heroes contributing to future discoveries in a linear way. Textbooks are rewritten after paradigm shifts.
        
May be easier for exposition, but gives false impression of science.          
          
The resolution of revolutions        
Many new paradigms fail to convert their contemporaries. The new theory is usually rough, and can't explain aspects of the old theory. "Sometimes you have to wait until the old scientists die off"
        
It's hard to do Bayesian model comparison for theory testing. How do you integrate over all possible theories?
                  
Progress through revolutions        
What is a science? Some people define it by progress, but progress only happens within a paradigm. And during the Reinessance, painting was the progressive domain
        
Grad students get narrow view in current paradigm, and are poorly equipped for new ones. Most creative individuals can be outsiders.
        
There is no grand goal of science -- we aren't getting closer to the "truth". This is like Darwin's theory of natural selection, there is no aim, and this was the hardest part to accept.
        
Even if this is the best characterization of science and it seems depressing, it seems to be working.      },
author = {Kuhn, Thomas S},
edition = {3rd},
keywords = {conceptual change},
mendeley-tags = {conceptual change},
publisher = {University of Chicago Press},
title = {{The Structure of Scientific Revolutions}},
year = {1962}
}
@inproceedings{Kulesza2010,
author = {Kulesza, A and Taskar, B},
booktitle = {{Neural Information Processing Systems (NIPS)}},
file = {:Users/Brenden/Documents/Mendeley/Kulesza, Taskar - 2010 - Structured Determinantal Point Processes.pdf:pdf},
keywords = {determinantal point process},
mendeley-tags = {determinantal point process},
title = {{Structured Determinantal Point Processes}},
year = {2010}
}
@inproceedings{Kulesza2011,
author = {Kulesza, Alex and Taskar, Ben},
booktitle = {{International Conference on Machine Learning (ICML)}},
file = {:Users/Brenden/Documents/Mendeley/Kulesza, Taskar - 2011 - k-DPPs Fixed-Size Determinantal Point Processes.pdf:pdf},
keywords = {determinantal point process},
mendeley-tags = {determinantal point process},
title = {{k-DPPs : Fixed-Size Determinantal Point Processes}},
year = {2011}
}
@article{Kundu1989,
annote = {HMM model of recognizing handwritten words
        
1. Characters are thinned
2. Characters are converted into features, where you detect end points, circles, t-junctions, etc.
3. K-means to cluster them into a set of M symbols
4. Then you can train an HMM on top of this
        
The features in here might be useful, for reconstructing how people draw these characters. },
author = {Kundu, Amlan and He, Yang and Bahl, Paramvir},
doi = {10.1016/0031-3203(89)90076-9},
file = {:Users/Brenden/Documents/Mendeley/Kundu, He, Bahl - 1989 - Recognition of handwritten word First and second order Hidden Markov model based approach.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
month = jan,
number = {3},
pages = {283--297},
title = {{Recognition of handwritten word: First and second order Hidden Markov model based approach}},
volume = {22},
year = {1989}
}
@article{Kwok1988,
author = {Kwok, Paul},
doi = {10.1145/50087.50092},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {thinning algorithm},
mendeley-tags = {thinning algorithm},
number = {11},
pages = {1314--1324},
title = {{A thinning algorithm by contour generation}},
url = {http://portal.acm.org/citation.cfm?doid=50087.50092},
volume = {31},
year = {1988}
}
@article{Lackner1972,
annote = {How do people solve the cocktail problem?
        
Is there an early or a late filter, for a theory of attention?
        
Attend in one ear:
L: The sailors enjoyed the port.
        
R: They poured out the wine. 
OR 
They entered the harbor.
        
They are immediately asked to paraphrase the attended ear's message. The other channel influences the interpretation, even if nothing about it can be reported.
        
These are big effects (like p=.5 in the neutral contex, and then p=.7 in the biased)},
author = {Lackner, J R and Garrett, M F},
file = {:Users/Brenden/Documents/Mendeley/Lackner, Garrett - 1972 - Resolving ambiguity Effects of biasing context in the unattended ear.pdf:pdf},
journal = {Cognition},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {4},
pages = {359--372},
title = {{Resolving ambiguity: Effects of biasing context in the unattended ear}},
volume = {1},
year = {1972}
}
@inproceedings{Lafferty2001,
author = {Lafferty, John and McCallum, Andrew and Pereira, Fernando C N},
booktitle = {International Conference on Machine Learning (ICML)},
file = {:Users/Brenden/Documents/Mendeley/Lafferty, McCallum, Pereira - 2001 - Conditional Random Fields Probabilistic Models for Segmenting and Labeling Sequence Data.pdf:pdf},
keywords = {classic AI},
mendeley-tags = {classic AI},
number = {Icml},
pages = {282--289},
title = {{Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data}},
volume = {2001},
year = {2001}
}
@inproceedings{Lahiri2013,
annote = {Trying to model synapses at a small set of discrete states, and understanding this stochastic system and its memory capacity
        
---------
What is a synapse from neuron j to i?
        
Theorist: W_ij
Experimentalist: hugely complicated
        
Real synapses only have a finite number of possible strengths, so you can't store nearly as much info. as a continuous values
        
M x M matrix of prob. transitions between synaptic states, where you have a different transition matrix when being enhanced vs. depressed
        
for a memory to be stored, you need some of the states to change
        
You can read out the upper bound on the number of memories
        
Some states take longer to get to get to potentiated states, in terms of all possible transitions over some fixed number of time steps
        
the area under the memory curve of a and system is boudned by that of a chain with the same equillibrium distribution
        
- the optimal system is actually a chain
        
Understanding complex synapses could have many implications:
- help us understand neurobiology
- synaptic complexity may help with the next stage of neural nets
+ can help temporal assignment problem
+ deepness can happen at a small scale within a synapse},
author = {Lahiri, Subhaneil and Ganguli, Surya},
booktitle = {Advances in Neural Information Processing Systems 26},
file = {:Users/Brenden/Documents/Mendeley/Lahiri, Ganguli - 2013 - A memory frontier for complex synapses.pdf:pdf},
title = {{A memory frontier for complex synapses}},
year = {2013}
}
@inproceedings{Lake2005,
author = {Lake, Brenden M and Cottrell, Gary W},
booktitle = {{Proceedings of the 27th Annual Conference of the Cognitive Science Society}},
file = {:Users/Brenden/Documents/Mendeley/Lake, Cottrell - 2005 - Age of Acquisition in Facial Identification A Connectionist Approach.pdf:pdf},
title = {{Age of Acquisition in Facial Identification: A Connectionist Approach}},
year = {2005}
}
@inproceedings{Lake2011a,
author = {Lake, Brenden M and McClelland, James L},
booktitle = {{Proceedings of the 33rd Annual Conference of the Cognitive Science Society}},
file = {:Users/Brenden/Documents/Mendeley/Lake, McClelland - 2011 - Estimating the strength of unlabeled information during semi-supervised learning.pdf:pdf},
keywords = {semi-supervised learning},
title = {{Estimating the strength of unlabeled information during semi-supervised learning}},
year = {2011}
}
@inproceedings{Lake2011,
author = {Lake, Brenden M and Salakhutdinov, Ruslan and Gross, Jason and Tenenbaum, Joshua B},
booktitle = {{Proceedings of the 33rd Annual Conference of the Cognitive Science Society}},
file = {:Users/Brenden/Documents/Mendeley/Lake et al. - 2011 - One shot learning of simple visual concepts.pdf:pdf},
title = {{One shot learning of simple visual concepts}},
year = {2011}
}
@inproceedings{Lake2013,
author = {Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},
booktitle = {Advances in Neural Information Processing Systems 26},
file = {:Users/Brenden/Documents/Mendeley/Lake, Salakhutdinov, Tenenbaum - 2013 - One-shot learning by inverting a compositional causal process(2).pdf:pdf;:Users/Brenden/Documents/Mendeley//Lake, Salakhutdinov, Tenenbaum - 2013 - One-shot learning by inverting a compositional causal process.pdf:pdf},
title = {{One-shot learning by inverting a compositional causal process}},
year = {2013}
}
@inproceedings{Lake2012,
author = {Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},
booktitle = {{Proceedings of the 34th Annual Conference of the Cognitive Science Society}},
file = {:Users/Brenden/Documents/Mendeley/Lake, Salakhutdinov, Tenenbaum - 2012 - Concept learning as motor program induction A large-scale empirical study.pdf:pdf},
keywords = {concept learning,department of statistics,one-shot learning,program induction,representations,ruslan salakhutdinov,structured},
title = {{Concept learning as motor program induction: A large-scale empirical study}},
year = {2012}
}
@article{Lake2010,
author = {Lake, Brenden M and Tenenbaum, Joshua B},
file = {:Users/Brenden/Documents/Mendeley/Lake, Tenenbaum - 2010 - Discovering Structure by Learning Sparse Graphs.pdf:pdf},
journal = {{Proceedings of the 32nd Annual Conference of the Cognitive Science Society}},
keywords = {inductive reasoning,property induction,semantic cognition,sparse representation,sparsity,structure discovery,unsuper-,vised learning},
mendeley-tags = {property induction,sparsity},
title = {{Discovering Structure by Learning Sparse Graphs}},
year = {2010}
}
@article{Lake2009,
author = {Lake, Brenden M and Vallabha, Gautam K and McClelland, James L},
file = {:Users/Brenden/Documents/Mendeley/Lake, Vallabha, McClelland - 2009 - Modeling unsupervised perceptual category learning.pdf:pdf},
journal = {IEEE Transactions on Autonomous Mental Development},
number = {1},
pages = {35--43},
title = {{Modeling unsupervised perceptual category learning}},
volume = {1},
year = {2009}
}
@article{Lam1992,
author = {Lam, L and Lee, S-W and Suen, Ching Y},
file = {:Users/Brenden/Documents/Mendeley/Lam, Lee, Suen - 1992 - Thinning Methodologies - A Comprehensive Survey.pdf:pdf},
journal = {{IEEE Transactions of Pattern Analysis and Machine Intelligence}},
keywords = {handwriting,thinning algorithm},
mendeley-tags = {handwriting,thinning algorithm},
number = {9},
pages = {869--885},
title = {{Thinning Methodologies - A Comprehensive Survey}},
volume = {14},
year = {1992}
}
@article{Landau1992,
author = {Landau, B and Smith, LB and Jones, Susan},
file = {:Users/Brenden/Documents/Mendeley/Landau, Smith, Jones - 1992 - Syntactic Context and the Shape Bias in Children’s and Adults’ Lexical Learning.pdf:pdf},
journal = {Journal of Memory and Language},
keywords = {shape bias},
mendeley-tags = {shape bias},
title = {{Syntactic Context and the Shape Bias in Children’s and Adults’ Lexical Learning}},
year = {1992}
}
@article{Landau1988,
annote = {Early shape bias study, showing that the bias first shows up between 2-3 years old, and is very strong in adults
        
----
Gavagi problem: so many reasonable definitions for the word. Even if you get the object right, you still have the level of categorization
        
While non-perceptual factors are important for representation of concepts, it does not imply that perceptual similarities are not also important
        
Features: shape, size, texture
                  
Experiment 1:        
Taught subjects novel CVC name for nonsense objects, and see how they generalize
        
Two different objects, and 2 size, 2 texture, and 2 shape changes
        
yes/no task (but prone to response bias)
also forced choice
                  
results:        
For yes/no, difference in shape caused most adjust to reject, while there was a gradient for children where shape was most important 
        
Given two-option forced chioce. Where all age groups preferred to choose the other changes instead of shape, and again stronger with time
        
Some children chose size changes relatively to control (replication) object
                  
Experiment 2
                
Added a third, more dramatic change along each of the dimensions
        
Used the 2nd and 3rd most daramtic changes
                  
Results
                
yes/no results: little evidence for shape bias in youngest children (2 year olds)
        
For forced choice, shape changes were still chosen 40 percent of the time for 2 year olds, 20 percent for 3 year olds, and 0 percent for adults
        
2 year olds showed no prefernce, although they did in Experiment 1. Children may break down tih large changes
                  
Experiment 3
                
In word, "This is a Dax", showed children the standard,
        
In non-word, asked which of the two other objects went with the standard
        
Also, pitted Shape 2 and Shape 3 items again the maximal size and texture changes
        
        results
                
The word vs. non-word conditio mattered for children, and adults were at ceiling in all of the tests
        
2-year-olds showed a strong shpae bias, paralleling Experiment 1. They have no explanation for variable performance in Experiment 2
        
"naming" an objet directed the children towards categoirzing by shape
                  
Discussion
                
Shape bias is important only if early words follow this structure
+ clear that basic level categories often have the same shaep
        
Their data suggests that the bias is not given but must be discovered, because it first apperas between 2 and 3 year sof age
        
It is the timing of this onset amid the growth of shape and general word learning},
author = {Landau, Barbara and Smith, Linda B. and Jones, Susan S.},
doi = {10.1016/0885-2014(88)90014-7},
file = {:Users/Brenden/Documents/Mendeley/Landau, Smith, Jones - 1988 - The importance of shape in early lexical learning.pdf:pdf},
issn = {08852014},
journal = {Cognitive Development},
keywords = {classic psychology,shape bias,word learning},
mendeley-tags = {classic psychology,shape bias,word learning},
month = jul,
number = {3},
pages = {299--321},
title = {{The importance of shape in early lexical learning}},
volume = {3},
year = {1988}
}
@article{Landauer1997,
annote = {Many researchers have posited constraints on word learning (Markman, Carey). Do we need such strong constraints?
        
Perhaps a large set of weaker constraints, when combined, and provide the necessary bias. Like a triangular structure with three breams.
        
Good way to test is to use an explicit computational model, and expose it to realistic data.
---
        
Latent semantic analysis
- try to locate words in a semantic space
- co-occurence indicates semantic similarity
        
Data:
rows are words, columns are contexts in which tye can  appaer
The data is tansformed, where frequency is replaced by log-frequency. Since this begins anew with each context, you get a diversity of contexts. Also, divide by the entropy across contexts. },
author = {Landauer, Thomas K and Dutnais, Susan T},
file = {:Users/Brenden/Documents/Mendeley/Landauer, Dutnais - 1997 - A Solution to Plato's Problem The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.pdf:pdf},
journal = {Psychological Review},
keywords = {classic psychology,semantic network},
mendeley-tags = {classic psychology,semantic network},
number = {2},
pages = {211--240},
title = {{A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge}},
volume = {104},
year = {1997}
}
@article{Larsson2011,
abstract = {Measurements of repetition suppression with functional magnetic resonance imaging (fMRI adaptation) have been used widely to probe neuronal population response properties in human cerebral cortex. fMRI adaptation techniques assume that fMRI repetition suppression reflects neuronal adaptation, an assumption that has been challenged on the basis of evidence that repetition-related response changes may reflect unrelated factors, such as attention and stimulus expectation. Specifically, Summerfield et al. (Summerfield C, Trittschuh EH, Monti JM, Mesulam MM, Egner T. 2008. Neural repetition suppression reflects fulfilled perceptual expectations. Nat Neurosci. 11:1004-1006) reported that the relative frequency of stimulus repetitions and non-repetitions influenced the magnitude of repetition suppression in the fusiform face area, suggesting that stimulus expectation accounted for most of the effect of repetition. We confirm that stimulus expectation can significantly influence fMRI repetition suppression throughout visual cortex and show that it occurs with long as well as short adaptation durations. However, the effect was attention dependent: When attention was diverted away from the stimuli, the effects of stimulus expectation completely disappeared. Nonetheless, robust and significant repetition suppression was still evident. These results suggest that fMRI repetition suppression reflects a combination of neuronal adaptation and attention-dependent expectation effects that can be experimentally dissociated. This implies that with an appropriate experimental design, fMRI adaptation can provide valid measures of neuronal adaptation and hence response specificity.},
annote = {Relevance to surprisal project:
        
All the visual areas tested have a strong expectation effect, detecting repeated patterns of stimuli.
        
This is both short term (what was right before?) and long term (what has tended to be?)
        
Therefore, if we find this effect in the MD system, is it really a unique feature?
        
---
        
fMRI adaption: there is a reduction in bold when a stimulus feature is repeated. This indicates processing in an area
        
Summerfield: This adaption effect might just be due to stimulus expectation (patterns) and not general processing.
        
This study: When attention is diverted from the repeated stimulus, there was no perceptual expectation, but the fMRI adaption remains. Thus it's a valid method. But it can be easily, and often is, confounded with stimulus expectation which says little about underlying neural structure},
author = {Larsson, Jonas and Smith, Andrew T},
doi = {10.1093/cercor/bhr119},
file = {:Users/Brenden/Documents/Mendeley/Larsson, Smith - 2011 - fMRI Repetition Suppression Neuronal Adaptation or Stimulus Expectation.pdf:pdf},
issn = {1460-2199},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {MD system,attention,cerebral cortex,human,neuroimaging,vision},
mendeley-tags = {MD system},
month = jun,
pmid = {21690262},
title = {{fMRI Repetition Suppression: Neuronal Adaptation or Stimulus Expectation?}},
year = {2011}
}
@article{Lashley1950,
author = {Lashley, K S},
chapter = {In search},
doi = {10.1097/00008877-199204001-00015},
file = {:Users/Brenden/Documents/Mendeley/Lashley - 1950 - In search of the engram.pdf:pdf},
journal = {Symposia of the Society for Experimental Biology},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {454-482},
pages = {30},
publisher = {Cambridge University Press},
title = {{In search of the engram}},
volume = {4},
year = {1950}
}
@article{Lau2003,
author = {Lau, Tessa and Wolfman, Steven A and Domingos, Pedro and Weld, Daniel S},
file = {:Users/Brenden/Documents/Mendeley/Lau et al. - 2003 - Programming by demonstration using version space algebra.pdf:pdf},
journal = {Machine Learning},
keywords = {adaptive user interfaces,complex function learning,program induction,programming by demonstration,version spaces},
mendeley-tags = {program induction},
pages = {111--156},
title = {{Programming by demonstration using version space algebra}},
volume = {53},
year = {2003}
}
@article{Lawrence2011,
address = {Fort Lauderdale, FL, USA},
author = {Lawrence, Neil D},
editor = {Gordon, G and Dunson, D and Miroslav, D},
file = {:Users/Brenden/Documents/Mendeley/Lawrence - 2011 - Spectral Dimensionality Reduction via Maximum Entropy.pdf:pdf},
journal = {{Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS)}},
keywords = {GGM},
mendeley-tags = {GGM},
pages = {51--59},
publisher = {JMLR W\&CP},
title = {{Spectral Dimensionality Reduction via Maximum Entropy}},
year = {2011}
}
@article{LeCun1989,
annote = {Early paper by LeCun on convolution nets.
        
---
Convolutional net: builds in prior knowledge, and thus reduces VC dimension
        
Massive weight sharing, where you have multiple feature maps, where each unit in a map has the same set of weights.
        
data:
9298 segmented numbers
        
Three hidden layers:
H1: 12 groups of 64 units, arranged as 12 8 x 8 maps , and there is a 2 to 1 undersample. Weights are a 5 x 5 kernel
- thus, exact position information is not needed
- hidden units do not share a bias
        
H2: 12 groups, each 4 x 4 maps, same undersample
H3: 30 units, full connectivity 
Overall: 1256 units, 64k connections, 10k independent parameters
        
If kernel goes off image, it is a background of constant color
        
Newton's algorithm, so it uses second-order gradient information
        
Results:
--about 5% test error on digit classification
--some filters look like edge detectors, center surround cells, etc.
        
Performs better than specialized architectures
        
        
      },
author = {LeCun, Y and Boser, B and Denker, J S and Henderson, D and Howard, R E and Hubbard, W and Jackel, L D},
file = {:Users/Brenden/Documents/Mendeley/LeCun et al. - 1989 - Backpropagation Applied to Handwritten Zip Code Recognition.pdf:pdf},
journal = {Neural Computation},
keywords = {classic AI,handwriting},
mendeley-tags = {classic AI,handwriting},
pages = {541--551},
title = {{Backpropagation Applied to Handwritten Zip Code Recognition}},
volume = {1},
year = {1989}
}
@article{LeCunBottou1998,
annote = {Abstract

        
Neural nets are most successful exapmle of gradient based learning. 

        
Convolutional nets are specifically designed to deal with 2D images

        
Graph transformer networks (GTNs) allow multimodule systems to be trained globally using gradient-based methods, which might include field extractino, segmentation, recognition, and language modeling

        
GTNs are deployed commercially and read millions of checks a day

        
---
How is a GTN close to what we are doing?

        
----

        
Introduction

        
Since the early days of pattern recognition, it was obvious that you can't build a recognition system entirely by hand

        
Recognition pert. often strongly depends on the success of the hand-drawn features
+ also, classifiers needed low-dimensional spaces
+ also, larger datasets has changed this too

        
First section: isolated characters
Second section: variable-length objects, like words or documents

        
Gradient baed learning

        
Two surprising successes
- local minima aren't really a problem. Since the space is high dimensional, extra dimensions help us get around the minima
- backprop

        
Real systems
-segmentaiton is hard
+ one approach is to try many candidate cuts, and see which score best by the recognizers
- GTN train a system at the level of whole strings
+ many different systems, including segmented, strung together

        
GTNS:
- take one or more graphs (with numerical info on edges) and produces a graph at output

        
Section 2: Individual characters

        
No pre-processing, like scale/translation invariance, can be perfect.. which is often normalized at the world level

        
Convolution nets get shift invariance by using conv. arch.
- translation invariance,
- local receptive fields
- shared weights
- spatial sub-smapling

        
once a feature is detect,d its exact position is less important -- hence the sub-sampling

        
LeNet5 details
- alternates between convolution layers and sub-sampling layers
- output units are radial basis functions, so similar characters get similar codes
- this can be useful when combined with a language model

        
- can train discriminatively, to maximize the probability of the correct class

        
MNIST
- 60,000 training examples from 10 classes

        
LeNet5
- Layer C1 (convolutional) just 6 feature maps (5x5 filters)
- Layer S2 (subsample) add 4 units, multiply by a coefficeint, and add trinable bias (then sigmoid) [halves the number of rows and columns)
- Layer C3 (conv) 16 feature maps, which operate on a subset of S2's feature maps (each map gets different inputs, breaking symmetry)
- Layer S4: similar to layer S2
- Layer C5 (fully connected): 120 feature maps (but really it's like 120 fully connected units)
- final output layer are Euclidean RBF units, one for each class (like a Gaussian distribution in feature space)
+ weights (codes) chosen by hand initially based on stylized binary exemplars (and kept fixed during training). Also, it assigns similiar codes to similiar classes, unlike 1/n encoding.
+ 1 of n encoding typically fails when there are many classes (over a few dozen)
- only 20 passes through the dataset (epochs), with a smal learning rate, were used

        
- does not observe increasing test error over training, thus not clearly over-fitting
-large learning rate prevents settling down, and encourages broader minima
- even better performance with enhanced pre-training

        
Comarpsions
- LeNEt (less than 1% error)
- simple linear classifier (8-12% error)
- nearest neighbor (5% error)
- PCA + classifier (3%)
- RBF network (like an adaptive K-means) (4%)
- one-hidden layer fully connected MNN (4%), many parameters
- Tangent distane (1.1% test erorr)
- SVMs (about 1%)

        
Should I try tangent distance on my task?

        
Remarkable that SVMs do so well, given that they have no prior knowledge, and can even do a pixel permutation

        
GTN

        
Goal is to back-propagate error through all of the components of the system, so we can train the whole system at once.

        
Object-oriented approach
modules with "fprop" and "bprop" methods. Limited to feed-forward networks, although this could be generalized

        
Discussion assumes fixed-size vectors, but many tasks deal with variable length inputs (like the number of characters)

        
GTMs: directed graphs with vectors on the edges, which is more general than a stochastic grammar
- can keep track of uncertainty of parts, like a lattice of phonemes 

        
Multiple object recognition
- very hard to devise approach to segment charters by hand
- desirable to minimize a word-level error rate

        
Segmentation graph
- first, over-segment the word
- segmentation graph, where a path through the graph indicates a partition of the ink fragments
- by putting values on these edges, we can represent a distribution over possibilities

        
Recognition transformer:
- takes segmentation as input, and applies recognizer to each segment

        
Interpretation graph:
- same as segmentation, where each arc is now a set of arcs that correspond to each identity decision
- penalty assigned to each edge by the recognizer

        
Virterbi transformer: produces a graph with a  single path, where it has the least cumulative penalty

        
Section 6: Global training for GTNs

        
'Viterbi training: compare most likely sequence to the real sequence, and back-propagate

        
discriminative viterbi: not only make the most likely path more probable, but also decrease the probability of potential paths with low penalty

        
forward algorithm: takes into account all possible ways to produce the output, rather than just one
+ this is like the forward algorithm for HMMs
- postpone normalization as long as possible, so things don't have a probabilistic interpretaion
- no reason that we have to manipulate normalized quantities

        
Space Displacement neural net (training without segmentation):
- convolutional net is replicated over the input space
- when networks are replicated in space, most of the inputs are the same, and the models produce the same output on the inputs

        
- at each point the replication, the network produces an output symbol, or if it is uncertain, it produces nothing at all
+ segmentation graph then produces a coherent interpretation in the same way

        
Trained LeNet on sequences composed from MNISt dataset

        
Section 8: Graph transformer networks and tranducers

        
This section reinterprets the GTNs as generalized transducers? (what is this?)
- here they mean finite state transducers

        
Somehow there is a deep conniption here\ldots I don't really get it

        
system for on-line recognition:
1) normalize words (fits it to horizontal lines like in grade school)
2) normalized pen trajectory (annotated image)
3) replicated convolutional NN that recognizes characters
4) GTN that interprets the networks output using word-level constraints

        
Annotated image does not depend on stroke order or writing speed

        
Similar structure to other GTN system

        
The bottom-up proposal for segmentation performs better than the replicated NNs, and with a lexicon, it can get less than a 2 percent character error rate

        
Results:

        
- trained on 100,000 hand printed isolated characters!
- much better with global training rather that non-global training
\ldots well maybe 25% better

        
Check system
- the amount is written in words and numbers, but for now, they just focused on the number

        
Step 1: find the relevant box, again with a segmentation graph-like system
Step 2: Segmentation transformer - segment the number string into characters
Step 3: Recognize the characters
Step 4: Compositional transformer: how to build a valid dollar amount

        
Reads millions of checks a day

        
Conclusion

        
More and more learning in pattern recognition

        
GTN's eliminate the need for hand-crafted heuristics

        
By not making the whole model probabilistic, we don't have "hard to justify" assumptions

        
Principles here could be applied to many other types of data, like speech recognition and visual scene analysis},
author = {LeCun, Y and Bottou, L and Bengio, Y and Haffner, P},
file = {:Users/Brenden/Documents/Mendeley/LeCun et al. - 1998 - Gradient-Based Learning Applied to Document Recognition.pdf:pdf},
journal = {Proceedings of the {IEEE}},
keywords = {classic AI,deep learning,handwriting},
mendeley-tags = {classic AI,deep learning,handwriting},
number = {11},
pages = {2278--2323},
title = {{Gradient-Based Learning Applied to Document Recognition}},
volume = {86},
year = {1998}
}
@inproceedings{LeCun1989a,
annote = {Method for pruning weights.
        
Takes an already state-of-the-art network, and idenfities parameters to remove (about 30%). This leads to slightly better generalization performance.
        
The brain damage is "optimal" because parameters are identified based on an estimate of how zeroing them out will change the error (using taylor approximation)
      },
author = {LeCun, Y and Denker, John S and Solla, Sara A},
booktitle = {Advances Neural Information Processing Systems 2},
file = {:Users/Brenden/Documents/Mendeley/LeCun, Denker, Solla - 1989 - Optimal Brain Damage.pdf:pdf},
keywords = {handwriting,neural networks},
mendeley-tags = {handwriting,neural networks},
pages = {598--605},
title = {{Optimal Brain Damage}},
volume = {58},
year = {1989}
}
@article{Lee2012,
annote = {Completely unsupervised acoustic modelling, where a corpus of words are segmented into phone like "sub-units"
- each phone is modeled as a 3-state HMM
- DP, where base measure is an HMM

        
Questions for Jackie:
- Does your model now have phone transitions?
+ current difference
++ not really non-parametric (it has an upper bound on the number of units)
++ transition between units

        
- When you do word classification, do you evaluate likelihood, or do DTW on the posterior states? Why did you do this?
+ now it is likelihood based 
+ does that work better?     
+ the document doesn't have word boundaries, so that is why you used that

        
---------
Problem statement

        
Has three goals:
- segmentation of the raw speech stream
- clustering of the segments
- modelling each cluster

        
Previous work has looked at each of these sub-tasks independently. It might make a bottom-up segmentation decision, with no way to refine it with knowledge of the clusters.

        
They unify the problem with a non-parametric bayesian formulation. The clusters are modeled with a DP, and each cluster is modeled with an HMM that represents the sub-word units

        
          
Model formulation

        
        
speech feature (x_t): windows are 25 ms, 13 dimensional MFCCs, and their 1st and 2nd derivatives
- 10 ms sampling rate

        
boundary: (b_t), is a binary variable asserting whether or not there is a aboundary after the th frame
- use g_p to denote the pth boundary frame

        
segment: p_jk is the segment between two boundary frames, r x_j to x_k

        
cluster label: c_jk  is the cluster label assigned to a given segment p_jk

        
HMM: (theta_c) is a three state HMM, which correspond to the beginning, middle, and end of a sub-word unit (only left-to-right transitons)
- emissions are diagonal Gaussians with 8 mixtures
(note: this could be non-parametric too)

        
hidden state (s_t): each feature vector x_t has an associated hidden state

        
HMM has three states, which correspond to the start/middle/end of a "phoneme". IT can cover a variable length feature vector, and it only allows left-to-right transitions. Each state in the HMM is itself a gaussian mixture model

        
          
Model

        
        
DPMM to cluster spoken segments

        
for generating observed utterances (assuming boundaries are given)
- just a cluster label for a segment
- choose a hidden state for each assigned feature
- sample from the GMM for each state
- sample continuous features
          

        
        
boundaries are sampled from a bernoulli
          

          
Inference

        
        
Clsuter assignments are re-sampled using the usual CRP prior rule
- for new clusters, Jackie approximates the integral by simply sampling a new HMM from the prior
          

          

        Straightforward to sample new state assignts (1 of 3) for within each hMM

        
Also straightfoward to switch the mixture ID for a feature
          

          
HMM paramters
        
- mixture weights: symmetric Dirichelt distribution the mixing proportions for each state of the tri-state HMM
- Gaussian mixutre : mean and variance of each Gaussian is darwn from a normal-Gamma conjugrate prior
          
- transition prob. : if we assume a symmmetric Dirichelt prior on each row, re-sampling is just drawing from a dirichlet with adds prior and empirical coumts
          

          
boundaries
        
- simple to compare probability of boundary being on vs. probability of us, by comparing prob. of segments togther or alone
          
- eliminate possibillties that are unlikely to be phonetic boundaries a priori

        
          
Results

        
        
Evaluated on TIMIT corpus

        
          
unsupervised segment
        
- compare phoneme boundaries to manual labels provided in TIMIT
- 20 ms tolerance window and compute recall, precision, and F-score of segmentation to TIMIT ground truth

        
          
nonparametic clustering
        
- do the learned clusters correlate with English phones?
- each cluster labe is assigned to the labeled phone boundary it overlaps most with, compare confusion matrix with 48 phonetic units

        
          
sub-word acoustic modeling
        
- gauge quality by a spoken term detection task
(which is the same task Jackie is measuring in one-shot learning)
- extract posterior distribution sub-unit states, and search for a similar pattern in test set (how all models were evaluated)
( could we have computed likleihood?)

        
          
training: 20,000 iterations, after which all their evaluation matrics converged

        
          
Results
        

        
- strong correlation between cluster labels and invidual phones

        
Comparison with supervised models
- for detection, the model does better than training a supervised model on the wrong language (like Thai)

        
Comparison with unsupervised models: beats both a DBM and a simple HMM basline

        
about as good as other methods for segmenting the corups},
author = {Lee, Chia-ying and Glass, James},
file = {:Users/Brenden/Documents/Mendeley/Lee, Glass - 2012 - A Nonparametric Bayesian Approach to Acoustic Model Discovery.pdf:pdf},
journal = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics},
keywords = {speech recognition},
mendeley-tags = {speech recognition},
pages = {40--49},
title = {{A Nonparametric Bayesian Approach to Acoustic Model Discovery}},
year = {2012}
}
@inproceedings{Lee,
annote = {Motivation- 

        
systems require phoneme annotations, and word-level annotations, so there is an inherent dependence on the dictionary, whcih defines all of the pronounciations of all the words
- but this dictionary often has to be created by experts
- strange that there is a manual dictionary, when everything else is learned from the acoustic modelling?
- why not leran dictionaries as well?

        
---
Very deep hierarhcial model, where for each level of context (preceding characters), we have a new DP drawn form the previous level

        
- thus, an infinite n-gram model where each  level of depth is drawn from the previous one
(get an automatic form of back-off)

        
- thus, sequential dependency is based on the letter sequence, not the simple transitions between phonemes 

        
- thus, this gives us a way to leverage a large corpus of text when learning an acoustic model
          

          
inference

        
        
-Gibbs sampler
          

          
experiment

        
        
consistently gets performance close to expert-defined phonetic inventory and lexicons

        
- out-performs models where these things are learned in separate stages},
author = {Lee, Chia-ying and Zhang, Yu and Glass, James},
booktitle = {Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP)},
file = {:Users/Brenden/Documents/Mendeley/Lee, Zhang, Glass - 2013 - Joint Learning of Phonetic Units and Word Pronunciations for ASR.pdf:pdf},
title = {{Joint Learning of Phonetic Units and Word Pronunciations for ASR}},
year = {2013}
}
@article{Lehman1975,
annote = {Generic constraints in drawings. Copying from memory or a model doesn't matter much. But left-handed children prefered to draw right-to-left over left-to-right. The distance of the model from the child also matters.
        
--
Previous work (grammar of action paper) used right-handed children and the model for copying was always present. What if you change those factors?
        
There is probably not a single origin for directional behavior in coping. 
        
Bernbaum et al. 1974: tracing and copying elicit the ame directional behaviors, but tracing you start more at the right of the shape
        
In Hebrew writing, they also start at the top, and the left-side of a letter. Some differences in vertical vs. horizointal lines.
        
Also, top-bottom and left-rigth behaviors are shown by illiterate Honduran children (Bernbaum, 1974)
        
        study 1: copying from memory        
in model absent group, the model was taken away after about five seconds
        
There wre no significant differences for model present vs. absent, in terms of starting at the left, top, and threading
                  
study 2: effects of handedness
                
Left handers are less likely to start at the leftmost point, and draw left-to-right. In fact, many draw right-to-left. These were significant differences.
        
No difference in threading, only slgith difference in start at the top
        
There is a realy preference for right starts in left-handed chidlren.
                  
study 3: alginment/proximity in copying
          
        half the children copied far: 6 in
half the children copied near: 1 in
        
In the far condition, children threaded more and, to a lesser extent, top-bottom directionality.},
author = {Lehman, Elyse Brauch and Goodnow, Jacqueline J},
file = {:Users/Brenden/Documents/Mendeley/Lehman, Goodnow - 1975 - Directionality in copying memory, handedness, and alignment effects.pdf:pdf},
journal = {Perceptual and Motor Skills},
keywords = {embodied cognition,handwriting,part-based models},
mendeley-tags = {embodied cognition,handwriting,part-based models},
pages = {863--872},
title = {{Directionality in copying: memory, handedness, and alignment effects}},
volume = {41},
year = {1975}
}
@inproceedings{Lewis2009,
author = {Lewis, Joshua M},
booktitle = {Proceedings of the 31st Annual Conference of the Cognitive Science Society},
file = {:Users/Brenden/Documents/Mendeley/Lewis - 2009 - Finding a Better k A psychophysical investigation of clustering.pdf:pdf},
keywords = {perceptual grouping},
mendeley-tags = {perceptual grouping},
pages = {315--320},
title = {{Finding a Better k : A psychophysical investigation of clustering}},
year = {2009}
}
@inproceedings{Lewis2012,
annote = {Try to make statistical data analysis less like a black box
        
Unsupervised machine learning for exploartory data analysis
- visualizes on the fly
        
Human perception during data analysis
        
Soliciation of human judgments prevades the machine learning literature
- "algorithm is what humans would have chosen"...
        
Can people identify quality embeddings?},
author = {Lewis, Joshua M and van der Maaten, Laurens and de Sa, V R},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
title = {{A behavioral investigation of dimensionality reudction}},
year = {2012}
}
@article{Li2003,
annote = {Tse and Cavanagh found that Chinese participants see apparent motion of a stroke in the opposite direction of Americans.
        
        
---
What if the stroke sequence is not in the correct order?
        
What if the script does not contain cues, like a thicker end, to indicate writing direction?
        
What if there was a shorter presentation of the strokes?
        
You only get the effect if the order is correct, the presentation is slow, and the script contains writing cues. So this effect only shows up in very particular circumstances.},
author = {Li, Jing-Ling and Yeh, Su-Ling},
doi = {10.1080/13506280244000195},
file = {:Users/Brenden/Documents/Mendeley/Li, Yeh - 2003 - Do Chinese and American see opposite apparent motions in a Chinese character Tse and Cavanagh (2000) replicated and revised.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
keywords = {embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
month = jun,
number = {5},
pages = {537--547},
title = {{Do "Chinese and American see opposite apparent motions in a Chinese character"? Tse and Cavanagh (2000) replicated and revised}},
volume = {10},
year = {2003}
}
@inproceedings{Liang2010,
annote = {Program induction: Learning in the space of functions most naturally represented by programs
        
Percy only considers programs that are deterministic, rather than stochastic. 
        
The likelihood results is 1 if the program produces the data, otherwise 0. To make inference possible, he provides a restricted set of candidate correct programs, since it's too hard to jump across disconnected states.
        
--
        
When using lambda calculus, there is a lot of repetition of a variable x. To allow sharing between programs, given a variable as input, it can be routed into place iwht special routers.
        
Programs are generated with probabilistic context-free grammars. By using a prior based on adaptor grammars, you can implement a notion of sharing sub-components. 
        
Examples:
        
 If you have multiple tasks, you can have very simple programs for each. But if you allow sharing across tasks, more complex programs have a chance since you can share sub-components.
        
Simple arithmetic: max(x,y), min(x,y)},
author = {Liang, Percy and Jordan, Michael I and Klein, Dan},
booktitle = {{Proceedings of the 27th International Conference on Machine Learning}},
file = {:Users/Brenden/Documents/Mendeley/Liang, Jordan, Klein - 2010 - Learning Programs A Hierarchical Bayesian Approach.pdf:pdf},
keywords = {program induction},
mendeley-tags = {program induction},
title = {{Learning Programs: A Hierarchical Bayesian Approach}},
year = {2010}
}
@inproceedings{Liang2007,
author = {Liang, Percy and Petrov, Slav and Jordan, Michael I and Klein, Dan},
booktitle = {Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL)},
file = {:Users/Brenden/Documents/Mendeley/Liang et al. - 2007 - The Infinite PCFG using Hierarchical Dirichlet Processes.pdf:pdf},
keywords = {non-parametric Bayes},
mendeley-tags = {non-parametric Bayes},
title = {{The Infinite PCFG using Hierarchical Dirichlet Processes}},
year = {2007}
}
@article{Liao1990,
annote = {Referenc for "maximum circle criterion"},
author = {Liao, Chia-Wei and Huang, Jun S},
file = {:Users/Brenden/Documents/Mendeley/Liao, Huang - 1990 - Stroke segmentation by bernstein-bezier curve fitting.pdf:pdf},
journal = {Pattern Recognition},
number = {5},
pages = {475--484},
title = {{Stroke segmentation by bernstein-bezier curve fitting}},
volume = {23},
year = {1990}
}
@article{Liberman1967,
annote = {Original paper on motor theory of speech.
        
"we find it more plausible that speech is perceived by processes that are also invovled in its production"
        
Main evidence:
-- perception mirrors articulation more than raw sound
-- it's hard to define phonemes directly in terms of sound
-- it's parsimonous to assume the generative model is used
        
        
--
About 40 phonemes in English.
        
Speech is special, in its very high rate of communication.
        
It is difficult to cut speech into phonemes, you cannot just substitute /d/ segments with one another from other words.
        
It is hard to define /d/ as any particular cue -- since it varies when combined with different vowels.
        
The best defining charactersitic of /d/, a particular frequency, is more articulatory, not acoustic. The art. tract is closed at the same point.
        
Categorical perception -- also supports motor theory? Nowadays, this is a far more general phenomenon
        
You can further decompose phonemes into sub-phonemic features. But any theory can't ignore the fact that phonemes are psychologically real.
        
"we find it more plausible that speech is perceived by processes that are also invovled in its production"
        
It is simpler to assume there is only one process. And pereption seems to mirror articulation more closely than sound. },
author = {Liberman, A M and Cooper, F S and Shankweiler, D P and Studdert-Kennedy, M},
file = {:Users/Brenden/Documents/Mendeley/Liberman et al. - 1967 - Perception of the speech code.pdf:pdf},
journal = {Psychological Review},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
number = {6},
pages = {431--461},
title = {{Perception of the speech code}},
volume = {74},
year = {1967}
}
@article{Liberman1985,
annote = {Speech is special, compared to other sounds, since you want to decode the intended gesture. 
        
"The objects of speech perception were not to be found at the acoustic surface."
        
"To perceive an utterance, then, is to  perceive a specific pattern of intended gestures"
        
This would be a meaningless theory if there was a clear one-to-one correspodence between acoustics and gesture. This is not the case, there is coarticulation, and the relation is paculiar to speech.
        
Theories that rely heavily on sound, might suggest that speech is governed by auditory principles, and thus so too is speech perception. These include theories that rely heavily on categorical perception to explain how distinctions are perceived, some of which are present in Chinillas for instance.
        
It's not necessarily a problem is other non-speech sound, which have similar acoustic cues, occassionally activate this mechanism
        
Evidence:
-- there is not set of cues that completely describe a phonetic category, it would be huge
-- coarticulation. the percept does not mirror the overlap of information in the sound
-- Invariant perception from different signals
-- Duplex perception: if a phoneme is presented with a complex procedure, you get simulatenous speech-like perception and another sound which is not. This might show an independence of the speech mechanism, and two mechanisms.
-- McGurk effect, where conflicting optical and phonemic stimuli are shown at the same time. You get a single gestural percept.},
author = {Liberman, A M and Mattingly, I G},
file = {:Users/Brenden/Documents/Mendeley/Liberman, Mattingly - 1985 - The motor theory of speech perception revised.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Humans,Psychological Theory,Speech Perception,embodied cognition},
mendeley-tags = {embodied cognition},
month = oct,
number = {1},
pages = {1--36},
pmid = {4075760},
title = {{The motor theory of speech perception revised.}},
volume = {21},
year = {1985}
}
@inproceedings{Lin2002,
author = {Lin, Feng and Tang, Xiaoou},
booktitle = {Proceedings of the 16th International Conference on Pattern Recognition},
doi = {10.1109/ICPR.2002.1047841},
file = {:Users/Brenden/Documents/Mendeley/Lin, Tang - 2002 - Off-line handwritten Chinese character stroke extraction.pdf:pdf},
isbn = {0-7695-1695-X},
keywords = {handwriting},
mendeley-tags = {handwriting},
pages = {249--252},
publisher = {IEEE Comput. Soc},
title = {{Off-line handwritten Chinese character stroke extraction}},
volume = {3},
year = {2002}
}
@incollection{Lindemann1998,
annote = {The motor program for writing a word is hierarchical, and the parts (letters and strokes) are stored separately and can be transferred to another motor effector. The reason writing is hard with the left-hand is because we have not developed the low-level pathways. We don't have to re-learn a stroke and letter level representation.
        
Participants practiced writing a small set of words with their left-hand. When new words were introduced, there is little decrement in performance if the letters and the strokes stay the same. However, these is likely a decrement if the strokes change -- since these low-level pathways need to be practiced again.
        
        
----
How does handwriting compare for the right vs. the left hand?
        
The puzzle of shape similarity: handwriting with different effectors looks pretty similar, and experts can generally match samples written by the same person and different body parts
+ this is interesting, because the effectors have a completely different physical make-up
+ huge difference in practice
+ What is the common thread?
        
Planning in general:
- ordering of steps is critical
- plans improve with experience
(driving on the highyway, and knowing where to exit)
        
Motor programs: plans in the motor domain
        
Early concept
+ early definition concerned velocity, low-level characteristics, etc.
+ it would not transfer to left hand, or another word
+ but writing "handwriting" smaller/larger seems to transfer skill
        
generalized motor program
+ includes a class of related movements
+ some variables left unspecificed, like speed
+ but limits of generalization (like new word)
+ driving to work in another car, the plan does not include the details of each tiny motor action
        
When do we create new programs, or apply existing ones?
+ claim: motor programs can be effector-independent        
++ you don't specify the program with specific muscles
        
Lashely (1942): shape similarity in handwriting means effector independence?
                  
Problem: This tells us more about the flexibility of the system, than the structure of the programs
        
Wright (1990): you shouldlook at other properties
+ different decomposition of letters into strokes
+ the shared representation might contribute little more than overall shape        
++ almost no detail about how to produce writing
+++ very abstract notion of a motor program the only way to go?
        
Hierarchical representation of plans: think about planning at many different levels
        
It's not that your left hand is less-coordinate or weaker (you use it all the timeO. It's a matter of practice.
        
        
        
hiearachy in handwriting:
highest: intention to write a letter
lowest: specific muscles
        
Levels used here:
word level
letter level
strokes of a letter
        
In cursive, handwritting strokes can be segmented by changes in speed
        
It doesn't make sense to ask whether a motor program is generalized: what level is it generalized? This makes more sense
        
Sternberg: for long sequences of actions, all the actions are slower -- reflecting planning
        
Changing effectors requires practice
-- initial left-handed writing may appear to have little overlap, but this doesn't mean you can't share motor program structure
-- with practice, transfer might develop
        
Evidence that two hands share a relatively low-level of the hiearchy of motor programs?
                  
Basic method        
- Teach participants to write a small set of words with left hand
- Ask them to write new words with left hand
- If there is little difference, then the represenation seems to be hand-independent
                
You can manipualte the overlap in terms of words, letters, and strokes -- to get at what level the sharing occurs
        
Sharing of letters and strokes
+ sharing of strokes is like sharing phonemes in speech.
                  
Analysis in experiments        
G-strokes:
+ Wright's generic strokes, which they hypothesize will generalize across different hands
+ Asked participants to write letters in context, and segemented strokes by velocity
++ About 200 different stroke types
        
Fit power-laws to practice curves
        
Method: three subjects over months of training (80 sessions of 30 minutes). Learned the initial set for the first 28 sessions.
        
Then "New words": same letters but in new orders
        
Then "New Letters": but same g-strokes, according to the g-stroke analysis
                  
Results:
          
Overall imporvement:        
Clear increase in fluency over all 80 trials (power function)
                  
Subject 1
          
New words (word set 1 to 2):        
When new words were introduced in session 28, performance continued at approximately the same level. Thus, there was a complete transfer of knowledge from the letter level.
                  
New lettesr, same strokes (word set 2 to 3)
- Added at session 61
- Slight degradation in perfomance (almost nine sessions of practice worth
[but this is a very small change in performance]
- The best estimate is there was a slight change, but it may not be reliable. But there is not major disruption.
                  
Other 2 subjects: Even less of a decrement. Taken together, strong evidence that representations at the letter level are hand-independent.
          
        While in Wright (1990), the strokes are not produced in a similar smooth movement after a subject switches to left-hand writing, these results suggest there is a transfer at the stroke level.           
Strokes are treated as independent units, and transferred across hands
          
Overall summary:
- Big imporvement in overall performance
- But nonetheless, no real decrement when the stimuli changed, although there was plenty of room for one.
          
Thus, strokes appear to be indepent of a particular hand. Effector independence.
          
Future directions
                
Would improvment in studying a new stroke-type on the right hand transfer to the left? This could be tested in young children
        
The motor program for writing a word is hierarchical, and the parts are stored separately and can be transferred. The reason writing is hard with the left-hand is because we have not developed the low-level pathways. We don't have to re-learn a stroke and letter level representation.          
          
        Initial data: there does seem to be a major deteriation when new g-strokes are added. Thus, you need to learn to map those low-level motor signals.},
author = {Lindemann, Patricia G and Wright, Charles E},
booktitle = {An Invitation to Cognitive Science},
edition = {2nd},
editor = {Scarborough, Don and Sternberg, Saul},
file = {:Users/Brenden/Documents/Mendeley/Lindemann, Wright - 1998 - Skill Acquisition and Plans for Actions Learning to Write with Your Other Hand.pdf:pdf},
keywords = {handwriting,motor equivalence},
mendeley-tags = {handwriting,motor equivalence},
pages = {523--585},
title = {{Skill Acquisition and Plans for Actions: Learning to Write with Your Other Hand}},
volume = {4},
year = {1998}
}
@inproceedings{Lindsey,
annote = {Summary: efficiently optimize instructor policies in a parameterized space, where we can find the global optimum without having to try the entire grid

        

        
---

        
What is the best way to teach a new concept?

        
- fading?
- blocking vs. interleaving?

        
both can be construed in a continuous space, but we won't have the data to test for statistical significance

        
Space of instructional policies, like how much blocking and fading

        
It's a continuous space

        
Try subjects in a few different points in this space, and use Gaussian processes to map out the space and find the maximum
- function approxixation

        
Do you get better performance with a small number of data points in a lot of places, or many at once?
- goal is a system that can completely auotmated experimental design

        
POMDP's have been used to find optimal teaching, but they require a lot of bias and are not model agnositic

        
Gaussian process regression
- allows for experimental noise
- smoothness can be assured with appropriate design of policy spaces

        
1) Generative model of student performance

        
Draw function f from a multi-variate normal with a standard covariace function, with 2 free paramters

        
The probability of answering any question right is related to the policy effectiveness by pushing the gaussian through a logistic function

        
The probability of answering questions right, given the mean of the function, can be computed analytically for this special case where questions are 2AFC

        
Posterior samples are drawn via slice sampling

        
Could extend the model to the situation where subjects are tested in multiple policies

        
          
Active selection

        
        
upper-confidenc bound (UCB) startegy, where you start with exploratory mode and shift to exploiting, where you draw closer to the mean with time

        
          
Experiment 1

          

        subjects were asked to learn the favorite sporting team of six individuals

        
each person's face was shown with their favorite team (either Jets or SHarks)

        
training policy specifies the duration of each face-team pair, given that there was an overall fixed budget of training time

        
After training, subjects were tested on each of the six faces in random order

        
After each subject, the posterior was reestimated and the UCB strategy was used to select the policy for the next subjet

        
Right answer was around 1.15 second duration -- where psychologists guessed somewhere betwee 1 and 2.5 seconds

        
With same amount of data in a traditional design, the results are coarsely consistent, but no clear pattern emerges

        
          
Experiment 2: Optimizing training example sequence

        
- learn GLOPNOR concept, which roughly means "graspabilitiy", or that it is easy to grasp with one hand
- images of these objects were the stimuli
- divided into two groups baesd on mean graspbability rating

        
Two dimensions:
- distance of exemplars to category boundary
- also, the probability of repeating a label (allows you to move between blocked and interleaved)

        
In policy space, there isa big differnece in fading, but the difference in blocking seems to be more subtle
- either start with many repetitions, or end with many reptitions, while the other half has many alternations
- or alternatve with repetition probability of 0.5

        
Ran 10 subjects in each of the 4 corners, then 150 other subjects

        
          
results
        
It seems that blocking didn't really matter, but it picked start with blocking and end with alternations

        
It also pciked substantial fading (66% of max)

        
To confirm results, they ran 50 subjects in each of the corners, as well as the optimal place
- they found a higher accuracy for the optimal one, but it wasn't signfifcant
- but there was very low power

        
          
discussion
        
A-B testing is popular for web site layout, marketing, and sales 
- but this offers a more systematic alternative solution

      },
author = {Lindsey, Robert V and Mozer, Michael C and Huggins, William J and Pashler, Harold},
booktitle = {Advances in Neural Information Processing Systems 26},
file = {:Users/Brenden/Documents/Mendeley/Lindsey et al. - 2013 - Optimizing Instructional Policies.pdf:pdf},
keywords = {automated teachers},
mendeley-tags = {automated teachers},
title = {{Optimizing Instructional Policies}},
year = {2013}
}
@article{Linebarger1983,
author = {Linebarger, M C and Schwartz, M F and Saffran, E M},
file = {:Users/Brenden/Documents/Mendeley/Linebarger, Schwartz, Saffran - 1983 - Sensitivity to grammatical structure in so-called agrammatic aphasics.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Adult,Aphasia,Aphasia, Broca,Aphasia, Broca: psychology,Aphasia: psychology,Female,Humans,Judgment,Linguistics,Middle Aged,Psychological Theory,Semantics,Vocabulary},
month = may,
number = {3},
pages = {361--92},
pmid = {6683142},
title = {{Sensitivity to grammatical structure in so-called agrammatic aphasics.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6683142},
volume = {13},
year = {1983}
}
@article{Liu2004,
abstract = {Online handwriting recognition is gaining renewed interest owing to the increase of pen computing applications and new pen input devices. The recognition of Chinese characters is different from western handwriting recognition and poses a special challenge. To provide an overview of the technical status and inspire future research, this paper reviews the advances in online Chinese character recognition (OLCCR), with emphasis on the research works from the 1990s. Compared to the research in the 1980s, the research efforts in the 1990s aimed to further relax the constraints of handwriting, namely, the adherence to standard stroke orders and stroke numbers and the restriction of recognition to isolated characters only. The target of recognition has shifted from regular script to fluent script in order to better meet the requirements of practical applications. The research works are reviewed in terms of pattern representation, character classification, learning/adaptation, and contextual processing. We compare important results and discuss possible directions of future research.},
annote = {Survey of online Chinese character recognition, which is very different than recognizing western alphabets
        
most character contain indepdent sub-structures, called radicals, which are shared by many characters.
        
Two main categories of methods
- structural
+ based on stroke analysis, which might be stroke-order dependent or order-free
- statistical
        
Steps for most recognition algorithms
1) Segment out the characters
2) Pre-processing of the strokes
        
Pre-processing::
- compression by making uniform spatial freq. or piece-wise linear approx
- often make traj. have uniform spatial frequency
- also, rescaling is key
        
Structural representation algorithms ave long been dominant.
        
        Representation        
- could use sequence of points
- stroke codes (with prototypes)
- relational 
+ attributed relational graph (ARG), denotes primitives and relations between them (like the type of junction)
- hiearchical representation, where you share radicals, stroke codes, etc. to build up the higher-level concept. 
+ they motivate it for storing, by obviously this is also the basis for one-shot learning algorithms
        
Statistical-structural models
- statistical versions of strutural rep.
see [76] and [150]
- includes HMMs
see [93] for hierarchical HMM
        
Feature-based
- can just produce image, and extrat off-line features
- can compute direction freatures, and use a blurred filter on the output of a direction detector applied along the strokes
                  
classification
                
generally have a coarse and fine-level classificatino step, where the coarse is used to prune the space of candidates
+ use the number of strokes to prune unlikely clases
        
structural matching -- you have a structural model of each class, and you compare the items to this. Based on identifying sub-parts (radicals), perhaps
        
dynamic time warping --
methods based on matching stroke with dynamic time warping. Also, you often need multiple prototypes for a character. Can insert/delete/merge strokes sometimes
see [123] for sophisticated viersion
        
Using gaussians to model strokes:
see [20,150,106,15]
        
Using clustering to find stroke prototypes
see [133,142,59,130]
                  
Performance evaluation
        You can get between 90 and 98% performance on on-line chinese character recognition. Performance varies greatly with the amount of training, but some methods seem to require very little
[see  16,18, 48]},
author = {Liu, Cheng-Lin and Jaeger, Stefan and Nakagawa, Masaki},
doi = {10.1109/TPAMI.2004.1262182},
file = {:Users/Brenden/Documents/Mendeley/Liu, Jaeger, Nakagawa - 2004 - Online recognition of Chinese characters the state-of-the-art.pdf:pdf},
issn = {0162-8828},
journal = {{IEEE Transactions of Pattern Analysis and Machine Intelligence}},
keywords = {Algorithms,Artificial Intelligence,Automated,Automatic Data Processing,Biomedical,China,Computer Graphics,Computer-Assisted,Computer-Assisted: methods,Controlled,Image Enhancement,Image Enhancement: methods,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Natural Language Processing,Numerical Analysis,Pattern Recognition,Reading,Reproducibility of Results,Review Literature as Topic,Sensitivity and Specificity,Signal Processing,Subtraction Technique,Technology Assessment,User-Computer Interface,Vocabulary,handwriting,part-based models},
mendeley-tags = {handwriting,part-based models},
month = feb,
number = {2},
pages = {198--213},
pmid = {15376895},
title = {{Online recognition of Chinese characters: the state-of-the-art}},
volume = {26},
year = {2004}
}
@article{Liu2001,
author = {Liu, Cheng-Lin and Kim, In-Jung and Kim, Jin H.},
doi = {10.1016/S0031-3203(00)00165-5},
file = {:Users/Brenden/Documents/Mendeley/Liu, Kim, Kim - 2001 - Model-based stroke extraction and matching for handwritten Chinese character recognition.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {chinese character recognition,handwriting,heuristic search,model-based stroke extraction,semi-admissible,structural matching},
mendeley-tags = {handwriting},
month = dec,
number = {12},
pages = {2339--2352},
title = {{Model-based stroke extraction and matching for handwritten Chinese character recognition}},
volume = {34},
year = {2001}
}
@inproceedings{Liu1997,
author = {Liu, K and Huang, Y S and Suen, Ching Y},
booktitle = {Proceedings of the Fourth International Conference on Document Analysis and Recognition},
file = {:Users/Brenden/Documents/Mendeley/Liu, Huang, Suen - 1997 - Robust Stroke Segmentation Method for Handwritten Chinese Character Recognition.pdf:pdf},
isbn = {0818678984},
keywords = {handwriting},
mendeley-tags = {handwriting},
title = {{Robust Stroke Segmentation Method for Handwritten Chinese Character Recognition}},
year = {1997}
}
@article{Liu1999,
author = {Liu, Ke and Huang, Yea S and Suen, Ching Y},
file = {:Users/Brenden/Documents/Mendeley/Liu, Huang, Suen - 1999 - Identification of Fork Points on the Skeletons of Handwritten Chinese Characters.pdf:pdf},
journal = {{IEEE Transactions of Pattern Analysis and Machine Intelligence}},
keywords = {handwriting,part-based models},
mendeley-tags = {handwriting,part-based models},
number = {10},
pages = {1095--1100},
title = {{Identification of Fork Points on the Skeletons of Handwritten Chinese Characters}},
volume = {21},
year = {1999}
}
@article{Liu1993,
annote = {On-line recognition of Chinese charaters, using sub-parts and relations.
        
Since many characters share radicals, they come up with rules for detecing radicals. This creates the hierarchical approach.},
author = {Liu, Y.-J. and Zhang, L.-Q. and Tai, J.},
doi = {10.1109/ICDAR.1993.395751},
file = {:Users/Brenden/Documents/Mendeley/Liu, Zhang, Tai - 1993 - A new approach to on-line handwritten Chinese character recognition.pdf:pdf},
isbn = {0-8186-4960-7},
journal = {Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)},
keywords = {handwriting},
mendeley-tags = {handwriting},
pages = {192--195},
publisher = {IEEE Comput. Soc. Press},
title = {{A new approach to on-line handwritten Chinese character recognition}},
year = {1993}
}
@article{Livingston1998,
author = {Livingston, K R and Andrews, J K and Harnad, S},
journal = {Journal of Experimental Psychology},
number = {3},
pages = {732--753},
title = {{Categorical perception effects induced by category learning}},
volume = {24},
year = {1998}
}
@article{Lombrozo2009,
abstract = {Recent theoretical and empirical work suggests that explanation and categorization are intimately related. This paper explores the hypothesis that explanations can help structure conceptual representations, and thereby influence the relative importance of features in categorization decisions. In particular, features may be differentially important depending on the role they play in explaining other features or aspects of category membership. Two experiments manipulate whether a feature is explained mechanistically, by appeal to proximate causes, or functionally, by appeal to a function or goal. Explanation type has a significant impact on the relative importance of features in subsequent categorization judgments, with functional explanations reversing previously documented effects of 'causal status'. The findings suggest that a feature's explanatory importance can impact categorization, and that explanatory relationships, in addition to causal relationships, are critical to understanding conceptual representation.},
author = {Lombrozo, Tania},
doi = {10.1016/j.cognition.2008.10.007},
file = {:Users/Brenden/Documents/Mendeley/Lombrozo - 2009 - Explanation and categorization how why informs what.pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
keywords = {Classification,Cognition,Cognition: physiology,Data Interpretation,Female,Humans,Male,Psycholinguistics,Statistical,Young Adult,explanation,rich concepts},
mendeley-tags = {explanation,rich concepts},
month = feb,
number = {2},
pages = {248--53},
pmid = {19095224},
publisher = {Elsevier B.V.},
title = {{Explanation and categorization: how "why?" informs "what?".}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19095224},
volume = {110},
year = {2009}
}
@article{LongcampAnton2003,
annote = {They showed participants latin characters, pseudo-characters that look letters from a foreign alphabet, and a control character that was three parallel lines. Using a region of interest (ROI) defined on the basis of peak activation during a writing task, the authors found stronger activity in left premotor cortex (BA6) for the latin characters compared to either pseudo-characters or the control.--
There was no task except to look at the stimuli.
        
The functional localizer was based on the results obtained in a writing task; then tested if it is significant for reading
        
significant contrasts:
letters vs. pseudoletters
pseudoletters vs. control
        
Activated left pre-motor cortex (BA6)},
author = {Longcamp, M and Anton, J L and Roth, M and Velay, J L},
file = {:Users/Brenden/Documents/Mendeley/Longcamp et al. - 2003 - Visual presentation of single letters activates a premotor area involved in writing.pdf:pdf},
journal = {Neuroimage},
keywords = {embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
number = {4},
pages = {1492--1500},
title = {{Visual presentation of single letters activates a premotor area involved in writing}},
volume = {19},
year = {2003}
}
@article{LongcampHlushchuk2010,
annote = {fMRI analysis of the difference between handwritten and printed characters. There is no difference in premotor cortex, but there is in primary motor cortex
        
method: fMRI
task: detect the letter ''z'' and count how many times it appeared
motor localizer task: regions involved in initiation of brisk finger movements
stimuli: printed vs. handwritten letters
result: left premotor cortex and supplementary motor area showed increased activity to handwritten letters
      },
author = {Longcamp, M and Hlushchuk, Y and Hari, R},
file = {:Users/Brenden/Documents/Mendeley/Longcamp, Hlushchuk, Hari - 2010 - What differs in visual recognition of Handwritten vs. Printed Letters An fMRI study.pdf:pdf},
journal = {Human Brain Mapping},
keywords = {embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
title = {{What differs in visual recognition of Handwritten vs. Printed Letters? An fMRI study}},
year = {2010}
}
@article{Longcamp2006,
abstract = {Humans are able to recognize handwritten texts accurately despite the extreme variability of scripts from one writer to another. This skill has been suggested to rely on the observer's own knowledge about implicit motor rules involved in writing. To investigate the possible neural correlates of such an ability, we monitored with magnetoencephalography (MEG) the approximately 20-Hz oscillations originating from the motor cortex. The oscillations were more suppressed after visual presentation of handwritten than printed letters, indicating stronger excitation of the motor cortex to handwritten scripts. These results support the idea of embodied visual perception of handwritten scripts and the involvement of the motor cortex in the underlying action-perception link.},
annote = {Task: vowel or consontant
Method: MEG with 20hz band
localizer: region of primary motor cortex involved in the finger lift task
Conclusion: primary motor cortex is more active for handwriting vs. print},
author = {Longcamp, M and Tanskanen, T and Hari, R},
doi = {10.1016/j.neuroimage.2006.06.042},
file = {:Users/Brenden/Documents/Mendeley/Longcamp, Tanskanen, Hari - 2006 - The imprint of action motor cortex involvement in visual perception of handwritten letters.pdf:pdf},
issn = {1053-8119},
journal = {NeuroImage},
keywords = {Adult,Brain,Brain Mapping,Brain: anatomy & histology,Brain: physiology,Female,Humans,Magnetoencephalography,Male,Motor Cortex,Motor Cortex: physiology,Oscillometry,Reaction Time,Reading,Reference Values,Visual Acuity,Visual Perception,Visual Perception: physiology,Writing,embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
month = nov,
number = {2},
pages = {681--8},
pmid = {16965922},
title = {{The imprint of action: motor cortex involvement in visual perception of handwritten letters.}},
volume = {33},
year = {2006}
}
@article{Longcamp2008,
abstract = {Fast and accurate visual recognition of single characters is crucial for efficient reading. We explored the possible contribution of writing memory to character recognition processes. We evaluated the ability of adults to discriminate new characters from their mirror images after being taught how to produce the characters either by traditional pen-and-paper writing or with a computer keyboard. After training, we found stronger and longer lasting (several weeks) facilitation in recognizing the orientation of characters that had been written by hand compared to those typed. Functional magnetic resonance imaging recordings indicated that the response mode during learning is associated with distinct pathways during recognition of graphic shapes. Greater activity related to handwriting learning and normal letter identification was observed in several brain regions known to be involved in the execution, imagery, and observation of actions, in particular, the left Broca's area and bilateral inferior parietal lobules. Taken together, these results provide strong arguments in favor of the view that the specific movements memorized when learning how to write participate in the visual recognition of graphic shapes and letters.},
author = {Longcamp, Marieke and Boucard, C\'{e}line and Gilhodes, Jean-Claude and Anton, Jean-Luc and Roth, Muriel and Nazarian, Bruno and Velay, Jean-Luc},
doi = {10.1162/jocn.2008.20504},
file = {:Users/Brenden/Documents/Mendeley/Longcamp et al. - 2008 - Learning through hand- or typewriting influences visual recognition of new graphic shapes behavioral and functi.pdf:pdf},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
keywords = {Adult,Association Learning,Association Learning: physiology,Cerebellum,Cerebellum: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Female,Form Perception,Form Perception: physiology,Handwriting,Humans,Imagination,Imagination: physiology,Magnetic Resonance Imaging,Male,Motor Cortex,Motor Cortex: physiology,Motor Skills,Motor Skills: physiology,Nonparametric,Parietal Lobe,Parietal Lobe: physiology,Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,Psychomotor Performance,Psychomotor Performance: physiology,Reference Values,Statistics,Visual,Visual Cortex,Visual Cortex: physiology,Visual: physiology,embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
month = may,
number = {5},
pages = {802--15},
pmid = {18201124},
title = {{Learning through hand- or typewriting influences visual recognition of new graphic shapes: behavioral and functional imaging evidence.}},
volume = {20},
year = {2008}
}
@article{Love2002,
author = {Love, B C},
journal = {Psychonomic Bulletin and Review},
number = {4},
pages = {829--835},
title = {{Comparing supervised and unsupervised category learning}},
volume = {9},
year = {2002}
}
@article{Love2004,
author = {Love, B C and Medin, D L and Gureckis, T M},
file = {:Users/Brenden/Documents/Mendeley/Love, Medin, Gureckis - 2004 - SUSTAIN A Network Model of Category Learning.pdf:pdf},
journal = {Psychological Review},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {2},
pages = {309--332},
title = {{SUSTAIN: A Network Model of Category Learning}},
volume = {111},
year = {2004}
}
@article{Love2007,
abstract = {Mental localization efforts tend to stress the where more than the what. We argue that the proper targets for localization are well-specified cognitive models. We make this case by relating an existing cognitive model of category learning to a learning circuit involving the hippocampus, perirhinal, and prefrontal cortices. Results from groups varying in function along this circuit (e.g., infants, amnesics, and older adults) are successfully simulated by reducing the model's ability to form new clusters in response to surprising events, such as an error in supervised learning or an unfamiliar stimulus in unsupervised learning. Clusters in the model are akin to conjunctive codes that are rooted in an episodic experience (the surprising event) yet can develop to resemble abstract codes as they are updated by subsequent experiences. Thus, the model holds that the line separating episodic and semantic information can become blurred. Dissociations (categorization vs. recognition) are explained in terms of cluster recruitment demands.},
author = {Love, Bradley C and Gureckis, Todd M},
file = {:Users/Brenden/Documents/Mendeley/Love, Gureckis - 2007 - Models in search of a brain.pdf:pdf},
issn = {1530-7026},
journal = {Cognitive, affective & behavioral neuroscience},
keywords = {Age Factors,Brain,Brain Mapping,Brain: physiology,Humans,Mental Processes,Mental Processes: physiology,Models, Biological,Models, Psychological,Neural Networks (Computer)},
month = jun,
number = {2},
pages = {90--108},
pmid = {17672381},
title = {{Models in search of a brain.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17672381},
volume = {7},
year = {2007}
}
@inproceedings{Lovett2007a,
annote = {Drawing is list of points corresponding to a line drawn by the drawer.
        
They extract some basic visual features:
-junctions
-possible corners (discontinuities in the line), endpoints, or termination
-They find simple shapes
        
Make a qualitative representaiton
- label lines as straight, curved, or elliptical
- left-of , above relations,
- connected-to
        
Two drawings are mapped using a structure mapping engine.
      },
author = {Lovett, Andrew and Dehghani, Morteza and Forbus, Kenneth},
booktitle = {{Proceedings of the International Joint Conference on Artificial Intelligence}},
file = {:Users/Brenden/Documents/Mendeley/Lovett, Dehghani, Forbus - 2007 - Incremental Learning of Perceptual Categories for Open-Domain Sketch Recognition Kenneth Forbus Comparisons and Generalization.pdf:pdf},
keywords = {CogSci2013 Symposium,analogy,one-shot learning},
mendeley-tags = {CogSci2013 Symposium,analogy,one-shot learning},
title = {{Incremental Learning of Perceptual Categories for Open-Domain Sketch Recognition Kenneth Forbus Comparisons and Generalization}},
year = {2007}
}
@inproceedings{Lovett2007,
author = {Lovett, Andrew and Lockwood, Kate and Dehghani, Morteza and Forbus, Kenneth},
booktitle = {Proceedings of Analogies: Integrating Multiple Cognitive Abilities},
file = {:Users/Brenden/Documents/Mendeley/Lovett et al. - 2007 - Modeling Human-Like Rates of Learning via Analogical Generalization.pdf:pdf},
title = {{Modeling Human-Like Rates of Learning via Analogical Generalization}},
year = {2007}
}
@article{Lu1986,
author = {Lu, H E and Wang, P S P},
file = {:Users/Brenden/Documents/Mendeley/Lu, Wang - 1986 - A Comment on “A Fast Parallel Algorithm for Thinning Digital Patterns”.pdf:pdf},
journal = {Communications of the ACM},
keywords = {handwriting,thinning algorithm},
mendeley-tags = {handwriting,thinning algorithm},
number = {3},
pages = {239--242},
title = {{A Comment on “A Fast Parallel Algorithm for Thinning Digital Patterns”}},
volume = {29},
year = {1986}
}
@article{Ren1991,
annote = {Algorithm for recognizing Chinese characters. Computes a structural description (a la Winston) based on a set of reconstructed strokes.
        
        
--
Step 1) Thin the character
2) Construct line segments by conjoining lines that start and end at the same place, with the same angle
3) Compute structural description (graph, where edges denote the structural relations). Compute one for each segment of the character. Then construct the whole character by combining segments, with more structural relations.
4) Define some distance metric on graph space
        
I'm not sure how this is handling multiple datapoints. But it seems like it might capture one-shot learning, relatively well.},
author = {Lu, S W and Ren, Ying and Suen, Ching Y},
doi = {10.1016/0031-3203(91)90029-5},
file = {:Users/Brenden/Documents/Mendeley/Lu, Ren, Suen - 1991 - Hierarchical Attributed Graph Representation and Recognition of Handwritten Chinese Characters.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {handwriting},
mendeley-tags = {handwriting},
month = jan,
number = {7},
pages = {617--632},
title = {{Hierarchical Attributed Graph Representation and Recognition of Handwritten Chinese Characters}},
volume = {24},
year = {1991}
}
@article{Luce1977,
annote = {The probability of choosing an item in a set is not affected by the addition or subtraction of other elements:
        
Thus P(i) \propto w_i
        
is a formal way to state this. But there are many counter-examples. 
        
Comments:
Tversky 1977, which criticizes spatial models of similarity,  probably has some relevance here. He shows examples where adding an element changes the similarity structure of a set.},
author = {Luce, R},
doi = {10.1016/0022-2496(77)90032-3},
file = {:Users/Brenden/Documents/Mendeley/Luce - 1977 - The choice axiom after twenty years.pdf:pdf},
issn = {00222496},
journal = {Journal of Mathematical Psychology},
month = jun,
number = {3},
pages = {215--233},
title = {{The choice axiom after twenty years}},
volume = {15},
year = {1977}
}
@article{Luck1996,
annote = {Semantic processing still happens during the attentional blink, even though we can't report what happened. Shows remarkable modularity.
        
Supports a late selection theory of attention.
        
--
        
EEG 
N400 peak represents mismatch of semantic context and future content
        
Targets were in red, subjects had to respond whether the first tartget was an odd or even number. Second target was a word, and they had to report whether the probe word was related to a context word
        
Attentional blink is strongest at lag 2-3, weaker at 6-8, and no impairment at 1 (Fig 2a)
        
N400 detects semantic mismatch either way, although subjects cannot report this aftewards},
author = {Luck, Steven J and Vogel, Edward K and Shapiro, Kimron L},
file = {:Users/Brenden/Documents/Mendeley/Luck, Vogel, Shapiro - 1996 - Word meanings can be accessed but not reported during the attentional blink.pdf:pdf},
journal = {Nature},
keywords = {attention,classic psychology},
mendeley-tags = {attention,classic psychology},
pages = {616--618},
title = {{Word meanings can be accessed but not reported during the attentional blink}},
volume = {383},
year = {1996}
}
@article{Ma2006,
abstract = {Recent psychophysical experiments indicate that humans perform near-optimal Bayesian inference in a wide variety of tasks, ranging from cue integration to decision making to motor control. This implies that neurons both represent probability distributions and combine those distributions according to a close approximation to Bayes' rule. At first sight, it would seem that the high variability in the responses of cortical neurons would make it difficult to implement such optimal statistical inference in cortical circuits. We argue that, in fact, this variability implies that populations of neurons automatically represent probability distributions over the stimulus, a type of code we call probabilistic population codes. Moreover, we demonstrate that the Poisson-like variability observed in cortex reduces a broad class of Bayesian inference to simple linear combinations of populations of neural activity. These results hold for arbitrary probability distributions over the stimulus, for tuning curves of arbitrary shape and for realistic neuronal variability.},
author = {Ma, WJ and Beck, JM and Latham, PE and Pouget, A},
file = {:Users/Brenden/Documents/Mendeley/Ma et al. - 2006 - Bayesian inference with probabilistic population codes.pdf:pdf},
institution = {Department of Brain and Cognitive Sciences, Meliora Hall, University of Rochester, Rochester, New York 14627, USA.},
journal = {Nature Neuroscience},
number = {11},
pages = {1432--1438},
publisher = {Nature Publishing Group},
title = {{Bayesian inference with probabilistic population codes.}},
volume = {9},
year = {2006}
}
@article{Machery2007,
abstract = {The operationalization of scientific notions is instrumental in enabling experimental evidence to bear on scientific propositions. Conceptual change should thus translate into operationalization change. This article describes some important experimental works in the psychology of concepts since the beginning of the twentieth century. It is argued that since the early days of this field, psychologists' theoretical understanding of concepts has been modified several times. However, in all cases but one, these theoretical changes did not translate into changes in the operationalization of the notion of concept learning.},
annote = {Main point: while there have been theoretical changes in the notion of a concept, there are surprisingly few operationalization changes
        
Similar experimental design since early 1900s
        
The only clear change in operationalization was from conscious access to genearlization -- in Hull's work.
        
Thus changes in the definition of concepts has not been because of experimental reasons
Comments: But what about exemplar models and the current emphasis on fitting quantitative aspects of data?
        
        Introspective tradition: Fisher 1916        
        
First artificial concept learning task. Concepts had a classical definition
        
Wanted to know how subjects consciously grasp a concept. 
        
Subjects saw stimuli, and then were asked to furnish a detailed introspective account. 
        
Operationalization: They repeated this every week, and acquired the concept when their conscious definition did not change in two subsequent weeks.
        
        Functional tradition: Hull 1920
                
Hull became a famous behaviorist who studied biological factors in motivation and learning. Also started the scientific study of hypnosis.
                  
First experimental study of concept learning that relies on behavioral data -- not introspection.        
        
He was interested in order effects on acquiring character concepts.
        
Seems influenced by the functional approach -- how having a concept changes behavior. 
        
Definition of concept: some conscious knolwedge of a criteria for membership in this category. But he believed acquiring is unconscious, so introspective reports can be of little use.          
                
Studied  modified Chinese characters -- there were necessary and sufficient conditions for defining them, usually a defining part.
        
Experiment 1: Is it easier to see the simpler examples of a concept first, then the more complex? Or the reverse. The same pack of cards was used until subjects could name all the characters -- and when starting the next pack, you could see if they generalize.           
                
6 packs were used for test aftewards. Subjects are also asked to draw the common part, but this is not used.          
          
Behaviorism: Smoke 1932
                
Behaviorism was dominant at the time. 
        
Introduces the idea of "negative evidence"
                  
        Concept: Developing a symbolic response to a member of a class. This removes the mentalistic aspect of Fischer and Hull
        
Stimuli were artificial with necessary and sufficient definition
        
The best measure of difficulty of a concept is the speed it takes to learn it          
                
Also looks at generalization to new exampes, so operationalization is the same as Hull's          
          
Cognitive: Rosch and Mervis 1975        
        
Definition of concept is not in terms of conscious knowledge, but it is also cognitive
        
Prototype theory. To have a concept is to know some properties about that concept. This does not have to be conscious, like Hull or Fisher.
        
Used letter strings with no classical definition.
        
The concept is learned when she makes no mistake at the end of training period -- this is the same operationalization as Hull or Smoke, but with the training items only},
author = {Machery, Edouard},
doi = {10.1016/j.shpsc.2006.12.005},
file = {:Users/Brenden/Documents/Mendeley/Machery - 2007 - 100 Years of Psychology of Concepts the Theoretical Notion of Concept and Its Operationalization.pdf:pdf},
issn = {1369-8486},
journal = {Studies in history and philosophy of biological and biomedical sciences},
keywords = {20th Century,Behaviorism,Behaviorism: history,Cognitive Science,Cognitive Science: history,Concept Formation,Experimental,Experimental: history,History,Humans,Learning,Psychology,Psychology: history},
month = mar,
number = {1},
pages = {63--84},
pmid = {17324809},
title = {{100 Years of Psychology of Concepts: the Theoretical Notion of Concept and Its Operationalization.}},
volume = {38},
year = {2007}
}
@book{MacKay2003,
address = {Cambridge, UK},
annote = {Introduction to information theory

        
Most communication channels are noisy
- DNA has mutations

        
How do we deal with noise?
- we could improve the physical characteristics of the device
- or we could try to correct errors

        
System solution
- encode the message, by adding some redundancy
- decoder infers original message + noise

        
If you have some bit flipping probability, you could transmit each bit 3 times in a row, and take the majority rule for each one
+ this is the optimal decoder (easy to prove)
+ obviously, this makes everything less efficient

        
Block code : convert a equence of bits s, of length K, to a sequence of length N (where extra bits are a linear function of the original bits)

        
Hamming code (7 bits for every 4)
- first extra bit is a partiy check of the first 3 source bits (if the sum is even or odd)
- second is parity of the last 3
- third is parity of source bits 3 and 4
- linear with modulo 2 arithmetic

        
Decoding with Hamming code
- syondrome is the pattern of parity checks that is violated
- find smallest set of flipped bits that can account for violation so parity rules
- the optimal decoder, if you  check all the cases, unflips at most one bit at any given point
- any 2-bit error will not be decoded properly
- can make a maximum likelihood decoder, which finds the most probably noise vector for explaining the received signal

        
What is the best possible code?
There seems to be a trade-off between the error probability p_b and the rate R (which is how much info you can transmit)
- it seemed that there was a boundary between achievable/unachievable, passing through the origin (with no noise but no rate)
- Shannon proved that this boundary meets at a non-zero value of the rate (noiseless). For any channel, there exists a code that make it possible to communicate with arbitrariyl small probability of err

        
          
results: noisy-channel coding theorem
+ first half of this book is about understanding this result
+ information theory addresses both the limitations nad possibilites of communication

        
          
Part 1
        
Data compression

        
Chapter: how you measure the information content of an outcome of an experiment

        
Shannon information content: 
h(x=a) = log_2 1 / p_a

        
entropy:
expectation of the information (average information content)

        
binary entropy: maximum whne p=0.5

        
why is information 1/p?
+ we want it to be additive when random variables are independent

        
if we are designing a sequence of experiments, we want to get the maximum information for each experiment

        
entropy is largest when all random variables are uniform -- thus, this is also maximally informative 

        
If you have to guess a random number, between 0 and 63, by asking inequalities? A reasonable strategy is binary search, which corresponds to binary encoding

        
Game of submarine -- where it hides in just one square on the board
--
Ruling out half of the hypotheses, if they are equal sized, gives 1 "bit" of information
- regradless of when we hit the submarine, we always get 6 bits of information total

        
raw bit content: the number of possible outcomes in an experiment (can be used to compute a lower bound on the entropy)
+ there is no way to make a compressor that does better than this for all possible programs
- a loseless compressor necessailry makes some files longer, while making other shorter

        

        
You can define a delta-sufficient subset, which is the smallest subset such that the probability of having a draw in that subset is greater than 1-delta (it picks out the strongest elements)

        
Essential bit content of X: log_2 |delta-subset | 

        
You have larger etropy (bit content) for smaller values of delta. 

        
However, in the case of repeated experiments with N observations, the average entropy of a trial is almost independent of delta. This is the "source coding theorem"

        
theorem: average entropy, across multiple trials, given any delta, can be arbitrariyl close to the real entropy of the distribution

        
another way: N iid observation sof a random variable X, with entropy H(X), can be compressed into more than NH(X) with negligble risk of information loss, as n -> inf, if theya re compressed into fewer bits, it is almost certain that information will be lost

        

        Symbol codes

          

        Entropy is a measure of average information content, in terms of how much compression is required to represent the probability distribution

        
we can incode N iid variables into a block of N(H(x)+epsilon) bits with vanishing probability of error, where fewer bits means more error. 

        
Inuition: This is because if the observations clump, we need fewer bits to encode them

        
What is a partical algorithm for encoding?

        
source coding theorem: there is a variable-length ecoding C of an ensmeble X such that the average length is related to its entropy

        
constructive Huffman coding produces optimal code

        
 symbol codes

        
useful codes:
- unique decoding
- easy to decode
- as much compression as possible

        
Thus, information theory predicts shorter codes for words the occur most often, or occur most often in context

        
prefix code: if no codeword is a prefix for any other codeword (thus, we don't need puncation)... they correspond to trees
- hence, you always know where the breaks are
- you don't lose anthing by using prefix codes

        
expected length is a useful statistics

        
The expected length of an optimal code is equal to its entropy

        
Optimal source codelengths: the expected length is minimized, as is equall to H(X), only if the codelengths are equal to the Shannon information

        
l = log_2(1/p_i) [longer codes for rare events]

        
source coding theorem for symbol codes: for an ensemble X, there exist a prefix code C with expected length between the entropy and the entropy + 1

        
relative entropy (KL divergence): if we use the wrong codelength, with defines a distribution Q implicity, the average length is larger than the entropy by the KL divergence

        
Huffman coding algorithm:
start backwards, taking the two least probable symbosl, and assigning them the longest codewords, with equal length, differing only in the lat digit
+ combine symbols in one (event), and repeat
+ this will build up a code recursively},
author = {MacKay, David J},
file = {:Users/Brenden/Documents/Mendeley/MacKay - 2003 - Information Theory, Inference, and Learning Algorithms.pdf:pdf},
keywords = {graphical models},
mendeley-tags = {graphical models},
publisher = {Cambridge University Press},
title = {{Information Theory, Inference, and Learning Algorithms}},
year = {2003}
}
@article{Mahon2009,
abstract = {One of the most provocative and exciting issues in cognitive science is how neural specificity for semantic categories of common objects arises in the functional architecture of the brain. More than two decades of research on the neuropsychological phenomenon of category-specific semantic deficits has generated detailed claims about the organization and representation of conceptual knowledge. More recently, researchers have sought to test hypotheses developed on the basis of neuropsychological evidence with functional imaging. From those two fields, the empirical generalization emerges that object domain and sensory modality jointly constrain the organization of knowledge in the brain. At the same time, research within the embodied cognition framework has highlighted the need to articulate how information is communicated between the sensory and motor systems, and processes that represent and generalize abstract information. Those developments point toward a new approach for understanding category specificity in terms of the coordinated influences of diverse regions and cognitive systems.},
author = {Mahon, Bradford Z and Caramazza, Alfonso},
doi = {10.1146/annurev.psych.60.110707.163532},
file = {:Users/Brenden/Documents/Mendeley/Mahon, Caramazza - 2009 - Concepts and categories A cognitive neuropsychological perspective.pdf:pdf},
issn = {0066-4308},
journal = {Annual review of psychology},
keywords = {Animals,Anomia,Anomia: diagnosis,Anomia: physiopathology,Anomia: psychology,Aphasia,Aphasia: diagnosis,Aphasia: physiopathology,Aphasia: psychology,Apraxias,Apraxias: diagnosis,Apraxias: physiopathology,Apraxias: psychology,Brain,Brain Mapping,Brain: physiopathology,Concept Formation,Concept Formation: physiology,Decision Making,Decision Making: physiology,Discrimination Learning,Discrimination Learning: physiology,Humans,Magnetic Resonance Imaging,Nerve Net,Nerve Net: physiopathology,Neuropsychological Tests,Oxygen,Oxygen: blood,Psychomotor Performance,Psychomotor Performance: physiology,Recognition (Psychology),Recognition (Psychology): physiology,Semantics,classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
month = jan,
pages = {27--51},
pmid = {18767921},
title = {{Concepts and categories: A cognitive neuropsychological perspective}},
volume = {60},
year = {2009}
}
@article{Makuuchi2009,
abstract = {In contrast to simple structures in animal vocal behavior, hierarchical structures such as center-embedded sentences manifest the core computational faculty of human language. Previous artificial grammar learning studies found that the left pars opercularis (LPO) subserves the processing of hierarchical structures. However, it is not clear whether this area is activated by the structural complexity per se or by the increased memory load entailed in processing hierarchical structures. To dissociate the effect of structural complexity from the effect of memory cost, we conducted a functional magnetic resonance imaging study of German sentence processing with a 2-way factorial design tapping structural complexity (with/without hierarchical structure, i.e., center-embedding of clauses) and working memory load (long/short distance between syntactically dependent elements; i.e., subject nouns and their respective verbs). Functional imaging data revealed that the processes for structure and memory operate separately but co-operatively in the left inferior frontal gyrus; activities in the LPO increased as a function of structural complexity, whereas activities in the left inferior frontal sulcus (LIFS) were modulated by the distance over which the syntactic information had to be transferred. Diffusion tensor imaging showed that these 2 regions were interconnected through white matter fibers. Moreover, functional coupling between the 2 regions was found to increase during the processing of complex, hierarchically structured sentences. These results suggest a neuroanatomical segregation of syntax-related aspects represented in the LPO from memory-related aspects reflected in the LIFS, which are, however, highly interconnected functionally and anatomically.},
annote = {Talk on Oct 2 at MIT
        
What makes humans special? Chomsky, Hauser, Fitch helped raise the question
        
20th century view
syntax area: Broca's area
semantic area: Wernicke's area
        
Brodmann's area 44 and 45
- semantic area shows asymmetry across hemispheres, for 44, earlier
-  syntax area shows asymmetry later, for 45
        
You can compare:
- correct sentences
- semantically incorrect sentence
- syntax incorrect sentence
        
Some areas are specific to one or the other, others are responsive to both
        
ERP - by averaging the EEG signal for spefic events, you get event related brain potentials
        
P600 - seems to be present in syntax violations, a decrase in signal around 600 ms which is broadly distributed across the posterior of the brain
        
grodizinsky: syntax is located in broca's area
        
meta-analysis of syntatic processing... there is a lot around Broca's area, but it is also spread out
        
Does broca's area increase in signal with increasing syntax complexity?
- In German, since you have case marking, you can use the same sentence and increase the complexity by scrambling the words
        
Experiment:
- train people on artificail grammars (finite state grammar, and phrase sturcture grammar - which cotton top tamarins can't learn, hierarchial dependence)
        
Broca's area is more active when learning the hierarchial structure
        
But, BA44 and BA45 have also been implicated in working memory, so how do we know what the issue is?
        
They had a design to tease these apart
        
Dissociation:
complex hierarchial structure in BA 44 (so these can be teased apart in German)
distance effect in left inferior frontal sulcus
These two areas work in concern
                  
Conclusions
                
Two syntatic network
1) local phrase structure (net 1)
- frontal operculum
- anterior STG
(near frontal cortex)
2) complex hierarchcail structure (net 2)
- BA 44 (broca's area)
- posterior STG/STS
        
addtional DTI evidence
        
        
      },
author = {Makuuchi, Michiru and Bahlmann, J\"{o}rg and Anwander, Alfred and Friederici, Angela D},
doi = {10.1073/pnas.0810928106},
file = {:Users/Brenden/Documents/Mendeley/Makuuchi et al. - 2009 - Segregating the core computational faculty of human language from working memory.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Adult,Brain Mapping,Female,Frontal Lobe,Humans,Language,Magnetic Resonance Imaging,Male,Memory,Memory: physiology,Myelinated,Nerve Fibers,Neural Pathways,Temporal Lobe,Young Adult},
month = may,
number = {20},
pages = {8362--7},
pmid = {19416819},
title = {{Segregating the core computational faculty of human language from working memory.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2688876&tool=pmcentrez&rendertype=abstract},
volume = {106},
year = {2009}
}
@article{Malioutov2006,
author = {Malioutov, Dmitry M and Johnson, Jason K and Willsky, Alan S},
file = {:Users/Brenden/Documents/Mendeley/Malioutov, Johnson, Willsky - 2006 - Walk-Sums and Belief Propagation in Gaussian Graphical Models.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {GGM,convergence of loopy belief,gaussian graphical models,propaga-,sparsity,walk-sum analysis},
mendeley-tags = {GGM,sparsity},
pages = {2031--2064},
title = {{Walk-Sums and Belief Propagation in Gaussian Graphical Models}},
volume = {7},
year = {2006}
}
@article{Maloney1986,
author = {Maloney, Laurence T and Wandell, Brian A},
file = {:Users/Brenden/Documents/Mendeley/Maloney, Wandell - 1986 - Color constancy a method for recovering surface spectral reflectance.pdf:pdf},
journal = {Journal of the Optical Society of America},
keywords = {feature prediction},
mendeley-tags = {feature prediction},
number = {1},
pages = {29--33},
title = {{Color constancy: a method for recovering surface spectral reflectance}},
volume = {3},
year = {1986}
}
@incollection{Mamassian2001,
annote = {The study of perceptual decision making is spread across multiple discliplines, giving the appearance of a bunch of heterogenous models
        
Alternative: Bayesian decision theroy
        
Visual perception is an ill-posd problem
        
Necker cube: consistent with a large set of possible polyhedra, yet people only see two, and they only see one at a time
        
Why? Certain interpretaitons are favored a priori
        
Bayesian decision theory:
        
Choice action, given the posterior, maximizes expected gain, which integrates over all possible latent variables given the posterior
        
different loss fuctions (mean squared error, etc.) are associated with different rules to maximizes score},
author = {Mamassian, Pascal and Landy, Michael and Maloney, Laurence T},
booktitle = {Probabilistic Models of the Brain: Perception and Neural Function},
file = {:Users/Brenden/Documents/Mendeley/Mamassian, Landy, Maloney - 2001 - Bayesian Modelling of Visual Perception.pdf:pdf},
pages = {13--36},
title = {{Bayesian Modelling of Visual Perception}},
year = {2001}
}
@book{Manning1999,
annote = {Chapter 11: Probabilistic context free grammar
        
Sentences have a tree structure, with heads and dependents. This is not captured by the linearity of HMMs, so PCFGs are a reaction to this.
        
Given the conditional independencies, you can calculate the probability of a parse by multipling the probability of each of the individual rules.
        
Analgous to the forward-backward algorithm or viterbi algorithm, there is an inside-out algorithm for PCFGS that allow you to compute the marginal probability of the data, without summing over all possible trees.
        
Probabilist regular grammar is an HMM, wiht a desginated start state and a sink state which you cannot leave.
        
It is possible to write down recursive models that do not sum to one. Some of the probaiblity mass gets lost in the infinite set of paths. This is not usually a problem, if we are just evaluating ratios. But this is still concerning in general.. how do you know when this happens?
        
Using this, one can do EM to learn the probabiltieis associated with various rules. But this is highly prone to local maxima.
                  
Chapter 12: Parsing
                
Grammar induction is very hard, and there is little success in inducing grammars from raw text.
        
Parsing is also very complicated... much more so that computing the probability of the data while marginalizing over trees.
        
Which is the right tree to fit the data? Didn't see examples of explicit calculations in this section.. focus was on building richer models
      },
author = {Manning, Christopher D and Sch\"{u}tze, Hinrich},
title = {{Foundations of statistical natural language processing}},
year = {1999}
}
@inproceedings{Mansinghka,
annote = {Vision as inverse graphics: goes back to helmholtz and monk
        
More of an inspiring idea than a technology
        
Key ideas
- general inference
- use variant of approximate bayesian computation - where you don't evaluate the likelihood
- Bayesian relaxtions for automatic annealing
        
Model:
- stochastic scene generator
- approximate renderer, with a variable that controls blur
- then approximate likelihood, again with a fidelity variable
        
captcha model
- objects can be on or off (fixed number)
- blur parameters
(Bayesian relaxation)
+ grealty helps convergence
        
Road example:
- road parameters
- competitive with bottom-up line finders
        
Key elements:
- probabilistic programming, that invokes graphics 
- general purpose inference
- approximate basyesian comp
- adaptive noise
      },
author = {Mansinghka, Vikash K},
booktitle = {Advances in Neural Information Processing Systems 26},
file = {:Users/Brenden/Documents/Mendeley/Mansinghka - Unknown - Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs.pdf:pdf},
title = {{Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs}}
}
@inproceedings{Mansinghka2013,
author = {Mansinghka, Vikash K and Kulkarni, Tejas D and Perov, Yura N and Tenenbaum, Joshua B.},
booktitle = {Advances in Neural Information Processing Systems 26},
file = {:Users/Brenden/Documents/Mendeley/Mansinghka et al. - 2013 - Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs.pdf:pdf},
keywords = {program induction},
mendeley-tags = {program induction},
title = {{Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs}},
year = {2013}
}
@article{Marcus1999,
annote = {What mechanisms are available to an infant on the cusp of learning langauge?
        
Saffran et al. purely statistical learning
        
Is statistica enough, or do you also need "algebaric" rules?
- which are open ended abstract relationships
        
No direct evidence that young infants can learn simplified versions of algebaric rules
- there is some suggestive evidence of rules, but it is almost always consistent with a simpler statistical account
        
Design
        
7 mo
        
Tried to teach abstract grammar, where transition probabilities have no influence
        
Conditions:
ABA :  
ABB : 
        
In ABA, 2-min of speech containing three sentences that followed an ABA gramar "ga ti ga"
        
In test phase, 12 sentences that consisted of entirely new words, 
- half were consistent
        
15/16 infants showed a preference for the inconsistent sentences, indicated by looking longer at a flashing side light during presentations of those sentences
        
        Experiment 2
                
There was still an overlap of some of the phonetic features (like voicing)
- more carefully constructed set of words
        
Results
15/16 infants looked longer during presentation of the inconsisnte items
                  
Experiment 3
                
Rather than AAB and ABA, where there is a duplication problem, they also tried
AAB vs. ABB 
All 16/16 looked longer at inconsistent items
                  
Discusison
                
SRN: only works by training on items that apply to all of them
        
System that accounts for their result learns algebra-like rules, representing placeholsd (variables)
- rules can be extracted easily from small amounts of data
        
      },
author = {Marcus, G F and Vijayan, S and {Bandi Rao}, S and Vishton, P M},
doi = {10.1126/science.283.5398.77},
file = {:Users/Brenden/Documents/Mendeley/Marcus et al. - 1999 - Rule Learning by Seven-Month-Old Infants.pdf:pdf},
issn = {00368075},
journal = {Science},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
month = jan,
number = {5398},
pages = {77--80},
title = {{Rule Learning by Seven-Month-Old Infants}},
volume = {283},
year = {1999}
}
@article{Marcus2013,
annote = {Some reasonable points:
- prior should be measured independently of the task at hand
- acknowledge that there are many Bayesian models for any task, and thus people may not be "optimal"
        
Some response points:
- Some of the alternative analyses are quite silly
- Are other modeling approaches immune to such critcisms? Neural networks have way more tuneable parameters -- where is the a prior justification?
- At least the assumptions/parameters are interpretable and verifiable
- also, all models engage in task selection, and there are plenty of tasks they cannot do
        
------          
introduction
                
Bayesian models remarkably successful, with good quantitaitve fits, in many domains of cognition
        
The approach has rarely been criticized
        
Two problems:
- task selection
- model selection
                  
Task selection
                
Battaglia et al.: good quantitative fit with tower tasks
+ but misses trajectory of a swining rock
        
Marcus applied model to balance beam task, with Gaussian noise around position of pegs
+ with any reasonable amount of noise, the model always gets the answer right, which is not true in Siegler's task
        
For most domains where there is apparently optimal performance, there are others phenomena that seem apparently nonoptimal
        
It seems Bayesian models are doing breadth first rather than depth first search. Don't just try a small number of tasks in each domain
        
        Model selection        
        
Griffiths and Tenenbaum predicting the future
- very good fits, but it depends heavily on how the priors are chosen
- if they are chosen post hoc, the true fit of the model will be overestimated
- poem question: your friend reads you her favorite line of a poem... which they assumed was uniform over the length of poems
- first, they used a plotting trick, where a lot of the fit is driven by knowing the poem must be at LEAST this long
        
- also, favorite lines tend to be first or last. If you incoporate this fact, the model fits rather poorly now
-also, for movies, the earnings are front-loaded, and it would lead to sub-optimalities
        
Frank and Goodman science paper
- model depended on assumption that people choose a word with probability proportional to the word's specificity
+ this is a common decision rule, but people might also follow the maximum-expected-utility rule
+ this analysis seems a bit silly, since they took out the stochasticity of the model by making choice determinsitic...which is rarely is (probability matching?)
        
But they did ask the question in a strange way, in terms of placing bets, rather than by asking "which word would you use?"
        
Decision rule often changes (how you take distribution and give answer), and is picked post-hoc
        
"a response that can be rationalized is not the same as a response that is rational"
                  
Discussion
                
It is too strong to say that people are never normative, but it is also too strong to say that they are always normative
        
Often, there are multiple Bayesian models for any given task, with different predictions. They aren't an "ideal observer" for the task
        
The model is very suitable for sensory motor tasks, and cue combination
        
For other domains, there is no reason to invoke a probabilistic model, and it appears the task has been made to fit the model
        
We should develop a clear criterio for what would not  cound as Bayesian performance
        
----
        
Seems to criticize using models for probability matching, but this is standard Luce choice rule! },
author = {Marcus, Gary F and Davis, Ernest},
doi = {10.1177/0956797613495418},
file = {:Users/Brenden/Documents/Mendeley/Marcus, Davis - 2013 - How Robust are Probabilistic Models of Higher-Level Cognition.pdf:pdf;:Users/Brenden/Documents/Mendeley/Marcus, Davis - 2013 - How Robust are Probabilistic Models of Higher-Level Cognition(2).pdf:pdf},
journal = {Psychological Science},
keywords = {13,27,8,bayesian models,be seen as an,cognition,engine of proba-,optimality,received 1,revision accepted 5,s,should the human mind},
number = {October},
title = {{How Robust are Probabilistic Models of Higher-Level Cognition?}},
year = {2013}
}
@article{Marcus1998,
author = {Marcus, GF},
file = {:Users/Brenden/Documents/Mendeley/Marcus - 1998 - Rethinking Eliminative Connectionism.pdf:pdf},
journal = {Cognitive psychology},
keywords = {connectionism},
mendeley-tags = {connectionism},
number = {37},
pages = {243--282},
title = {{Rethinking Eliminative Connectionism}},
volume = {282},
year = {1998}
}
@article{Margolin1983,
annote = {Disorders of handwriting can give insight into motor control.
        
Stroke patient, with severe damage to on side of his brain, resulting in paralysis
        
Writing of letters is severly impaired. Only when copying individual letters is it somewhat readable
        
When writing cursive, the patient tended to duplicate strokes, like writing the up-loop of a cursive f twice rather than adding in a down-loop},
author = {Margolin, David I and Wing, Alan M},
file = {:Users/Brenden/Documents/Mendeley/Margolin, Wing - 1983 - Agraphia and micrographia Clinical manifestations of motor programming and performance disorders.pdf:pdf},
journal = {Acta Psychologica},
keywords = {handwriting},
mendeley-tags = {handwriting},
pages = {263--283},
title = {{Agraphia and micrographia: Clinical manifestations of motor programming and performance disorders}},
volume = {54},
year = {1983}
}
@article{Marinkovic2003,
abstract = {The ability of written and spoken words to access the same semantic meaning provides a test case for the multimodal convergence of information from sensory to associative areas. Using anatomically constrained magnetoencephalography (aMEG), the present study investigated the stages of word comprehension in real time in the auditory and visual modalities, as subjects participated in a semantic judgment task. Activity spread from the primary sensory areas along the respective ventral processing streams and converged in anterior temporal and inferior prefrontal regions, primarily on the left at around 400 ms. Comparison of response patterns during repetition priming between the two modalities suggest that they are initiated by modality-specific memory systems, but that they are eventually elaborated mainly in supramodal areas.},
author = {Marinkovic, Ksenija and Dhond, Rupali P and Dale, Anders M and Glessner, Maureen and Carr, Valerie and Halgren, Eric},
file = {:Users/Brenden/Documents/Mendeley/Marinkovic et al. - 2003 - Spatiotemporal dynamics of modality-specific and supramodal word processing.pdf:pdf},
issn = {0896-6273},
journal = {Neuron},
keywords = {Adult,Auditory,Auditory: physiology,Brain Mapping,Cerebral Cortex,Cerebral Cortex: anatomy & histology,Cerebral Cortex: physiology,Evoked Potentials,Functional Laterality,Functional Laterality: physiology,Humans,Magnetoencephalography,Male,Neural Pathways,Neural Pathways: anatomy & histology,Neural Pathways: physiology,Neuropsychological Tests,Pattern Recognition,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Reading,Speech Perception,Speech Perception: physiology,Verbal Behavior,Verbal Behavior: physiology,Visual,Visual: physiology},
month = may,
number = {3},
pages = {487--97},
pmid = {12741994},
title = {{Spatiotemporal dynamics of modality-specific and supramodal word processing.}},
volume = {38},
year = {2003}
}
@inproceedings{Markant2012,
annote = {People select data all-along the boundaries in a multi-category learning task. This is not predicted by rational models that select data based on information gain.
        
---
What is more effective for learning: selection or reception?
        
Is it beneficial to pick your own data?
        
Perceptual category learning task.
        
Category was one-dimensional division
        
Self-directed has a clear advantage for, in terms of speed, for learning
        
But for a diagonal category, it does not help to have selection.
        
Attention is quickly focused on the boundary, rather than in other places.
                  
model: can uncertaintly predict whether or not it will be selected?
        
model 1: seeking confirmation (pick most certain examples), or least certain exapmles
        
model 2: reducing global uncertainty -- higest classification uncertainty. consistent with normative accounts
        
model 3:sampling at the "margins". Pick ones that could belong to either two categories, but not necessarily the most uncertain (only makes a difference for 2+ categories)
        
about half of people were fit best by model 2, other half best fit by model 3
        
Used probability ratings, not a model-based approach, to decide which stimuli are the most uncertain
        
conclusions
- At least in some cases, this allows us to learn categories more efficiently
- This is not predicted by "normative models" that only going with the most uncertain regions
+ even if you make the task just a little more complicated, you can see thsi model doesn't fit
+ There is little evidence that people have a fixed sampling strategy       
        
      },
author = {Markant, Doug and Gureckis, Todd},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Markant, Gureckis - 2012 - One piece at a time Learning complex rules through self-directed sampling.pdf:pdf},
title = {{One piece at a time: Learning complex rules through self-directed sampling}},
year = {2012}
}
@article{Markant2013,
abstract = {People can test hypotheses through either selection or reception. In a selection task, the learner actively chooses observations to test his or her beliefs, whereas in reception tasks data are passively encountered. People routinely use both forms of testing in everyday life, but the critical psychological differences between selection and reception learning remain poorly understood. One hypothesis is that selection learning improves learning performance by enhancing generic cognitive processes related to motivation, attention, and engagement. Alternatively, we suggest that differences between these 2 learning modes derives from a hypothesis-dependent sampling bias that is introduced when a person collects data to test his or her own individual hypothesis. Drawing on influential models of sequential hypothesis-testing behavior, we show that such a bias (a) can lead to the collection of data that facilitates learning compared with reception learning and (b) can be more effective than observing the selections of another person. We then report a novel experiment based on a popular category learning paradigm that compares reception and selection learning. We additionally compare selection learners to a set of "yoked" participants who viewed the exact same sequence of observations under reception conditions. The results revealed systematic differences in performance that depended on the learner's role in collecting information and the abstract structure of the problem. (PsycINFO Database Record (c) 2013 APA, all rights reserved).},
annote = {Comments: they did find they could predict category boundaries based on test blocks, and that distance to these subjective boundaries were more informative

        
can I look at the data collected on adaptive teachers?

        
———————
Bayesian models predict that choosing your own data doesn't matter, but it seems to matter quite a bit

        
They explain it as using MH with a limited memory, which seems very reasonable

        
-- 
Bruner et al (1956) described difference between active and passive paradigm

        
theory: hypothesis-dependent sampling bias, where learners select observations based on what they currently have in mind
+ thus, the same sequence of observations will be less helpful to other learners

        
science is also a process of active hypothesis testing, and Popper famously argued this is a good way to do science

        
in causal learning, selection has consisntely shown to improve learning
- this is critical, because you often have to actively intervene to distinguish causal networks

        
But it may not be beneficial, and some evidence it hurts for complex concepts

        
In machine learning, labels are expensive, so active learing allows only the collection of labels for important data

        
Previous studies have found that yoked learners are slower to learn, even though they have less attention demands. How come? Data is less-well-matched to the mental states
- however, it is aslo possible that selection learners have better attention and improed memory
- deeper processing        

        
For a Bayesian learning, the yoked learner vs. the active learner would not make different model predictions
+ only for a weak bayesian learner, that makes no assumptio about sampling process
++ their description here isn't quite right
+ but, in Xu and Tenenbaum, the same data can lead to very different generalizations                ?
+ thus, they argue for a process-level account of the effect. But couldn't it be a computational-level effect based on how the data was sampled?

        
"win-stay, lose shift", where you only change hypotheses if it is inconsistent with the data

        
Other models

        
assumption 1: single hypothesis        
sequential hypothesis learning, or win-stay lose shift.

        
assumption 2: choose data points near boundary of category
  - if this bias is weak, then there is less of a difference between conditions      

        
thus, the yoked learner differs from the selection learner in terms of the initial hypothesis, and you have these assumptions, you can get a major differnece in performance

        
Task

        
simple dimensional category or          

        
information-integration: 
where there is no verbal rule, so you have to learn it implicitly (and doesn't work well unsupervised)

        
Other conditions:
- observational learning
- active learning
- yoked learning (aware and naive)

        
260 total participants

        
stimuli
2 dimensions
- size of circle
- angle of centrlal diameter (vary over 150 deg)
- told they were loop attenas for televions tuned to one of two channels (1 or 2)
+ sometimes noisy

        
training phase: all conditions, they saw a sequence of stimuli but made no explicit prediction (observational learning)
- ideal for self-directed, because otherwise people would just want to get all of the items "correct"

        
Some participants could manipulate the stimuli before getting feedback, while others could not

        
test trials: each set of 16 training trials were followed by 32 test trials (asked for a response, and no feedback was provided)
- also collected confidence

        
Results

        
analysis of selection learning
over time, people were increasingly likely to sample more closely to the true category boundary, but more shift in the RB (rule based) task rather than II (information integration)

        
average sample distance
-main effect of category type, where information integration is much hrader          
- People tended to sample near the boundary more over time, and more so for the simple category

        
analysis of test accuracy
- main effect of task, where RB was easier
- for RB, selection learners were more accurate than both yoked learners, and marginally more than reception
- for II task, no difference between selection and reception, but both were better than yoked
++ no difference between two yoked conditions

        
Interestingly, selection learners who sampled further away from the boundary had worse performance
- while yoked participants that received a lot of data near the boundary were among the worst performers, which is tough to explain with a bayesian account

        
Very hard to explain with something other than the dependent sampling based account

        
decision bound analysis

        
Maybe if we fit a linear decision bound to each test block, we will have better predictive power on how distance from boundary effects performance?
- previous analysis was distance from true category. Here, they looked at distance to the estimated boundary from the previous test block
- again, they found that smile distance was strongly correlated
- unlike the previous analysis, there was a trend towards the same relationship for yoked participants 

        
- learners in the II task are more likely to make large changes from block to block in their decision boundary
+ and this is even worse for yoked learners, suggesting the difference may be due to searching for the right form of boundary

        
discussion

        
notable that active learning participants are successful at all, given large literature on selection bias
- yoked participants were worse in both tasks, particularly RB    

        
model

        
- prior that favors unidimensional rules, where model is over linear classifiers
- MH rule for switching hypotheses, which is similar to "win-stay-lose-shift”\ldots is it?
+ there is one proposal per trial, where we get a new data point

        
- limited memory, where we consider only the last n observations
- hypothesis-dependent sampling bias, where you pick the next data point from a region around the current boudnary

        
---------

        
why does active learning help? Because of limited memory, sampling along the boundary is more useful 

        
Related to Xu and Tenenbaum, where they compared weak and strong sampling. Weak is selected by the learner, and strong is selected by the "concept" and provides information.
It's not clear how this explains the data in the current sutdy

      },
author = {Markant, Douglas B and Gureckis, Todd M},
doi = {10.1037/a0032108},
file = {:Users/Brenden/Documents/Mendeley/Markant, Gureckis - 2013 - Is It Better to Select or to Receive Learning via Active and Passive Hypothesis Testing.pdf:pdf},
issn = {1939-2222},
journal = {Journal of experimental psychology. General},
keywords = {a set of alter-,and,bayesian modeling,category learning,dependent sampling bias,either explicitly or implicitly,hypothesis testing,hypothesis testing refers to,hypothesis-,native conceptions of the,self-directed learning,the act of generating,world},
month = mar,
number = {2},
pmid = {23527948},
title = {{Is It Better to Select or to Receive? Learning via Active and Passive Hypothesis Testing.}},
volume = {142},
year = {2013}
}
@article{Markman2003,
annote = {Points out that classification is only one of many uses for category knowledge},
author = {Markman, Arthur B. and Ross, Brian H.},
doi = {10.1037/0033-2909.129.4.592},
file = {:Users/Brenden/Documents/Mendeley/Markman, Ross - 2003 - Category use and category learning.pdf:pdf},
issn = {1939-1455},
journal = {Psychological Bulletin},
keywords = {rich concepts},
mendeley-tags = {rich concepts},
number = {4},
pages = {592--613},
title = {{Category use and category learning}},
volume = {129},
year = {2003}
}
@book{Markman1989,
address = {Cambridge, MA},
annote = {        General: Markman presents a theory of word learner where the learner uses constraints to narrow the hypotheses about the meaning of words.
          
Constraints on word learning:        
1) Words are taxonomic rather than thematic. If the word "fep" refers to Dog 1, children generalize to Dog 2 rather than a Bone.
2) Bias towards the basic level for word meanings, but perhaps for standard basic level reasons (Rosch)
3) Children assume that categories are like natural kinds. They make strong generalizations about properties, even sometimes unjustified ones (weight and size based on labels)
4) Mutual exclusivity -- the famous one. Children only want one name for an object at a time, which is usually the basic level.
Example 1: They deny a mouse is an "animal", although they use "animal" to refer to the collection. This is the best evidence I think.
Example 2: Say a child hears a new word for an object that already has a name. They think the new word refers to either the new object, or a part of the old object.
                  
Relation to learning the structural form:         
"At some point children obviously violate the assumption to allow multiple labels for the same object" (pg 215). Thus, they learn the taxonomy at some point.
                  
Relation to one-shot learning and fast mapping:        
Say a child hears a new word for an object that already has a name. They think the new word refers to either the new object, or a part of the old object. This is like the generalization seen in Carey fast-mapping. There are similar experiments with the taxonomic constraint.},
author = {Markman, Ellen M},
keywords = {fast mapping,one-shot learning,word learning},
mendeley-tags = {fast mapping,one-shot learning,word learning},
publisher = {MIT Press},
title = {{Categorization and Naming in Children}},
year = {1989}
}
@article{Markson1997,
abstract = {Children can learn aspects of the meaning of a new word on the basis of only a few incidental exposures and can retain this knowledge for a long period-a process dubbed 'fast mapping". It is often maintained that fast mapping is the result of a dedicated language mechanism, but it is possible that this same capacity might apply in domains other than language learning. Here we present two experiments in which three- and four-year-old children and adults were taught a novel name and a novel fact about an object, and were tested on their retention immediately, after a 1-week delay or after a 1-month delay. Our findings show that fast mapping is not limited to word learning, suggesting that the capacity to learn and retain new words is the result of learning and memory abilities that are not specific to language.},
annote = {Is fast-mapping the result of a dedicated language mechanism?
        
Fast-mapping. This study is more interesting than most, since children were taught that a new word referred to one object out of 6 novel ones.
        
This word was introduced during a task where subjects measured one object against another, in size
        
Then after a month, they were asked to remember which object it was (but this wasn't a test generalization).
        
Both children and adults perform very well.
        
Evidence for non-dedicated system:
        -- this also works for where the object is from, or "if it was given by an Uncle" or "came from a place called Kob" -- which includes a novel word        
-- doesn't work for arbitrary property like sticker, where you place a sticker and say "this is where the sticker goes"
        
Also, there is no critical period for fast mapping, since this task was readily done by adults as well},
author = {Markson, L and Bloom, P},
doi = {10.1038/385813a0},
file = {:Users/Brenden/Documents/Mendeley/Markson, Bloom - 1997 - Evidence against a dedicated system for word learning in children.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {fast mapping,one-shot learning,word learning},
mendeley-tags = {fast mapping,one-shot learning,word learning},
month = feb,
number = {6619},
pages = {813--5},
pmid = {9039912},
shorttitle = {Nature},
title = {{Evidence against a dedicated system for word learning in children.}},
volume = {385},
year = {1997}
}
@article{Marr1978,
annote = {Early paper on part-based, compositional models of object recognition.
        
Main characteristics:
-- principal axis (length of the human body)
-- parts, or minor axis, are defined in local
coordinates compared to the major axis.
-- sub-parts can be defined recursively from there
-- recognition is likely to work from the general to the specific.
        
Also, famous criteria for a good recognition system.
        
-------
        
        
Famous criterion for a good recognitin system:
        
-- accessibility: the description is not expensive to compute.
-- scope and uniqueness:  shapes should be naturally represented in your system, and they must fall within its scope
-- stability and sensitivity: the representation should be stable across multiple instances, yet sensitive to detail
        
The model design principles
-- object centered coordinate system, so you don't have to enumerate all possible appearances
-- primitives, the elementary units of shape information used in the representation. You can have spheres, cylinders, other shapes etc.
-- organization. How the shape information is organized. Give names to groups of elements, so they can be referenced (like in Winston)
        
Their 3-D model
-- define  a major axis (the length of a sausage), the elongated body of an animal, etc.
-- shapes were generalized cones
The axis-based primitives are like a stick figure, which allows little commitment to details
Components
1. a model axis (the overall extension)
2. component axis and their context, as related to 1 (arms and legs of aperson)
3. internal refernces for the parts
        
You can define this recursively, as in the famous figure (body, arm, fore-arm,hand, finger, etc.)
        
Local coordinates, like angles compared to the principal axis.
        
Learning creates the 3D models, and recognition than uses these representations. The principal axes must be recognized, from either symmetry, features etc.
        
The 2D view must then be converted to the 3D model.
        
Models can be indexed hiearchically, starting with a cylinder, and adding details as necessary (2 legs, 4 legs, etc.). This helps create a measure of structural similarity too
        
Recognition is a gradual process that proceeds from general to specific, starting with general shape.
        
Given that stick figures are so identifiable, does this mean they play a primary role?},
author = {Marr, D and Nishihara, H K},
file = {:Users/Brenden/Documents/Mendeley/Marr, Nishihara - 1978 - Representation and recognition of the spatial organization of three-dimensional shapes.pdf:pdf},
issn = {0080-4649},
journal = {Proceedings of the Royal Society of London. Series B},
keywords = {Form Perception,Humans,Models,Structural,part-based models},
mendeley-tags = {part-based models},
month = feb,
number = {1140},
pages = {269--94},
pmid = {24223},
title = {{Representation and recognition of the spatial organization of three-dimensional shapes.}},
volume = {200},
year = {1978}
}
@book{Marr1982,
address = {San Francisco, CA},
author = {Marr, David C},
publisher = {W.H. Freeman and Company},
title = {{Vision}},
year = {1982}
}
@techreport{Marr,
annote = {Introduction of 4 levels

Algorithmic becomes mechanism and algorithm levels- unsure of difference},
author = {Marr, David and Poggio, T},
file = {:Users/Brenden/Documents/Mendeley/Marr, Poggio - 1976 - From Understanding Computation to Understanding Neural Circuitry.pdf:pdf},
institution = {MIT},
keywords = {classic AI,classic psychology},
mendeley-tags = {classic AI,classic psychology},
title = {{From Understanding Computation to Understanding Neural Circuitry}},
year = {1976}
}
@article{Maye2002,
author = {Maye, J and Werker, J F and Gerken, L},
journal = {Cognition},
pages = {B101--B111},
title = {{Infant sensitivity to distributional information can affect phonetic discrimination}},
volume = {82},
year = {2002}
}
@inproceedings{Mayor2012,
annote = {Consontants are more important the vowels
        
Simulation 1:
Mani & Plunkett (2007)
sounds to infants -- no difference between mispronounciation vowel and consonant phonemes
        
Difference between vowel/constant developmental trends, can be accounted by differences in the size and structure of the infant lexicon
        
Simulation 2:
Infants show graded sensitvity to mis-pronounciation
+ you don not get this in default trace
+ but you do, if you turn down the lateral inhibition},
author = {Mayor, Julien and Plunkett, Kim},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Mayor, Plunkett - 2012 - Going with TRACE beyond Infant Mispronunciation Studies Lexical Networks and Phoneme Competition.pdf:pdf},
keywords = {1,inhibition,language ac-,lateral inhibition at the,phonemic and lexical levels,quisition,see fig,speech perception,with lexical-phonemic feedback and,word learning},
pages = {737--742},
title = {{Going with TRACE beyond Infant Mispronunciation Studies: Lexical Networks and Phoneme Competition}},
year = {2012}
}
@article{Mccandliss2003,
abstract = {Brain imaging studies reliably localize a region of visual cortex that is especially responsive to visual words. This brain specialization is essential to rapid reading ability because it enhances perception of words by becoming specifically tuned to recurring properties of a writing system. The origin of this specialization poses a challenge for evolutionary accounts involving innate mechanisms for functional brain organization. We propose an alternative account, based on studies of other forms of visual expertise (i.e. bird and car experts) that lead to functional reorganization. We argue that the interplay between the unique demands of word reading and the structural constraints of the visual system lead to the emergence of the Visual Word Form Area.},
author = {Mccandliss, B D and Cohen, L and Dehaene, S},
doi = {10.1016/S1364-6613(03)00134-7},
file = {:Users/Brenden/Documents/Mendeley/Mccandliss, Cohen, Dehaene - 2003 - The visual word form area expertise for reading in the fusiform gyrus.pdf:pdf},
institution = {Sackler Institute for Developmental Psychobiology, Weill Medical College of Cornell University, Box 140, 1300 York Avenue, 10021, New York, NY, USA},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
keywords = {embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
number = {7},
pages = {293--299},
pmid = {12860187},
title = {{The visual word form area: expertise for reading in the fusiform gyrus}},
volume = {7},
year = {2003}
}
@article{McClelland1995,
abstract = {Damage to the hippocampal system disrupts recent memory but leaves remote memory intact. The account presented here suggests that memories are first stored via synaptic changes in the hippocampal system, that these changes support reinstatement of recent memories in the neocortex, that neocortical synapses change a little on each reinstatement, and that remote memory is based on accumulated neocortical changes. Models that learn via changes to connections help explain this organization. These models discover the structure in ensembles of items if learning of each item is gradual and interleaved with learning about other items. This suggests that the neocortex learns slowly to discover the structure in ensembles of experiences. The hippocampal system permits rapid learning of new items without disrupting this structure, and reinstatement of new memories interleaves them with others to integrate them into structured neocortical memory systems.},
author = {McClelland, J L and McNaughton, B L and O'Reilly, R C},
file = {:Users/Brenden/Documents/Mendeley/McClelland, McNaughton, O'Reilly - 1995 - Why there are complementary learning systems in the hippocampus and neocortex insights from the successes and failures of connectionist models of learning and memory.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Amnesia, Retrograde,Amnesia, Retrograde: physiopathology,Cerebral Cortex,Cerebral Cortex: physiology,Hippocampus,Hippocampus: physiology,Hippocampus: physiopathology,Humans,Learning,Learning: physiology,Memory,Memory: physiology,Neural Networks (Computer)},
month = jul,
number = {3},
pages = {419--57},
pmid = {7624455},
title = {{Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7624455},
volume = {102},
year = {1995}
}
@article{McClellandRogers2003,
author = {McClelland, J L and Rogers, T T},
file = {:Users/Brenden/Documents/Mendeley/McClelland, Rogers - 2003 - The parallel distributed processing approach to semantic cognition.pdf:pdf},
journal = {Nature Reviews Neuroscience},
pages = {310--322},
title = {{The parallel distributed processing approach to semantic cognition}},
volume = {4},
year = {2003}
}
@article{McClelland2013,
abstract = {This article seeks to establish a rapprochement between explicitly Bayesian models of contextual effects in perception and neural network models of such effects, particularly the connectionist interactive activation (IA) model of perception. The article is in part an historical review and in part a tutorial, reviewing the probabilistic Bayesian approach to understanding perception and how it may be shaped by context, and also reviewing ideas about how such probabilistic computations may be carried out in neural networks, focusing on the role of context in interactive neural networks, in which both bottom-up and top-down signals affect the interpretation of sensory inputs. It is pointed out that connectionist units that use the logistic or softmax activation functions can exactly compute Bayesian posterior probabilities when the bias terms and connection weights affecting such units are set to the logarithms of appropriate probabilistic quantities. Bayesian concepts such the prior, likelihood, (joint and marginal) posterior, probability matching and maximizing, and calculating vs. sampling from the posterior are all reviewed and linked to neural network computations. Probabilistic and neural network models are explicitly linked to the concept of a probabilistic generative model that describes the relationship between the underlying target of perception (e.g., the word intended by a speaker or other source of sensory stimuli) and the sensory input that reaches the perceiver for use in inferring the underlying target. It is shown how a new version of the IA model called the multinomial interactive activation (MIA) model can sample correctly from the joint posterior of a proposed generative model for perception of letters in words, indicating that interactive processing is fully consistent with principled probabilistic computation. Ways in which these computations might be realized in real neural systems are also considered.},
author = {McClelland, James L},
doi = {10.3389/fpsyg.2013.00503},
file = {:Users/Brenden/Documents/Mendeley/McClelland - 2013 - Integrating probabilistic models of perception and interactive neural networks a historical and tutorial review.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in psychology},
keywords = {context in perception,generative,interactive activation,neu,neural networks,probabilistic computation},
month = jan,
pmid = {23970868},
title = {{Integrating probabilistic models of perception and interactive neural networks: a historical and tutorial review}},
volume = {4},
year = {2013}
}
@article{McClelland2010,
abstract = {Connectionist and dynamical systems approaches explain human thought, language and behavior in terms of the emergent consequences of a large number of simple noncognitive processes. We view the entities that serve as the basis for structured probabilistic approaches as abstractions that are occasionally useful but often misleading: they have no real basis in the actual processes that give rise to linguistic and cognitive abilities or to the development of these abilities. Although structured probabilistic approaches can be useful in determining what would be optimal under certain assumptions, we propose that connectionist, dynamical systems, and related approaches, which focus on explaining the mechanisms that give rise to cognition, will be essential in achieving a full understanding of cognition and development.},
author = {McClelland, James L and Botvinick, Matthew M and Noelle, David C and Plaut, David C and Rogers, Timothy T and Seidenberg, Mark S and Smith, Linda B},
doi = {10.1016/j.tics.2010.06.002},
file = {:Users/Brenden/Documents/Mendeley/McClelland et al. - 2010 - Letting structure emerge connectionist and dynamical systems approaches to cognition(2).pdf:pdf},
issn = {1879-307X},
journal = {Trends in Cognitive Sciences},
keywords = {Cognition,Cognition: physiology,Humans,Language,Learning,Neural Networks (Computer),Nonlinear Dynamics,Probability,connectionism},
mendeley-tags = {connectionism},
month = aug,
number = {8},
pages = {348--56},
pmid = {20598626},
title = {{Letting structure emerge: connectionist and dynamical systems approaches to cognition.}},
volume = {14},
year = {2010}
}
@article{McClelland2010a,
annote = {Emergence is the creation of complexity from something simpler. In cognition, the structure of behavior, which might look rule-like or gammar-like, is actually something simpler at its core. Symbols are only approximate characterizations of the true underlying processes.
        
--------
        
-- Symbols are emergents, or approximate characterizations of the true underlying processes.
-- explicit, goal-direction action may play a role, but this itself is emergent
-- in math, intuition may come first, followed later by formal specification and proof
-- like evolution, complexity comes from things much simpler than it
        
The history of emergnece:
-- genetic algorithms (John Holland)
-- exemplar models, you can have rule-like behavior as emergent from little elements
-- rules in language, like past tense, rules are really only approximate characterizations
-- Hopfield ntworks
-- Emergent schemata (Rumelhart) 
        
Other applications of emergence:
-- memory, is emergent, collaborative between cortex and medial temporal lobes)
-- semantic memory
-- genetic code, and how this produces humans. You don't have the minature built in from the start
-- the balance scale task, not explicit rules, but emergent consequence of learning how balance works
-- some of the brain's modularity (visual word from area) is an emergent consequence
-- grammar
-- consciousness
        
It may be hard to ever fully understand some emergent phenomena.},
author = {McClelland, James L.},
doi = {10.1111/j.1756-8765.2010.01116.x},
file = {:Users/Brenden/Documents/Mendeley/McClelland - 2010 - Emergence in Cognitive Science.pdf:pdf},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {connectionism},
mendeley-tags = {connectionism},
month = oct,
number = {4},
pages = {751--770},
title = {{Emergence in Cognitive Science}},
volume = {2},
year = {2010}
}
@article{McClelland1981,
annote = {model of letter perception, not learning. Assumes concept is already there
        
Basic findings:
        
- consistent with word facilitation effect
- Pronounceable pseudowords are faciliated
-rule-like behavior without actual rules
        
Three layers of processing, including features, letters, and words. There are inhibitory and excitatory connections between consistent/inconsistent hypotheses. 
        
The basic idea is that the word level can faciliate the perception of letters, with higher activation, especially under noise, since they only add activation in a top-down way (assumption)
        
However, there are a lot of paramters, many feel arbitrary
        
-----        
Introduction
        
How does knowledge influence perception?
        
It has been known for 100 years that it is easier to identify letters in context
        
Reicher (1969) : letters shown in words, unpronounceable nonwrods, and alone
- tested on forced choice between two letters alone
+ both would form a word in the previous contet
- suggests that letter perception can be facilitate by presenting it in context
        
Model:
multiple levels of knowledge, where word level can increase the activation of individual letters
        
Word advantage also applies to pronounceable non-words
+ advantage is much larger than unpronounceable nonwrods
        
Also, effect is weaker when the context is not defining, and leaves room for ambiguity
        
Interactive activation model
        
Three levels of structure, at different levels of abstraction
+ each level has their own representation
1) visual feature level
2) letter level
3) word level
        
There are both top-down and bottom-up constraints on perception
- excitatory and inhibitory connections
        
All words are 4 letter strings
        
All excitatory and inhibitory connections are pre-wired
        
change in activation is modulated by the degree to which it is active, and it is thresholded at a maximum M
        
input assumptions: each feature is detected with some probability
        
responses are made by taking running average of the activation of a node over time
- then Luce's choice rule
        
Operation of networks
- quiet at first, and then settles such that nodes compete and some win over time\ldots
        
Grid fonts were used, only four letter words (but 1,179 of them)
        
Example
Say the word "WORK" is presented but some of the features of K go missing
- then, a few words are active at first, and then WORK comes to dominate
- Also, certain letters become active quickly, and then compete
- letter output probability expands this function out, so that the right letter is perceived with very high probability
        
Many ad hoc parameters
- also, no inhibition from word level to letter level (why?)
        
Differs from previous interactive models, in that processing in the different levels is explicitly done in parallel
        
Finding 1: Word advantage
about a 15% word advantage, when word is presented briefly and then masked
        
masking: replace feature display with other features
        
Why is there a word advantage? The words feed back to the letters, adding more activation (But they turned the inhibit. connections off!)
        
 Perception of letters in a words under conditions of degraded input
        
Finding 2: Perception of letters in regular non words
        
One of the most important findings
        
Model accounts for it by partially activating words that share multiple letters with the observed word
- driven by words that share 3 letters with the pseudowords
- also, you get facilitation depending on the number of friends/enemies a letter interpretation has by matching the other 3 letters
- gangs of words, that match on the same 3 letters, exert an undue influence since they all mutually reinforce each other
        
Also, prior activation is based on use in English language
        
Was able to fit the performance of words vs. pseudo words quite well, matching the accuracy almost exactly.. how did they do this? which parameters?
        
word vs. pseudo-word has similar accuracy
        
However, this gang effect has not been found in the lab, or only in a week case
 - the model also captures this effect, since the word-level inhibitions tends to keep the overall activitiy roughly constant despire cahnges in cluster strenght
        
Also, both in simulation and data, unprounceable nonwords still give a tiny advantage over just a single letter
        
some models work by claiming the context constrains the letter set, but highly constrained contexts are not recognized faster. neither does hte model
        
bigrams are influential if you report only a the word level. This is because a low frequency word, with many high frequency competitors, will have a tough time being recognized
        
      },
author = {McClelland, James L. and Rumelhart, David E},
file = {:Users/Brenden/Documents/Mendeley/McClelland, Rumelhart - 1981 - An interactive activation model of context effects in letter perception Part 1. An Account of Basic Findi.pdf:pdf},
journal = {Psychological Review},
keywords = {classic psychology,handwriting},
mendeley-tags = {classic psychology,handwriting},
number = {5},
pages = {375--407},
title = {{An interactive activation model of context effects in letter perception: Part 1. An Account of Basic Findings}},
volume = {88},
year = {1981}
}
@article{McCloskey1980,
abstract = {University students were asked to draw the path a moving object would follow in several different situations. Over half of the students, including many who had taken physics courses, evidenced striking misconceptions about the motion of objects. In particular, many students believed that even in the absence of external forces, objects would move in curved paths.},
annote = {College students show a remarkable lack of understanding of physics, but this disappates with formal training.
        
Experiment shows a ball coming out of a spiral tube, and most people think the ball keeps curving.
                  
Aristotelian view:  an object keeps moving only as it remains in contact with its mover
                  
Medieval view: objects get an impetus and want to continue on the path they were taking. This is most similar to the college students.
                  
Modern view: Objects continue on a path unless otherwise stopped.},
author = {McCloskey, M and Caramazza, A and Green, B},
doi = {10.1126/science.210.4474.1139},
file = {:Users/Brenden/Documents/Mendeley/McCloskey, Caramazza, Green - 1980 - Curvilinear motion in the absence of external forces naive beliefs about the motion of objects.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = dec,
number = {4474},
pages = {1139--41},
pmid = {17831469},
title = {{Curvilinear motion in the absence of external forces: naive beliefs about the motion of objects.}},
volume = {210},
year = {1980}
}
@article{McCloskey1983,
annote = {Investigates human intuitive physics. General conclusion is that naive people have a concept of motion very similar to Impetus theories from medeival times that built off of Aristotle. Here objects acquire a desire to continue on the current path.
        
Few, even after proper training, understand that objects continue at their current velocity unless moved by an outside force. Thus people have a fundamentally incorrect notion of intuive physics.},
author = {McCloskey, Michael},
file = {:Users/Brenden/Documents/Mendeley/McCloskey - 1983 - Intuitive Physics.pdf:pdf},
journal = {Scientific American},
number = {4},
pages = {122--130},
title = {{Intuitive Physics}},
volume = {248},
year = {1983}
}
@inproceedings{Mcdonnell2005,
annote = {Despite decades of work on category learning, the story on semi-supervised learning is surprisingly murky and inconsistent
        
Design:
Labeled data: two gaussians in opposite corners of a square
unlabeld data: shows that only one dimension has bimodal separation
        
Prediction:
if supervised, then even split in categorization direction
if semi-supervised, clear choice of one direction
        
Conditions:
systematically interpolate along the continuum of the number of labeled examples 
        
280 trials
        
unlabeled
10 labels in corners + unsupervised
40 labels in corners + unsupervised
only 40 labels in corners
        
Analysis: genearl linear classifers fit to each subject
two-dimensional classifier
one-dimensional classifer (unimodal or bidmoal)
flat model which is random
        
used BIC
        
Results:
        
no major differences between fully-labeled group and semi-supervised groups;
        
However, the fully-labeled group were strongly biased towards the bimodal model, suggesting that THEY DID DO semi-supervised learning
        
most people in the fully-labeled condition used bimodal model, perhaps from learning at test (although isnt this semi-supervised learning?)
        
      },
author = {McDonnell, John V and Jew, Carol A and Gureckis, Todd M},
booktitle = {Proceedings of the 34th Annual Conference of the Cognitive Science Society},
file = {:Users/Brenden/Documents/Mendeley/McDonnell, Jew, Gureckis - 2012 - Sparse category labels obstruct generalization of category membership.pdf:pdf},
keywords = {semi-supervised learning},
mendeley-tags = {semi-supervised learning},
title = {{Sparse category labels obstruct generalization of category membership}},
year = {2012}
}
@phdthesis{McGrawJr.,
annote = {        abstract
                
Letters are in gridfonts, where sameness can be defined in terms of finding "a"s or classifying alphabtes
        
Program attempts to take a few tokens of a font, and reconstruct the rest of the alphabet in that font
        
Model:
- letters are made of conceptual constitutes called "roles", which are like relations or parts
                  
conceptualizations
                
each letter can be thought of as parts and relations, and there are multiple conceptualizations for each letter
- although some are better than others
        
roles are like pen strokes, but not neessarily described as such
        
most letter recognition views letters are simply shapes, not in terms of roles
        
a letter, across spirits, does not have an underlying shape lurking beneath each one
                  
grid fonts
                
Using a one-to-one match of straight line segments and curved pipe segments, you can turn grid fonts into real fonts
                  
discussion
                
currently, the mdoel hsa no role for learing},
author = {McGraw, Gary E},
file = {:Users/Brenden/Documents/Mendeley/McGraw - 1995 - Letter Spirit Emergent High-Level Perception of Letters Using Fluid Concepts.pdf:pdf},
keywords = {letter spirit},
mendeley-tags = {letter spirit},
title = {{Letter Spirit: Emergent High-Level Perception of Letters Using Fluid Concepts}},
year = {1995}
}
@inproceedings{McGraw1994,
annote = {Theory of letter representation as parts and relations

        
Runs confusability study with multiple different fonts, but it's unclear to me how this is really evidence for the representations they talk about

        
----
          
Introduction

        
        
We can recognize letters in a large variety of styles

        
'a' is not just a shape - it is an interconnected web of abstractions

        
representation
- perceptually based parts (not motor based), called "glphs"s
- connected with relations (called "roles")
How far can these parts be perturbed?

        
Roles are easier to conceptualize that whole charcters, thus step towards simplification

        
Letters can have multiple parses into glyphs and roles

        
roles allow for slippage, where the relations don't have to hold exactly

        
letters are gridformss, drawn on a fixed 7 x 3 grid with 56 legal line segments ("quanta")

        
still a lot of diversity, allows for studying style

        
          
Human study 
        

        
Predictions:
1) RT should be longer and lower recognition for stimuli where roles are poorly filled
2) Purely match vs. not on quana will not be enough to account for human errors
3) category errors are made by humans with similar roles

        
stimuli:
normals: central eaxmples of each letter
fonts: 6 entire fonts

        
task:
- pressed keyboard letter for each stimulus

        
results:
subjects varied between 64% and 96% correct, wtih mean 84% correct
- show confusion matrix

        
Normals are recognized more quickly that fonts, because the roles are more evident in normals (any quantitative evidence for this??)

        
so far, weird fonts are harder to recognize

        
number of quanta does nto determine difficulty

        
          
prediction 2
        
hierarchical clusterin analysis of dataset, based on blurred prototypes of the entier dataet

        
there are errors, like e-s and c-o that people rarely make, but the clustering of prototypes clsuters as very close

        

        predction 3
        
salientdifferencesin roles prevernts confusions

        
r vs. n are easily confused, but they have the same relations, just a difference in part length

        
          
prediction 4
        
tokens that take longer to categorize are generally categorized as more different things

        
          
conclusoin

        
        
provides evidence for roles?},
author = {McGraw, Gary E and Rehling, John and Goldstone, Robert L},
booktitle = {Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society},
file = {:Users/Brenden/Documents/Mendeley/McGraw, Rehling, Goldstone - 1994 - Letter Perception Toward a conceptual approach.pdf:pdf},
keywords = {letter spirit},
mendeley-tags = {letter spirit},
pages = {613--618},
title = {{Letter Perception: Toward a conceptual approach}},
year = {1994}
}
@article{McKone2007,
abstract = {Does face recognition involve face-specific cognitive and neural processes ('domain specificity') or do faces only seem special because people have had more experience of individuating them than they have of individuating members of other homogeneous object categories ('the expertise hypothesis')? Here, we summarize new data that test these hypotheses by assessing whether classic face-selective effects - holistic processing, recognition impairments in prosopagnosia and fusiform face area activation - remain face selective in comparison with objects of expertise. We argue that evidence strongly supports domain specificity rather than the expertise hypothesis. We conclude that the crucial social function of face recognition does not reflect merely a general practice phenomenon and that it might be supported by evolved mechanisms (visual or nonvisual) and/or a sensitive period in infancy.},
annote = {Argues that neural evidence for expertise might be general attention. First of all, the effect is weak and inconsistent
        
Experts are excited about objects they are experts on, and there is activation everywhere.
        
In fact, there are larger expertise effects outside the FFA when this has been looked at},
author = {McKone, Elinor and Kanwisher, Nancy and Duchaine, Bradley C},
doi = {10.1016/j.tics.2006.11.002},
file = {:Users/Brenden/Documents/Mendeley/McKone, Kanwisher, Duchaine - 2007 - Can generic expertise explain special processing for faces.pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Animals,Brain,Brain Mapping,Brain: cytology,Face,Facial Expression,Humans,Medicine,Neurons,Neurons: physiology,Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,Prosopagnosia,Prosopagnosia: genetics,Prosopagnosia: physiopathology,Specialization,Visual,Visual: physiology,perceptual expertise},
mendeley-tags = {perceptual expertise},
month = jan,
number = {1},
pages = {8--15},
pmid = {17129746},
title = {{Can generic expertise explain special processing for faces?}},
volume = {11},
year = {2007}
}
@inproceedings{Mclure2010,
annote = {Model of concept learning that provides analogical generalization (using SEQL) along with near-miss analysis
        
SME: given two relational representatoins, SME computes a mpapping between how they are aligned
        
SEQL: maintains a list of generalizations and ungeneralized examples. Given a new example, it is first compared again each generalization in the context
        
Winston: importance of near-miss examples, that differ in only one property
inclusion hypotheses: possible necessary conidtions
exclusion hypotheses: possible sufficient negative conidtions
        
new examples:
retrieve the most similar previous model. Examine inclusion/exclusin criteria
                  
experiment:        
trained on three 11-eample segments, for 33 examples
+ remaining 11 are used for testing
                  
rapid learning        
About 3--6 examplers per concept were used
        
        discussion
                
Generalization of Winston's idea:
- near misses do not have to be labeled
- captures disjunctive concepts},
author = {Mclure, Matthew D and Friedman, Scott E and Forbus, Kenneth D},
booktitle = {Proceedings of the 32nd Annual Conference of the Cognitive Science Society (CogSci)},
file = {:Users/Brenden/Documents/Mendeley/Mclure, Friedman, Forbus - 2010 - Learning concepts from sketches via analogical generalization and near-misses.pdf:pdf},
keywords = {CogSci2013 Symposium,a near miss exemplar,analogy,concept 1,concept learning,generalization,model of concept learning,should be highly alignable,some instances of a,that,this paper describes a,way,with},
mendeley-tags = {CogSci2013 Symposium},
title = {{Learning concepts from sketches via analogical generalization and near-misses}},
year = {2010}
}
@article{McMurray,
author = {McMurray, B and Aslin, R N and Toscano, J},
journal = {Developmental Science},
title = {{Statistical learning of phonetic categories: Insights from a computational approach}},
year = {2009}
}
@article{Medin1978,
annote = {Introduced exemplar model
        
Previous studies suggest that learning is a combination of prototype extraction, as well as specific item memory. Over time, the knowlege becomes more abstract.
        
      },
author = {Medin, D L and Schaffer, M M},
file = {:Users/Brenden/Documents/Mendeley/Medin, Schaffer - 1978 - Context Theory of Classification Learning.pdf:pdf},
journal = {Psychological Review},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {3},
pages = {207--238},
title = {{Context Theory of Classification Learning}},
volume = {85},
year = {1978}
}
@article{Medin1984,
author = {Medin, DL and Smith, EE},
file = {:Users/Brenden/Documents/Mendeley/Medin, Smith - 1984 - Concepts and concept formation.pdf:pdf},
journal = {Annual review of psychology},
pages = {113--138},
title = {{Concepts and concept formation}},
volume = {35},
year = {1984}
}
@article{Medin1993,
annote = {Summary
        
Similarity cannot be defined in a way that ignores the processing side. The judgements are highly variable, but they are bound to the details of the comparison process.
        
Similarity of two objects is like two dancers. Each has a stylistic preference, but the actual performance depends on their interaction. There can also be a "lead" dancer, accounting for asymmetry.
        
Their comparison framework:
1) Similarity comparisons involve mutually constraining properties and interpretations
2) Similarity can be directional
3) Similarity is influenced by the comparison context
4) Similarity involves global alignment
        
-------
similarity is a central construct in psychology (concept learning, memory retrieval, gestalt similatiy, property induction)
        
Cognition is deeply invested in similarity. But what is it?
        
Murphy and Medin: feature weights vary with the stimulus context and task
- no unique answer to "how similar"
- if predicates are matched/unmatched, what predicates do you use?
+ thus, they must be constrained to make it non-arbitrary
        
Goodman: similarity has no meaning without "respects"
        
Measuring similarity
indirect: categorization, old vs .new
direct: asking similarity ratings
        
Not just hard-wired perception: since it can depend on relations between figures
+ can't be so inflexible
        
Developmental changes (learning constraints):
Smith: learning dimensions of importance
Gentner: similarity becomes more abstract, more relational
+ also depends on knowledge/expertise
        
Similarity changes in context-specific ways
- learning the shape bias
- relational similarity is a the core of interpreting analogies
        
Initial assessment
- similarity is linked to processing principles, that changes with presentation time, experience, and context
- even so, it is still very flexible
** We need to understand it AS A PROCESS
        
Do things get worse when we move from perceptual to conceptual similarity?
        
- there are ways to characterize the integration process (multiplicative rather than additive features, Shepard's exponential law)
        
Similarity as comparison
- similarity is directional (butchers are like surgeons, surgeons are like butchers) (see Tversky, 1977) Red China and North Korea
+ accentuate distinctive features
        
alignment process is much like structural alignment in analogical mapping
        
Summary
similarity involves brining aspects of entities in correspondence: dynamic and driven by multiple constraints
        
Empirical
        
Tversky showed that when asking whether A or B is more similar to X, the presence of a C can change the answer
(can emphasize either geography or politics)
        
Experiment 1 - perceptual stimuli
        
Deisgn: Compare A-B and B-C. Ask participants to list common and distinct vs properties. B can have two mutually exclusive interpretations, and A vs. C are designed to invoke the different ones.
        
Also, some stimuli were not ambiguous, but A and B were designed to evoke different features.
        
Results: The features were analyzed as "comparison consistent" or "comparison inconsistent": whether the description of B's critical feature was the same or different as the comparison itme
        
 About 3x as many comparison consistent features. More often in similarities, but also significantly in the differences The features of B are dependent on the context. 
        
Different pattern of results when used in inconsistent trials, much more likely to list comparison inconsistent descriptions
        
Discussion: It is well known that context influences perception (Carmichale, Selfridge's ambiguous A vs. H)
        
Experiment 2 - conceptual stimuli
        
Deisgn : Pairs of conceptual stimuli (England vs. US, blimps vs. cars, etc.)
"How similar is X to Y?" Also, list properties that X and Y have in common.
        
Two conditions, where X and Y are switched
        
Results: listed features were rated as more applicable to X or Y by naive judges
        
For both judges, significantly more features biased towards the base category
Also, there were asymmetric similarity judgements
        
Experiment 3 - effect of context
        
Asked for similarity ratings between a pair. Context was either separate (A vs. B and then later A vs. C) or combined (both paris together)
- is there a pooling of respects? can you only have separate respects when presented separately?
        
Antonyms can be made more similar when compared with a 3rd thing that is unrelated
        
        
Results:
        
Antonyms
Example: black and white has a rating of 2 separate. But when compared with red, black and white now have a rating of 4
- thus, it can make antonyms similar when compared with something unrelated
        
Metaphors: skin-hair and skin-bark and rated as more similar separately than together.. since you have to share respects to some extent
-But this was not found very often
        
Feature independence
        
You show a figure of 3 objects. Then have 4 possible sets of 3 objects, which have the same number of matches total, but differ in the number of feature matches and relational matches
- features and relations are not independent. You have to fix the respects, and then choose the most similar pair (the MAX effect)
        
Another study showed that by asking similarity judgments first, it can change how you map objects to objets in two scenes.
        
        
Discussion
- viewing similarity as fixed ignores the processing side of similarity
- similarity is DYNAMIC and CONTEXT DEPENDENT
        
Not only does similarity vary with experience and context, but there is also an active comparison process
        
Is similarity so unconstrained that it may play little or no role in fixing respects? The present results describe something about how respects are fixed
        
Their main point: similarity cannot be defined in a way that ignores the processing side of similarity. The judgements are highly variable, but they are bound to the details of the comparison process.
        
Their comparison framework:
1) Similarity comparisons involve mutually constraining properties and interpretations
2) Similarity can be directional
3) Similarity is influenced by the comparison context
4) Similarity involves global alignment
        
Most models of categorization do not account for an active similarity process. Tversky (1977) pointed out the importance of this, and this article continues in this direction
        
Is it just one process?
Only modest correlations between similarity ratings and same/difference judgments ($\sim$0.6).
        
Are direct and indirect measures fundamentally different?
They are significantly correlated, but there is a lot of other stuff going on.
        
Does it play a key role in categorization? Dobermans can be categorized with sharks or with raccoons, depending on how you think about them -- whether you emphasize "ferocious"
        
Keil: maybe similarity takes over where theories leave off. If you don't have outside knowledge, then you turn it over to the similarity process
        
Similarity is like two dancers. Each has a stylistic preference, but the actual performance depends on their interaction. There can also be a "lead" dancer, accounting for asymmetry.
        
People don't answer "how similar are X and Y?" rather they seem to be answering "How are X and Y similar?" It's a process.},
author = {Medin, Douglas L and Goldstone, Robert L and Gentner, Dedre},
file = {:Users/Brenden/Documents/Mendeley/Medin, Goldstone, Gentner - 1993 - Respects for similarity.pdf:pdf},
journal = {Psychological review},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {2},
pages = {254--278},
title = {{Respects for similarity}},
volume = {100},
year = {1993}
}
@incollection{Medin1989,
annote = {Idea that the mental representation for cateogires is a hidden essence, like the idea of "mammal." Surface similarities might be a good shortcut to categorization, but it's not always the real concept.
        
Relevance to motor theories of characters. The motor program is the concept, or the essence, behind the character. 
        
---
Maybe Wittegenstein's advice: don't think, look! About categories was taken too literally
        
There is something right about definitions, or important but perhaps hidden features.
        
psychological essentialism: the idea that surface features are constrainted by, or generated by, the deeper more central parts of concepts
        
There is a lot of divergence of opinion on the role of similarity in categorization.
        
What properties are relevant? Both shoes and tennis balls don't have ears, but this doesn't seem relevant
        
Metaphysical essentialism: that objects have hidden essences that make them what they are. But what if they take different roles? Thus, it is an implausible doctrine
        
Psychological essentialism: it's not that things have essences, it's that people's representations of things have essences
        
It's not the same as the classical view, where the definitions are probably a reflection of the essence.
        
      },
author = {Medin, Douglas L and Ortony, Andrew},
booktitle = {Similarity and Analogical Reasoning},
file = {:Users/Brenden/Documents/Mendeley/Medin, Ortony - 1989 - Psychological essentialism.pdf:pdf},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
pages = {179--195},
title = {{Psychological essentialism}},
year = {1989}
}
@article{Metcalfe1986,
author = {Metcalfe, Janet and Glenberg, Art and Logan, Gordon and Nelson, Thomas and Oikawa, Lorene and Roediger, Henry and Ryan, Paula and Sharpe, Don and Steiger, James},
file = {:Users/Brenden/Documents/Mendeley/Metcalfe et al. - 1986 - Premonitions of Insight Predict Impending Error.pdf:pdf},
journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
keywords = {ah-ha,classic psychology},
mendeley-tags = {ah-ha,classic psychology},
number = {4},
pages = {623--634},
title = {{Premonitions of Insight Predict Impending Error}},
volume = {12},
year = {1986}
}
@article{Meulenbroek1996,
abstract = {This report shows how a model initially developed for the control of reaching can be adapted for the control of handwriting. The main problem addressed by the model is how people can produce essentially the same written output with different effectors (e.g., the preferred or nonpreferred hand, the foot, or even the mouth). The model is based on the assumption that writers strive for invariant graphic outputs when they write with different effectors, when they write on surfaces with different orientations, or when they write large or small script; such output invariance is an essential requirement for later recognition of the written result. Given this assumption, the question is how the motor system enables the relevant effectors to generate the necessary pen strokes. The adapted model provides one possible answer to this question. It is first fully working model of multijoint activity underlying writing and related graphic tasks. We describe how the model differs from other models developed in the past, and we review the model's strengths and weaknesses.},
annote = {The goal of the motor system is to produce the same visual output, using whatever means possible (so the motor system is the slave system).
        
Key points, that the pen must travel through, are specified by the drawer. This model then specifies the specific motor actions.
        
Motor equivalence is a misnomer: Stimulus equivalence is the goal of writing, and motor flexibility gives you a means of achieving this goal
                  
Model        
- spatial error: distance to travel if the stored posture was adopated at the target spatial location
- travel costs: how much effort to get from the current to stored posture
- Each posture is given a weight, and the goal posture is a sum of the stored postures
        
Where the pen tip is directed: points on the writing surface where curvature is lcoally minimal, or locally maximal
+ maximum curves -- stop locations
+ minimum curves -- via points, must pass through
                  
Results:
- given a human-drawn cursive character, the model produces pen-tip kinematics that closely match the actual data in terms of velocity
        
Production with different effectors:
1) can be drawn larger/smaller
2) Can be drawn on a blackboard, and the output looks the same, although the angular velocities of the joints are quite different
        
Predicts Wright and Lindemann result: transfer of shared strokes to left hand, but not of new strokes. This is because you can store postures in the model},
author = {Meulenbroek, R G and Rosenbaum, D a and Thomassen, a J and Loukopoulos, L D and Vaughan, J},
file = {:Users/Brenden/Documents/Mendeley/Meulenbroek et al. - 1996 - Adaptation of a reaching model to handwriting how different effectors can produce the same written output, and other results.pdf:pdf},
issn = {0340-0727},
journal = {Psychological research},
keywords = {Female,Functional Laterality,Handwriting,Humans,Kinesthesis,Male,Motor Skills,Orientation,Posture,Psychomotor Performance,Reaction Time,handwriting,part-based models},
mendeley-tags = {handwriting,part-based models},
month = jan,
number = {1},
pages = {64--74},
pmid = {8693052},
title = {{Adaptation of a reaching model to handwriting: how different effectors can produce the same written output, and other results.}},
volume = {59},
year = {1996}
}
@article{Meulenbroek1991,
abstract = {The aim of the present study is to examine the contribution of two independent spatial reference systems in the manipulation of writing instruments. One system relates to the anatomical structure of the arm and the hand (resulting in preferences for oblique, i.e., diagonal movement directions) while the other corresponds with a more abstract, geometrical system (resulting in a bias favouring orthogonal, i.e., vertical and horizontal movement directions). Three experiments are reported in which the independence of these two reference systems is explored in drawing tasks in which subjects produced small back-and-forth movements in a variety of directions. The outcome of the first experiment showed that stroke-direction variability is larger in horizontal than in other directions. In experiment 2 it was predicted that when subjects are forced to choose repeatedly among a set of 16 different directions, a change of arm position would affect the pattern of preferences for oblique directions more than the pattern of preferences for orthogonal directions. The data confirm this hypothesis. In experiment 3 we analysed the changes in stroke-direction preferences as a function of variations in the type and the size of the movements to be produced as well as the effects of visual control of the motor task on the subjects' choice of movement directions. This last experiment provides additional evidence for the view that geometrical and anatomical reference systems must be distinguished. Finally, a frame-by-frame analysis of video-recordings of hand and finger movements indicates that the two anatomical subsystems cooperate consistently and predictably during the production of different movement directions.},
annote = {Doesn't seem directly relevant, instead focused on coordinate systems and variance in horizontal rather than verdical dimensiosn},
author = {Meulenbroek, Ruud G.J. and Thomassen, Arnold J.W.M.},
doi = {10.1016/0167-9457(91)90006-J},
file = {:Users/Brenden/Documents/Mendeley/Meulenbroek, Thomassen - 1991 - Stroke-direction preferences in drawing and handwriting.pdf:pdf},
issn = {01679457},
journal = {Human Movement Science},
keywords = {handwriting},
mendeley-tags = {handwriting},
month = may,
number = {2-3},
pages = {247--270},
title = {{Stroke-direction preferences in drawing and handwriting}},
volume = {10},
year = {1991}
}
@article{Meyer1976,
annote = {Summary: Survey of semantic network models and support data at the time. Not only is a semantic network a useful explanatory tool, but it seems to play a role in even mundate lexical decision tasks.
        
-----
There is lots of work on memory, but there was less work on the time on long-term, semantic memory.
        
Using RT, rather than correct/incorrect, was a major advance in our understanding
                  
Comprehension and RT        
stimuli like "some stones are rubies"
subset: "some pines are trees"
partial overlap: "some writers are mothers"
disjoint: "some clouds are wrists"
About 110 ms faster if there was a subset relation rather than partial overlap.
-- also an effect of category size, like "trees" vs "plants" for "some pines are plants", where larger categories are slower.
Thus, semantic memory is not instantaneous
                  
A model of human memory        
- Quillian's semantic network
- This would account for many of the effects on category size, since you have to traverse more links, also, it would explain why disjoint sets are harder to evaluate
                  
Word recognition and RT        
Human memory includes a semanci network, and it seems to infeluence even how printed words are seen (somehow meaning is accessed even here)
-- procedure, where you go down a row, and say whether each word is a word or not. 
But meaning mattered considerably, on deciding for a word pair whether or not they were both words, when stimuli were degraded or not.
        
        Visual analyzers and word detectors        
By connecting a feature-net style model of detecting words, with a semantic network on top, you can explain teh context effect
-- think interactive activation model, with semantic relations on top of the word level
        
                  
Inhibition of senetence comprehension
-- if they are false exisential sentences, like all stones are rubies, the closeness hurts performance Explain these types of judgments by comparing defining attributes (which we now know is not how it would work)},
author = {Meyer, David E and Schvaneveldt, R W},
file = {:Users/Brenden/Documents/Mendeley/Meyer, Schvaneveldt - 1976 - Meaning, Memory Structure, and Mental Processes.pdf:pdf},
journal = {Science},
keywords = {classic psychology,semantic network},
mendeley-tags = {classic psychology,semantic network},
pages = {27--33},
title = {{Meaning, Memory Structure, and Mental Processes}},
volume = {192},
year = {1976}
}
@article{Meyer1974,
annote = {Are words encoded by the grapheme or the phonology, or both?
        
This paper provides early evidence for phonological coding.
        
When reading, do you have to recode in phonology, or not?
-- We now know that you do, because of categorizationt asks where "ROWS" has slow RT because it sounds like "ROSE" in a flower judgmenet
        
Experinent 1:
Receive a pair
"yes" if both are words, "no" otherwise
        
orthographically similar: (but not phonological)
FREAK-BREAK
both similar:
bribe-tribe
        
Result:
performance depended on the phonemic relation between pairs of words, not just graphemic relations
-- performance is inhibited by grapheme similarity alone
        
Experiment 2: successive pairs rather than simulataneously pairs},
author = {Meyer, David E and Schvaneveldt, R W and Ruddy, M G},
file = {:Users/Brenden/Documents/Mendeley/Meyer, Schvaneveldt, Ruddy - 1974 - Functions of graphemic and phonemic codes in visual word-recognition.pdf:pdf},
journal = {Memory \& cognition},
keywords = {classic psychology,semantic network},
mendeley-tags = {classic psychology,semantic network},
number = {2},
pages = {309--321},
title = {{Functions of graphemic and phonemic codes in visual word-recognition}},
volume = {2},
year = {1974}
}
@article{Meyer1971,
annote = {Do we just have a lexicon? During a lexical decision task, should it matter if a word pair are related?
        
Nurse-doctor (related)
bread-doctor (unrelated)
        
Experiment 1:
Ss said "yes" if both are a word, and "no" otherwise
        
There was an RT benefit if the words were associated (about 1 second)
        
Experiment 2:
Otherwise the same task, except particiapnts responded "same" or "different" to the status of the words
        
Conclusion:
Supports idea that words are organized semantically. Supports spreading activation theories -- it's not a random access memory.
        
Or, it could be like a magnetic tape, where related things are nearby, and you don't have to shift the tape often},
author = {Meyer, David E and Schvaneveldt, Roger W},
file = {:Users/Brenden/Documents/Mendeley/Meyer, Schvaneveldt - 1971 - Facilitation in recognizing pairs of words Evidence of dependence between retrieval operators.pdf:pdf},
journal = {Journal of Experimental Psychology},
keywords = {classic psychology,semantic network},
mendeley-tags = {classic psychology,semantic network},
number = {2},
pages = {227--234},
title = {{Facilitation in recognizing pairs of words: Evidence of dependence between retrieval operators}},
volume = {90},
year = {1971}
}
@inproceedings{MillerMatsakis2000,
annote = {One-shot learning of handwritten digits
        
This method "congeals" a set of images by aligning them using affine transformations.
        
      },
author = {Miller, E G and Matsakis, N E and Viola, P A},
booktitle = {{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}},
file = {:Users/Brenden/Documents/Mendeley/Miller, Matsakis, Viola - 2000 - Learning from one example through shared densities on transformations.pdf:pdf},
title = {{Learning from one example through shared densities on transformations}},
year = {2000}
}
@article{Miller2001,
abstract = {The prefrontal cortex has long been suspected to play an important role in cognitive control, in the ability to orchestrate thought and action in accordance with internal goals. Its neural basis, however, has remained a mystery. Here, we propose that cognitive control stems from the active maintenance of patterns of activity in the prefrontal cortex that represent goals and the means to achieve them. They provide bias signals to other brain structures whose net effect is to guide the flow of activity along neural pathways that establish the proper mappings between inputs, internal states, and outputs needed to perform a given task. We review neurophysiological, neurobiological, neuroimaging, and computational studies that support this theory and discuss its implications as well as further issues to be addressed},
author = {Miller, E K and Cohen, Jonathan D},
file = {:Users/Brenden/Documents/Mendeley/Miller, Cohen - 2001 - An integrative theory of prefrontal cortex function.pdf:pdf},
institution = {Center for Learning and Memory, RIKEN-MIT Neuroscience Research Center and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA. ekm@ai.mit.edu},
journal = {Annual Review of Neuroscience},
number = {1},
pages = {167--202},
pmid = {11283309},
publisher = {Annual Reviews 4139 El Camino Way, P.O. Box 10139, Palo Alto, CA 94303-0139, USA},
title = {{An integrative theory of prefrontal cortex function.}},
volume = {24},
year = {2001}
}
@article{Miller1956,
abstract = {First, the span of absolute judgment and the span of immediate memory impose severe limitations on the amount of information that we are able to receive, process, and remember. By organizing the stimulus input simultaneously into several dimensions and successively into a sequence or chunks, we manage to break (or at least stretch) this informational bottleneck. Second, the process of recoding is a very important one in human psychology and deserves much more explicit attention than it has received. In particular, the kind of linguistic recoding that people do seems to me to be the very lifeblood of the thought processes. Recoding procedures are a constant concern to clinicians, social psychologists, linguists, and anthropologists and yet, probably because recoding is less accessible to experimental manipulation than nonsense syllables or T mazes, the traditional experimental psychologist has contributed little or nothing to their analysis. Nevertheless, experimental techniques can be used, methods of recoding can be specified, behavioral indicants can be found. And I anticipate that we will find a very orderly set of relations describing what now seems an uncharted wilderness of individual differences. Third, the concepts and measures provided by the theory of information provide a quantitative way of getting at some of these questions. The theory provides us with a yardstick for calibrating our stimulus materials and for measuring the performance of our subjects. In the interests of communication I have suppressed the technical details of information measurement and have tried to express the ideas in more familiar terms; I hope this paraphrase will not lead you to think they are not useful in research. Informational concepts have already proved valuable in the study of discrimination and of language; they promise a great deal in the study of learning and memory; and it has even been proposed that they can be useful in the study of concept formation. A lot of questions that seemed fruitless twenty or thirty years ago may now be worth another look. In fact, I feel that my story here must stop just as it begins to get really interesting. And finally, what about the magical number seven? What about the seven wonders of the world, the seven seas, the seven deadly sins, the seven daughters of Atlas in the Pleiades, the seven ages of man, the seven levels of hell, the seven primary colors, the seven notes of the musical scale, and the seven days of the week? What about the seven-point rating scale, the seven categories for absolute judgment, the seven objects in the span of attention, and the seven digits in the span of immediate memory? For the present I propose to withhold judgment. Perhaps there is something deep and profound behind all these sevens, something just calling out for us to discover it. But I suspect that it is only a pernicious, Pythagorean coincidence.},
author = {Miller, George},
file = {:Users/Brenden/Documents/Mendeley/Miller - 1956 - The Magical Number Seven, Plus or Minus Two Some Limits on Our Capacity for Processing Information.pdf:pdf},
institution = {Harvard.U.},
journal = {Psychological Review},
keywords = {classic psychology,cognitive psychology,memory,perceptual cognitive psychology,psychophysics},
mendeley-tags = {classic psychology,memory},
number = {2},
pages = {81--97},
publisher = {American Psychological Association},
title = {{The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information}},
volume = {63},
year = {1956}
}
@inproceedings{Miller,
annote = {Even in the limit of infinite data, if you take a sample from the posterior of a DPMM, you should not expect it to return the correct number
        
This is if your data is from a fininte mixture model
        
This is from an general empirical observation that you often have many small clusters
        
This is because the prior favors this, and the likelihood does not care very much about it},
author = {Miller, Jeffrey W and Harrison, Matthew T},
booktitle = {Advances in Neural Information Processing Systems 26},
file = {:Users/Brenden/Documents/Mendeley/Miller, Harrison - Unknown - A simple example of Dirichlet process mixture inconsistency for the number of components.pdf:pdf},
title = {{A simple example of Dirichlet process mixture inconsistency for the number of components}}
}
@article{Mishkin1983,
author = {Mishkin, Mortimer and Ungerleider, Leslie G and Macko, Kathleen A},
file = {:Users/Brenden/Documents/Mendeley/Mishkin, Ungerleider, Macko - 1983 - Object vision and spatial vision two cortical pathways:},
journal = {Trends in Neurosciences},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
pages = {414--417},
title = {{Object vision and spatial vision: two cortical pathways}},
volume = {6},
year = {1983}
}
@inproceedings{Mitchell2008,
annote = {Questions:
        
- Why do we want a vector-based representation, rather than somethine else, like a parse tree for a sentence?
        
- What if we substituated LSA or something rather than the raw co-occurences},
author = {Mitchell, Jeff and Lapata, Mirella},
booktitle = {Proceedings of ACL-08},
file = {:Users/Brenden/Documents/Mendeley/Mitchell, Lapata - 2008 - Vector-based Models of Semantic Composition.pdf:pdf},
number = {June},
pages = {236--244},
title = {{Vector-based Models of Semantic Composition}},
year = {2008}
}
@article{Mitchell1986,
annote = {Most methods require a lot of training examples with no domain knowledge
        
EBL: domain-specific knowledge to make inferences from a single training example
        
EBL methods analyze an example by constructing an explanation of how the example satisfies the definition of the concept at hand
        
Explanation structure: proof tree, where specific instances of the rule are placed with their general form
        
Parts: goal concept, where the predicate is defined as a disjunctino of high-level predicates
        
Training example: represented as a semantic netowrk
        
Domain theory: general laws that could be helpful
        
Operationality criterion: what constitutes a useufl proof, like one that only uses terms that are easily observed form example
        
Goal: determine a generalizatino of the traiing example that is sufficient for the concept definition
        
First, you construct a proof for the given example from your domain knowledge
        
Second, you need to generalize it, using "goal regression".
If there is a disjunction, you only generalize through the path the example took
+ specific values, like "volume" or "weight" are generalized by seeing which values of this predicate would have allowed the inference to go through
+ this is "regression", where we want to find the weakest condition under which the rule can infer the next predicate
                  
Discussion        
this procedure produces a justified generalization from a single training example in a 2-step process
        
It only worked for a single training example
                  
Example
                
Learning cup
- start with high-level features of object, which will lead to ruling out unimportant features like color and size
        
From one example of a cup, we can learn that if the bottom is flat, and it has a handle, and it is light, then it is a cup
        
Simple enough example that we just had to replacing constants by rules
        
This was Winston et al's example, which worked without general knowledge, but by appealing to specific exemplars
+ system called ANALGOY
+ it is very much like EBL, but with exemplar based knowledge
        
Have to hand-engineer the knowledge base that it knows
        
Why do you need training examples at all?
- the training example guides by learner by forcing it to make critical generalizations and transformations
                  
Research issues
                
What if you can't prove the concept from the rules you have?
+ you might be able to summarize links between features and concepts
        
Intractable theories, where you can't summarize it ia few high-level featuers
+ like how to win at chess
        
Combining it with similarity based theories},
author = {Mitchell, Tom M and Keller, Richard R and Kedar-cabelli, Smadar T},
file = {:Users/Brenden/Documents/Mendeley/Mitchell, Keller, Kedar-cabelli - 1986 - Explanation-Based Generalization A Unifying View.pdf:pdf},
journal = {Machine Learning},
keywords = {EBL,abstract,back-propagation,been a,constraint,explanation-based generalization,explanation-based learning,general concepts from specific,goal regression,has focused on empirical,learning research,major focus of machine,operationalization,similarity-based generalization,the problem of formulating,training examples has long,while most previous research},
mendeley-tags = {EBL},
pages = {47--80},
title = {{Explanation-Based Generalization: A Unifying View}},
volume = {1},
year = {1986}
}
@article{Mitra2007,
annote = {Often use non-visual sensors on the body to aid recognition.
        
Many to one mapping -- there are many signals for "stop". 
        
The field consists of:
-- general gestures during talk
-- sign language
-- facial gestures and emotions
        
Otherwise, this is a pretty bad paper, with rambling technical details that are not tied to anything},
author = {Mitra, Sushmita and Acharya, Tinku},
doi = {10.1109/TSMCC.2007.893280},
file = {:Users/Brenden/Documents/Mendeley/Mitra, Acharya - 2007 - Gesture Recognition A Survey.pdf:pdf},
issn = {1094-6977},
journal = {IEEE Transactions on Systems, Man and Cybernetics, Part C (Applications and Reviews)},
keywords = {part-based models},
mendeley-tags = {part-based models},
month = may,
number = {3},
pages = {311--324},
title = {{Gesture Recognition: A Survey}},
volume = {37},
year = {2007}
}
@inproceedings{Mooney,
abstract = {Talk sep21 at MIT},
annote = {Grounded language. Learning language from a perceptual context, rather than just reading text.
        
-------
-Children don't learn from supervised language data, or unsupervised learning (raw data)
- Do learn language, you need to learn the connection between language and the world
        
If you look definitions in word net, they are circular
                  
problem:        
- Learning to sportscasat a robocup game (robot soccer),  based on data from someone else sportscasting it
- Given 2D simulation, so you don't need to solve the vision problem
        
Learn everything about the language, just by getting the text and watching the game
        
Need to map "meaning representation" from the "natural language commentary"
- meaning predicates are like passing, kicking, etc.
        
There are about 2.5 possible events for each sentence (last 5 sentences)
+ assumes a semantic parser, that can make a logical form from the sentences
        
This was not a generative model, but they have a fully probabilistic generative version
        
problem 2:
- try to follow directions in Chinese, in terms of navigating around a set of hallways
- It can learn to follow these directions pretty well
        
Input: predicate logic description of the world, and actions that people executed from the correspodning instructions
- a semantic parser transforms the language to a logical representation
        
You cannot enumerate all possible meanings for a senstence
- so first they learned the meanings of word
- use these to compose meanings of sentences
        
At the end, the system gets about 30% of the paragraphs correct. People are around 70% correct.
                  
research vision        
Can't we allow language and vision to cross-supervised eachother? They are both very hard, AI complete problems
- eventual goal: train on videos with language describing them, and then use this to annotate new videos
        
      },
author = {Mooney, Raymound J},
booktitle = {International Conference on Machine Learning (ICML 2008)},
file = {:Users/Brenden/Documents/Mendeley/Mooney - 2008 - Learning language from perceptual context.pdf:pdf},
title = {{Learning language from perceptual context}},
year = {2008}
}
@article{Morasso1982,
abstract = {This paper proposes a computational model for different aspects of trajectory formation, from point-to-point movements to handwriting. The proposed model is based on a mechanism of composition of basic curve elements (strokes) which separates the spatial and the temporal aspects of trajectory formation. At the same time, the model suggests a method for storing and describing arm movements, as a list of stroke descriptors. Experimental trajectories were digitized and analyzed with regard to several types of movements: i) point-to-point trajectories, ii) closed trajectories, iii) trajectories with inflection points, iv) spiral-like trajectories, v) handwritten trajectories. Velocity and curvature profiles were computed for the trajectories and the model was fitted to the data. The implications of the model and its “credibility” in the general context of motor control are discussed.},
author = {Morasso, P. and {Mussa Ivaldi}, F. A.},
doi = {10.1007/BF00335240},
file = {:Users/Brenden/Documents/Mendeley/Morasso, Mussa Ivaldi - 1982 - Trajectory formation and handwriting A computational model.pdf:pdf},
issn = {0340-1200},
journal = {Biological Cybernetics},
keywords = {Computer Science},
month = sep,
number = {2},
pages = {131--142},
publisher = {Springer Berlin / Heidelberg},
title = {{Trajectory formation and handwriting: A computational model}},
volume = {45},
year = {1982}
}
@article{Muggleton1997,
annote = {Gold showed that regular grammars can't be learned from just positive data

        
But within a Bayesian framework, it can be learned.
- replace Gold's exact identification of a language with the need to converge with arbitrarily low error, in terms of posterior probability

        
Implementation is with inductive logic programming

        
          
bayes' posterior estimation

        
        
Gold's negative result relies on the fact that for any sequence of positive examples, there are at least two possible candidate hypotheses
1) the language containing all possible sentences
2) the language corrresponding to elements of data alone

        
(this is a ridiculous argument)

        

      },
author = {Muggleton, Stephen},
file = {:Users/Brenden/Documents/Mendeley/Muggleton - 1997 - Learning from positive data.pdf:pdf},
journal = {Inductive logic programming},
keywords = {logic},
mendeley-tags = {logic},
pages = {358--376},
title = {{Learning from positive data}},
url = {http://link.springer.com/chapter/10.1007/3-540-63494-0_65},
year = {1997}
}
@article{Murphy1988,
annote = {How do we do conceptual combination? (engine repair) from engine and repair. This paper argues you can't just combine/re-weight object features: there is a necessary contribution of world knowledge.
        
two experiments show that features are typical of the compound, but neither of the component parts
        
        
for both adjective-noun and noun-noun concepts, they don't combine linearly:
corporate lawyer, corporate car, corporate clothes
ocean road, ocean plate, ocean view, ocean bird
        
an "apartment dog" doesn't have most of th features of an apartment
        
a "pet fish" isn't like most pets or most fish
        
an "empty store" is likely to be losing money, but not for just "empty" thigns or "stores"
        
        
-----
        
Many theories of concepts make similar predictions for simple concepts, but very different predictions for conceptual combination. Thus, better for discriminating theories
        
how do we define a complex concept? Not just primitives, because then feature might count.
complex concept: a concept that requires more than one word
+ unless the combination is idiomatic and far too common
+ decent guide since vocabulary is a sign of conceptual simplicity
        
concepts are closely related to word meaning (E. Clark)     
- "how do people combine concepts?" is not really a well-defined question, unless it is in the context of some task. This paper focuses on interpretation of phrases (semantic)
                  
accounts of complex concepts
                
extensional definition: its just the intersection of the extension sets, but this isn't helpful for the intentional meaning (the concept)
        
concept specialization: the modifying (first) concept acts by filling a slot in the head concept's schema
+ asymmetrical
+ schemata as lists of slots and fillers
+ heavily knowledge-dependent operation, that requires knowing about other conetps
++ know than an "apartment dog" lives in an apartment, and doesn't look like one
++ you can elaborate on other features, like an apartment dog is likely to be small
        
feature weighting: for adjective-noun concepts, reweight the adjective's primary feature in the noun concept
+ again defined by schemata
+ but DOES NOT refer to any information outside the two concepts being combined
+ what about noun-noun compounds
        
thus, one theory requires world knowledge, the other doesnt. But the first is inherently more vague.
        
are these additional operations necesarry?
        
        linguistic evidence        
        
adjective-noun concepts: "red apple"
for feature weighting, no world knowledge necessary. Also easy for schema theory since it picks out the schema
conclusion: might not need world knowledge for these
        
also, "non-predicating" adjectives, that do not have a common meaning "corporate lawyer, corporate office, corporate car, corporate lawayer"
- does not modify the same slot in each concept
- it is related to a corporation, but this vague reading is not the meaning
 - these pose a problem, since they don't always provide the same feature to be reweighted
- often derived from nours, hence the noun-noun complexity is reflected
                  
noun-noun compounds        
- challenge for anything theroy
- ocean raod, ocean cruite, ocean plate, ocean view
- salient properties of oceans (blue, wet, large etc.) not carried onto the noun it is atatched to
- people use their world knoweldge to agree on an interpretation
        
Hampton (1988) "extensional feedback", after hearing apartment dog, we think of dogs we have seen that meet these requirements
- this is a kind of world knowledge
                  
Experient 1:        
Is feature-weighting sufficent for adjetive-noun concepts?
- is the concept formation a closed operation?
        
assumption: if the feature is atypical of both components, it should not be typical of the compound
        
subjects made feature-category typicality ratings (barks is typical of dog)
        
results: many times, the feature tested aws most typical of the adjective-noun concept
        
empty stores - liekly to lose money
green bicycles - likely to be painted green
shelled peas - likely to be long
        
Medin and Shoben (1988): wooden spoons are more typical of large spoon than small spoon. extensional feedback
                  
experiment 2        
rather than explicilty constructed counter-examples, they used 10 nouns and 10 adjectives, and all pairs
        
instructions asked to define each pairing.
        
then, definitions were grouped by adjective, to see if a single feature was be emphasied in each case
        
adjective long
(year) passes slowly in time
(people) tall
(life) many years
(word) many syllables
        
often, many more than one meaning (on average, 7 meanings in 10 words)
        
also, the noun meaning can change (card hand changes from body part)
                  
the two concepts are not processed independently
          
disussion
                
so we need world knowledge, but this is a scruffy theory rather than a neat one
        
Fodor's first law of nonexistenec of cognitive science: "the more global a cognitive process is, the less anybody understands it"
- thus, we can only study the modules
- clearly, conceptual resources are global},
author = {Murphy, Gregory L},
doi = {10.1016/0364-0213(88)90012-2},
file = {:Users/Brenden/Documents/Mendeley/Murphy - 1988 - Comprehending complex concepts.PDF:PDF},
issn = {03640213},
journal = {Cognitive Science},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
month = dec,
number = {4},
pages = {529--562},
title = {{Comprehending complex concepts}},
volume = {12},
year = {1988}
}
@article{Murphy2001,
annote = {Murphy vs. Bloom on one-shot learning
        
Studies of word learning and children often conclude they do "fast-mapping" (one-shot learning), where concept learning studies with adults show learning can be very slow
        
Are the college sophomores dumber than children?
        
It may be the neither scenario is realistic. Nautral categories are less arbitrary than many category learning studies, but they may not be as simple as when tested with Children
        
It may take years to fill out the category with exceptions, etc.  Thus, it is not truly "learned"
        
Note: he cites concept learning studies where it takes many blocks to learn anything. But does this just show how little these tasks have to do with actual concept learning?
        
----
        
Bloom's response: the usual conception of word learning is getting the gist right, not the entire word with all of the exceptions
+ thi sis not word learning, it is conceptual development},
author = {Murphy, Gregory L},
file = {:Users/Brenden/Documents/Mendeley/Murphy - 2001 - Fast-mapping children vs. slow-mapping adults Assumptions about words and concepts in two literatures.pdf:pdf},
journal = {Behavioral and Brain Sciences},
number = {5},
title = {{Fast-mapping children vs. slow-mapping adults: Assumptions about words and concepts in two literatures}},
url = {http://journals.cambridge.org/abstract_S0140525X01310130},
volume = {24},
year = {2001}
}
@book{Murphy2004,
address = {Cambridge, MA},
annote = {        Chapter 1: Introduction        
        
Uses of concepts
- realizing that new tomato is a tomato, and you could eat it (otherwise you might starve)
- knowing we can sit in a chair, even though we have never seen someone do it
- how we interact with others, knowing someone is a bore would change our behavior
        
-We now think concepts are present in early life (within a few months)
- We should be careful not to call everything a conept
- There is a lot more to learn about concepts -- as a researcher, psychologist, or human beign
                  
Chapter 2: Typicality and the classical view of concepts
                
Early thoughts          
- Hull's (1920) Ph.d. theses ran concept learning experiments with modified chinese characters.
+ He assumed nececessary and sufficient conditions story, and thought the same processes would generalize to dogs, etc. unconsciously
- Smoke (1932) criticized this view, but thought criteria should just be more complicated
- Piaget thought concepts had logical definitions, which fit with his world view
- Bruner et al (1956) looked at concept learning with simple logical rules (OR, AND)
        
Claims
- Necessary and sufficient definition
- Objects are clearly in or out of the concept
        
Downfall
- Wittgenstein (1953) said concepts often don't have definitions
+ But this is a negative argument, he couldnt think of any
+ famous cafe of "a game"
- Many cases are not clear cut
+ Is a toaster furniture?
+ Is a tomato a veggie or a fruit?
+ Even individnaul subjects change their minds (McCloskey and Glucksberg, 1978)
        
Typicality ratings
- tend to be highly consistent across participants
+ production frequency correlates
+ affects sentence verification tasks
+ basically always influences categorization performance
        
Response from classical view
- characteristic features vs. definitional features (Simth et al, 1974)
- But what is the purpose of the definition then?
- Typicality predicts even untimed judgments, which should "come from the definition"
- But people want to preserve this theory because it involves logical reasoning, it's classic (Aristotle)
- Hampton showed failure of transitivity: Big ben is a clock, clocks are furniture, but big ben is not furniture
(this is a key feature of definitions)
        
Rosch and Mervis (1975) famous prototype study
- frequency does not predict typicality
- Used feature ratings, and found that typical items share the most features with their classes, but also they share few features with contrasting classes (this second fact is often ignored)
- Barsalou's (1985) additions
+ frequency of instantion: how often you think about item in the category
+ ideals: degree to which it fits the primary goal of the categroy
+ both of these have significant partial correlation with typicality
+ also ran category exemplar production , and foudn that typical examples are thought of first
        
People still try to revive classical view, because it's intuitive and very old. But it should be very dead
                  
Chapter 3: Theories
                
Prototype view:
- Rosch rejected formalizing her view, or saying that it was exactly a prototype
- some think of prototypes are the "best example" but this doesnt work very well
- instead, its the average of the examples, with different feature weights (for dogs, barking is highly weighted but color isn't)
- (additive similarity, like Tversky) for each feature, it has a weight, and categorization happens by adding the weights of features it does have
- but many statements of the theory are vague 
- Perhaps also you track interactions of features (but combinatorial explosion?)
- schemata -- an improved version where you have slots (like color, with many values). Previous theories just had binary features. You could also have relations between the feature slots
        
Exemplar view:
- no summary representation, just a set of examples
- categorization is made by adding similarities
+ this can explain typicality effects, since these reach threshold quickly
- this is generally a counter-intuitive view, since we have no conscious process of this
- also, any theory needs to account for examples, since we have that knowledge
- Medin & Schaffer (1978) was the first formal view, where you have a multiplicative rule for features (MULT RULE)
- also, they have dimension weights for each item
- then you add up the sum of the similarities, which are converted from distance with Shepard's exponential function
- best is to be very similar to a few, than kinda similar to most
- This can account for the Posner and Keele paradigm, since the prototypes are similar to many of the examples
- which is an exemplar?
+ each type of object, or each token  (view) of an object?
+ evidence supports each token/exposure (Nosofsky, 1988, also Barsalou)
        
Knowledge view
- just part of general knowledge, not separate
(also, theory theory, but use of word theory make it sound scientific)
-Barsalou's "ideals" is an example of the theory-based concept, or goal-driven categories
- no learning mechanism is part of view, and we can't just assume it would blend well with an exemplar model
        
generalized context model
- Krushke's ALCOVE could learn feature attention weights
- Shepard's generalizaton laws converts distance to similarity
- then Luce choice rule allows for categorization
- "gamma" can exponentiate elements in Luce choice, which influence degree of probability matching
        
        Chapter 4: Exemplar effects and theories
          
- one-shot learning does not require some abstract notion of a concept (is this true?) 
+ I think this is only true if the exemplar theory is right
- Ross: people reason from examples with simple math problems
        
Exemplar effect:
- just an advantage of old items over new ones?
+ not considered valid data for use of exemplars anmore, since exemplars decay over time
        
Exemplar reminder effects:
- Ross: learn 2 exemplars
+ get 3rd that reminds you of one of the previous
+ shows that this influences feature generalization
+ neither exemplar nor prototype models can really account for this, since it's an entire generalization from one specific example
- the order of the examples matters
+ where two consecutive items can highlight a certain dimension of similarity
- superficial similarity to one example seems to matter a lot (doctors and skin with diseases, Brooks et al.)
        
Allen and Brooks (1991) - taught subjects rules for categories, but they were still influenced by individual example similarity
+ different for visual vs. verbal feature list, where it's easier to pay attention to the verbal list
        
Malt: different strategies in cateogrization?
- Also, categorizing a new item can prime a subsequent repsonse to an old item in that category
+ evidence for exemplar representation
- but is it just implicit memory?
+ it might not be part of the concept, just a simple practice effect?
        
Exemplar models don't account for the exemplar reminder effects, while prototype models do not account for exemplar effects in categorization (but they can account for the other's weakenss)
+ prototype theory has episodic memory to help it as well, so pointing to particular exapmles isn't a good argument against these models
        
Main difference between models: linear separability (Medin & Scwaneflugel, 1981)
- no difference in linear separability vs not in terms of ease of learning
- Smith and Minda (1998). Prototype is learned early on, then exemplar model fits better
- Explained by the HDP?
        
- exemplar model almost always fits better, but the studies are so simple, that exemplars may have advantage (unlike with natural categories)
+ also, in many non-linear setups, people find it really hard to learn! (60% or less success)
+ another replication of Medin and Schaffer need 38 blocks to learn the 9 stimuli
+ also, Rosch and Mervis (1975) found many features can linearly separate categories!
+ little attempt to use realisitic category structures (and people can learn from one example!)
+ sometimes, some participants are fit well by prototype learners, and other by exemplar model
+ people find it easier to learn names for stimuli in non-linear task, rather than categories them!
+ also, sensitivity parameters can absord imperfect memoy in exemplar models (even the difference between amnesics vs. not!), which isn't very psychologically useful
        
** Exemplar models usually fit better, but we seem to use both types
                  
Chapter 5: Misc. effects        
        
Base rate neglect
- People seem to judge by likelihood, while neglecting the base rate of the categories
- Krushke offers an attentional learning theory of this, also (Gluck and Bower)
        
Feature correlation
- How does a prototype represent this?
- Malt and Smith (1984). Feature correlations did not matter much for predicting typicality
- Chin-Parker and Ross (2002). People do not learn correlations while learning classification, but did for induction learning
- inconsistent with exemplar models, which implicity track correlatinos
- Note: this is weird! shouldn't it be easy to track correlations in a probabilistic account?      
        
Category construction
- or unsupervised learning
- typical way a child learns words
- difficult to have people learn mult-dimensional categories (e.g. Ashby study), als see Medin et al. 1987
- there is less unidimensional learning in a sequential version
- prior knowledge also helps learn multi-dimensions
-various other ways to counter-act this effect, like a feature-induction task
        
Category use
- we have lots of other experience with items in categories, not just labeling them as in the studies here
- inferences, uses, etc. and this can influence subsequent categorization
                  
Chapter 6: Knowledge effects
                
TODO          
          
Chapter 7: Taxanomic Organization and the Basic Level of Concepts
                
Most things are not in a single category, but can be placed in a large number of them
        
in a neutral setting, people have a preferred level of labels objects
        
Levels          
- superordinate          
- basic          
- sub-ordinate
        
property inheritance: every property true of a members of a category is true of its sub-ordinates (used in Collins & Quillian)
+ putting a category in the proper place gives you a lot of information (a point that has motivated Josh for a long time)
        
cognitive econonmy: easier way to store properties, which motivated Collins & Quillian (1969) when computer storage was an issue
        
Are links hierarchy pre-stored or computed on the fly?          
+ if we list all of the properties for each category, without worrying about storage, we don't need to store links, we can compute them on the fly          
        + many studies on this, but they were not conclusive
        
Collins & Quillian found that response time for category verificiation depended on number of IS-A links in trees, but this could also be predicted by a shared property story
+ Rips et al (1973) found that typical items were faster, which does not fill well with strict hierarchy tory
        
violations of transitivity exist (car seat is a chair, chairs are furniture, but car seat is not furniture). This is a problem for stored links, but can be accounted for by computing similarity on the fly
        
summary: it seems that some things are stored and some are computed, but Murphy things computation has edge in the battle
+ perhaps the non-obvious ones are stored (like a whale is a mammal), while other are computed, so memory is not as elegant as the picture would suggest
        
Basic level
- first noted by Brown (1958) "bird" rather than "animla" or "sparrow"
- first categories people name
- expertise can change levels, as posited by Rosch
- otherwise, basic level carves nature at her joints
- most inclusive level where members share a significant number of common attributes
+ attribute listing stdies
- most incluvie level whee highly similar movements are made to members
- can identify average shapes in basic level categories, but not higher levels
- hearing a basic-level name helps prime picture recognition (due to shape expectations), but other levels do not
- Rosch argued for cue validitiy, like P(cat|tail) is highest for basic level, but this is not true since it is highest for the most inclusive (super) category
        
What makes the basic level special
- differentiation hypothesis: both distinctive (sub-orindates are not) and informative (super categories are not)
- artificial categories:
+ can show a basic level
+ not just determined by the order learned, since they could manipulate this experimentally
        
Atypical sub-ordinates (penguin, boxing glove) might be named at a different level, over-riding the basic level advantage
        
Tversky: it is sharing distinctive parts that makes the basic level special, but there are basic-level advantage even when normal parts are not present
        
Sub-ordinates cannot usually be pluralized, rather acting as mass nouns
(funiture, jewelry, clthoing)... people think of super cateogires as referring to multiple objects
+ children group animlas together and called animal, but will deny this to any single animal
+ it is harder to learn super caegories, like furniture, in part because abstrat function property ties them together
        
Expertise
- Tanaka and Taylor (1991) is first study
- experts list more features at sub-oridante level in their domains of expertise
- fairly likely to produce sub- names when referring to objects
- experts and novices group objects together (like physics roblems)
- thus, the preferred level depends on domain, and specific nature of expertise (even dog experts only know a couple of breeds)
        
Prototype models
- can account for feature-overlap notion of hierachy, which is one advantage of this type of model
Exemplar models
- not attempted to account for basic level
- the entire notion of hierarchical structure does not work naturally with approach
+ basic level advantage for classifying objects, but exemplar model would give advantage to the sub-ordinate level
+ also, doesn't make strong predictions about any of the levels of hierarchy, since same examples are stored at al levels
+ could store only certain examples at each level? seems very ad hoc
        
knowledge view doesn't predict basic-level advantage, but is consistent with it
+ basic-level may not be heavily dependent on knowledge
        
Rosch's 1976 paper was a genuine discovery, so none of the modelling frameworks really predicted it          
          
Chapter 8: Induction
                
category-based induction: extending category information to a new object or category
        
chapter deals with tcase where category is already known
        
Rip's induction task
- Rips (1975) is classic reference, which introduced the ideas and techniques, but strangely there was little follow-up work until 10 years or more later
- single premise inductive arguments
- identified two factors tha tmatter:
+ typicality of the given category
+ similarty of premise category to target category
++ it is clear that the typicality result is an obvious matter of categorization
++ predicts asymmetries in induction, which exist for people
        
Osheron et al. 1990
- multiple premises
- similarity + coverage, or how well the premises cover the smallest category that includes all the items
effects
- premise typicality
- premise diversity
- premise monotonicity (add more premises for a stronger argument)
- inclusion falacy
+ people sometimes claim that the argument is stronger when the conclusion is a whole category rather than just 1 item, like "all birds" rather than "ostrich"
++ get this by similarity
- kindergartenrs showed evidence of using similarity but not coverage, but by 2nd grade, they use coverage
- criticism:
+ it doesn't account for non-blank properties
+ similarity varies with respects
Coley et al. found that induction is not always influenced by expertise, when indigenous socities that categorized birds at a lower level showed similar inferences to college students
+ thus, even if you are missing the property knowledge, your biology knowledge my override it
+ thus, it's not just similarity, its something more biological and deep about a domian
Also, knowledge effects can make transfer thematic rather than biological, like a bacteria in cats ending up in their litter
        
How many categories are used in induction, if you are unsure about membership?
- see object with missing features, asked to predict a missing one
- the key experimental design is that the alternative categories change the property estimates,  if they are used in the mental representation
- by and large, people seem to only use the primary category
- asking a categorization question, "what category is this object?", does not necessarily matter
- Ross and Murphy (1996), when the question istelf brings the secondary category to mind, people then do use it. But they forget to in neutral cases
        
Does this have any implications for prototype and exemplar models?
- most of the work on category-based induction implicitly uses prototype view of concepts
- exemplar models have failed to provide an answer for hierarchcial categories. How could an exemplar model represent that all robins are birds
- clear influence of knowledge-based effects in induction
        
        Chapter 9: Concepts in infancy
                
If there was a single main theme to cogntive science, it is how do people come to have knowledge
        
Finding out the development tells us about the adult structure, and vice versa
        
Last twenty years have dramatically changed our understanding of infancy, mostly due to new methods
+ object permanence much earlier with looking time procedure
        
Testing for categories
- present a bunch of bunnies, then a mouse, see if they dishabituate
- should choose a constrast category that is perceptually as close as posibble
- can only really say discrimination relative to this pair, not in general
- weird asymmetries: Quinn has found cat -> dog is discrim., but not vice versa
- could often be based on perceptual features
+ for instance, if you saw a bunch of red things and then another color, you would notice it but it is not a category
        
Trouble with infant sutdies
- between subjects, and subjects are expensive
- paired preference procedure: have them look at two different objects, measure which is longest
- hard to tell if category was not learned, or if the test was too difficult
+ not that they didn't learn, but they didnt "learn to discriminate bunnies from mice"
        
Much of development can be thought of as category learning, but it often is not described that way
- often conflate learning in task with learning in real world -- which are they looking for?
        
Bomba and Siqueland: like Posner and Keele, infants learned prototypes for simple shapes without seeing them, and it was done so "unsupervised
+ follow-ups have shown infants can learn unsupervised cateogries, multiples of them, if they are intermixed
+ can learn artificila categories
        
Natural concepts
- infants seem to use face information more than body information
- Mandler: sequential touching paradigm, where children get a bunch of toys, and how many of the same type they play with in a row is recorded
- Mandler argues hat global categories (superordinate) are learned first, and only these are conceptual
+ basic level categories show no difference in this type of task
+ claims previous studies were based on surface features, even though they may be learned much earlier than other categories
        
Muprhy thinks pereptual/conceptual divide is murky
- there are many high-level commonalities amongst supercateogires as well
- view that perceptual categories are enriched to become conceptual ones, rather than two separate syetmes
- also, distinctive items are played with more in sequential touching task  
        
General problems with these studies (infant knows "dog")
- small number of pictures
-very atypical examples are never tested    
        
sortals: concepts that can be counted, like cats, rather than "red"
- Xu and Carey claim these don't develop until 11 or 12 months, because infants don't use categories to track objects disappearing/reappearing behind screen
- Baillergeon and colleagues disagree, on going debate
        
Can test for categories by property induction, where toy makes a cool sound if turned over, see if they try it with a new toy
        
Studies seem to be caught up in particular of cateogires, what they do/dont acquire, 
        
Important aspects of human conceptual structure arises from innate learhcing mechanism rather than from education and experience},
author = {Murphy, Gregory L},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
publisher = {MIT Press},
title = {{The Big Book of Concepts}},
year = {2004}
}
@article{Murphy1985,
annote = {Theory: mental "explanation," or the glue that holds concepts together. Thus, it does not have to be a full-fledged intuitive science-like theory. Mostly, it's an explanation, which might include causal knowledge, rules, etc.
                  
Problems with other views        
--Maybe the draw towards the classical theory of concepts is that they are defined by theories -- not necessary and sufficient definitions.
-- Prototypes (probabilistic theory) do not allow for non-linear categories, and people can learn these
-- Exemplar models: doesn't explain how the concepts are held together
        
        
What is wrong with similarity? Concepts can be made arbitrarily more similar or less similar depending on the features chosen. To change the importance of age, "around 10 years ago," "around 100 years ago," "1000 years ago etc." could all be included.
        
Whatever is selecting the relevant features, is doing the explanatory work
        
Famous example: Silver dollars are 4 cm in diameter, soda can is 7.5 cm. If you see a round silver thing at 5 cm, you are more likely to think it is a soda can. This is because it's a theory of soda cans, even though the statistics match.
        
Another famous example: flammable is applicable to many things, but we associated with wood because of its typical theoretical role. Flammable is not associated with money by contrast.
        
Correlations stick when they are attached to theories.
        
Barsalou ad hoc categories are good examples of theory-based categories.
        
Why are some groups of correlated feautres, more coherent than others? There may be an underlying theory that explains why they cohere, like "flight", "wings", "beak"
        
                  
Relation to development:        
        
Markman's work: Children have trouble learning superordinate categories, perhaps because they want a theory to explain how these diverse things hang together
        
Carey's work: Children initially organize biological things around similarity to humans, but later shift to scientific metric. But even 4 year olds don't think a toy monkey will have a spleen, so they have a richer theory than just perceptual similarity
                  
Relation to classical theory of concepts        
-- Many people believe they can define concepts, even when they can't
-- Maybe because they can EXPLAIN them
-- when people list defining features, maybe they are listing the aspects most central to their concepts, rather than a necessary and sufficient definition
                  
Conclusion        
- It's not that the previous toolkit (prototypes, exemplars) is not worthwhile, but they are insufficient to provide a theory of concepts
-- A coherent concept is one that we have a good theory about, and that fits well with other knowledge},
author = {Murphy, Gregory L. and Medin, Douglas L.},
doi = {10.1037/0033-295X.92.3.289},
file = {:Users/Brenden/Documents/Mendeley//Murphy, Medin - 1985 - The role of theories in conceptual coherence.pdf:pdf},
issn = {1939-1471},
journal = {Psychological Review},
keywords = {theory theory},
mendeley-tags = {theory theory},
number = {3},
pages = {289--316},
title = {{The role of theories in conceptual coherence.}},
volume = {92},
year = {1985}
}
@article{Murphy1994,
annote = {Categorization is not helpful if it did not support prediction, like those of novel features
        
Many categorization judgments are uncertain. Is that painting a cezanne? Is chis an extrovert?
        
It is difficult to test theories of categorization, since they involve a large number of component processes.
- encoding, abstraction, storage, retriveal, decision process
- also, you can make categorical predictions 
        
Here, they tried to isolate one component of this process
- given a set of examples, which they see the whole time
- related paradigm by Osherson et al
                  
prediction rules        
- often vague about what it means to make a predictoin
(relative proportion of dogs that drool?)
- Anderson's Rational Model does provide a detailed proposal for feature prediction, with Bayesian decision rule
- assumes features are independent, and use uncertainty optimally
                  
single-category view
- people may just base predictions on one category, in a sort of "cognitive economy" to simplify processes
                  
epxeriments
                
stimuli were "children's drawings" that differed in shape and shading. Given a drawing's shape, which child drew it? Then... what is the probability of the particular shading?
        
Construct stimuli where there is a 10% difference, according to the Bayesian rule, whether you use the alternative categories or not
        
Experiment 1: explicit categorization decision before prediction
Experiment 2: no such decision before prediction
        
increasing condition: looking outside the category increasing the probability of prediction
neutral condition: this would make no difference
        
Which child do you think drew it?
Then, what color do you think it is?
        
Exp 1 Results:
percentage of critial features had ceiling effect
- probability judgments did not
        
No difference between conditions
        
Exp 2 Results: No initial categorizations,
No difference was foundn again
        
They also did a power analysis, and did not find this likely to be the problem here.
        
Experiment 3
        
Replicated first experiment, using more typical category learning procedure.
        
Results: small but nonsignificant difference between groups (about 4% points). But due to two subjects with very high increasing scores
        
But learning criterion was very strict, where subjects needed to learn every feature of every item perfectly.
        
Experiment 4
        
Manipulated within-target category and outside category statistics, such that the rational moel predicts the same effect for both manipulations
        
Results: manipulating the taret stimuli had a highly signifcant effect, but no effect in the nontarget manipulation
        
Experiment 5 and 6
Single category rule suggests one answer, and Bayesian rule suggests another.
        
Also, tests an alternative called the "conjuntion strategy"
        
Results ex 5: (without initial decision) single-category view was predicted 58% of the time but not significant
        
ex 6: (with initial decision) overwhelming chose consistently with the single-category view
                  
Part 2: feature independence
                
- hypothesis: once a decision is made, the features that lead to that decision no longer influence categorization
- true of rational model, and also many prototype models
        
- evidence in literature is not consistent
        
        
Experiments 7 and 8: Participants made a feature-prediction judgment. They found that alternative categories, where the features are perfectly correlated, can influence teh decision.
        
But isn't this exactly the scenario that was tested against in the first experiments? It's not clear where they learned the correlatoin, whether its inside or outside of the caegories.
        
Experiment 10: They clustered all the additiona information in one other alternative category, rather than distributed across all of them. But, still this made no difference!
        
Experiment 11: People could have been sensitive to correlations outside the target category. Experiment 11 tried to distinguish this.
        
Finally, there was a big difference! But they suggest it is trhough a very different route, kind of an explicit memory trace strategy, than the Bayesian acount would predict.
        
        Conclusions
                
Nice that they were able to isolate the decision process. But you risk the decision process being different than it usually is, but this is for future research to decide.
        
Anderson's rational model. This  study was designed to test the Bayesian idea more generally, not just this specific model. It's possible that the rational model would  make different preditions, since it always learns its own categories (sub-clusters)
      },
author = {Murphy, Gregory L. and Ross, Brian H},
file = {:Users/Brenden/Documents/Mendeley/Murphy, Ross - 1994 - Predictions from Uncertain Categorizations.pdf:pdf},
journal = {Cognitive Psychology},
keywords = {classic psychology,feature prediction,rich concepts},
mendeley-tags = {classic psychology,feature prediction,rich concepts},
pages = {148--193},
title = {{Predictions from Uncertain Categorizations}},
volume = {27},
year = {1994}
}
@book{Murphy2012,
author = {Murphy, Kevin},
file = {:Users/Brenden/Documents/Mendeley/Murphy - 2012 - Machine Learning A Probabilistic Perspective.pdf:pdf},
isbn = {9780262018029},
publisher = {MIT Press},
title = {{Machine Learning: A Probabilistic Perspective}},
year = {2012}
}
@inproceedings{Murray2006,
author = {Murray, Iain and Mackay, David J C and Ghahramani, Zouin},
booktitle = {{Proceedings of the 22nd Annual Conference on Uncertainty in Artificial Intelligence (UAI-06)}},
file = {:Users/Brenden/Documents/Mendeley/Murray, Mackay, Ghahramani - 2006 - MCMC for doubly-intractable distributions.pdf:pdf},
keywords = {classic AI},
mendeley-tags = {classic AI},
pages = {359--366},
title = {{MCMC for doubly-intractable distributions}},
year = {2006}
}
@article{Nakamura2012,
annote = {I was curious about Dehaene's take on the evidence for a motor contribution to letter recognition, and I think this paper gives a pretty clear answer. 
        
"We therefore suggest that [left pre-motor cortex] contributes to fluent reading by inferring the writing gestures corresponding to the observed handwritten letters.... We therefore conclude that both VWFA and [left pre-motor cortex]  are automatically activated even during fluent reading."
        
It seems that he sees this as complementary to his neuronal recycling hypothesis. Also, interestingly, the motor region showed invariance to some major spatial distortions, while the VWFA did not.
Uses dynamic stimuli to show unique contirubtion of motor areas.
-----
The brain changes during reading. Do they very from one culture to another, or is it largely universal?
        
The acquisition of reading in Chinese has been though to be heavily motor dependent, but not for other languages.
        
The "neuronal recycling" hpoyhtesis would suggest cross-cultural invariance, since there are strong innate constraints based on prior evolution
                  
hypothesis: all cultures have two main systems, one of rshape analysis (VWFA) and one for motor gesture decoding (premotor cortex)
        
potential confound: most neuroimaigng studies of alphabetic reading used printed letter strings, while Chinese studies used cursive. Since one of these departs strongly from handwriting, it might require different top-down activation.
                  
experiment
                
attempt to sparate culture-specific and culture-universal models
        
repetition priming / fmri adapation design. Word is presented in cursive, then look at degree of repretition if shown all at once, written dynamically forward, written backward, or spatially compressed...
        
this should activate the entire set of brain areas using in reading.
        
VWFA: shoudl respond maximally to static words
Exner's area: should respond maximally to dynamic trajectory, backard directino should prevent advitvity
        
Will these systems operate differently in French and Chinese?
                  
results:
          
behavioral data        
task was letter classification (I think?). People were faster at forward than backward, and slower at distortions. Priming was more pronounced for dynamic too
        
Difference between forward and backward was more pronoucned in chinese
        
Spatiall distorted words, relative to not, activated some regions
        
Moving, relative to not, activated MT and a whole range of areas.
        
Fast reading system: capable of suppression efects due to primes. There was activity in Exner's area (premotor cortex).
        
Again, no between-group comparisions survied test.
                  
main prediction        
forward vs. backwards motion:
significant activity in Exner's area for forward tirals.
Also, it showed no significant difference for normal vs. distorted layouts -- very idfferent from VWFA. has a distorition resitant component -- capable of inferring the gestures associated with writing.
          
        Decoding was faster with consistent motor dynamics, contributing to the notion that gestures contribute to visual letter perception.
        
This whole network (motor and visual) activates very quickly, all part of a fast and invariant network underlying fluent reading.
                  
no cultural differences were found        
                  
double association
VWFA: showed no difference in priming for forward/backward trajectories, but enhanced activation for spatially distorted letters, showing top-down amplication by cognitive load
                  
left PMd (Exner's area) priming with cursive, but only in forward direction. However, priming does not change with spatial distrotion or not. This region contributes to fluent reading by inferring the writing gestures corresponding to the observed handwritten letters. It remains highly senstiveit o flashed cursive words in expert adults -- maybe evne a larger role in kids.
      },
author = {Nakamura, K. and Kuo, W.-J. and Pegado, F. and Cohen, L. and Tzeng, O. J. L. and Dehaene, S.},
doi = {10.1073/pnas.1217749109},
file = {:Users/Brenden/Documents/Mendeley/Nakamura et al. - 2012 - Universal brain systems for recognizing word shapes and handwriting gestures during reading.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = nov,
number = {50},
pages = {20762--20767},
title = {{Universal brain systems for recognizing word shapes and handwriting gestures during reading}},
volume = {109},
year = {2012}
}
@inproceedings{Navarro,
annote = {Can people learn categories that change over time?
        
For instance, cell phones get smaller over time
        
Experiment 1: stimuli varied in height. classify as 1 or 2
+ supervised category learning
+ the mean of both categories increases linearly over time
+ perfect adapation is to figure out the line of best fit
        
results:
some bias: High items are classified better than the low items
        
models:
- stationary prototype model
- recency weighting: weight more recent data stongly
- regression model: fit the optimal regression
        
model results:
- regression model is unbiased
- prototype model is terrible
- recency + bias: this one fits the best [ respose bias for higher category]
        
Model accounts at an individual level:
- response bias is useful: they tend to do better on performance
        
conclusions:
- if the world changes systematically, then they need to adapt
- what kinds of mental representations?
+ clear individual differences
+ relative stimlus magnitude does some of the word
+ learned response bias suggests improved performance
        
Other types of changes?},
author = {Navarro, Daniel J and Perfors, Amy},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Navarro, Perfors - 2012 - Anticipating changes Adaptation and extrapolation in category learning.pdf:pdf},
keywords = {at no two moments,born and die,categorization,change detection,concepts,dy-,in time are we,namics,objects move,order effects,plants and animals are,presented with the same,time dependence,world},
pages = {809--814},
title = {{Anticipating changes: Adaptation and extrapolation in category learning}},
year = {2012}
}
@article{Nayak2012,
annote = {With sign language, there is a lot of co-articulation structure. Between signs, there are transition movements. Most sign systems deal with segmented signs, so they might fall apart when this is added.},
author = {Nayak, Sunita and Duncan, Kester and Sarkar, Sudeep and Loeding, Barbara},
file = {:Users/Brenden/Documents/Mendeley/Nayak et al. - 2012 - Finding Recurrent Patterns from Continuous Sign Language Sentences for Automated Extraction of Signs.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {2589--2615},
title = {{Finding Recurrent Patterns from Continuous Sign Language Sentences for Automated Extraction of Signs}},
volume = {13},
year = {2012}
}
@techreport{Neal1993,
annote = {MH is typically applied where you partition the variables into a set of K components, which are subsequently updated with independent moves
        
It is desirable to try to choose the decomposition such that highly dependent choices are blocked together.
                  
not including the current variable value        
If your proposal distribution does not include the current state, this can lead to faster convergence, but it can lead to non-ergodtic chains if applied in a fixed order
        
There are alternative acceptance functions, like sampling from the porposed vs. current state based on the probability ratio
        
There are rejectionless methods, but they require a lot of computation
                  
dynamical and hybrid monte carlo        
continuous variables, derivatives must be easy to calculate
                  
assessing convergence        
If there are two modes, one with more mass, and you start at the small mode.... how do you decide when to start burn in? When it transitions to the new mode? how much before?
                  
number of chains        
Should you pick one long chain, or many shorter chains? 
a) use one chain if there is doubt that the quilibirum can be reached in a short run
c) use many chains when you can reach the equalibrium quickly (but not many practical examples)
b) but for most problems, you probably want a few runs ton assess convergence, so that's a good strategy
        
If you have a bunch of chains, and they are all in different places, it's tought to know if they are stuck in lcoal minima or moving about the equilibrium distribution slowly (which would be ideal).},
author = {Neal, Radford M},
file = {:Users/Brenden/Documents/Mendeley/Neal - 1993 - Probabilistic Inference Using Markov Chain Monte Carlo Methods.pdf:pdf},
institution = {University of Toronto, Department of Computer Science},
title = {{Probabilistic Inference Using Markov Chain Monte Carlo Methods}},
year = {1993}
}
@article{Needham2002,
author = {Needham, Amy and Barret, Tracy and Peterman, Karen},
doi = {10.1016/S0163-6383(02)00097-8},
file = {:Users/Brenden/Documents/Mendeley/Needham, Barret, Peterman - 2002 - A pick-me-up for infants' exploratory skills Early simulated experiences reaching for objects using '.pdf:pdf},
issn = {01636383},
journal = {Infant Behavior and Development},
keywords = {baby toolbox,classic psychology,exploratory skills,infant,sticky mittens},
mendeley-tags = {baby toolbox,classic psychology},
number = {3},
pages = {279--295},
title = {{A pick-me-up for infants' exploratory skills: Early simulated experiences reaching for objects using 'sticky mittens' enhances young infants' object exploration skills}},
volume = {25},
year = {2002}
}
@inproceedings{Newell1959,
annote = {One of the first programs to separate it's knowledge of a domain from it's general problem solving ability
        
means-end analysis: take steps that bring you closer to the end goal
        
operator: applied to objects to produce different objects
features: characterize the objets
        
Task could be to find an object with a given feature, like if the object is a chess board, you want to have a winning position
        
Proving theorems can be structured in this way
                  
principals:        
        
1) make progress by working on a set of easier goals
- this leads to a recursive algorithm
        
2) means-ends analysis
- reduce the difference between the current state and the end state (greedy step)
        
Could be used for logical proofs, where you transform one expression into another},
author = {Newell, A and Simon, H A},
booktitle = {Proceedings of the International Conference on Information Processing},
file = {:Users/Brenden/Documents/Mendeley/Newell, Simon - 1959 - Report on a general problem-solving program.pdf:pdf},
keywords = {classic AI,classic psychology},
mendeley-tags = {classic AI,classic psychology},
pages = {256--264},
title = {{Report on a general problem-solving program}},
year = {1959}
}
@misc{Ng,
annote = {Reinforcement learning
- no consensus on whether value iteration or policy iteration is better
        
- you might have to learn the state-transition model, where you have a policy, estiamte these parameters, learn a new policy, etc.
        
- for continuous proble, you can discretize, but you have the curse of dimensionality},
author = {Ng, Andrew},
file = {:Users/Brenden/Documents/Mendeley/Ng - Unknown - CS229 Lecture Notes.pdf:pdf},
pages = {1--15},
title = {{CS229 Lecture Notes}}
}
@misc{Nga,
annote = {Thus, the number of training examples needed to learn "well" typically grows linearly in the VC dimension
        
-----
Tries to formalize the "bias/variance" trade-off in the classification setting.
        
PAC, is a framework and set of assumptions, under which many learning theory results were proved
        
empirical risk minimization (ERM): the hypothesis that minimizes classification error on the training set
                  
the case of finite H
                
theorem (uniform convergence result):
the probability that there is no hypothesis in the set, such that the training and generalization error for that hypothesis are greater than some gamma, decreases linearly in k, the number of hypotheses in the set, and and increases exponentially in the sample size        
        
sample complexity:
the number of samples you need, m, to get a certain level of generalizaito, grows with the log of k          
          
        what can we prove about our ERM algorithm?
the bound on generalization error grows linearly in the training error and logrithmically in the number of hypotheses
                  
the case of infinite H        
        
VC-dimension: for a classifier, the largest number of points for which it can shatter A SINGLE configuration of those points
        
shattering means to classify the points in all possible ways
        
Theorem due to Vapnik:
        
generalization error of our ERM hypothesis can be bounded by a quantity that grows:
- linearly in the true error of the best hypothesis
- linearly in the VC dimension
- linearly in M
        
Thus, the number of training examples needed to learn "well" typically grows linearly in the VC dimension},
author = {Ng, Andrew},
file = {:Users/Brenden/Documents/Mendeley/Ng - Unknown - CS229 Lecture notes Learning theory.pdf:pdf},
pages = {1--11},
title = {{CS229 Lecture notes: Learning theory}}
}
@inproceedings{Ng2002,
annote = {Presents spectral clustering algorithm, and an analysis under matrix perturbation theory.
        
This is a highly cited paper, and probably the most common version of spectral clustering.},
author = {Ng, Andrew Y and Jordan, Michael I and Weiss, Yair},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:Users/Brenden/Documents/Mendeley/Ng, Jordan, Weiss - 2002 - On Spectral Clustering Analysis and an algorithm.pdf:pdf},
keywords = {classic AI},
mendeley-tags = {classic AI},
title = {{On Spectral Clustering: Analysis and an algorithm}},
year = {2002}
}
@inproceedings{Ng2000,
author = {Ng, Andrew Y and Russell, Stuart},
booktitle = {{International Conference on Machine Learning (ICML 2000)}},
file = {:Users/Brenden/Documents/Mendeley/Ng, Russell - 2000 - Algorithms for Inverse Reinforcement Learning.pdf:pdf},
keywords = {inverse optimal control},
mendeley-tags = {inverse optimal control},
title = {{Algorithms for Inverse Reinforcement Learning}},
year = {2000}
}
@inproceedings{Niculescu-mizil2007,
author = {Niculescu-mizil, Alexandru and Caruana, Rich},
booktitle = {{Elevent International Conference on Artificial Intelligence and Statistics (AISTATS-07)}},
file = {:Users/Brenden/Documents/Mendeley/Niculescu-mizil, Caruana - 2007 - Inductive Transfer for Bayesian Network Structure Learning.pdf:pdf},
keywords = {graphical models},
mendeley-tags = {graphical models},
number = {1},
title = {{Inductive Transfer for Bayesian Network Structure Learning}},
volume = {14853},
year = {2007}
}
@article{Niedenthal2007,
abstract = {Recent theories of embodied cognition suggest new ways to look at how we process emotional information. The theories suggest that perceiving and thinking about emotion involve perceptual, somatovisceral, and motoric reexperiencing (collectively referred to as "embodiment") of the relevant emotion in one's self. The embodiment of emotion, when induced in human participants by manipulations of facial expression and posture in the laboratory, causally affects how emotional information is processed. Congruence between the recipient's bodily expression of emotion and the sender's emotional tone of language, for instance, facilitates comprehension of the communication, whereas incongruence can impair comprehension. Taken all together, recent findings provide a scientific account of the familiar contention that "when you're smiling, the whole world smiles with you."},
annote = {Posture and body changes influence emotion and preference. 
        
Embodied cognition is an old idea (read Prinz)
        
      },
author = {Niedenthal, Paula M},
doi = {10.1126/science.1136930},
file = {:Users/Brenden/Documents/Mendeley/Niedenthal - 2007 - Embodying emotion.pdf:pdf},
issn = {1095-9203},
journal = {Science},
keywords = {Animals,Brain,Brain: physiology,Cognition,Comprehension,Emotions,Facial Expression,Humans,Kinesics,Mental Processes,Models,Neurons,Neurons: physiology,Psychological,Social Perception,Thinking,embodied cognition},
mendeley-tags = {embodied cognition},
month = may,
number = {5827},
pages = {1002--5},
pmid = {17510358},
title = {{Embodying emotion.}},
volume = {316},
year = {2007}
}
@article{Niedenthal2010,
abstract = {Recent application of theories of embodied or grounded cognition to the recognition and interpretation of facial expression of emotion has led to an explosion of research in psychology and the neurosciences. However, despite the accelerating number of reported findings, it remains unclear how the many component processes of emotion and their neural mechanisms actually support embodied simulation. Equally unclear is what triggers the use of embodied simulation versus perceptual or conceptual strategies in determining meaning. The present article integrates behavioral research from social psychology with recent research in neurosciences in order to provide coherence to the extant and future research on this topic. The roles of several of the brain's reward systems, and the amygdala, somatosensory cortices, and motor centers are examined. These are then linked to behavioral and brain research on facial mimicry and eye gaze. Articulation of the mediators and moderators of facial mimicry and gaze are particularly useful in guiding interpretation of relevant findings from neurosciences. Finally, a model of the processing of the smile, the most complex of the facial expressions, is presented as a means to illustrate how to advance the application of theories of embodied cognition in the study of facial expression of emotion.},
author = {Niedenthal, Paula M and Mermillod, Martial and Maringer, Marcus and Hess, Ursula},
doi = {10.1017/S0140525X10000865},
file = {:Users/Brenden/Documents/Mendeley/Niedenthal et al. - 2010 - The Simulation of Smiles (SIMS) model Embodied simulation and the meaning of facial expression.pdf:pdf},
issn = {1469-1825},
journal = {Behavioral and Brain Sciences},
keywords = {Animals,Biological,Brain,Brain: physiology,Emotions,Emotions: physiology,Eye Movements,Eye Movements: physiology,Facial Expression,Humans,Models,Recognition (Psychology),Reward,Smiling,Smiling: physiology,Smiling: psychology,embodied cognition},
mendeley-tags = {embodied cognition},
month = dec,
number = {6},
pages = {417--33; discussion 433--80},
pmid = {21211115},
title = {{The Simulation of Smiles (SIMS) model: Embodied simulation and the meaning of facial expression.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21211115},
volume = {33},
year = {2010}
}
@article{Niedenthal2001,
author = {Niedenthal, Paula and Brauer, Markus and Halberstadt, Jamin and Innes-Ker, \AA se},
doi = {10.1080/02699930143000194},
file = {:Users/Brenden/Documents/Mendeley/Niedenthal et al. - 2001 - When did her smile drop Facial mimicry and the influences of emotional state on the detection of change in emotional expression.pdf:pdf},
issn = {0269-9931},
journal = {Cognition \& Emotion},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
month = nov,
number = {6},
pages = {853--864},
title = {{When did her smile drop? Facial mimicry and the influences of emotional state on the detection of change in emotional expression}},
volume = {15},
year = {2001}
}
@article{Nieuwenhuis2011,
author = {Nieuwenhuis, Sander and Forstmann, Birte U and Wagenmakers, Eric-Jan},
doi = {10.1038/nn.2886},
file = {:Users/Brenden/Documents/Mendeley/Nieuwenhuis, Forstmann, Wagenmakers - 2011 - Erroneous analyses of interactions in neuroscience a problem of significance.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {statistics},
mendeley-tags = {statistics},
month = aug,
number = {9},
pages = {1105--1107},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
shorttitle = {Nat Neurosci},
title = {{Erroneous analyses of interactions in neuroscience: a problem of significance}},
volume = {14},
year = {2011}
}
@incollection{Nigam2006,
author = {Nigam, K and McCallum, A K and Mitchell, T},
booktitle = {Semi-Supervised Learning},
editor = {Chapelle, O and Scholk\"{o}pf, B and Zien, Alexander},
publisher = {MIT Press},
title = {{Semi-Supervised Text Classification Using {EM}}},
year = {2006}
}
@article{Nigam2000,
author = {Nigam, K and McCallum, A K and Thrun, S and Mitchell, T},
journal = {Machine Learning},
pages = {103--134},
title = {{Text Classification from Labeled and Unlabeled Documents using EM}},
volume = {39},
year = {2000}
}
@article{Nihei1983,
author = {Nihei, Yoshiaki},
file = {:Users/Brenden/Documents/Mendeley/Nihei - 1983 - Developmental change in covert principles for the organization of strokes in drawing and handwriting.pdf:pdf},
journal = {Acta Psychologica},
keywords = {handwriting},
mendeley-tags = {handwriting},
pages = {221--232},
title = {{Developmental change in covert principles for the organization of strokes in drawing and handwriting}},
volume = {54},
year = {1983}
}
@article{Ninio2007,
abstract = {30 4-5-year-old children copied a horizontal line, a vertical line, and an inverted T. Preference for a certain strategy in copying the compound figure was interpreted in terms of a simple phrase structure, one involving movements controlled with minimal degrees of freedom. Considerations of the total utterance in terms of semantics and phrase structure are necessary to account for copying patterns. In a second experiment, 163 children from kindergarten through sixth grade were given the inverted-T copying task. With increased age, children come to prefer increasingly complex combinational structures.},
annote = {Follow up on work from Goodnow and Levine (1973). They only looked at drawing an inverted-T. 
        
They found evidence for more "complicated phrase-structure" as children get older. By this, they mean keeping track of degrees of freedom for where the next stroke should start.
        
They found that the adult drawing pattern has teh most degrees of freedom, and early drawing patterns have fewer.},
author = {Ninio, Anat and Lieblich, Amia},
file = {:Users/Brenden/Documents/Mendeley//Ninio, Lieblich - 1976 - The Grammar of Action``Phrase Structure in Children's Copying.pdf:pdf},
journal = {Child Development},
keywords = {handwriting,program induction},
language = {EN},
mendeley-tags = {handwriting,program induction},
month = oct,
number = {3},
pages = {846--850},
publisher = {University of Chicago Press},
title = {{The Grammar of Action:``Phrase Structure" in Children's Copying}},
volume = {47},
year = {1976}
}
@article{Nisbett1977,
author = {Nisbett, Richard E and Wilson, Timothy Decamp},
file = {:Users/Brenden/Documents/Mendeley/Nisbett, Wilson - 1977 - Telling more than we can know Verbal reports on mental processes.pdf:pdf},
journal = {Psychological Review},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {3},
pages = {231--259},
title = {{Telling more than we can know: Verbal reports on mental processes}},
volume = {84},
year = {1977}
}
@article{Nisbett1983,
annote = {There seems to be a bias in finding failures of inductive reasoning, but less so successes of inductive reasoning. This paper takes this aim
                  
representative heuristic:         
best studied of the biases
        
Flaws in reasoning regarding social situations is particularly harmful. When people fail to help a struggling person, this is attributed to personality, even if they are explicitly told about the low base rate of helping
        
It seems crazy people don't take into account sample size... "I don't understand it, I have 8 grandchildren and all are boys" seems like a reasonable statement
        
People seem to take into account base rates, when they don't infer a student who got an A+ on an exam is a genius if the lowest grade was an A-
        
People also understand the more evidence is better than less, when doing just about anything (20 min vs 5 min interview)
        
Piaget found that by age 10, children have a good undesratnding of randomness and chance -- realize they can't predict the spinner. If you spin it longer, it will land in more places, or it could miss all the places},
author = {Nisbett, Richard E. and Krantz, David H. and Jepson, Christopher and Kunda, Ziva},
doi = {10.1037//0033-295X.90.4.339},
file = {:Users/Brenden/Documents/Mendeley/Nisbett et al. - 1983 - The use of statistical heuristics in everyday inductive reasoning.pdf:pdf},
issn = {0033-295X},
journal = {Psychological Review},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {4},
pages = {339--363},
title = {{The use of statistical heuristics in everyday inductive reasoning}},
volume = {90},
year = {1983}
}
@article{Nishida1995,
abstract = {An essential problem in handwriting recognition is how to cope with the complex shape deformation, and, therefore, the modeling of the deformation and metamorphosis (transformation of an instance of a class into an instance of the other class via continuous transformation) is a key to breaking through the difficulties in handwriting recognition. In this paper, on the basis of the structural feature extraction and description by Nishida, we present a model for structural deformation with simple, local operations that preserve the global structure of the shape. Furthermore, we present an experimental approach to analysis of metamorphosis of character shapes based on the structural deformation model.},
annote = {Recognition by grammartical transformation. First, it does an over-segmentation. These segments can then be removed, combined, transformed, etc. for deformation and recognition
        
But this method looks very complicated.
        
---
Terminology:
singular point -- junction in the image skeleton
        
Steps
1. get singular points
2. Given the singular points, this decomposes an image into "strokes", although these are not real strokes
3. decompose strokes into primitives (straight lines)
4. these primitives are combined, using rules based on concavitiy compared ot the singular point (where do these come from?_
5. Apply transformation to the primitives
-- you can add or remove segments, etc., to get variants in the shape
        
Recognition performance is unclear, and this method seems very, very complicated},
author = {Nishida, Hirobumi},
doi = {10.1016/0031-3203(94)00025-H},
file = {:Users/Brenden/Documents/Mendeley/Nishida - 1995 - A structural model of shape deformation.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {character recognition,image transformation,shape analysis,shape deformation,transformation model},
month = oct,
number = {10},
pages = {1611--1620},
title = {{A structural model of shape deformation}},
volume = {28},
year = {1995}
}
@incollection{Nordborg2004,
address = {Chichester, UK},
author = {Nordborg, Magnus},
booktitle = {Handbook of Statistical Genetics},
doi = {10.1002/0470022620},
edition = {3},
editor = {Balding, D. J. and Bishop, M. and Cannings, C.},
file = {:Users/Brenden/Documents/Mendeley/Nordborg - 2004 - Coalescent Theory.pdf:pdf},
isbn = {0470022620},
keywords = {sparsity},
mendeley-tags = {sparsity},
month = jul,
publisher = {John Wiley & Sons, Ltd},
title = {{Coalescent Theory}},
url = {http://doi.wiley.com/10.1002/0470022620},
year = {2004}
}
@article{Nosofsky1986,
annote = {Early important work on exemplar models
        
Is there a close relationship between identification and classification?},
author = {Nosofsky, R},
file = {:Users/Brenden/Documents/Mendeley/Nosofsky - 1986 - Attention, Similarity, and the Identification-Categorization Relationship.pdf:pdf},
journal = {Journal of Experimental Psychology: General},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {1},
pages = {39--57},
title = {{Attention, Similarity, and the Identification-Categorization Relationship}},
volume = {115},
year = {1986}
}
@article{Nosofsky1997,
abstract = {The authors propose and test an exemplar-based random walk model for predicting response times in tasks of speeded, multidimensional perceptual classification. The model combines elements of R. M. Nosofsky's (1986) generalized context model of categorization and G. D. Logan's (1988) instance-based model of automaticity. In the model, exemplars race among one another to be retrieved from memory, with rates determined by their similarity to test items. The retrieved exemplars provide incremental information that enters into a random walk process for making classification decisions. The model predicts correctly effects of within- and between-categories similarity, individual-object familiarity, and extended practice on classification response times. It also builds bridges between the domains of categorization and automaticity.},
author = {Nosofsky, R M and Palmeri, T J},
file = {:Users/Brenden/Documents/Mendeley/Nosofsky, Palmeri - 1997 - An exemplar-based random walk model of speeded classification.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Concept Formation,Concept Formation: physiology,Cues,Decision Making,Decision Making: physiology,Humans,Memory,Memory: physiology,Models,Perception,Perception: physiology,Psychological,Stochastic Processes},
month = apr,
number = {2},
pages = {266--300},
pmid = {9127583},
title = {{An exemplar-based random walk model of speeded classification.}},
volume = {104},
year = {1997}
}
@article{Nosofsky1994,
author = {Nosofsky, Robert M and Gluck, Mark A and Palmeri, Thomas J and McKinley, Stephen C and Glauthier, Paul},
file = {:Users/Brenden/Documents/Mendeley/Nosofsky et al. - 1994 - Comparing models of rule-based classification learning A replication and extension of Shepard, Hovland, and Jenkins (1961).pdf:pdf},
journal = {Memory \& Cognition},
number = {3},
pages = {352--369},
title = {{Comparing models of rule-based classification learning: A replication and extension of Shepard, Hovland, and Jenkins (1961)}},
volume = {22},
year = {1994}
}
@techreport{O'Donnell2009,
annote = {probabilistic context free grammar: A context free grammar, where the rules for each symbol are selected with some probability (known or unknown)
                  
probability of a tree        
The probability of a parse tree is given by the product of the probability of each of the rules
                  
probability of an expression        
marginalizing over all derivation trees that share the expression
        
PCFGS have no history. We can count the number of rule uses as sufficient statistics.
        
We can count in whatever way or order we like.. the probability of parses can be computed just from counts                  
          
stochastic memorization        
        
When computing a fibonaci number, computation tends to be repeated many times. Dynamic programming algorithms, use memoization techniques
        
memotable: a list of input-output pairs
        
In scheme, you can have a function mem, where you take an argument of a procedure and return a memoized version of it
        
stochastic memoization: sometimes you return a previously used value, sometimes a new value
        
You can build a memoizer based on the chinese restaurant process. Thus, each time you call a function, you pick from past computations with the CRP as a prior
        
Pitman-Yor process: has a discount parameter a, that moves a fraction of a unit of probability mass from each occupied table to the new table
        
Thus, a is the productivity of a restaurant, how much sitting at a new table depends on how many tables already exist
        
Multinomial-dirichelt probabilistic CFG
- where the PCFG probabilities are drawn from a dirichelt prior
        
Adaptor gramar: each non-terminal procedure has been stochastically memoized -- using the Pitman-Yor adaptor grammar. The same Pitman-Yor can appear in different places along the tree, since there can be recursive structure in the grammar
        
When a table is re-used for a high-level non-terminal symbol, it does not increment the tables for all the dependent sub-trees, since this was already cached
        
        Two-stage Adaptor Grammar
                
A slight reformulation (although trivial) where a lexical item (choice in terms of a RHS) is no longer thought of as just the expression, but rather, it is a distribution. Although, it is a very simple distribution, which is just a delta function on the expression.
        
This allows us to more easily build the fragment grammar
                  
Fragment grammar
                
Allows distributions associated with individual lexical items to be non-trivial
        
grow-lexical-child: flips a coin, and if heads, it returns a sample from the child procedure. Otherwise, it returns the procedure itself. This results in an expression, with some non-terminals embedded, which is what is stored at each table. 
        
Thus, while we are sampling the expressions at the tables of the PYP, each decision in the grammar can either be an evaluation or the procedure, where an evaluation recurses and the "procedure" in some sense is the termination point.
        
This results in a non-trivial distribution at each table.
        
It returns an expression, where we can have non-terminal symbols. Thus, we can evaluate the expression to fill-it-in/grow it when we forward sample from that table.
        
Choices that are stored in the lexical item never need to be made again, while choices outside that item must pay the probability "cost" over and over again
                  
Intuition
                
If there is repeated sub-trees, it makes sense to cache this as a lexical item
        
like "a chef" repeated three times should be cached as a lexical item
        
however, "a chef" "a soup" "a omelete" should be cached as a table, but with a variable, since something appears to be changing
        
        Inference        
        
We have a corpus of expressions E (like sentences), and we wish to do inference on the posterior distribution of lexical items P
        
Thus, we don't observe the latent variables that produced it
[which is different than the alphabet learning example in my model]
        
Exchangeable distribution, meaning we can treat each expression E as the "last" expression in the corpus
                  
Metropolis Hastings
                
Proposals are drawn from an approximating PCFG, and scored with the larger fragment grammar model
        
For FGs, and choice immediately changes the probabilities of all other possible choices from the same nonterminal procedure. Thus, we cannot do efficient dynamic programming
        
To make proposals, they "freeze" all the restaurants assocaited with nonterminals, hold their counts constant, while the next expression is parsed. The snapshot is a PCFG},
author = {O'Donnell, Timothy J and Goodman, Noah D and Tenenbaum, Joshua B},
file = {:Users/Brenden/Documents/Mendeley/O'Donnell, Goodman, Tenenbaum - 2009 - Fragment Grammars Exploring Computation and Reuse in Language.pdf:pdf},
title = {{Fragment Grammars: Exploring Computation and Reuse in Language}},
year = {2009}
}
@inproceedings{O'Donnell2011,
annote = {Fragment grammar model is evaluated on morphological datasets
        
Two morphological systems:
- english past tense
- english derivational morphology
        
        Multionmial-Dirichelt PCFG        
- A context free grammar, with a random choice for each of the production rules at eah step. These probabilities are unknown, so they are drawn from a multi-nomial dirichlet. This has a rich get richer property, where commonly used paths are strengthened
        
        Adaptor Grammar        
- This is the same as a MDPCFG, except for what happens after the random choice for a production rule is made. Rather than regenerating the tree from that point downwards, you drawn a tree from a pitman-yor process. Thus, you are likely to reuse, but you can also generate from a regular MDPCFG. However, if a new table is made, this model is recursive, so there could be re-use at the lower levels.
        
But in practice, there is only really reuse at the highest levels of the tree. 
                  
Fragment grammar        
        
This was designed to correct the problem with the adaptor grammar. 
        
Say we are at a given node t (could be the root). We sample a sub-tree (which chooses the rules from the grammar) from a Pitman-Yor. So we tend to re-use sub-trees we already have. But at any step in the recursion for generating a sub-tree, you have a probability of stopping. This is why it only creates sub-trees.
        
Then, at the non-terminal symbols of the sub-tree, the process repeats recusrively. Thus, we no longer share basically complete trees. We share tree fragments.
                  
Experiment 1: English past tense
                
+ There is a lot of reuse for the "-ed" rule, but there is very little reuse for irregulars.
+ This makes it challenging, so it can account very different partterns
        
Past-tense words were sampled from all of the models, and the log-odds of correct inflections was measured
        
Across regular, irregular, and novel words as a whole, the fragment grammar model does the best.
                  
Experiment 2: English derivational morphology
        
Sample new words from a model trained on derivational morphology.
        
We can  measure the P[suffix|novel] and P[novel|suffix], for both teh corpus and what the models generate.
        
Fragment grammars correlate much better than the alternative models.
                  
Discussion
                
The model instantiates a tradeoff between future novely and future reuse -- not just computation in space and time
        
This seems to follow from the structure of language:
- you want to maintain flexibility and productivity, while specializing for commonly encountered situations},
author = {O'Donnell, Timothy J and Snedeker, Jesse and Tenenbaum, Joshua B and Goodman, Noah D},
booktitle = {{Proceedings of the 33rd Annual Cognitive Science Conference}},
file = {:Users/Brenden/Documents/Mendeley/O'Donnell et al. - 2011 - Productivity and Reuse in Language.pdf:pdf},
keywords = {bayesian model,computation,derivational morphology,edu,harvard,harvard university department of,jesse snedeker,past tense,productivity,psychology,reuse,snedeker,storage,wjh},
title = {{Productivity and Reuse in Language}},
year = {2011}
}
@article{O'Reilly2006,
abstract = {Computer models based on the detailed biology of the brain can help us understand the myriad complexities of human cognition and intelligence. Here, we review models of the higher level aspects of human intelligence, which depend critically on the prefrontal cortex and associated subcortical areas. The picture emerging from a convergence of detailed mechanistic models and more abstract functional models represents a synthesis between analog and digital forms of computation. Specifically, the need for robust active maintenance and rapid updating of information in the prefrontal cortex appears to be satisfied by bistable activation states and dynamic gating mechanisms. These mechanisms are fundamental to digital computers and may be critical for the distinctive aspects of human intelligence.},
author = {O'Reilly, Randall C},
doi = {10.1126/science.1127242},
file = {:Users/Brenden/Documents/Mendeley/O'Reilly - 2006 - Biologically based computational models of high-level cognition.pdf:pdf},
issn = {1095-9203},
journal = {Science},
keywords = {Brain,Brain: physiology,Cognition,Computer Simulation,Humans,Intelligence,Models,Nerve Net,Nerve Net: physiology,Neurological,Neurons,Neurons: physiology,Prefrontal Cortex,Prefrontal Cortex: physiology},
month = oct,
number = {5796},
pages = {91--4},
pmid = {17023651},
title = {{Biologically based computational models of high-level cognition.}},
volume = {314},
year = {2006}
}
@article{Olshausen1996,
abstract = {The receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs.},
author = {Olshausen, B A and Field, D J},
doi = {10.1038/381607a0},
file = {:Users/Brenden/Documents/Mendeley/Olshausen, Field - 1996 - Emergence of simple-cell receptive field properties by learning a sparse code for natural images.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {Algorithms,Learning,Models,Neurological,Neurons,Neurons: physiology,Ocular,Ocular: physiology,Vision,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,sparsity,sparsity in the brain},
mendeley-tags = {sparsity,sparsity in the brain},
month = jun,
number = {6583},
pages = {607--9},
pmid = {8637596},
shorttitle = {Nature},
title = {{Emergence of simple-cell receptive field properties by learning a sparse code for natural images.}},
volume = {381},
year = {1996}
}
@misc{Olympus2012,
author = {Olympus},
file = {:Users/Brenden/Documents/Mendeley/Olympus - 2012 - Olympus instructions manual.pdf:pdf},
title = {{Olympus instructions manual}},
year = {2012}
}
@article{Oppenheimer2009,
annote = {Suggests having a test for comprehension of the instrutions, or reading them at all.
        
Like, "click the banner on top" rather than answering this first question
                  
Experiment 1:        
They found that doing so would increase the power of their studies
                  
Experiment 2:        
Loop, such that failing the instructions test brings you back to the instructions.
        
After this loop, they performed indistinguishably from those who failed it.
        
This suggests you can eliminate participants based on failing these tests, or recycling them around is another valid way to improve results},
author = {Oppenheimer, Daniel M. and Meyvis, Tom and Davidenko, Nicolas},
doi = {10.1016/j.jesp.2009.03.009},
file = {:Users/Brenden/Documents/Mendeley/Oppenheimer, Meyvis, Davidenko - 2009 - Instructional manipulation checks Detecting satisficing to increase statistical power.pdf:pdf},
issn = {00221031},
journal = {Journal of Experimental Social Psychology},
keywords = {experimental methods},
mendeley-tags = {experimental methods},
month = jul,
number = {4},
pages = {867--872},
publisher = {Elsevier Inc.},
title = {{Instructional manipulation checks: Detecting satisficing to increase statistical power}},
volume = {45},
year = {2009}
}
@article{Orban2008,
abstract = {Efficient and versatile processing of any hierarchically structured information requires a learning mechanism that combines lower-level features into higher-level chunks. We investigated this chunking mechanism in humans with a visual pattern-learning paradigm. We developed an ideal learner based on Bayesian model comparison that extracts and stores only those chunks of information that are minimally sufficient to encode a set of visual scenes. Our ideal Bayesian chunk learner not only reproduced the results of a large set of previous empirical findings in the domain of human pattern learning but also made a key prediction that we confirmed experimentally. In accordance with Bayesian learning but contrary to associative learning, human performance was well above chance when pair-wise statistics in the exemplars contained no relevant information. Thus, humans extract chunks from complex visual patterns by generating accurate yet economical representations and not by encoding the full correlational structure of the input.},
annote = {Visual chunks cannot be identified from just low-level grouping cues, since there are multiple objects, noise etc.
+ same argument has been applied to explain why it is too hard to learn "language" chunks
        
controvery over whether chunking is based on associate learning or co-occurence statistics
        
Here, they show that associative learning does not work, with a model that bridges the gap between low-level statistics and abstract rules        
                  
model
                
scenes: observed variables (1 for present, 0 for absence) and 2D positions
        
inventory of chunks I that specifies the number of hidden variables, and the observed shapes it influences, which are weights that also ahve to be inferred
        
chunks appear independently from each other in each scene, again encoded as on or off and with positions. Positions are gaussian, and on/off based on sigmoid
        
given chunks, shapes are independent, where the probability of appearane is the strength is a sum over all chunkas that influence it 
+ position is based on product of normals of all variables and influenced it (renomrailzed...kind of weird)
        
When computing likelihood, you have to marginalize over all possibile parses and continous variables, and this is where you get the Occam's razor effect
        
Want posteiror P(inventory | scene)
- complex inventories produce more scenes, but this complex is penalized with Bayesian Occam's razor (size principle)
- chunks are observed as suspcisou coincidences between pairs of shapes, and some pairs occur noisely on their own
                  
alternative models        
- sophisticated counters of shape frequencies and co-occurences
- associated learner (AL), keeps track of all pairw-sie correlations between shapes
        
AL model is basically a fully-observed boltzmann machine, where the pairwise statistics are all you have to fit a paritcular experiment
                  
          
Previous studies        
1) basic
both models distinguished pairs vs broke pairs
2) frequency-balanced
both models distinguished between pairs and broken pairs, balanced for freqeuency
3) both models could learn triplets, but did not distinguish between two-element embedding within a triplet and a random pair. Both models got this
4) Original chunks were 4-peice chunks and pairs. The models could learn embeeded 3-way chunks but not 2-way chunks.
        
All models seem pretty good at this
                  
New study
                
Two groups of scenes, matched for single and pairwise statistics of objects, but contained some triples
        
groups
1) shapes appear in 3-way groups
2) shapes appear only individually or in pairs
        
BCL was able to distinguish between true tripls vs not, while the AL model could not
                  
discussion
                
chunks formulated for vision, but can be thought of more generally.
        
raises possiblity that rule learning is merely a higher-order example of extracting hidden variables from complex inputs},
author = {Orb\'{a}n, Gergo and Fiser, J\'{o}zsef and Aslin, Richard N and Lengyel, M\'{a}t\'{e}},
doi = {10.1073/pnas.0708424105},
file = {:Users/Brenden/Documents/Mendeley/Orb\'{a}n et al. - 2008 - Bayesian learning of visual chunks by human observers.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Bayes Theorem,Humans,Learning,Learning: physiology,Ocular,Ocular: physiology,Vision,classic psychology,statistical learning},
mendeley-tags = {classic psychology,statistical learning},
month = feb,
number = {7},
pages = {2745--50},
pmid = {18268353},
title = {{Bayesian learning of visual chunks by human observers.}},
volume = {105},
year = {2008}
}
@article{VanOrden1987,
annote = {Classic study showing phonological recoding
        
Category name:  A FLOWER
        
Examples:   TULIP  (respond “yes”)
 CAR  (respond “no”)
  ROWS  (respond “yes,... I mean, no”, since it sounds like   ROSE)
        
Thus, phonological representation must mediate between reading and identification},
author = {Orden, Guy C},
file = {:Users/Brenden/Documents/Mendeley/Orden - 1987 - A ROWS is a ROSE Spelling, sound, and reading.pdf:pdf},
issn = {0090-502X},
journal = {Memory \& cognition},
keywords = {Female,Form Perception,Humans,Male,Pattern Recognition,Phonetics,Reading,Semantics,Visual,classic psychology},
mendeley-tags = {classic psychology},
month = may,
number = {3},
pages = {181--98},
pmid = {3600258},
title = {{A ROWS is a ROSE: Spelling, sound, and reading}},
volume = {15},
year = {1987}
}
@article{Oruc2003,
annote = {        Summary:        
-Confirming evidence that depth cue combiantion is linear
-Under certain conditions, sub-optimal cue combination might be explained by non-independence of the cues
                  
longer summary, from Larry's webpage:        
Human observers can have multiple sources of information about the shape, location, orientation, color or material of objects in a scene and each source is typically perturbed by error. Combining these sources of information into a single estimate is a fundamental problem in statistics. In our work, we compare human performance in combining information for multiple sources to optimal performance. We have investigated cue combination in human perception of depth, shape, slant and color. In one recent experiment (Oru\c{c}, Maloney & Landy, 2003), we asked observers to repeatedly adjust the slant of a plane to 75 deg. Feedback was provided after each setting and the observers trained extensively until their setting error stabilized. We designed the experiment so that we could determine whether the observer's estimates of slant from each of two slant cues were correlated or uncorrelated. 
The slant of the plane was defined by either                                   linear perspective                                 alone (a grid of lines) or                                   texture gradient                                 alone (diamond-shaped texture elements) or the two cues together. We chose a HIGH and LOW variance version of each cue type and measured setting variability in four single-cue conditions (LOW, HIGH for each cue) and in the four possible combined-cue conditions (LOW-LOW, LOW-HIGH, etc.). 
We compared performance in the combined-cue conditions to predictions based on single-cue performance. Six out of eight observers did better with combined cues than with either cue alone, showing that they were in fact combining information from both cues. For three observers, performance was consistent with optimal combination of uncorrelated cues. Three other observers' results were also consistent with optimal combination, but with the assumption that internal cue estimates were correlated. The remaining two observers' performances were sub-optimal. 
Cue combination:
        
most common model is a linear combinatino of unbiased cues. If they are uncorrleated, the optimal weights are proportional to the inverse of the variance
        
Reliability (reciprocal of variance) of the overall combined estiamte is the sum of the individual ones
        
Considerable evidence that people do use a weighted linear combination, and the weights depend on cue reliability
        
Task:
        
- judging 75 degree incline, using two cues (linear perspetive lines) and texture
- cues were desigend to be somewhat dependent a priori
- substantial pre-triaing with feedback. After reaching criterion, there were many test trials
        
Compare person's performance with an ideal observer, and look at whether their combined cue reliability is distinguishable from the optimal value
        
 3 observers were approximately optimal , and four were sub-optimal. Confirmed by boot-strap
        
What if we allow he cues to be correlated? If they are, we get less information in the optimal observer
        
Two subjects can be accounted for with an optimal model that has non-zero correlation between cues
        
Final two subjects do not have an significant benefits for two cues over one},
author = {Oru\c{c}, İpek and Maloney, Laurence T. and Landy, Michael S.},
doi = {10.1016/S0042-6989(03)00435-8},
file = {:Users/Brenden/Documents/Mendeley/Oru\c{c}, Maloney, Landy - 2003 - Weighted linear cue combination with possibly correlated error.pdf:pdf},
issn = {00426989},
journal = {Vision Research},
keywords = {correlated cues,cue combination,pictorial depth cues,slant perception},
mendeley-tags = {cue combination},
month = oct,
number = {23},
pages = {2451--2468},
title = {{Weighted linear cue combination with possibly correlated error}},
volume = {43},
year = {2003}
}
@article{Osherson1981,
annote = {Concepts underly "kind" terms "animal", "tree", "tool", etc.
        
Major concern: complex concepts
        
Here, they argue that the prototype theory fairs worse than the old one.
        
      },
author = {Osherson, D N and Smith, E E},
file = {:Users/Brenden/Documents/Mendeley/Osherson, Smith - 1981 - On the adequacy of prototype theory as a theory of concepts.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Concept Formation,Humans,Psychology,Set (Psychology),classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
month = feb,
number = {1},
pages = {35--58},
pmid = {7196818},
title = {{On the adequacy of prototype theory as a theory of concepts.}},
volume = {9},
year = {1981}
}
@article{Osherson1990,
annote = {very impressive quantitative fits, to mammals, horses, and other datasets},
author = {Osherson, D N and Smith, E E and Wilkie, O and Lopez, A and Shafir, E},
file = {:Users/Brenden/Documents/Mendeley//Osherson et al. - 1990 - Category-based induction.pdf:pdf},
journal = {Psychological Review},
number = {2},
pages = {185--200},
title = {{Category-based induction}},
volume = {97},
year = {1990}
}
@article{Osherson1991,
author = {Osherson, D N and Stern, J and Wilkie, O and Stob, M and Smith, E E},
file = {:Users/Brenden/Documents/Mendeley/Osherson et al. - 1991 - Default probability.pdf:pdf},
journal = {Cognitive Science},
pages = {251--269},
title = {{Default probability}},
volume = {15},
year = {1991}
}
@inproceedings{Osindero2007,
annote = {Deep belief network, but with lateral connections between each of the layers as well.},
author = {Osindero, Simon and Hinton, Geoffrey E},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:Users/Brenden/Documents/Mendeley/Osindero, Hinton - 2007 - Modeling image patches with a directed hierarchy of Markov random fields.pdf:pdf},
keywords = {deep learning},
mendeley-tags = {deep learning},
title = {{Modeling image patches with a directed hierarchy of Markov random fields}},
year = {2007}
}
@inproceedings{Ouyang2009,
author = {Ouyang, Tom Y and Davis, Randall},
booktitle = {2009 Intelligent User Interfaces Workshop on Sketch Recognition},
file = {:Users/Brenden/Documents/Mendeley/Ouyang, Davis - 2009 - Visual Recognition of Sketched Symbols.pdf:pdf},
keywords = {handwriting,sketch-understanding},
mendeley-tags = {handwriting,sketch-understanding},
title = {{Visual Recognition of Sketched Symbols}},
year = {2009}
}
@inproceedings{Ouyang2009a,
author = {Ouyang, Tom Y and Davis, Randall},
booktitle = {Advances in Neural Information Processing Systems 22},
file = {:Users/Brenden/Documents/Mendeley/Ouyang, Davis - 2009 - Learning from Neighboring Strokes Combining Appearance and Context for Multi-Domain Sketch Recognition.pdf:pdf},
keywords = {handwriting,sketch-understanding},
mendeley-tags = {handwriting,sketch-understanding},
pages = {1401--1409},
title = {{Learning from Neighboring Strokes: Combining Appearance and Context for Multi-Domain Sketch Recognition}},
year = {2009}
}
@inproceedings{Pacer2005,
annote = {People falsely assume that just because their child had the symptoms of autism shorlty after getting vacinations, that this was the causal force
        
Causal models generally do not deal with the time domain.
How does causal models extend over time?
        
Poisson process: where you model the rate of occurence, within a given time window
        
The cause is another poisson process, and teh base rate is a poisson process. You add them together, you still have a poisson process
        
You can estimate structure, and do model comparison to see whether or not there is a cause
      },
author = {Pacer, Michael and Griffiths, Thomas L},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Pacer, Griffiths - 2012 - Elements of a rational framework for continuous-time causal induction.pdf:pdf},
pages = {833--838},
title = {{Elements of a rational framework for continuous-time causal induction}},
year = {2012}
}
@article{Paivio1969,
author = {Paivio, Allan},
file = {:Users/Brenden/Documents/Mendeley/Paivio - 1969 - Mental imagery in associative learning and memory.pdf:pdf},
journal = {Psychological Review},
keywords = {classic psychology,mental codes},
mendeley-tags = {classic psychology,mental codes},
number = {3},
title = {{Mental imagery in associative learning and memory}},
volume = {76},
year = {1969}
}
@article{Paivio1991,
annote = {Review of dual coding theory.
        
Main idea: multiple codes, with a major distinction between verbal/nonverbal symbolic constrast. 
        
Verbal representations and imaginal representations
or (logogen, word generator, and imagen, image generator)
        
These systems function independently, and they can have additive effects on recall. 
        
There are interconnections between concepts in the two systems. There are associative connections within systems (like a behaviorist association)},
author = {Paivio, Allan},
file = {:Users/Brenden/Documents/Mendeley/Paivio - 1991 - Dual coding theory Retrospect and current status.pdf:pdf},
journal = {Canadian Journal of Psychology},
keywords = {classic psychology,mental codes},
mendeley-tags = {classic psychology,mental codes},
number = {3},
pages = {255--287},
title = {{Dual coding theory: Retrospect and current status}},
volume = {45},
year = {1991}
}
@incollection{Palatucci2009,
author = {Palatucci, M and Pomerleau, D and Hinton, G and Mitchell, T},
booktitle = {{Neural Information Processing Systems (NIPS)}},
editor = {Bengio, Y and Schuurmans, D and Lafferty, J},
file = {:Users/Brenden/Documents/Mendeley/Palatucci et al. - 2009 - Zero-Shot Learning with Semantic Output Codes.pdf:pdf},
title = {{Zero-Shot Learning with Semantic Output Codes}},
year = {2009}
}
@article{Pammer2004,
abstract = {We used magnetoencephalography (MEG) to map the spatiotemporal evolution of cortical activity for visual word recognition. We show that for five-letter words, activity in the left hemisphere (LH) fusiform gyrus expands systematically in both the posterior-anterior and medial-lateral directions over the course of the first 500 ms after stimulus presentation. Contrary to what would be expected from cognitive models and hemodynamic studies, the component of this activity that spatially coincides with the visual word form area (VWFA) is not active until around 200 ms post-stimulus, and critically, this activity is preceded by and co-active with activity in parts of the inferior frontal gyrus (IFG, BA44/6). The spread of activity in the VWFA for words does not appear in isolation but is co-active in parallel with spread of activity in anterior middle temporal gyrus (aMTG, BA 21 and 38), posterior middle temporal gyrus (pMTG, BA37/39), and IFG.},
author = {Pammer, Kristen and Hansen, Peter C and Kringelbach, Morten L and Holliday, Ian and Barnes, Gareth and Hillebrand, Arjan and Singh, Krish D and Cornelissen, Piers L},
doi = {10.1016/j.neuroimage.2004.05.004},
file = {:Users/Brenden/Documents/Mendeley/Pammer et al. - 2004 - Visual word recognition the first half second.pdf:pdf},
issn = {1053-8119},
journal = {NeuroImage},
keywords = {Adult,Brain Mapping,Cerebral,Cerebral: physiology,Computer-Assisted,Decision Making,Decision Making: physiology,Dominance,Evoked Potentials,Female,Humans,Image Processing,Imaging,Magnetics,Magnetoencephalography,Male,Memory,Middle Aged,Pattern Recognition,Reading,Short-Term,Short-Term: physiology,Three-Dimensional,Verbal Learning,Verbal Learning: physiology,Visual,Visual: physiology},
month = aug,
number = {4},
pages = {1819--25},
pmid = {15275938},
title = {{Visual word recognition: the first half second.}},
volume = {22},
year = {2004}
}
@article{Park2007,
abstract = {To allow perception of a continuous world, cortical mechanisms extrapolate missing information with highly constrained predictions about the environment just beyond the edges of a view. Here, we report functional magnetic resonance imaging evidence for extrapolation of scene layout information beyond what was physically presented, an illusion known as boundary extension. Consistent with behavioral reports, we observed boundary extension for scene-selective attenuation in the parahippocampal place area (PPA) and retrosplenial cortex (RSC), but no such extrapolation of object representations in the lateral occipital complex (LOC). These results demonstrate that scene layout representations are extrapolated beyond the confines of the perceptual input. Such extrapolation may facilitate perception of a continuous world from discontinuous views.},
annote = {Boundary effect: observers remember seeing more of the picture. IT is not the case that they remember the object smaller.
        
Found evidence of the boundary extension effect in 
PPA and RSC, but not in LOC
        
This suggests that we might automatically extrapolate beyond the boundaries of a scene, to facilitate more continuous perception
        
Contrastred:
close scene -> wide scene
wide scene -> close scence
with fMRI adaptation.
        
Large effect, thus, boundary computation seems to happen in the PPA
        
If area is computing boundary effect, then wide scene -> close scene should not be adapated, since boundary effect would have gone in other direction.
        
Beautiful effect.},
author = {Park, Soojin and Intraub, Helene and Yi, Do-Joon and Widders, David and Chun, Marvin M},
doi = {10.1016/j.neuron.2007.04.006},
file = {:Users/Brenden/Documents/Mendeley/Park et al. - 2007 - Beyond the edges of a view boundary extension in human scene-selective visual cortex.pdf:pdf},
issn = {0896-6273},
journal = {Neuron},
keywords = {Adult,Data Interpretation,Female,Humans,Illusions,Illusions: physiology,Magnetic Resonance Imaging,Male,Occipital Lobe,Occipital Lobe: physiology,Parahippocampal Gyrus,Parahippocampal Gyrus: physiology,Statistical,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology,classic psychology},
mendeley-tags = {classic psychology},
month = apr,
number = {2},
pages = {335--42},
pmid = {17442252},
title = {{Beyond the edges of a view: boundary extension in human scene-selective visual cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17442252},
volume = {54},
year = {2007}
}
@article{Pashler2013,
abstract = {Training that uses exaggerated versions of a stimulus discrimination (fading) has sometimes been found to enhance category learning, mostly in studies involving animals and impaired populations. However, little is known about whether and when fading facilitates learning for typical individuals. This issue was explored in 7 experiments. In Experiments 1 and 2, observers discriminated stimuli based on a single sensory continuum (time duration and line length, respectively). Adaptive fading dramatically improved performance in training (unsurprisingly) but did not enhance learning as assessed in a final test. The same was true for nonadaptive linear fading (Experiment 3). However, when variation in length (predicting category membership) was embedded among other (category-irrelevant) variation, fading dramatically enhanced not only performance in training but also learning as assessed in a final test (Experiments 4 and 5). Fading also helped learners to acquire a color saturation discrimination amid category-irrelevant variation in hue and brightness, although this learning proved transitory after feedback was withdrawn (Experiment 7). Theoretical implications are discussed, and we argue that fading should have practical utility in naturalistic category learning tasks, which involve extremely high dimensional stimuli and many irrelevant dimensions.},
annote = {Most work on structure of categories, rather than training procedures
        
fading: deliberate exaggeration of a perceptual distinction
        
cross-dimensional fading: use another dimenison as a cue to pick out the relevant one, like make two letters different colors
        
can produce much faster trail and error learning in pigeons, octopus, etc.
        
Mccleland and McCandliss tried to use fading to teach Japanese speakers the R/L contrast
        
Experiment 1: auditory duration discriminat
        
12 block sof 40 trainig trials
        
short vs long tones
        
fading: staircase algorithm, where the gap was adaptively reduced after three sequential successes
        
difficult condition: constant difficult gap
        
no difference in performance at test time
        
Experiment 2: Line length discrimination
        
very similar results
        
However, in these procedures, the adaptive training never reaches the same difficulty level as the diffuclt group. so that's a big difference
        
Experiment 3: Linear fading
        
where, the fixed schedule ends atthe same point as the difficult group. But here there was little difference
        
Experiment 4: 
        
Learned to distinguish "New World demons" vs. "Old World demons"
        
one dimension embedded in three nonpredictive dimeinsons
        
fading: can't tell if staircase method or fixed
        
results: hardly any learning at all in the difficult condition
                  
Experiment 5: Expanding the length difference
                
Since difficult condition learned nothing, here they made it a harder discrimination
        
Here, the fading group learned even better, but the difficult group also learened
                  
Experiment 6: Erasing the fading advantage through verbal instructions
                
Here, the participants were advised that the key difference was related to the height of the hrons
        
Now, at test time, the fading group performend slightly worse than the difficult group
                  
Experiment 7: fading wit hard-to-verbalize dimensions
                
saturation was the key dimenisio, differnet from hue and brightness
        
Here, the fading group had an advantage at test, but it appeared to lose some of its gains
                  
Discussion
                
Fading does not help if you only have one dimenison. But it is extremely useful when the dimension was not specificed in advance
        
Maybe Hebbian learning can help explain fdaing?
        
Zhu theoreitcal result: complicated and perhaps wrong, but maybe interpreted as "more attention should be paid to dimensions with more hypotheses left"
        
Or, perhaps it is just general variability. this can be tested easily},
author = {Pashler, Harold and Mozer, Michael C},
doi = {10.1037/a0031679},
file = {:Users/Brenden/Documents/Mendeley/Pashler, Mozer - 2013 - When does fading enhance perceptual category learning.pdf:pdf},
issn = {1939-1285},
journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
keywords = {a majority of articles,active learning,automated teachers,beings,categories and their,category learning,fading,in,large body of literature,learning,on the learning of,on the structure of,perceptual categories by human,perceptual learning,this area have focused,while there is a},
mendeley-tags = {active learning,automated teachers},
month = jul,
number = {4},
pages = {1162--73},
pmid = {23421513},
title = {{When does fading enhance perceptual category learning?}},
volume = {39},
year = {2013}
}
@article{Pavlidis1986,
annote = {Transforms digits into LAGs, or line adjacency graph. These can be compressed into junctions and paths, to form a c-LAG (or compressed LAG).
        
Thinning:
First, it divides a character into horizontal cross-sections. Paths are defined as segment with just one block, above and below. But junctions have more than one block above and below.
        
Transformation:
This can then be compressed into a c-LAG, but there are ambiguities, and this seems complicated
        
No real recognition performance is reported. Does this even work?},
author = {Pavlidis, Theo},
doi = {10.1016/0734-189X(86)90128-3},
file = {:Users/Brenden/Documents/Mendeley/Pavlidis - 1986 - A vectorizer and feature extractor for document recognition.pdf:pdf},
issn = {0734189X},
journal = {Computer Vision, Graphics, and Image Processing},
keywords = {handwriting,thinning algorithm},
mendeley-tags = {handwriting,thinning algorithm},
month = jul,
number = {1},
pages = {111--127},
title = {{A vectorizer and feature extractor for document recognition}},
volume = {35},
year = {1986}
}
@article{Pegg1997,
author = {Pegg, J E and Werker, J F},
journal = {Journal of the Acoustical Society of America},
pages = {3742--3753},
title = {{Adult and infant perception of two English phones}},
volume = {102},
year = {1997}
}
@article{Pelli2006,
abstract = {Seeking to understand how people recognize objects, we have examined how they identify letters. We expected this 26-way classification of familiar forms to challenge the popular notion of independent feature detection ("probability summation"), but find instead that this theory parsimoniously accounts for our results. We measured the contrast required for identification of a letter briefly presented in visual noise. We tested a wide range of alphabets and scripts (English, Arabic, Armenian, Chinese, Devanagari, Hebrew, and several artificial ones), three- and five-letter words, and various type styles, sizes, contrasts, durations, and eccentricities, with observers ranging widely in age (3 to 68) and experience (none to fluent). Foreign alphabets are learned quickly. In just three thousand trials, new observers attain the same proficiency in letter identification as fluent readers. Surprisingly, despite this training, the observers-like clinical letter-by-letter readers-have the same meager memory span for random strings of these characters as observers seeing them for the first time. We compare performance across tasks and stimuli that vary in difficulty by pitting the human against the ideal observer, and expressing the results as efficiency. We find that efficiency for letter identification is independent of duration, overall contrast, and eccentricity, and only weakly dependent on size, suggesting that letters are identified by a similar computation across this wide range of viewing conditions. Efficiency is also independent of age and years of reading. However, efficiency does vary across alphabets and type styles, with more complex forms yielding lower efficiencies, as one might expect from Gestalt theories of perception. In fact, we find that efficiency is inversely proportional to perimetric complexity (perimeter squared over "ink" area) and nearly independent of everything else. This, and the surprisingly fixed ratio of detection and identification thresholds, indicate that identifying a letter is mediated by detection of about 7 visual features.},
author = {Pelli, Denis G and Burns, Catherine W and Farell, Bart and Moore-Page, Deborah C},
doi = {10.1016/j.visres.2006.04.023},
file = {:Users/Brenden/Documents/Mendeley/Pelli et al. - 2006 - Feature detection and letter identification.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Adolescent,Adult,Aged,Aging,Aging: psychology,Child,Contrast Sensitivity,Discrimination Learning,Humans,Language,Mathematics,Mental Recall,Middle Aged,Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,Preschool,Reading,Sensory Thresholds,Size Perception,Time Factors,Visual,handwriting},
mendeley-tags = {handwriting},
month = dec,
number = {28},
pages = {4646--74},
pmid = {16808957},
title = {{Feature detection and letter identification.}},
volume = {46},
year = {2006}
}
@article{Pelli2003,
abstract = {Do we recognize common objects by parts, or as wholes? Holistic recognition would be efficient, yet people detect a grating of light and dark stripes by parts. Thus efficiency falls as the number of stripes increases, in inverse proportion, as explained by probability summation among independent feature detectors. It is inefficient to detect correlated components independently. But gratings are uncommon artificial stimuli that may fail to tap the full power of visual object recognition. Familiar objects become special as people become expert at judging them, possibly because the processing becomes more holistic. Letters and words were designed to be easily recognized, and, through a lifetime of reading, our visual system presumably has adapted to do this as well as it possibly can. Here we show that in identifying familiar English words, even the five most common three-letter words, observers have the handicap predicted by recognition by parts: a word is unreadable unless its letters are separately identifiable. Efficiency is inversely proportional to word length, independent of how many possible words (5, 26 or thousands) the test word is drawn from. Human performance never exceeds that attainable by strictly letter- or feature-based models. Thus, everything seen is a pattern of features. Despite our virtuosity at recognizing patterns and our expertise from reading a billion letters, we never learn to see a word as a feature; our efficiency is limited by the bottleneck of having to rigorously and independently detect simple features.},
author = {Pelli, Denis G and Farell, Bart and Moore, Deborah C},
doi = {10.1038/nature01516},
file = {:Users/Brenden/Documents/Mendeley/Pelli, Farell, Moore - 2003 - The remarkable inefficiency of word recognition.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {Contrast Sensitivity,Contrast Sensitivity: physiology,Humans,Language,Models,Neurological,Pattern Recognition,Reading,Visual,Visual: physiology,handwriting},
mendeley-tags = {handwriting},
month = jun,
number = {6941},
pages = {752--6},
pmid = {12802334},
title = {{The remarkable inefficiency of word recognition.}},
volume = {423},
year = {2003}
}
@article{Perez1994,
author = {Perez, Juan-Carlos and Vidal, Enrique},
file = {:Users/Brenden/Documents/Mendeley/Perez, Vidal - 1994 - Optimum polygonal approximation of digitized curves.pdf:pdf},
journal = {Pattern Recognition Letters},
keywords = {classic AI,dominant points,dynamic programming,handwriting,polygonal approximation,shape representation},
mendeley-tags = {classic AI,handwriting},
pages = {743--750},
title = {{Optimum polygonal approximation of digitized curves}},
volume = {15},
year = {1994}
}
@inproceedings{Perfors2012,
annote = {Say you know the prefix, for a new concept (word)
        
How do you choose a suffix?
        
Do you regulairze?
- always pick the most common affix
        
Do you probability match?
- pick affixes with prob. of occurence
        
What strategy is the most sensible?
- language, it helps to have a fixed term of reference
        
adults tend to probability match -- basically all the time
                  
experient        
viewed a bunch of objects, where the stem was highly consistent across categories, but suffix was not          
                
Conditions: vary pressure to use "correct language"
- team (high pressure): you a paired with a partner, and the partner is given your labels at the end and has to pick the right picture
- error (low pressure): no pairing. Also, told that given labels were from another person, and there may be some errors
- match (no pressure): 
        
Results: you can push around regularization with adults, depending on condition (pressure to be "correct")
        
This manipulation has larger effects on regularization than many other types of experimental manipulation
        
      },
author = {Perfors, Amy},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Perfors - 2012 - Probability matching vs over-regularization in language Participant behavior depends on their interpretation of the task.pdf:pdf},
keywords = {ity matching,language acquisition,over-regularization,probabil-,statistical learning},
pages = {845--850},
title = {{Probability matching vs over-regularization in language: Participant behavior depends on their interpretation of the task}},
year = {2012}
}
@article{Perfors2010,
abstract = {Children acquiring language infer the correct form of syntactic constructions for which they appear to have little or no direct evidence, avoiding simple but incorrect generalizations that would be consistent with the data they receive. These generalizations must be guided by some inductive bias - some abstract knowledge - that leads them to prefer the correct hypotheses even in the absence of directly supporting evidence. What form do these inductive constraints take? It is often argued or assumed that they reflect innately specified knowledge of language. A classic example of such an argument moves from the phenomenon of auxiliary fronting in English interrogatives to the conclusion that children must innately know that syntactic rules are defined over hierarchical phrase structures rather than linear sequences of words (e.g., Chomsky, 1965, 1971, 1980; Crain & Nakayama, 1987). Here we use a Bayesian framework for grammar induction to address a version of this argument and show that, given typical child-directed speech and certain innate domain-general capacities, an ideal learner could recognize the hierarchical phrase structure of language without having this knowledge innately specified as part of the language faculty. We discuss the implications of this analysis for accounts of human language acquisition.},
annote = {Can the hierarchical structure of grammar be learned, or must is be innately specified?
        
Bayes' over grammars with varying complexity, based on data from child-directed-speech, show that it can be learned. But this requries the relevant types of grammar be specified in advance.
        
This does not have much of an emergent flavor, since all of the different grammartical types have to be prespecified in advance.
      },
author = {Perfors, Amy and Tenenbaum, Joshua B and Regier, Terry},
doi = {10.1016/j.cognition.2010.11.001},
file = {:Users/Brenden/Documents/Mendeley/Perfors, Tenenbaum, Regier - 2010 - The learnability of abstract syntactic principles.pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
month = dec,
pmid = {21186021},
publisher = {Elsevier B.V.},
title = {{The learnability of abstract syntactic principles.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21186021},
year = {2010}
}
@inproceedings{Pfau2011,
annote = {This paper proposes a model of sequence data, that is strictly more powerful than an n-gram model but less powerful than an HMM.
        
A probabilistic deterministic finite automata (PDFA) has latent states that stochastically emit observable symbols. Given a state and it's symbol, the transition to the next state is then deterministic. 
        
Inference is over the emission probabilities and the state transition matrix.
        
With conjugate priors, the math works out nicely and you can basically do gibbs sampling on just the deterministic transitions. Also, since it is deterministic, much of this matrix doesn't even need to be computed for any given dataset.
        
The model can be made non-parametric by taking the infinite limit, leading to an unbounded number of states
        
Results:
Tested on a segement of "Alice in wonderland" text and a small sequence of mouse genome.
        
It beats HMMs and many n-gram models, except for the 5-gram and 6-gram models that are 
"smoothed" (sub-sequences provide a prior on longer sub-sequenecs).
      },
author = {Pfau, David and Bartlett, Nicholas and Wood, Frank},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:Users/Brenden/Documents/Mendeley/Pfau, Bartlett, Wood - 2011 - Probabilistic Deterministic Infinite Automata.pdf:pdf},
title = {{Probabilistic Deterministic Infinite Automata}},
year = {2011}
}
@article{Piantadosi2012,
abstract = {In acquiring number words, children exhibit a qualitative leap in which they transition from understanding a few number words, to possessing a rich system of interrelated numerical concepts. We present a computational framework for understanding this inductive leap as the consequence of statistical inference over a sufficiently powerful representational system. We provide an implemented model that is powerful enough to learn number word meanings and other related conceptual systems from naturalistic data. The model shows that bootstrapping can be made computationally and philosophically well-founded as a theory of number learning. Our approach demonstrates how learners may combine core cognitive operations to build sophisticated representations during the course of development, and how this process explains observed developmental patterns in number word learning.},
annote = {Children make inductive leap from "1-knowers", "2-knowers" etc. up to a "CP-knower" where they know that each number word maps onto a set of a particular cardinality
        
Learning involves "bootstrapping" in a language of thought. It is a LOT because there is a set of primatives, which can be combined compositionally to create more sophisticated representations.
                  
Hypothesis space
                
Prior:
All possible lambda expressions, that can be produced from this set of primitives. 
        
They use the rational rules prior, which penalizes complex, long epxressions, but premotes re-using primitive components
        
Data:
Got number word frequencise from CHILDES corpus
        
Inference:
tree-based monte-carlo from Goodman et al. (rational rules)
        
Results: the model transitions through the counting phases in roughly the same order, as you increase the "amount of data"},
author = {Piantadosi, Steven T and Tenenbaum, Joshua B and Goodman, Noah D},
doi = {10.1016/j.cognition.2011.11.005},
file = {:Users/Brenden/Documents/Mendeley/Piantadosi, Tenenbaum, Goodman - 2012 - Bootstrapping in a language of thought A formal model of numerical concept learning.pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
keywords = {classic psychology,conceptual change,number word learning},
mendeley-tags = {classic psychology,conceptual change},
month = jan,
number = {2},
pages = {199--217},
pmid = {22284806},
publisher = {Elsevier B.V.},
title = {{Bootstrapping in a language of thought: A formal model of numerical concept learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22284806},
volume = {123},
year = {2012}
}
@article{Pitcher2008,
abstract = {Theories of embodied cognition propose that recognizing facial expressions requires visual processing followed by simulation of the somatovisceral responses associated with the perceived expression. To test this proposal, we targeted the right occipital face area (rOFA) and the face region of right somatosensory cortex (rSC) with repetitive transcranial magnetic stimulation (rTMS) while participants discriminated facial expressions. rTMS selectively impaired discrimination of facial expressions at both sites but had no effect on a matched face identity task. Site specificity within the rSC was demonstrated by targeting rTMS at the face and finger regions while participants performed the expression discrimination task. rTMS targeted at the face region impaired task performance relative to rTMS targeted at the finger region. To establish the temporal course of visual and somatosensory contributions to expression processing, double-pulse TMS was delivered at different times to rOFA and rSC during expression discrimination. Accuracy dropped when pulses were delivered at 60-100 ms at rOFA and at 100-140 and 130-170 ms at rSC. These sequential impairments at rOFA and rSC support embodied accounts of expression recognition as well as hierarchical models of face processing. The results also demonstrate that nonvisual cortical areas contribute during early stages of expression processing.},
author = {Pitcher, David and Garrido, L\'{u}cia and Walsh, Vincent and Duchaine, Bradley C},
doi = {10.1523/JNEUROSCI.1450-08.2008},
file = {:Users/Brenden/Documents/Mendeley/Pitcher et al. - 2008 - Transcranial magnetic stimulation disrupts the perception and embodiment of facial expressions.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of Neuroscience},
keywords = {Adult,Analysis of Variance,Brain Mapping,Discrimination (Psychology),Discrimination (Psychology): physiology,Emotions,Emotions: physiology,Facial Expression,Female,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,Occipital Lobe,Occipital Lobe: physiology,Occipital Lobe: radiation effects,Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,Time Factors,Transcranial Magnetic Stimulation,Visual,Visual: physiology,embodied cognition},
mendeley-tags = {embodied cognition},
month = sep,
number = {36},
pages = {8929--33},
pmid = {18768686},
title = {{Transcranial magnetic stimulation disrupts the perception and embodiment of facial expressions.}},
volume = {28},
year = {2008}
}
@article{Plamondon2000,
author = {Plamondon, R and Srihari, S},
file = {:Users/Brenden/Documents/Mendeley/Plamondon, Srihari - 2000 - On-Line and Off-Line Handwriting Recognition A Comprehensive Survey.pdf:pdf},
journal = {{IEEE Transactions of Pattern Analysis and Machine Intelligence}},
keywords = {handwriting},
mendeley-tags = {handwriting},
number = {1},
pages = {63--84},
title = {{On-Line and Off-Line Handwriting Recognition: A Comprehensive Survey}},
volume = {22},
year = {2000}
}
@article{Planton2013,
annote = {Meta-analysis of regions involved in writing.},
author = {Planton, Samuel and Jucla, M\'{e}lanie and Roux, Franck-Emmanuel and D\'{e}monet, Jean-Fran\c{c}ois},
doi = {10.1016/j.cortex.2013.05.011},
file = {:Users/Brenden/Documents/Mendeley/Planton et al. - 2013 - The “handwriting brain” a meta-analysis of neuroimaging studies of motor versus orthographic processes.pdf:pdf},
issn = {00109452},
journal = {Cortex},
month = jun,
publisher = {Elsevier Ltd},
title = {{The “handwriting brain”: a meta-analysis of neuroimaging studies of motor versus orthographic processes}},
year = {2013}
}
@techreport{Poggio2012,
annote = {Notes from Intelligence Initiative workshop: Can we understand how individual cells implement intelligence?
                  
Gabriel Kreiman
          
        Divide and conquery: pick specific examples of "intelligent behavior", an dtry to understand it in neural circuits
        
Assume "cortext is cortex", meaning similar algorithms in the brain
        
Possible approaches:
- can understanding visual invariance transfer to other domains?
- can understanding object completion (inference) help understand other domains?
        
Bill Clinton neurons: how could they solve this difficult invariance problem?
        
Similar experiments find specifcity to particualr speakers
                  
Matt Wilson
                
- Does the brain implement algorithms? IS there are series of steps, a flow digram, that underly computation? Or is this an awkward metaphor for computation in the brain?
        
- his claim is there is, and there is an important sequential component that can implement an algorithm
        
the closer you look in the brain, the more structure that you see. He thinks this is encouraging.
- its not like chaos, emergence. The brain doesn't seem to be chaos at a low-level. There is always more structure
        
Place cells: Using Bayesian estimate, you can decode where the animal is. We could do this 20 years ago
        
The brain can create generative sequences: compose possible sequences that it could take
        
Josh: Can we figure out how the brain represents the graph, that is used for planning? Not where is it encoded, but exactly how it is being implemented?
                  
Josh
                
Success story:
"Intelligence as statistics on a grand scale"
- We could just apply stats to data, find cluster, etc.
- heyday was neural nets in the 80s
        
Self-driving cars, watson, etc. obviously use 21st century data structures
- but COSYNE abstracts sound like 1970s electrical engineering (phase, frequency, etc.)
        
We have made a lot of progress modeling the function on intelligence using computer science, nothing else is close. So we should be looking for these things in the brain
        
Let's look in the brain, for one of the simplest forms of recusrive structure -- like recursive structure in motion
        
Love the example of a dot moving around an axis, vs. no axis, looks totally different
        
Another thing we are really missing is objects.
        
Even infants can represent another agent representing another agent. This is a very complex computation
        
Modelling balls bouncing around: (Hinton temporal RBM)
You don't get long-range structure, unless you explicitly try to represent it.
- infants solve this not just for 3 objects, but lots of different environments
        
Objects have never been a data structure in neural networks.
        
Objects like objects in logic, can quantify over, have predicates.
      },
author = {Poggio, Tomaso},
file = {:Users/Brenden/Documents/Mendeley/Poggio - 2012 - The Levels of Understanding framework, revised.pdf:pdf},
title = {{The Levels of Understanding framework, revised}},
year = {2012}
}
@article{Polk2002,
author = {Polk, T A and Behensky, C and Gonzalez, R and Smith, E E},
journal = {Cognition},
pages = {B75--B88},
title = {{Rating the similarity of simple perceptual stimuli: asymmetries induced by manipulating exposure frequency}},
volume = {82},
year = {2002}
}
@article{Pollack1990,
author = {Pollack, Jordan B.},
doi = {10.1016/0004-3702(90)90005-K},
file = {:Users/Brenden/Documents/Mendeley/Pollack - 1990 - Recursive distributed representations.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {NLP,classic AI,neural networks,recursion},
mendeley-tags = {NLP,classic AI,neural networks,recursion},
month = nov,
number = {1-2},
pages = {77--105},
title = {{Recursive distributed representations}},
volume = {46},
year = {1990}
}
@inproceedings{Porikli2004,
author = {Porikli, Fatih},
booktitle = {European Conference on Computer Vision},
file = {:Users/Brenden/Documents/Mendeley/Porikli - 2004 - Trajectory Distance Metric Using Hidden Markov Model based Representation.pdf:pdf},
keywords = {handwriting},
mendeley-tags = {handwriting},
title = {{Trajectory Distance Metric Using Hidden Markov Model based Representation}},
year = {2004}
}
@article{Posner1968,
annote = {Is an abstract idea acquired during learning (a prototype)? This is one of the earliest experiments on concept learning
                  
Experiment 1:        
- Participants learned concepts, with different level of distortion applied to the prototypes. 
- Low-distorition learns faster, but high-distortion has better generalization, if the transfer stimuli are very highly distored.
        
But this has some problems, since it took the high-distortion group longer to reach criterion. Also, it might be due to the "shock" of seeing very distorted things
                  
Experiment 2:         
-- tried to fix some of these problems
        
If people were just storing a schema, then low-noise would be the best condition. If variability is important, then it would not...which is what they found.
        
        Experiment 3:        
Learning of two classes, which have a prototype + distorition.
Test uses learned examples, prototypes, and new examples
                  
Day 1:        
Prototypes (schemas) are classfied as well as old distoritions, and better than new distoritions          
Day 2:        
Prototypes seem to be a little better than old distortions, but not significant
        
        
        
This was tested the same day, and a day later},
author = {Posner, M I and Keele, Steven W},
file = {:Users/Brenden/Documents/Mendeley/Posner, Keele - 1968 - On the genesis of abstract ideas.pdf:pdf},
journal = {Journal of Experimental Psychology},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {3},
pages = {353--363},
title = {{On the genesis of abstract ideas}},
volume = {77},
year = {1968}
}
@article{Posner1980,
abstract = {Detection of a visual signal requires information to reach a system capable of eliciting arbitrary responses required by the experimenter. Detection latencies are reduced when subjects receive a cue that indicates where in the visual field the signal will occur. This shift in efficiency appears to be due to an alignment (orienting) of the central attentional system with the pathways to be activated by the visual input. It would also be possible to describe these results as being due to a reduced criterion at the expected target position. However, this description ignores important constraints about the way in which expectancy improves performance. First, when subjects are cued on each trial, they show stronger expectancy effects than when a probable position is held constant for a block, indicating the active nature of the expectancy. Second, while information on spatial position improves performance, information on the form of the stimulus does not. Third, expectancy may lead to improvements in latency without a reduction in accuracy. Fourth, there appears to be little ability to lower the criterion at two positions that are not spatially contiguous. A framework involving the employment of a limited-capacity attentional mechanism seems to capture these constraints better than the more general language of criterion setting. Using this framework, we find that attention shifts are not closely related to the saccadic eye movement system. For luminance detection the retina appears to be equipotential with respect to attention shifts, since costs to unexpected stimuli are similar whether foveal or peripheral. These results appear to provide an important model system for the study of the relationship between attention and the structure of the visual system.},
author = {Posner, M I and Snyder, C R and Davidson, B J},
file = {:Users/Brenden/Documents/Mendeley/Posner, Snyder, Davidson - 1980 - Attention and the detection of signals.pdf:pdf},
issn = {0022-1015},
journal = {Journal of Experimental Psychology},
keywords = {Attention,Cues,Humans,Orientation,Space Perception,Visual Perception,attention,classic AI},
mendeley-tags = {attention,classic AI},
month = jun,
number = {2},
pages = {160--74},
pmid = {7381367},
title = {{Attention and the detection of signals.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7381367},
volume = {109},
year = {1980}
}
@article{Pothos2002,
abstract = {We address the problem of predicting how people will spontaneously divide into groups a set of novel items. This is a process akin to perceptual organization. We therefore employ the simplicity principle from perceptual organization to propose a simplicity model of unconstrained spontaneous grouping. The simplicity model predicts that people would prefer the categories for a set of novel items that provide the simplest encoding of these items. Classification predictions are derived from the model without information either about the number of categories sought or information about the distributional properties of the objects to be classified. These features of the simplicity model distinguish it from other models in unsupervised categorization (where, for example, the number of categories sought is determined via a free parameter), and we discuss how these computational differences are related to differences in modeling objectives. The predictions of the simplicity model are validated in four experiments. We also discuss the significance of simplicity in cognitive modeling more generally.},
annote = {General: similar to the experiments we want to run regarding perceptaual grouping
        
Features of their approach:
-- They run in both a "visual grouping" and unsupervised categorization paradigm. This gives stronger support to the model than just one.
-- Displays were very simple and easily separable
-- They don't have a full learning model, just a metric of evaluation
-- They don't have any comparison models
        
        
------
Grouping is both perceptual organization and categorization
        
How are these related?
-- Goldstone (1994). Categorization affects perceptual grouping
-- categorical perception
        
Look at Compton and Logan (1993, 1999). They looked at perceptual grouping
                  
Model        
Given a point of points in a display, you could encode all the distance relations by just a list. But there is obvious redundancy.
        
Model uses the optimal compression for a dataset, where distances within-groups are smaller than between groups. Then exceptions can also be used.
        
They do not have a model of how compression happens, they just study the metric
                  
Experiment 1        
Participants saw the points drawn on a piece of paper, and drew lines around around "good" groups
        
Participants selections were non-random, as shown by a Chi-square test where the counts were different types of partitions. It is non-random for clear datasets, but random for unstructured ones.
                  
Experiment 2        
Same stimuli, except the two-dimensinos were construed to be physical -- and related to star shaped stimuli. Subjects were asked to sort these
        
The model makes similar predictions in both cases
                  
Experiment 3        
Same as in 2, but with a concrete scenario where stars need to be shipped in boxes -- how many boxes do you need?
                  
Experiment 4        
Small set of stimuli where people made all pair-wise similarity matrix. The best compression of this matrix was a clustering predicted by the simplicity model},
author = {Pothos, E and Chater, Nick},
doi = {10.1016/S0364-0213(02)00064-2},
file = {:Users/Brenden/Documents/Mendeley/Pothos, Chater - 2002 - A simplicity principle in unsupervised human categorization.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
keywords = {perceptual grouping},
mendeley-tags = {perceptual grouping},
month = jun,
number = {3},
pages = {303--343},
title = {{A simplicity principle in unsupervised human categorization}},
volume = {26},
year = {2002}
}
@article{Potter1975,
annote = {For a word vs. a picture, do they active an common representation (the idea)? Or does the picture activate an image representation, and then it is transformed to an idea?
        
Argues against: Dual Coding Theory
-- verbal representation has associations (like chair is furniture) which we would typically regard as conceptual
-- image representation has associations about features. 
-- there is no common code
        
It takes much longer (250 ms) to name an object than it does to read a word (supporting Paivio's theory). 
                  
Experiment: Category verfication, where the probe is either a written word or a line drawing.
        
But making a categorization judgment takes slightly less time for a drawing, a result that seems inconsistent with the separate representation view. You would expect this to take about 250ms longer from pictures, by Paivio's view.
        
Most likely that the word and picture lead to a common representation in memory.},
author = {Potter, Mary C and Faulconer, Barbara A},
file = {:Users/Brenden/Documents/Mendeley/Potter, Faulconer - 1975 - Time to understand pictures and words.pdf:pdf},
journal = {Nature},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
pages = {437--438},
title = {{Time to understand pictures and words}},
volume = {253},
year = {1975}
}
@article{Potter1984,
annote = {When learning a second language, do words get associated to words (word association hypothesis)?
Or do the new words get associated with the underlying concepts (concept mediation)?
        
Words are named faster than pictures, supporting the notion that there is a separate representations for words (which is a premise for this question to make sense)
        
Task:
- Receive stimulus (image or L1 condition)
- Name in L2
        
If word-association hypothesis is correct, then picture naming sshould be strictly slower, since it must go to the concpt, then to L1, then to L2
Otherwise, both go to the concept, and then to L2
        
Particiapnts:
Either ESL Chinese students studying in the US (L2 is English)
Or American students studying L2 French
        
Task 1: L2 Naming
Task 2: Category verification (presented before item)
        
Although the students were must faster in naming Chinese words than pictures, they were about equally fast for responding in L2 for words vs. pictures
        
Results: In fact, a picture was named in L2 slightly FASTER than an L1 word was named in L2. This argues strongly against a word-to-word association.
                  
Experiment 2: Same thing, but with students learning French L2. The results were very similar. Also, English is more similar to French, so you might expect the word-to-word associations are more likely.},
author = {Potter, Mary C and So, Kwok-Fai and {Von Eckardt}, Barbara and Feldman, Laurie B},
file = {:Users/Brenden/Documents/Mendeley/Potter et al. - 1984 - Lexical and conceptual representation in beginning and proficient bilinguals.pdf:pdf},
journal = {Journal Of Verbal Learning And Verbal Behavior},
keywords = {classic psychology,mental codes},
mendeley-tags = {classic psychology,mental codes},
pages = {23--38},
title = {{Lexical and conceptual representation in beginning and proficient bilinguals}},
volume = {23},
year = {1984}
}
@article{Potter1977,
annote = {Experiment supporting conceptual coding, rather than dual coding.
        
People show no difference making semantic judgments, between images and words -- supporting an abstract conceptual code.
        
------
- Is meaning a word-based code, an image-based code, or a conceptual code?
        
- When presented with an object, and asked if it is related to a picture or a word, should the modality matter? If so, perhaps the code is modality specific 
        
Paivio's theory: verbal code is associated with meaning, but picture code is not
        
Task:
Participants saw a sentence, like "Adam and Eve were the firt humans"
Afterwards, there was a probe, which is an image of an apple or the word "apple", and they had to decide whether or not its semantically related.
        
If anything, drawings were faster, rather than words. This seems to invalidate Paivio's dual coding idea
        
It was possible that participants could predict the probe, which masked the response. But they were only correct .27 on their first guess.},
author = {Potter, Mary C and Valian, Virginia V and Faulconer, Barbara A},
doi = {10.1016/S0022-5371(77)80002-9},
file = {:Users/Brenden/Documents/Mendeley/Potter, Valian, Faulconer - 1977 - Representation of a Sentence and Its Pragmatc Implications Verbal, Imagistic, or Abstract.pdf:pdf},
issn = {00225371},
journal = {Journal of Verbal Learning and Verbal Behavior},
keywords = {classic psychology,mental codes},
mendeley-tags = {classic psychology,mental codes},
month = feb,
number = {1},
pages = {1--12},
title = {{Representation of a Sentence and Its Pragmatc Implications: Verbal, Imagistic, or Abstract?}},
volume = {16},
year = {1977}
}
@article{Pouget2013,
abstract = {There is strong behavioral and physiological evidence that the brain both represents probability distributions and performs probabilistic inference. Computational neuroscientists have started to shed light on how these probabilistic representations and computations might be implemented in neural circuits. One particularly appealing aspect of these theories is their generality: they can be used to model a wide range of tasks, from sensory processing to high-level cognition. To date, however, these theories have only been applied to very simple tasks. Here we discuss the challenges that will emerge as researchers start focusing their efforts on real-life computations, with a focus on probabilistic learning, structural learning and approximate inference.},
author = {Pouget, Alexandre and Beck, Jeffrey M and Ma, Wei Ji and Latham, Peter E},
doi = {10.1038/nn.3495},
file = {:Users/Brenden/Documents/Mendeley/Pouget et al. - 2013 - Probabilistic brains knowns and unknowns.pdf:pdf},
issn = {1546-1726},
journal = {Nature neuroscience},
month = sep,
number = {9},
pages = {1170--8},
pmid = {23955561},
title = {{Probabilistic brains: knowns and unknowns}},
volume = {16},
year = {2013}
}
@article{Prelec2004,
abstract = {Subjective judgments, an essential information source for science and policy, are problematic because there are no public criteria for assessing judgmental truthfulness. I present a scoring method for eliciting truthful subjective data in situations where objective truth is unknowable. The method assigns high scores not to the most common answers but to the answers that are more common than collectively predicted, with predictions drawn from the same population. This simple adjustment in the scoring criterion removes all bias in favor of consensus: Truthful answers maximize expected score even for respondents who believe that their answer represents a minority view.},
author = {Prelec, Drazen},
doi = {10.1126/science.1102081},
file = {:Users/Brenden/Documents/Mendeley/Prelec - 2004 - A Bayesian truth serum for subjective data.pdf:pdf},
issn = {1095-9203},
journal = {Science},
keywords = {Bayes Theorem,Bias (Epidemiology),Experimental,Games,Humans,Judgment,Mathematics,Motivation,Truth Disclosure},
month = oct,
number = {5695},
pages = {462--6},
pmid = {15486294},
title = {{A Bayesian truth serum for subjective data.}},
volume = {306},
year = {2004}
}
@article{Price2011,
abstract = {The ventral occipitotemporal cortex (vOT) is involved in the perception of visually presented objects and written words. The Interactive Account of vOT function is based on the premise that perception involves the synthesis of bottom-up sensory input with top-down predictions that are generated automatically from prior experience. We propose that vOT integrates visuospatial features abstracted from sensory inputs with higher level associations such as speech sounds, actions and meanings. In this context, specialization for orthography emerges from regional interactions without assuming that vOT is selectively tuned to orthographic features. We discuss how the Interactive Account explains left vOT responses during normal reading and developmental dyslexia; and how it accounts for the behavioural consequences of left vOT damage.},
annote = {It is difficult to pin down the contribution of area vOT (visual occipital-temporal cortex)
        
Responds selectively to letters, but also other things, evn non-visual
        
Theory that it integrates bottom-up information  and top-down expectation, "the consensual integration of visual inputs with higher-level language representations"
        
In monkeys, cooling of higher-level regions changes the function of down-stream cells
        
This feedback is automatic, where visual words automatically engage processing of their sounds and meanings
        
        
        
      },
author = {Price, Cathy J and Devlin, Joseph T},
doi = {10.1016/j.tics.2011.04.001},
file = {:Users/Brenden/Documents/Mendeley/Price, Devlin - 2011 - The interactive account of ventral occipitotemporal contributions to reading.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Dyslexia,Dyslexia: pathology,Humans,Language,Neural Pathways,Neural Pathways: physiology,Occipital Lobe,Occipital Lobe: anatomy & histology,Occipital Lobe: physiology,Photic Stimulation,Reading,Speech Perception,Temporal Lobe,Temporal Lobe: anatomy & histology,Temporal Lobe: physiology,embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
month = jun,
number = {6},
pages = {246--53},
pmid = {21549634},
publisher = {Elsevier Ltd},
title = {{The interactive account of ventral occipitotemporal contributions to reading.}},
volume = {15},
year = {2011}
}
@article{Prinz1997,
abstract = {A new framework for the understanding of functional relationships between perception and action is discussed. According to this framework, perceived events and planned actions share a common representational domain (common-coding approach). Supporting evidence from two classes of experimental paradigms is presented: induction paradigms and interference paradigms. Induction paradigms study how certain stimuli induce certain actions by virtue of similarity. Evidence from two types of induction tasks is reviewed: sensorimotor synchronisation and spatial compatibility tasks. Interference paradigms study the mutual interference between the perception of ongoing events and the preparation and control of ongoing action. Again, evidence from two types of such tasks is reviewed, implying interference in either direction. It is concluded that the evidence available supports the common coding principle. A further general principle emerging from these studies is the action effect principle that is, the principle that cognitive representations of action effects play a critical role in the planning and control of these actions. A new framework for the understanding of functional relationships between perception and action is discussed. According to this framework, perceived events and planned actions share a common representational domain (common-coding approach). Supporting evidence from two classes of experimental paradigms is presented: induction paradigms and interference paradigms. Induction paradigms study how certain stimuli induce certain actions by virtue of similarity. Evidence from two types of induction tasks is reviewed: sensorimotor synchronisation and spatial compatibility tasks. Interference paradigms study the mutual interference between the perception of ongoing events and the preparation and control of ongoing action. Again, evidence from two types of such tasks is reviewed, implying interference in either direction. It is concluded that the evidence available supports the common coding principle. A further general principle emerging from these studies is the action effect principle that is, the principle that cognitive representations of action effects play a critical role in the planning and control of these actions.},
annote = {Argues against separate event code and action code. Instead, they share a common code, and do not require translation.
        
This is related to the motor theory of speech perception, as cited by Prinz.
        
Sensorimotor Synchronisation: if you asked people to press a button at exactly the time they hear a click, almost everyone thinks they are perfect but they are early. Perhaps this is because they are synchronizing the representation, not the exact stimulus
        
Interference: common coding suggests this can happen when the same code is used at the same time.
There is a strange inverted compatibility effect, where perception in the same direction as action impedes RT
      },
author = {Prinz, Wolfgang},
doi = {10.1080/713752551},
file = {:Users/Brenden/Documents/Mendeley/Prinz - 1997 - Perception and Action Planning.pdf:pdf},
issn = {0954-1446},
journal = {European Journal of Cognitive Psychology},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
month = jun,
number = {2},
pages = {129--154},
publisher = {Psychology Press},
title = {{Perception and Action Planning}},
volume = {9},
year = {1997}
}
@article{Pulvermuller2005,
annote = {Are there close interactions between language areas and motor areas? 
Are actions represented by their motor programs? This is a review article about this idea
        
--
        
Results: "lick, pick, kick" are words associated with tongue, hand, and leg. When reading these words, the relevant area of premotor and motor cortex light up. 
        
But fMRI is too slow to understand the timecourse. EEG results show that this activity happens very early (200 ms)
        
Same with MEG and passive listening to the word.
        
Also found with TMS to these regions, can faciliate the relevant motor area. Was not the case for right hemisphere, or sham stimulation.},
author = {Pulverm\"{u}ller, Friedemann},
file = {:Users/Brenden/Documents/Mendeley/Pulverm\"{u}ller - 2005 - language and action.pdf:pdf},
journal = {Nature Reviews Neuroscience},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
pages = {576--582},
title = {language and action},
volume = {6},
year = {2005}
}
@book{Quammen2006,
address = {New York},
annote = {Biograph of Charles Darwin. This book skips over his time on the Beagle, since it is well-known. Instead, it focuses on how he develops his theory and procrastinates publishing it for a number of years.
        
I wanted to know where the idea came from.
-- He remarked on the Beagle that it was strange that many different species of finches inhabit nearby islands. Why would a creator do this?
-- More cards fell into place after he got his specimens analyzed
-- It's not clear if the theory was a gradual development or not, since he never wrote down the Eureka moment all at one time
-- Further elboration on his notebooks, A-E
        
Interesting facts:
-- Darwin sketched a tree structure in The Origin, which is the only figure
-- He took a very long time (decades) to publish his theory, perhaps out of fear
-- Wallace is a co-inventor, who sent a transmutation paper to Darwin independently, which pusher Darwin to publication
-- Darwin was an atheist
-- Darwin struggled with unexplained vomiting his entire life
-- Species reproduce geometrically, so we would be over-run if there was no constraining force},
author = {Quammen, David},
publisher = {W. W. Norton \& Company},
title = {{The Reluctant Mr. Darwin}},
year = {2006}
}
@article{Raibert1978,
author = {Raibert, M H},
file = {:Users/Brenden/Documents/Mendeley/Raibert - 1978 - A model of sensorimotor control and learing.pdf:pdf},
journal = {Biological Cybernetics},
keywords = {handwriting,part-based models},
mendeley-tags = {handwriting,part-based models},
pages = {29--36},
title = {{A model of sensorimotor control and learing}},
volume = {29},
year = {1978}
}
@inproceedings{Raina2007,
author = {Raina, R and Battle, A and Lee, H and Packer, B and Ng, A Y},
booktitle = {Twenty-fourth International Conference on Machine Learning},
title = {{Self-taught Learning: Transfer Learning from Unlabeled Data}},
year = {2007}
}
@article{Ramer1972,
author = {Ramer, Urs},
file = {:Users/Brenden/Documents/Mendeley/Ramer - 1972 - An Iterative Procedure for the Polygonal Approximation of Plane Curves.pdf:pdf},
journal = {Computer Graphics and Image Processing},
keywords = {classic AI,handwriting},
mendeley-tags = {classic AI,handwriting},
pages = {244--256},
title = {{An Iterative Procedure for the Polygonal Approximation of Plane Curves}},
volume = {1},
year = {1972}
}
@article{Ramesh1989,
author = {Ramesh, S R},
file = {:Users/Brenden/Documents/Mendeley/Ramesh - 1989 - A generalized character recognition algorithm A graphical approach.pdf:pdf},
journal = {Pattern Recognition},
number = {4},
pages = {1--4},
title = {{A generalized character recognition algorithm: A graphical approach}},
volume = {22},
year = {1989}
}
@misc{Rangel,
annote = {ventral medial PFC -- evidence for where value is computed
        
---
simple choice: just values for two options, no complex "you shouldn't pick this one" response
        
Where is value computed/stored in the brain?
        
Experiment 1
- present squence of items
- implicit step where value is computed
- ask them to make bid
- have to purchase some number of the bids at random at the end
        
Control is where bid is determined for you
        
Value of bids correlate with two regions: 1 inch deep, between eyes
        
Experiment 2
- Is there a system that computes value for aversive stimuli?
- bid is how much you would pay "not to eat the item"
- same controls as before
        
Areas that correlate with aversiveness? nothing on its own
        
Same areas that are correlated with positive value in the firs ttask, are negatively correlated with engative value in the other experiment
        
-----
        
Is this just for food?
- choice between fixed monitary value, and 80% chance of getting some item
        
medial orbital frontal cortex: correlateswith value of the stimuli for food, money, snacks, goods, etc.
        
--
Another experiment:
- do these areas correlate with value, or the absolute magnitude of the value in either diretion?
[thus, absolute signal could be arosal]
        
Other "value" areas don't seem to do this... they look like they are salience instead
        
ventral medial PFC -- evidence for where value is computed
        
---          
how are values computed?
                
you don't just attach a value to each stimulus independently
-- perhasp its a summatio of value for sweetness, calroies, acidity to get the value of apple?
        
Experiment:
- show t-shirts with message in korean, vary in font, color etc.
- rate how much they would like to wear it around
- then train them in these korean words
- ask them to do experiment again
        
contrast semantic vs. visual ratings
- localize with separate visual and semantic ratings tasks
- during valuation, you get a separate value signal in each area for hte relevant attribute
- consistent with separate valuation model
        
---
attentional drift-diffusion model
- choosing between two items
- you have linear increase proportional to the value of each item, but which value you pay attention to deterines which direction the model drifts
- usualy gaussian noise
- fixation is chosen independently of value
        
strangely, fixation is not related to value
        
idiosyncratic predictions of diffusion model, like the length of the last fixation (how long you look at it), seem to turn out in the data
        
if you run this in a scanner, when attention is not free but cued to one item, the value area flips at the contrast of the values (how much better is this than the other things)
        
this is a precusor to choice (just computes value), not choice 
        
----
        
why should this semantic area and visual area respond linearly with the value?
+ its what his data suggests, but you also need to know the meaning/features for things you don't like},
author = {Rangel, Antonio},
title = {{The neuroeconomics of simple choice}}
}
@incollection{Rehder2007,
address = {Oxford, UK},
annote = {Categorization's mind problem is determining how core and perceptual features interact
        
        causal model theory: observed featuers provided indirect evidence for core featuers, which are more diagonistic of the category membership
        
---------
essentialism: categorization's mind-body problem, how core and perceptual features interact
        
Introduction: children as young as 3 believe the "insides" of objects are relevant in determining its class membership
        
essential vs. accidental properties
        
Like Cartesian dualism? How can these different types of features interact?
        
causal model theory
Solution: use observable features to infer the presence of more core properties, which are taken as more diagnostic of category membership
        
The causal mechanisms must be probabilistic, since they don't always cause the observed feature
        
Experiment 1:
        
four features of lake victoria shrimp
        
conditions:
causal story provided or not, with a chain-structured graphical model
        
results:
tested with exemplars that have each feature, with everything else unknown
        
causal condition shows nice declining induction along the causal chain, with also a higher overall inductive potential
        
Experiment 2:
        
Two categories of shrimp, with opposite values of all the features
        
conditions:
either provided with causal information or not
        
results:
causal condition experience boundary intensitifation (Gelman), relative to the control condition
        
Experiment 3:
        
common-effect: multiple features can cause HIV+ status
common-cause: HIV+ status leads to multiple symptoms
        
In common-effect, P(F | HIV) is larger for one feature and then asymptotes as the number of "on" features increases
        
In common-cause, P(F | HIV) has most if it's mass on all the features being on
        
Results show signatures of this effect, when comparing groups that were given teh two different structures for Lake Victoria shrimp
        
Experiment 4
        
You can also define categories that are defined by the correlation of featuers, not just their presence of absence
        
Discussion
        
Challenge for categorization: observable properties and categories have an underlying relatiyy that goes beyond what is preceptually available
        
When do people override perceptual information?
        
causal model theory: there is a defining "feature", and observable features serve as evidence for category membership by implinyg its presence
        
There can be non-causal categories, like a movie scene with the hula invokes an "island", but not because an island's observable properties cause it somehow
        
Essential shift:
- categories start off being defined by surface features
- posit essence, which explains features
- finally, the essence is identified as the "true" determiner of category membership, and the other features provide merely indirect evidence},
author = {Rehder, Bob},
booktitle = {Causal learning: Psychology, philosophy, and computation},
editor = {Gopnik, Alison and Schulz, Laura E},
file = {:Users/Brenden/Documents/Mendeley/Rehder - 2007 - Essentialism as a generative theory of classification.pdf:pdf},
keywords = {causal reasoning,theory theory},
mendeley-tags = {causal reasoning,theory theory},
pages = {190--207},
publisher = {Oxford University Press},
title = {{Essentialism as a generative theory of classification}},
year = {2007}
}
@article{Rehder2003,
abstract = {This article presents a theory of categorization that accounts for the effects of causal knowledge that relates the features of categories. According to causal-model theory, people explicitly represent the probabilistic causal mechanisms that link category features and classify objects by evaluating whether they were likely to have been generated by those mechanisms. In 3 experiments, participants were taught causal knowledge that related the features of a novel category. Causal-model theory provided a good quantitative account of the effect of this knowledge on the importance of both individual features and interfeature correlations to classification. By enabling precise model fits and interpretable parameter estimates, causal-model theory helps place the theory-based approach to conceptual representation on equal footing with the well-known similarity-based approaches.},
annote = {Computational model of categorization, where exemplars are evaluted on the probability of belonging to a category, where the category is a causal model of the features. Quantiative fits puts theory approaches on equal footing with similarity-based approaches.
        
Used simple 4 feature chain based categories, and find that a Bayesian network provides a good fit to inductive judgements.
        
However, the "essence" or deep causal features are OBSERVED, rather than latent in most cases. It would be interesting to try to model categories with latent essences versus not, and trying to figure out if it has such an essense
        
------------
        Introduction        
        
Little work on formal models of theory-based approaches.
+ gives a concrete way for "weighting" features, a problem for all approaches
+ allows for the fact that some feature combinations seem particularly diagnostic
+ asymmetries in features, where a animal that doesn't flight seems like a good bird, where nest is less diagonstic
                  
Causal-model theory        
        
Bayesian network
- If you have a chain structure, and the root is on, the probability of each feature being on slowly diffused across the chain
- also, variables are less strongly correlated when their distance increases
                  
Experiment 1:
          
condition: chain or control
        
Four featuers were arranged in a chain, and the causal relation between each link was described
- base rates were 75% on independently
        
After reading instructions, they rated the categorization strength of 48 exemplars
        
Exemplars were rated differently in chain vs. control condition (like 1111 or 1010)
        
Also looked at how categorization changed, depending on particular feature contrasts (deltas)
                  
Modeling        
Fit within sample (could be better...), where we have the base rate parameters and causal strenght parameters. Just 4 parameters
        
Very tight fit to the categorization ratings
                  
Experiment 2
                
Did not have a base rate of 75%, which may have limited room to show experimental effect
        
Results:
accounted for 93% of the variance in people's ratings
        
However, they did not find that more upstream features were stronger in predicting the category, which is surprising (when compared to results from Ahn)
        
Experiment 3
        
First feature was always on, but not shown to the participants (like a hidden essence). But it was described to be on, and clamped
        
Results:
There was a linearly decreasing effect of feature strength
        
Model accounted for 97% of the variance
        
Again, sensitive to features that violated causal laws
                  
Discussion
                
They fit a prototype model with interaction terms, which fits about as well as the causal model. However, it doesn't EXPLAIn the data Rehder claims (Do I believe this?). Also, has fewer parameters
        
Tells us that deeper properties are more predictive of category mebership
        
Did not present participants with category members,which is not typical. But they could be fit to empirical regularities in real data
        
All "theoretical" knowledge is causal to some extent, whether its physical cause or naive psychology
        
Helps place theoretical knowledge on equal footing with similarity approaches},
author = {Rehder, Bob},
doi = {10.1037/0278-7393.29.6.1141},
file = {:Users/Brenden/Documents/Mendeley/Rehder - 2003 - A causal-model theory of conceptual representation and categorization.pdf:pdf},
issn = {0278-7393},
journal = {Journal of experimental psychology. Learning, memory, and cognition},
keywords = {Causality,Concept Formation,Discrimination Learning,Humans,Models,Probability Learning,Problem Solving,Psychological Theory,Statistical,causal reasoning,classic psychology,classics on concepts},
mendeley-tags = {causal reasoning,classic psychology,classics on concepts},
month = nov,
number = {6},
pages = {1141--59},
pmid = {14622052},
title = {{A causal-model theory of conceptual representation and categorization.}},
volume = {29},
year = {2003}
}
@article{Rehder2001,
annote = {Causal knowledge interacts with category learning. Causal knowledge described between the features of a category, where one feature my be causally central
        
Causal relations determine how a category is generalized in terms of classifying new examples, generalizing properties in an induction task, and in terms of feature weights
        
Thus, while structure and data-driven statistics can be combined, structure seems to be dominant in this set of studies. 
        
Causal Bayes nets provide a way of infusing "essentialism" in categories, in a way that simple exemplar models cannot
        
---------------------
Introduction:
-need for theory-based categories
- rational vs. empiricism
+ prior beliefs conveyed through instruciton
+ empirical information through experience with exemplars
        
Essentialism
- natural kinds have a underlying, causally potent essence that establishes category membership (like a common cause to the features of a category)
        
Study: 
- manipualte the causal structure and the empirical structure of the categories
        
Psychological essentialism
- "psychological" is needed to dstinguish it from its philosophical counter-part which was descrited
- natural kinds seem to have an essence, nonobvious characteristics with lawful relationships, while artifacts do not
        
causal-essentialism hypothesis: distinctive characteristics of natural kinds arise from the rich causal structure organized around a central feature
        
some have argued essentialism has innate, domain specific competencies, but this view is domain general
        
claim: attributes become central when they are the causal force behind many other attributes
+ Experiment: learn a common-cause causal schema, and rate new members
        
Test: property induction. If one member of a category has it, how likely is it that all ahve it
+ using blank properties
        
Experiments
        
conditions
causal schema: common-cause, common-effect, no-correlation, no data
kind of category: biology, natural kind, artifact
statistical structure: common-cause corr., common-effect corr, no corr, no data
        
Experiment 1
        
-no correlations in data
- either common cause or common effect causal story
        
Each attribute has a 25/75 base rate
        
Causal relations were described, like a high quantiy of ACH neurotransmitter causes a strong flight or fight response.. then describe how that neurotran. contributes to other properties
        
Multiple choice test for instructions comprehension.
        
Exemplars divided in categories based on feature base rates, which had no correlation. 1111 was one prototype and 0000 was another. 32 exemplars total
        
Transfer trials: 2 of each possible stimulus
Property induction: if these four exemplars have the property, how likely is it that all other do?
        
also similarity ratings
        
A1 causes all
or A4 is caused by all
        
Results
It was harder to learn the task in either causal scenario, compared to none, since those correlations did not manifest
        
There were differences in transfer effects, where some exemplars were categorized differently depending on the causal schema, like if the base property is missing but all others are on
        
Regression analysis where we compute weight for each feature, and common cause had high weight for feature 1 and common effect for feature 4
        
No difference in property induction ratings, although study had high power
        
Discussion
        
Clear that causal knowledge influences categorization
        
Feature that causes others will be viewed as most important member
        
Also, pairs of features were important, even though empirical structure of exemplars did not reflect it
        
Experiment 2
        
-no examples from categories
        
Same as experiment 1, except participants never observed examples of the categories
        
Results
        
Items were categorized consistently with the causal story, and undergraduates took into account the asymmetries associated with causal relations
        
Schema also had similar effect on the induction strength, as it did on the categorization schema. Very similar pattern (figure 7 vs. Figure 5)
        
Experiment 3
        
- congruent data, where data matches the causal story. It was generated from a Bayesian network associated with each of the causal patterns
        
Categories with a common cause produced exemplars with greatest similarity, using the multiplicative similarity rule of Medin and Schaffer
        
Otherwise, there was a similar pattern of data
        
Again, exemplars were categorized differently depending on the causal story
        
Also, exemplars that followed the causal rules promoted stronger inductive generalizations
        
Expreiment 4
        
-no schema, where correlation structure varied but participants were not taught any schemas. Otherwise, it was the same as Experiment 3
        
Weaker classification results, where features A1 and A4 did not play different roles in the different models anymore
        
No effect in property induction
(disappointing that there is little effect when the causal structure is latent, rather than provided explicitly)
        
Discussion and comparisons across experiments
        
Interactions between features was only a key component when the causal story was explicit
        
Exemplar model can account for feature correlations, by storing a set of exemplars, but it cannot account for data of Experiment 1 where there were no correlations in the stored exemplars
        
Different in saliency of attributes not enough (they fit an exemplar model)
        
Skipped section on similarity ratings
        
General Discussion
        
Results suggest that after you acquire causal structure, it will dominate in subsequent categorization judgements
        
It does not require coherent exemplars that follow the causal story, or any exemplars at all
        
It was present not only in natural kinds, but in many kinds of stimuli
        
Causal effect hypothesis: causes are more important than effects (Ahn). This is not supported by the data here, since in the common effect, the effect is the most important dimension
        
Main point
Classificaton by theory: emphasizes causally central attributes
Classificatoin by datA: emphasizes similarity based on features
        
These do not converge to the same thing
        
Here, it seemed the causal information dominated the data information, although many factors could influence this
        
Supports Gelman's finding that second graders are more likely to generalize new properties to natural kinds, since they have more of an essence
        
Data demands description in terms of inter-feature relations, not just feature arrays},
author = {Rehder, Bob and Hastie, Reid},
file = {:Users/Brenden/Documents/Mendeley/Rehder, Hastie - 2001 - Causal Knowledge and Categories The Effects of Causal Beliefs on Categorization, Induction, and Similarity.pdf:pdf},
journal = {Journal of Experimental Psychology: General},
keywords = {causal reasoning,classics on concepts},
mendeley-tags = {causal reasoning,classics on concepts},
number = {3},
pages = {323--360},
title = {{Causal Knowledge and Categories: The Effects of Causal Beliefs on Categorization, Induction, and Similarity}},
volume = {130},
year = {2001}
}
@article{Rehder2003a,
annote = {Summary: This model can account for various knowledge effects, like categories with related features are learned faster, whether or not there are previous concepts that relate them, or the features just seem related. Also, inconsistent prior knowledge can be overriden
----
        
Relation to my work: 
causality causal model theory: observed features predict latent features, which are more indicative of category membership (Rehder)
        
composition - in terms primitives, constituiting a form of prior knowledge. Existing featuers, and their relations, which we can parse new concepts (Muprhy
        
Connectionist model of knowledge effects in categorization. Rather than just associating features with labels, features can have existing associations between themselves and with previous concepts. Recurrent activation.
        
---------
Introduction
Since Hull (1920), tabula rasa learning is responsible for category learning
        
However, it is clear the learning is not just the co-occurence of arbitrary features. It is also influence by prior world knowledge
        
Knowledge effects (Murphy, 2002) influence verything:
- analysis of exemplars into featuers
-which are atended during learning
- knowledge of causal relations
- influences category-based induction
        
Knowledge-resonance model (KRES) Model
        
-recurrent network
- contrastive Hebbian learning
- feature-to-feature connections operationalize prior knowledge, suh as semantic relations, causal relatoins, part-whole relations, etc.
- also, prior concepts, like a videocasstte player which helps to learn a DVD player
+ Heit and Bott use only such prior concepts, but you can get knowledge effects with new features too, and thus feature connections are more flexible
        
Model
units can be category labels, features, or prior concepts
- activation function is standard sigmoid
- full connectivity between layers
- binary features are represented by two units, which inhibitory connections between them -- allowing them to be part of their own networks of units, fixed inhibitory connections I think?
- groups of features can be related by prior knowledge (wings with flying)
        
RT: the number of cycles until the harmony stops changing
- error rate: categorization decisions made by Luce's choice rule based on activities of the two units
- learning: plus phase and minus phase, where plus phase has label units clamped on. Adjust weights to make plus phase more likely, in terms of pairwise stats, compared to minus phase
+ approximation of backpropagatoin (O'Reilly)
        
Experiment 1:
        
Does is capture simple prototype effects, without knowledge effects?
- presented network with examples of two categories, defined by all 1s and all 0s, with one exception feature. 
- the unseen prototypes were categorized more accurately than the original exemplars
        
Overshadowing
- stronger cues overshadow weaker cues. If the model has a single feature which is perfectly predictive, the other features are not learned well. 
- Also, block effect, where previously learned cues hurt learning new ones
        
Experiment 2: Learning with prior concepts
        
Most consistent effect is that learning is faster when prior knowledge is consistent
        
Like, if the features of a category all relate to "honesty" in some sense, the category is easier to learn than if they don't
        
To model this, they set excitatory connections between features related to honesty and a previous concept "honesty". Seemed to just choose values of these weights arbitrarily.
- shows similar effect when learning is faster with preexisting concept
+ prior concept units have the strongest connection to new category labels. 
++ Thus, did it really learn something new, or just associate a past concept with a new one?
        
Experiment 3: Learning facilitated by knowledge
        
Here, Heit and Bott, half the features were related and the other half were unrelated. Categories were "church building" and "office building", where irrelevant features were things like "near a gas station" and relevant was "slanted roof"
        
Some features, both related and unrelated, were never presented, and used as "test features" for classification decisions
        
Model had parameters set to different arbitrary values
        
Results:
Unpresented unrelated features did not active labels, but unpresented related features did
- also, unrelated features are learned by the model, to some extent, just like people
        
Experiment 4: Prior knowledge without prior concepts
        
Heit and Bott had a model, Baywatch, that has only feedforward connections and backdrop, with on recurrent connections. It can produce the effect of the last experiment, which mostly comes from existing categories
        
Why do we need the recurrent connections?
        
Murphy and Allopenna (1994), where participate learned Jungle vs. Arctic vehicles, where features either made sense or they were scrambled. However, the categories were novel, and not prior concept nodes
        
Thus, we model this as connections between feature nodes. Again, unclear how parameters are chosen.
        
The related features were easier to learn, because of the recurrent connectivity, which Heit and Bott can't account for based on prior concepts or backdrop
        
Captures effect that categorization based on related features doesn't depend on frequency of presentation, but it does depend on that if the feature was unrelated
        
But still, why do we need recurrent conniptions from category nodes, not just between feature nodes
        
Simulation 5: Learning features unrelated to knowledge
        
Features were related across examples, but there were no other related features (thus only one per exemplar). Yet, people still learned these related categories faster than controls
        
In the model, the connections between the 6 related features and the category label were strengthened every trial, at least to some degree, because of recurrent connectivity. 
        
Also, model accounts for feature frequency effects, where frequent features (wether related or unrelated) were categorized quickly, but other infrequent ones were only categorized quickly if they were related
        
Simulation 6: Interpreting ambiguous stimuli and updating prior knowledge
        
The model can change classification of a new example when it violates expectation\ldots
-- however, does this over-rule old knowledge? (catastrophic forgetting?)
        
Discussion
        
- Few formal accounts of how both empirical learning, and prior knowledge, can be integrated together
        
Also, theories behind categories don't account for everything, so it's necessary to learn about the extraneous empirical information
        
Problems:
-- cannot solve non-linear categories
- not all types of prior knowledge can be captured as simple associations, and there is a need for predicates and variable binding
- prior knowledge is not itself learned
- how are the existing connections set? currently, just done by hand},
author = {Rehder, Bob and Murphy, Gregory L},
file = {:Users/Brenden/Documents/Mendeley/Rehder, Murphy - 2003 - A knowledge-resonance (KRES) model of category learning.pdf:pdf},
journal = {Psychonomic Bulletin & Review},
keywords = {theory theory},
mendeley-tags = {theory theory},
number = {4},
pages = {759--784},
title = {{A knowledge-resonance (KRES) model of category learning}},
volume = {10},
year = {2003}
}
@inproceedings{Rehling,
annote = {Given a few examples of latin letters in a particular font, Letter spirit fills in the rest with latin letters
        
three modules into a single strategy:
review and revision
        
Fluid Analgy Research Group:
Codelets (small programs ) on a coderack combine to  produce an overall goal, excpet it is not obvious from the low-level activity
        
      },
author = {Rehling, John},
booktitle = {Proceedings of the Sixth International Confernece on Cognitive Modeling},
file = {:Users/Brenden/Documents/Mendeley/Rehling - Unknown - Letter Spirit A Model of Visual Creativity.pdf:pdf},
keywords = {letter spirit},
mendeley-tags = {letter spirit},
pages = {249--254},
title = {{Letter Spirit : A Model of Visual Creativity}}
}
@phdthesis{Rehling2001,
author = {Rehling, John A},
file = {:Users/Brenden/Documents/Mendeley/Rehling - 2001 - Letter Spirit (Part Two) Modeling Creativity in a Visual Domain.pdf:pdf},
number = {July},
school = {Indiana University},
title = {{Letter Spirit (Part Two): Modeling Creativity in a Visual Domain}},
year = {2001}
}
@book{Reisberg2010,
address = {New York, NY},
annote = {        General themes        
-- inference to the best explanation
-- memory is influenced by how you organize the knowledge (schemas)
-- decision making may have two systems, one with fast heuristics and the other is slow and deliberate
        
===
        Chapter 1: Introduction        
        
Brief history, 
-- from introspectionists
-- to behaviorists
-- to cognition
        
Not everything can be attributed to physical stimulus, those subejctive things are real.
Example of benefit of cognition -- the phonological loop of Baddely and Hitch (1974). When you are asked to remember a list, you reherse it in a loop.
-- evidence, people make "sound-alike" errors in a span task. If you have verbal shadowing, this mechanism also breaks down 
        
Chapter 2: the neural basis of cognition
        
-- Capgras syndrome -- you think everyone is an imposter. Dissociation between face recognition (which works) and your emtion system which should trigger a warm response to loved ones
    -- probably disrupts amygdala
    -- prefrontal cortex abnoralities
Brain stats
   -- about a trillion neurons
   -- 10,000 connections
        
FFA and PPA activity correlates with conscious preception, more so than just physical presence of stimulus (as tested by binocular rivarly)
-- appraxia - problem initiating action
-- agnosia -- problem with perception
        
Visual system:
In V1 (Hubel and Wiesel)
-- center surround cells
-- edge detectors
In LGN (stage after retina)
--P cells (parvocellular), small receptive fields, continue to fire if a stimulus remains unchanged
-- M cells (magnocellular), fire when stimulus appears and disappears
        
Chapter 3: object recognition
-- we go beyond the information given (Gestalt psychologists)
How do we do recognition?
-- feature accounts, 
-- visual search (Treisman)
-- Word superiority effect -- show the effect of context, letters are easier to indentify in context. Can get facilitation with well-formed non words
-- over-regularization errors, if CQRN is presented quickly, the prior could domiante and become CORN
        
Possible theories:
-- feature nets (Selfridge pandemonium model), could also combine with bigram detectors besides just single letters. This implements distributed knowledge, no central part knows everything.
-- McClelland and Rumelhart interactive activation model. There are top-down effects, and also there is lots of feedback connections in the brain.
-- Biderman's recognition by components. You need just 36 geons, which are viewpoint invariant. If you obscure geon identity, it's hard to identify the objects.
-- Recognition by multiple views (Tarr, Poggio, etc.). Most object sensitive neurons seem to be view-tuned. 
        
Faces -- perception gets screwed up when you view it upside down.
Are they speical?
 They may seem special, but it also might be expertise. Prosopagnosic brid-watchers lost the ability to distinguish birds. 
-- Gautheir found FFA responds for experts
-- Diamond and Carey, found that dog experts were disrupted when dogs were inverted, much the same was a faces
        
Chapter 4 - Attention
        
Dichotic listening: 
-- left and right ears get different streams of speech. You shadow one of them
-- People pick up very little from the unattended channel. If the other becomes nonesense, few people notice
-- There are leaks: You tend to catch your own name, or things with personal significance
        
Broadbent's filter theory: we can shut out a distractor at a low level.
-- evidence: this has to be done at for each new distractor
-- counter-evidence: but this is only a small part of the story. We can select something positively too.
        
Inattentionl blindness: failure to see something at all
-- Claim: there is no perception without attention
-- False: Moore & Egeth, 1997, found that a Muller-Lyer illusion, which was not recalled, nonetheless influences which line looks longer
        
There is no conscious perception without attention.
        
People miss a lot of things they are looking right at.
        
Change blindness:
-- you don't notice a change in a scene without attention
        
Early selection: most things aren't processed deeply
Late selection: most things are processed deeply, attention operates at the last minute
-- can even happen in real life (people with door walking through a conversation)
- Luck & Vogel, EEG study, supports a late attention story. Meaning of words is processed during the attentional blink, even if it is not reported
-- early attention evidence: area V4, neurons are more responsive to the attended stimulus
-- bottom line: complex stimuli look like early selection, while simple stimuli more like late selection
        
Priming
Two types:
1) stimulus-prime, just seeing it leads to facilitation
2) expectation-based, where you think you can predict what will happen next
Classic studies by Posner and Snyder. People are faster with a predictive cue, even for a simple task, like pressing a key depending on whether the stimulus is to the right or the left
        
What is attention? Is it object based, or space based?
-- spatial account has evidence from unilaterial neglect syndrome. Here, people can't pay attentiont to anyting on the left
-- object account: even in these patients, you can lock onto an object on the left side, and follow it to the other side
        
Intereference
-- stronger when tasks are more similar
-- But cell phones do hurt driving! This is an example of a general resource limitation
        
Executive control as a limited resoure
-- people with larger working memory have an advantage on many tasks
-- practice, helps people deal with multiple elements simulataeously
        
Automaticity
-- Stroop task: people can't help but read the word, even if they should just say the color
        
Chapter 5 -- Working memory
        
modal model: memory has multiple kinds, including working memory and long term        
        
working memory (WM): the desk space, or room to work
LTM: general knowledge base
        
Effects in free recall:
        
Central claim: organization effects recall
        
primary: comes from memory rehersal
-- you can improve all items by slowing down the list
recency: since older words are bumped out of WM
- you can disrupt this by counting backwards, which only effects the recent items
-- early items seem to depend on hippocampus, but not recency itmems
        
Digit span
-- Miller's (7 plus or minus 2) chunks. Introduced chunking, not raw amount of information
-- chunks can be hierarchical, and thus even more powerful (interesting that this is a tree?)
-- "operation span" or "reading span" can be used instead, where you are asked for the last word in each sentence, or testing memory in a more natural setting. This correlates better with IQ, SAT, etc.
        
What are the frontal lobes doing?
With damage, goal neglect: relyign on habitual responses even if those don't move towards the assigned goal
        
Reherasal:
--maintenance: just saying it again
-- relational: think about how the items relate, what they mean, etc.
Relational is far superior
-- activation in hippocampus and PFC predict more likely to recall
        
Depth of processing:
You are asked to recall words you saw, each appearing in pairs
-- depending on how you related the two words, this effects recall dramatiaclly
- incidental vs. intentional learning -- this matters very little!
        
EFfets of organzation
-- you can have a puzzling passage, but if you know its about laundry, you remember it much better
        
It's hard to study memory on its own, given its close connections to prior knowlege
        
WM is not one thing
-- visuospatial buffer
-- articulatory rehearsal loop
        
        Chapter 6: Acquistion and Retreival        
You can't access knowlege from any angle, usually you retrieve it in a manner related to how it was acquired
        
state-dependent: drivers were better if items learned underwater were tested underwater (Godden and Baddeley, 1975)
Also works for quite vs. noisy, scents etc.
        
context reinstatement: improved memory if you recreate context
        
Also, benefit for deep associations (semantic) rather than shallow (like sound)
        
encoding sepcificity: it's not just the stimulus, but the stimulus + contextvthat is stored
        
recognition vs. recall: is this familiar? or what was it?
        
Dissociations: seeng a face, but not remembering why it is familiar. Or capgras: having recall, but no feeling of familiarity
--fMRI: hippocampus invovled in remembering,
but parahippocampus for familiarity (rhinal cortex)
        
Repetition priming: just seeing something, even without awareness, will change future performance
(words checked for spelling, and later used in a lexical decision task)
Also happens for word completion ("CLA-") and finish the word
        
Explicit vs implicit memory: reflected in direct vs. indirect memory tests
        
also, implicit memory is memory without "awareness"
        
Faces with fake nams, which were pronounced a day earlier, are rated as "more famous". It somehow "rings a bell"
        
illusion of truth: Same with sentences, and people judging them to be true (even if they previously knew half of the sentences they read were false). 
        
source confusion: something looks familiar, but you don't know from where
        
implicit memory can just feel like processing fluency, or something that changed in your perceptual system. Thus, you can trick a sense of familiarity, by making something easier to process.
        
Amnesia:
retrograde -- forget past information
anterograde -- can't make new memories after the impact
        
Korsakoff's syndrome: similar to HM, most often seen in alcoholics. 
A patient who had their hand pricked, coudl not remember the experience, but would not shake hands with the person again
Likewise, HM can trace the star, showing a dissociation between implict and explicit memory. But implicit memory can be damaged if the visual cortex is.
                  
Chapter 7: Remembering complex events        
- We locate memories extremely efficiently -- how is this possible?
Memory errors
-- recall a film we have never seen, but because the event is so well known
-- recall books were in an office, even though they were not
-- intrusion erros, other knowledge intrudes on the memory event
-- context leds to imported errors
-- themes interfere with memory (known as the DRM) procedure
        
Schematic knowledge 
- schema, gneeric knowledge, what appens in a restaurant is a classic example
-- Bartlett (1932) native American story, where people regularize the narrative during recall so that it makes more sense
-- Supplements memory with well-informed inference
-- Loftus, the cars "smashed" vs. "hit" eachother, not only influences the rating of the speed, but whether they saw glass (one week later)
        
Misinformation effect -- being influenced by misinformation, given after the event
-- false personal narrartives
-- easier if it is plausible
        
Accurate memories: usually, you are correct!
        
Source monitoring: remembering sources
        
Sources of errors: 
- intervening venets, more so than decay (Baddeley & Hitch, 1977)
- forgetting is often due to retrieval problems, thus, undone by stimulation?
- confidence correlates fairly little with accuracy (also, not correlation with emotional content)
        
Autobiographical memory
- self-reference effect: benefit for remembering things you said/did
- biased to increase consistency, or to a more positive portrait
- flashbulb memories, which are highly accurate traces (questionally accurate sometimes, but more so if they were casually relevant)
- remarkably accurate for remembering names in high school yearbook
        
-permastore - (Behrick, 1984). A permanent memory trace, like high school algebra
                  
Chapter 8: Associative long-term memory
                
This chapter discusses various network models of long-term memory.
        
-- network mode: the connections are the associations between words/concepts
-- spreading activation: nodes and connections
Example: What is the capitcal of South Dakota? You may not know, but if you also say Hint: it's a man's name, you might get the answer: Pierre. Thus, activation can be accumulated from multiple sources
        
Lexical-decision tasks
(Meyer & Schvandevelt, 1971 - read this)
-- decide whether or not eah of a pair of words is a word
-- some pairs were semantically related, others were not
-- there is almost a 100ms speed increase if they are related, indicating general support for network models
        
Sentence verificatin
-- Is a robin a bird? (true/false)
-- Collins and Quilian -- models of memory organizatino, where facts are stored at the most general level
- criticism: typicality correlated with speed
- "peacocks have feathers" is faster too, even though its a general fact
        
Degree of fan:
(Andreson, 1974). The more fan, the smaller the activation that spread form the node.
-- works for memorizing propositions
"The lwayer is in the park"
The banker is in the house"
vs. 
Both are in the park
If there is an overload from the park, you are slower to indicate sentences involving the park are correct
        
Semantic networks are closely related to feature networks
        
How do you represent different types of links?
has-a vs. is-a dog, is very important
- propositions: smallest unit of knowledge that can be true/false
-- these are represented as ovals in ACT, where you have links (subject,object,relation) to things that make of the propositon
-- type vs. tokens are linked by is-a links
-- also "time" links are used to indicate specific facts. vs general knowlegde
        
Tip of tongue (TOT) phenomena: perhaps just a faiulre to reach threshold. There are general problems with figuring out how activatino should spread in a net model, how far, and whether there is a winner-takes-all mechanism
        
Connectionistm
-- make nodes simpler, not more complex
-- distributed representations: no nodes have a simple interpretation
-- simultaneous multiple constraint satisfcation (not serial thought)
-- error-driven learning (backprop)
-- But criticms of biological realsim (see Bowers, 2009)
-- learning is also too slow, for people's rapid inferences
        
        Chapter 9: Concepts and Generic Knowledge
          
Chapter 10: Language
                
morphemes -- smallest units at carry meaning
- "umpire,' "talk," "-s", "-ed"
phonemes -- smallest units of sound that are used to distinguish words
        
phonology
- voicing - vibration caused by vocal folds (feels like it comes from Adam's apple)
- also change sound by narrowing air passageway with moust ([s] or [f])
- "stops" [p],[b],and [t] where the air is stopped
- "voiced", [v], [z], [n]
- "place of articulation" - where airflow is restricted by the tongu
        
complexity
- speech segmentation - getting th words out of the stream, which is continuous
- coarticulation - sounds overlap, making it challenging
        
how we solve it
- only use a few words very often
- active process that uses prior knowledge, on-line information
- phonemic restoration effect - can fill in noise with right phonemes (subconscious)
- categorical precpetion - better discrimination along the category boundaries (hear an abrupt shift)
        
words
- #45,000 words for high school grad, 75-100K for college graduates
- referent/meaning of a word is not identical ("pope" vs. the current pope...see discussion of concepts)
- generativity - it's real power, "knowing" a language
        
syntax
- govern the sequence of words
- not the same as meaning
	"colorless green ideas sleep furiously"
- phrase-structure 
S -> NP VP
(can be described by rules)
- competence vs. performance
- D-structure (deep), aka the parse tree
"discuss sex with Jay Leno"
        
linguistic univerals - principles applicative to every human language
        
- subject before object (98%)
- subject before verb (80%)
- Chomsky - adjusting universal parameters accounts
+ explains how language can be learned so quickly
        
Sentence parsing
- people parse online
- more efficient, but sometimes leads to errors
- garden path sentences
- assumptions
+ active  voice/minimal attachment (phrases are small)
- semantics as a guide
+ can lead you astray by thining "secretary" is a female
+ chunking common phrases
++ "fat people", "tree" as a noun rather than a verb
- extralinguistic context
+ "put the apple on the towel into the ball"
+ not treated as a graden path sentence, if there was a good reason to say "on the ball", to disambiguate
        
prosody -- pattern of parsing
pragmatics -- "some" means not all
        
biology
- aphasia
+ non-fluid is Broca's
+ fluid is Wernecke's 
- anomia - inability to name objects
over-generalize the endings (-ed) ("runned", "goed")
        
language and thought
- time, direction (absolute vs. relative)
        
                  
Chapter 11: Visual Knowledge
                
Imagery
-- who hwas bushier eyebrow? (brad pitt or your mom)
-- how many windows does your house have?
-- to answer these questions, we seem to draw up a mental picture
        
chronometric studies: "time measuring" studies to investigate imagery
-- Kosslyn (1976)
-- do carts have a head? do cats have claws?
-- if people are primed to use imagery, faster at the head question. Otherwise, they are faster at the claws
-- Kossly, Ball, 1978-- famous map study
-- "image scanning" or mental travel between locations correlates strongly with the original physical distance
        
Mnetal rotation
-- Cooper and Shepard (1973)
- effect with 2D vs. 3D rotations is about the same
-- strong correlation between mental time and degree of rotation
        
Both these studies suffer form DEMAND CHARACTER -- or participants having the ability to infer the experimenter's intention. But many have been replicated in an implicit context.
        
Interactions between imagery and perception
-- interefernece if imargery is in the same perceptual modality
-- fMRI evidence, the same brain regions are active, also TMS evidence
-- interesting neglect case, where the subject only mentioned the imageined stuff in one visual field
        
Other ffects
--seems to show visual acuity
-- STRONG GENERAL CASE FOR IMAGERY
-- but congentially blind people show many effects (particularly spatial ones), so this might be something separate
-- Also, self-reported poor images are fine on spatial tasks, but worse on pure visual (feature) tasks
        
Ways images are not pictures
-- inherently organized (you cannot reinterpret, like ambiguous image)
-- reference frame is establisehd
        
Long-term visual knowledge
-- what is the format?
-- more like a frame, where the details can be filled in (SEEMS LIKE A GENERATIVE MODEL)
        
Verbal coding
-- Charmichael (1932) -- memory of ambiguous objects is biased towards whatever their verbal label was
-- also, geographical judgments are biased by state-to-state or country-to-country relations 
        
Imagery helps memory
-- highly imagable words, or interactions of objects, helps to remember them
        
Dual coding
-- separate word and picture codes (Pavio)
        
Boundary exentsion
-- people remember images are zoomed out images (Intraub)
-- seems to argue for a pereceptaul schema
        
Verbal and image memory are not completely different systems, have many of the same governing principles
        
        Chapter 12 Judgement: Drawing conclusions from evidence
- attribute substitution - sampels from a latent parameter, which you substitute for the real thing you want to kow
        
availability heuristic
- "r" in first vs. third position of words. People think there are more words with it in the first position, but only because we can draw those sampels
- but also applies to other less wird examples
1) Ask for 6 or 12 eamples of you being assertive. If people are asked for more samples, they rate themselves as less assertive. So it's the ease of coming up with the examples
        
representativeness heuristic:
- gambler's fallacy - a tale's is due after a long sequence of heads, but only because it's more representative of a fair coin vs. not
- people don't care much if the sample is typical or not (asked to evaluate the prison system, after watching a video of a guard they told was typical or not)
- categories are homogenous, so all mult be the same
- representativeness: relying on what you think is representative when making a category judgent
        
anchoring
- if value is unclear, start with the anchor, then adjust to it
- Did Gandhi live to 140? How long did he live? If you change 140 to 9, you get a huge anchor effect of answering that first question
        
covariation
- illusory convariation - correlations that are not there, but often driven by a priori theories
- professional trainig  not mitigate this illusion
- theory-based - extravagent judgments with prior knowledge, but much more conservative without
- confirmation bias- tendencvy to confirm one's beliefs, rather than challenge it
- only register examples that confirm belief
        
base rates
- Chinese professor vs. psychologist. If you hear a description of someone who sounds shy, people think it's the chinese professor, ignoring the obvious difference in base rates
- lawyers and engineers. Say the person is awkard and nerdy, which isre likely? Swap 30/70 ratio, and it doesn't matter much.
        
assessing the damage -- examples of success?
- how mcuh sumo wrestlers do such and such? we don't predict 0, even if we have encountered none
- Nisbett et l. (1983)
showed how skin color, eement properties, bird color, islander obserity are all inferred differently, showing this is theory-based
        
dual process models
- system 1 - fast/automatic (error prone)
- system 2- slow, effortful
- use of system 2 is correlated with high IQ?
- lesse with time pressure
- more accurate with number over percents
+ it matter how you code the data
- it matters whether people see a causal relationship between base rate and hypothesis
- basic stats training helps
        
        Chapter 13: Reasoning        
deduction - premises as given, see what follows
confirmation bs: tendenc to seek out confirming evidence
+ and fail to consider/ evaluate alternative hypothes
+ difficulty in learning "increasing" rule for sets of numbers
belief preseverance - not using disconfirming evidence
+ suicide not study, where people tried to guess whether notes were real, and got fake feedback
++ they were told feedback was random, but yet after this, it still influenced their ratings of "social sensitivity"
++ debriefing is not always as useful as intend
        
logic
- categorical syllogism  - logical argument that beings with the premises and leads to a conclusion
- people are bad at them
+ depends on whether you already believe the conclusion
- modus ponens is easier than modus tollens
- poor reasoning about condtional in general
(see Rips, 1990; Evans, 1982)
-Wason's card task
A 6 J 7 
if vowel, then there is an even number on the oter side
- terrible performance, but much better if in a cheater-detection context
- maybe we don't use raw logic, but it's based on cheater detection
+ you need a schema to attach it to
-again, maybe two systems?
        
Mental models
- reason from concrete cases
(Johnson-Liard, 1990)
-more models needed, more errors
        
Decision making
- expected value - probability of outcome x utility
- seek to maximize utility
- framing - whether outcome is positive or negative affects decision
+ for loses, people are risk-seeking
+ for gains, people are risk-averse
        
Emotion
- value of wedding ring is not the same as other things
-somatic markers  emotiona/physical reaction to events with risk
- people are bad at predicting future emotions
                  
Ch 14 Solving problems        
- initial state, operators, goal state
- space quickly becomes unfeasible
- hill-climbing, greedily choose the best move
+ people have trouble with backward moves that are necessary before forward ones
        
Mental models and images
- these can help when solving problems
-helpful to consider analogies (Gick & Holyoak, 1986)
-most find appropriate structure map
- helps to orient problem by the deeper features
        
Expert reasoning
- Ph.D. students in physics categorie problems by deep structure, not superficial similarity
- cheese experts remember the organization of the chess board
( and huge memory benefit overall)
- might rely on well-rehearsed routines (specialized)
        
Defining the problem
- well/ill-defined problems
-functional fixedness- tendency to think rigidly about object funtions
-swingin strings (Maier, 1931)
+ example of not noticing priming as influencing you
- tendency to use overly complex strategies that have worked in the past, like chunking
+ water-jug puzzles
- mechanization of tasks can interfere
        
Creativity
- single "ah ha!" moment is largely a myth 
(read Sawyer, 2012)
- some problems seem to be Aha! worthy, by design, they can go from cold to "got it" (metcalf, 1986)
+ but this is for any new path to try, not necessarily the right one
incubation 
- sitting on it does not reliably help
                  
Chapter 15: Conscious Thought, Unconscious Though        
- much of the work that supports our abilities (categorization, reasoning, etc.) happens behind the scenes
- we are aware of the products, not the processes (not memory search, priming, etc.)
- study where people are given a pill, and told that it mitigates shocks (subjects did not believe this pill plays a role
- poor source inferences for emotions
- after-the-fact reconstructions (although people feel like it's introspection)
- set: unconscious assumptinos that guide thinking
- blind sight: patients are blind for all practical purposes, but can "guess" (X vs. O) above chance
- unconscious routines are not that flexible
- action slips - habit takes over for a second
- what "is" consciousness?
+ studies informed by what it is  for
        
neuronal workspace hypothesis
- visual fefatures processesed separeatly, and maybe consciousness solves the binding problem
- attention is closely related
- anterior cingulate cortex (ACC) detects conflicts
        
People and patients seem unwilling to let implicit processing control important decisions (blindsight, etc.)
(need reason, justification, credible information. etc)
        
Perhaps this is consciousness's primary role
And this hasn't even touched the really hard problems
      },
author = {Reisberg, Daniel},
edition = {4},
title = {{Cognition: Exploring the science of mind}},
year = {2010}
}
@article{Rensink1997,
annote = {Famous work that shows ATTENTION is key to perceiving changes in a scence.
        
---
        
Although we feel like we see a whole scene at once, we may not. It takes awhile to locate a singing bird in a tree.
        
Previous studies have found it difficult to detect changes during briefly flashed stimuli, or during saccades. But this might be due to abnormal viewing conditions.
        
flicker paradigm: scene is displayed for a period (seconds), then a blank screen, then scene etc.
        
---
        
Divided changes into central or marginal interest, where central involve objects that are mentioned when naive observers describe the scene
        
                  
results        
                  
experiment 1        
A,A,A',A'
Took 17 alternations for marginal interest, and 7 alternations for central interest.
        
A remarkably long time
        
experiment 2
A,A',A,A'
        
used longer image durations, so there would be consolidation time.
                  
experiment 3        
Repeated experiment 1, but with a verbal cue placed at the beginning of each trial.
        
Valid cues caused identification to quickly speed up, showing that it's not difficulty in seeing -- it's attention
                  
dicussion
          
proprosal        
If an object is not in attention, its contents are simply over-ridden by the next image.
        
there is no buffer where subsequent images are compared/combined
        
the alterations were well within the 300-ms limit of iconic memory.
        
future directions:
        
maybe flicker paradigm can be used to determine interesting part of scenes (non-verbally)
        
If attention can switch quickly enough, little is gained by simultaneous representation of all their details
        
        
      },
author = {Rensink, Ronald A and O'Regan, Kevin and Clark, James J},
file = {:Users/Brenden/Documents/Mendeley/Rensink, O'Regan, Clark - 1997 - To see or not to see The need for attention to perceice changes in scenes.pdf:pdf},
journal = {Psychological Science},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {5},
pages = {368--373},
title = {{To see or not to see: The need for attention to perceice changes in scenes}},
volume = {8},
year = {1997}
}
@incollection{Rescola1972,
author = {Rescola, R A and Wagner, A R},
booktitle = {Classical conditioning II: current research and theory},
file = {:Users/Brenden/Documents/Mendeley/Rescola, Wagner - 1972 - A theory of Pavlovian conditioning variations in the effectiveness of reinforcement and nonreinforcement.pdf:pdf},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
pages = {64--69},
title = {{A theory of Pavlovian conditioning: variations in the effectiveness of reinforcement and nonreinforcement}},
year = {1972}
}
@article{Rescorla1968,
annote = {Showed that contingency, not just frequency, is important for classical contingency.
        
This was very important for motivating models of error-driven learning.},
author = {Rescorla, R a},
file = {:Users/Brenden/Documents/Mendeley/Rescorla - 1968 - Probability of shock in the presence and absence of CS in fear conditioning.pdf:pdf},
issn = {0021-9940},
journal = {Journal of Comparative and Physiological Psychology},
keywords = {Animals,Classical,Conditioning,Conditioning (Psychology),Electroshock,Fear,Male,Methods,Probability,Rats,classic psychology},
mendeley-tags = {classic psychology},
month = aug,
number = {1},
pages = {1--5},
pmid = {5672628},
title = {{Probability of shock in the presence and absence of CS in fear conditioning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/5672628},
volume = {66},
year = {1968}
}
@article{Reshef2011,
abstract = {Identifying interesting relationships between pairs of variables in large data sets is increasingly important. Here, we present a measure of dependence for two-variable relationships: the maximal information coefficient (MIC). MIC captures a wide range of associations both functional and not, and for functional relationships provides a score that roughly equals the coefficient of determination (R(2)) of the data relative to the regression function. MIC belongs to a larger class of maximal information-based nonparametric exploration (MINE) statistics for identifying and classifying relationships. We apply MIC and MINE to data sets in global health, gene expression, major-league baseball, and the human gut microbiota and identify known and novel relationships.},
author = {Reshef, David N and Reshef, Yakir a and Finucane, Hilary K and Grossman, Sharon R and McVean, Gilean and Turnbaugh, Peter J and Lander, Eric S and Mitzenmacher, Michael and Sabeti, Pardis C},
doi = {10.1126/science.1205438},
file = {:Users/Brenden/Documents/Mendeley/Reshef et al. - 2011 - Detecting novel associations in large data sets.pdf:pdf},
issn = {1095-9203},
journal = {Science},
keywords = {Algorithms,Animals,Baseball,Baseball: statistics & numerical data,Data Interpretation,Female,Fungal,Gene Expression,Genes,Genomics,Genomics: methods,Humans,Intestines,Intestines: microbiology,Male,Metagenome,Mice,Obesity,Saccharomyces cerevisiae,Saccharomyces cerevisiae: genetics,Statistical},
month = dec,
number = {6062},
pages = {1518--24},
pmid = {22174245},
title = {{Detecting novel associations in large data sets.}},
volume = {334},
year = {2011}
}
@inproceedings{Resnik1995,
archivePrefix = {arXiv},
arxivId = {arXiv:cmp-lg/9511007v1},
author = {Resnik, Philip},
booktitle = {Proceedings of IJCAI-95},
eprint = {9511007v1},
file = {:Users/Brenden/Documents/Mendeley/Resnik - 1995 - Using Information Content to Evaluate Semantic Similarity in a Taxonomy.pdf:pdf},
keywords = {semantic network},
mendeley-tags = {semantic network},
primaryClass = {arXiv:cmp-lg},
title = {{Using Information Content to Evaluate Semantic Similarity in a Taxonomy}},
volume = {1},
year = {1995}
}
@article{RevowWilliams1996,
author = {Revow, M and Williams, C K I and Hinton, G E},
file = {:Users/Brenden/Documents/Mendeley/Revow, Williams, Hinton - 1996 - Using Generative Models for Handwritten Digit Recognition(2).pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {handwriting,part-based models},
mendeley-tags = {handwriting,part-based models},
number = {6},
pages = {592--606},
title = {{Using Generative Models for Handwritten Digit Recognition}},
volume = {18},
year = {1996}
}
@article{Richardson2006,
abstract = {Complex, non-additive genetic interactions are common and can be critical in determining phenotypes. Genome-wide association studies (GWAS) and similar statistical studies of linkage data, however, assume additive models of gene interactions in looking for genotype-phenotype associations. These statistical methods view the compound effects of multiple genes on a phenotype as a sum of influences of each gene and often miss a substantial part of the heritable effect. Such methods do not use any biological knowledge about underlying mechanisms. Modeling approaches from the artificial intelligence (AI) field that incorporate deterministic knowledge into models to perform statistical analysis can be applied to include prior knowledge in genetic analysis. We chose to use the most general such approach, Markov Logic Networks (MLNs), for combining deterministic knowledge with statistical analysis. Using simple, logistic regression-type MLNs we can replicate the results of traditional statistical methods, but we also show that we are able to go beyond finding independent markers linked to a phenotype by using joint inference without an independence assumption. The method is applied to genetic data on yeast sporulation, a complex phenotype with gene interactions. In addition to detecting all of the previously identified loci associated with sporulation, our method identifies four loci with smaller effects. Since their effect on sporulation is small, these four loci were not detected with methods that do not account for dependence between markers due to gene interactions. We show how gene interactions can be detected using more complex models, which can be used as a general framework for incorporating systems biology with genetics.},
annote = {Markov logic network (L):
        
is a set of pairs (F_i,w_i) whre F_i is a formula and w_i is a weight
        
There is a set of constants C
        
The network has one binary node for each possible grounding of each predicate in L. The node is 1 if true, 0 if false.
        
L has one feature for each possible grounding of a formula F_i. 
        
Thus, the probability of a dataset X is determined by exp(\sum_i w_i*n_i(x)), where n_i is the number of true groundings of F_i in x
        
Both discrete probability disributions and FOL are special cases. The argument about discrete probability is a little confusing.
                  
Learning:        
The gradient of the weight is the difference between the number of times a formula is true, and it's expectation under the model
                  
Experiment        
Collected a dataset of the UWash CS department, listing courses, TAs, students, professors, and publications. They had people write down a set of laws, like if a student is an author ona paper, so is their advisor. 
        
They asked the system to predict a student's advisor, given the other info. It is better than a standard Bayes' net or standard ILP
        
-------
Talk by Pedro
"Learning tractable but expressive models"
        
- inference is the hardest part of learning
+ it's a subroutine of many things
+ all approximate inference techniques have their issues
        
approximate inference, and optimization, generally interact badly
+ learning tractable models are rarely expressive enough
                  
tractable representaitons
- thin junction trees        
Srerbro: maybe only learn low-treewidth models?
+ but this is way too restrictive          
          
- large mixture models        
just use a simple model (naive bayes), with tons of clusters
-  inference is linear in model size... going through clusters one by one
- compared to state of the art Bayes net structure learning
+ comparable data likelihood
+ query likelihood was much higher, since inference is fast
problem: curse of dimensionality. a mixture model is really a local learning problem... which won't work well in huge dimensional spaces, which will be under-sampled          
          
-arithmetic circuits
- based on sum/products
- you can get away with high tree-width, because you have context-specific indepdendence
- determinism.... so lots of states have 0 probability
        
what is an arithmetic circuit?
joint distribution could be a table, but instead, 
- dag where leaves are inputs (positive and negation)
- first have layer of products, and then all of those products are summed up
- computes marginals in linear time... you just pass in values of 1 for all possible values of the other variables
        
Most bayes net learning 
- score is log like and penalize number of parameters
        
Instead, try maximize log-like and penalize complexity of the inference, even the bayes net learning setting
+ if you try this, data likelihood is the same, but query likelihood is much better
                  
-feature trees        
thin junction trees work by finding conditional joints, P(b,c|a) = P(b|a)P(c|a)
- but you can do the same, by conditioning on any feature, not just a value of some variable (x1, not x3, x5 could be a feature)
- get much more complicated then graphical models
                  
-sum-product networks        
goal: find the most expressive tractable representaiton possible
- generalization of a arthimetic circuit, and if the values are positive, then its a valid prob. dist?
- use constraint that marginalziation can be done with a single forward pass ( called valid)
- two conditions
+ you ahve to have the same variables on all incoming edges of the sum
+ other condition, a product node never has the inputs from a node and its negation
+ with these conditions, you can compute all of the marginals with a linear pass
        
start with dense architecture (like backprop), and learn weights
- online learning with Hard EM
+ soft EM has gradient diffusion problem like backprop
        
        
                  
          
-tractable markov logic        
        
        
      },
author = {Richardson, Matthew and Domingos, Pedro},
doi = {10.1007/s10994-006-5833-1},
file = {:Users/Brenden/Documents/Mendeley/Richardson, Domingos - 2006 - Markov logic networks.pdf:pdf},
institution = {University of Washington},
issn = {08856125},
journal = {Machine Learning},
keywords = {classic AI,logic},
mendeley-tags = {classic AI,logic},
number = {1-2},
pages = {107--136},
pmid = {20958249},
publisher = {Springer},
title = {{Markov logic networks}},
volume = {62},
year = {2006}
}
@article{Rips1975,
author = {Rips, Lance J},
file = {:Users/Brenden/Documents/Mendeley/Rips - 1975 - Inductive judgments about natural categories.pdf:pdf},
journal = {Journal of Verbal Learning and Verbal Behavior},
keywords = {classic psychology,classics on concepts,property induction},
mendeley-tags = {classic psychology,classics on concepts,property induction},
number = {6},
pages = {665--681},
title = {{Inductive judgments about natural categories}},
volume = {14},
year = {1975}
}
@article{RiveraLake2004,
author = {Rivera, M and Lake, J},
journal = {Nature},
pages = {152--155},
title = {{The ring of life provides evidence for a genome fusion origin of eukaryotes}},
volume = {431},
year = {2004}
}
@article{Rizzolatti2004,
abstract = {A category of stimuli of great importance for primates, humans in particular, is that formed by actions done by other individuals. If we want to survive, we must understand the actions of others. Furthermore, without action understanding, social organization is impossible. In the case of humans, there is another faculty that depends on the observation of others' actions: imitation learning. Unlike most species, we are able to learn by imitation, and this faculty is at the basis of human culture. In this review we present data on a neurophysiological mechanism--the mirror-neuron mechanism--that appears to play a fundamental role in both action understanding and imitation. We describe first the functional properties of mirror neurons in monkeys. We review next the characteristics of the mirror-neuron system in humans. We stress, in particular, those properties specific to the human mirror-neuron system that might explain the human capacity to learn by imitation. We conclude by discussing the relationship between the mirror-neuron system and language.},
annote = {Mirror neurons are critical for action understanding.
        
        
--- 
Originally found in monkey pre-motor cortex
-- not sensitive to visual specifics
-- requires interactino of hand and object
        
What are they for?
-- immitation
-- action understanding
        
"This automatically induced, motor representation of the obesrved action corresponds to that which is spontaneously genereated during active action and whose outcome is known to the acting individual. Thus, the mirror sysm transforms visual information in knowledge"
        
To test this understanding hypothesis:
about 15% are also activated by sound
        
Some evidence these systems exist in humans. Even priming shows the basis for htis idea.
        
Language
--- 
maybe speech evolved mostly from gestural communication},
author = {Rizzolatti, Giacomo and Craighero, Laila},
doi = {10.1146/annurev.neuro.27.070203.144230},
file = {:Users/Brenden/Documents/Mendeley/Rizzolatti, Craighero - 2004 - The mirror-neuron system.pdf:pdf},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {Animals,Dogs,Haplorhini,Humans,Imitative Behavior,Imitative Behavior: physiology,Learning,Learning: physiology,Motor Cortex,Motor Cortex: anatomy & histology,Motor Cortex: cytology,Motor Cortex: physiology,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Neurons,Neurons: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Social Behavior,Verbal Behavior,Verbal Behavior: physiology,embodied cognition},
mendeley-tags = {embodied cognition},
month = jan,
pages = {169--92},
pmid = {15217330},
title = {{The mirror-neuron system.}},
volume = {27},
year = {2004}
}
@article{Rizzolatti2002,
abstract = {Recent data show that the ventral premotor cortex in both humans and monkeys has motor and cognitive functions. The cognitive functions include space perception, action understanding and imitation. The data also show a clear functional homology between monkey area F5 and human area 44. Preliminary evidence suggests that the ventral part of the lateral premotor cortex in humans may correspond to monkey area F4. A tentative map of the human lateral premotor areas founded on the reviewed evidence is presented.},
author = {Rizzolatti, Giacomo and Fogassi, Leonardo and Gallese, Vittorio},
doi = {10.1016/S0959-4388(02)00308-2},
file = {:Users/Brenden/Documents/Mendeley/Rizzolatti, Fogassi, Gallese - 2002 - Motor and cognitive functions of the ventral premotor cortex.pdf:pdf},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
keywords = {action recognition,embodied cognition,mirror neurons,peripersonal space,ventral premotor cortex},
mendeley-tags = {embodied cognition},
month = apr,
number = {2},
pages = {149--154},
title = {{Motor and cognitive functions of the ventral premotor cortex}},
volume = {12},
year = {2002}
}
@article{Rodriguez2008,
author = {Rodr\'{\i}guez, Abel and Dunson, David B and Gelfand, Alan E},
doi = {10.1198/016214508000000553},
file = {:Users/Brenden/Documents/Mendeley/Rodr\'{\i}guez, Dunson, Gelfand - 2008 - The Nested Dirichlet Process.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {classic AI,clustering,dependent dirichlet process,gibbs sampler,hierarchical model,non-parametric Bayes,nonparametric bayes,random probability},
mendeley-tags = {classic AI,non-parametric Bayes},
month = sep,
number = {483},
pages = {1131--1154},
title = {{The Nested Dirichlet Process}},
volume = {103},
year = {2008}
}
@article{Roediger1995,
author = {Roediger, Henry L and McDermott, Kathleen B},
file = {:Users/Brenden/Documents/Mendeley/Roediger, McDermott - 1995 - Creating False Memories Remembering Words Not Presented in Lists.pdf:pdf},
journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {4},
pages = {803--814},
title = {{Creating False Memories: Remembering Words Not Presented in Lists}},
volume = {21},
year = {1995}
}
@book{RogersMcClelland2004,
address = {Cambridge, MA},
author = {Rogers, T T and McClelland, J L},
publisher = {MIT Press},
title = {{Semantic Cognition: A Parallel Distributed Processing Approach}},
year = {2004}
}
@inproceedings{Rogers2010,
author = {Rogers, T and Kalish, C and Gibson, B and Harrison, J and Zhu, X},
booktitle = {32nd Annual Conference of the Cognitive Science Society},
title = {{Semi-supervised learning is observed in a speeded but not an unspeeded 2D categorization task}},
year = {2010}
}
@book{Rogers2004,
address = {Cambridge, MA},
author = {Rogers, Timothy T and McClelland, James L},
publisher = {MIT Press},
title = {{Semantic Cognition}},
year = {2004}
}
@article{Rosch1975a,
annote = {Classic representation was Aristotilean, with necessary and sufficient conditions.
        
Previous studies showed typicality ratings predict category verificationt tasks. This study expands the range of phonemna that are related to typicality, and clarifies the prototype view.
        
Priming study used here...
        
        
Can people make meaningful ratings of typicality for conepts?
        
Priming:
When shown the name in advance, you are facilited to respond to good examples and hindered for bad. Task was you have a pair of stimuli, and you say same for either the same category or same physical identity
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
      },
author = {Rosch, Eleanor},
doi = {10.1037//0096-3445.104.3.192},
file = {:Users/Brenden/Documents/Mendeley/Rosch - 1975 - Cognitive representations of semantic categories.pdf:pdf},
issn = {0096-3445},
journal = {Journal of Experimental Psychology: General},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {3},
pages = {192--233},
title = {{Cognitive representations of semantic categories.}},
volume = {104},
year = {1975}
}
@incollection{Rosch1978,
annote = {Two points:
1) Cognitive economy. Our cognitive system has pressure to represent things as concisely as possible
2) Perceived world structure. There are correlated attributes in the world, like feather and wings. 
        
Together, this has implications for the level of abstraction and for the internal structure once formed.
        
Cue validity: how strongly a single feature indicates a category is present. Cue validity for a category is the sum of all of the validities for the featires. The basic level maximizes cue validity, since superordinate is more abstract (too much variety), and the subordinate level the features don't predict any one category since they are common.
        
This was tested with attribute listing task, where subordinate level does not have many more features than the basic level had listed.
                  
Motor movements. Same is true when listing motor programs that we can apply to objects
                  
Similarit in shapes. Measured as the amount of silhoutte overlap, again, same effect where overlap levels off at the basic level
                  
Identifiability of average shape. Same things with super-imposed shapes, where subordinate level was not more easily identifiable.},
author = {Rosch, Eleanor},
booktitle = {Cognition and Categorization},
publisher = {Lawrence Erlbaum Associates, Inc.},
title = {{Principles of categorization}},
year = {1978}
}
@article{Rosch1975,
abstract = {Six experiments explored the hypothesis that the members of categories which are considered most prototypical are those with most attributes in common with other members of the category and least attributes in common with other categories. In probabilistic terms, the hypothesis is that prototypicality is a function of the total cue validity of the attributes of items. In Experiments 1 and 3, subjects listed attributes for members of semantic categories which had been previously rated for degree of prototypicality. High positive correlations were obtained between those ratings and the extent of distribution of an item's attributes among the other items of the category. In Experiments 2 and 4, subjects listed superordinates of category members and listed attributes of members of contrasting categories. Negative correlations were obtained between prototypicality and superordinates other than the category in question and between prototypicality and an item's possession of attributes possessed by members of contrasting categories. Experiments 5 and 6 used artificial categories and showed that family resemblance within categories and lack of overlap of elements with contrasting categories were correlated with ease of learning, reaction time in identifying an item after learning, and rating of prototypicality of an item. It is argued that family resemblance offers an alternative to criterial features in defining categories.},
annote = {Prototypical: most attriutes in common with other members of the category and least with other categories. People tend to forget about the second characteristic.
        
This is strong evidence for the use of prototypes, but Rosch doesn't spell out a formal account or say exactly what the proposal is
        
Introduction:
-most traditions have treated category membership as all-or-nothing
- for most domains, prototypes do not seem to precece the category and most be formed by learing
- family resemblance links categories (Wittgenstein)
- dicrete features might be a myth, but even with these, they can be shown to underlie category prototype structure
                  
Experiment 1 (with super-ordinate categories):
- pariticpants wrote down as many attributes as they can think of for categories, 1.5 minutes each
-120 items, eeach rated by 20 subjects
                  
Family resemblance: There are 20 items in each category. The basic measure of family resemblance is the sum of the weighted scores of each of the attributes that had been listed for that item, where each score is 1-20 depending on how many items in that category have the feature.
        
Results: Attributes are generally true of some, but not all, members of a category
        
Score for a category item is the sum of its attribute scores, weighted by how important each one is. Correlations wree
about .84-.94 for the various categories. The more an item has attributes in common with other members, the more it will be considered a good example. 
        
With MDS, in all cases, the most prototypical example appeared in the middle
                  
Experiment 2 (with-superordinate categories) -- Are typical members maximally distant?
They asked people to list higher-level categories (animal, pet) etc. for collie that the item is a member of
        
Then they derived a measure of dominance, which is first subordinate minus the other frequently mentioned ones.
        
This correlates well with prototypicality.
                  
Experiment 3: (with basic categories)        
Studied pictures of basic level cateogires (car, truck, chair, lamp)
Looked at correlation between typicality and item scores (as in experiment 1). Again, very large correlations.
                  
Experiment 4: (with basic cateogires)        
Analog of experiment 2. But hypothesis could be tested directly, with contrast pairs chair--sofa and car--truck.
They tallied the overlap betwen the attributes of a given item and the attriutes of items in the closest contrasting categories (if it occured in at least one of the pictures of the other three contrast cateogires).
        
 There is a strong negative correlation (around r=-.7) with prototypicality and attribute overlap with the contrast sets. 
                  
Experiment 5: artificial caetgory (read this more carefully)        
Stimuli were string of letters, where each letter indicates a specific feautre. Control group all items had equal family resemblance.
        
Prototype (as measured by categorization RT and rating) is a function of the greater family resemblance when there was no influence of overlapping attributes from contrasting categories.
                  
Experiment 6:         
Are these more prototypical if they don't overlap? This can be controlled while keeping internal structure the same.
        
 Yes -- people rate them more prototypically, and reaction time and errors reflect that.  Thus this is evidence for a kind of discriminative learning. Also, family resemblance seems to toake precendence of overlap if they conflict.
        
Does not argue that this is a formal model, or does not precisely specify a formulation},
author = {Rosch, Eleanor and Mervis, Carolyn B},
doi = {10.1016/0010-0285(75)90024-9},
file = {:Users/Brenden/Documents/Mendeley/Rosch, Mervis - 1975 - Family resemblances Studies in the internal structure of categories.pdf:pdf},
issn = {00100285},
journal = {Cognitive Psychology},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
month = oct,
number = {4},
pages = {573--605},
title = {{Family resemblances: Studies in the internal structure of categories}},
volume = {7},
year = {1975}
}
@article{Rosch1976a,
author = {Rosch, Eleanor and Mervis, Carolyn and Gray, Wayne D and Johnson, David M and Boyes-Braem, Penny},
file = {:Users/Brenden/Documents/Mendeley/Rosch et al. - 1976 - Basic Objects in Nautral Categories.pdf:pdf},
journal = {Cognitive Psychology},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {3},
pages = {382--439},
title = {{Basic Objects in Nautral Categories}},
volume = {8},
year = {1976}
}
@article{Rosch1976,
author = {Rosch, Eleanor and Simpson, Carol and Miller, R. Scott},
doi = {10.1037//0096-1523.2.4.491},
file = {:Users/Brenden/Documents/Mendeley/Rosch, Simpson, Miller - 1976 - Structural bases of typicality effects.pdf:pdf},
issn = {0096-1523},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {4},
pages = {491--502},
title = {{Structural bases of typicality effects.}},
volume = {2},
year = {1976}
}
@article{Rosenblatt1958,
annote = {Perceptron: single layer neural network with a threshold activation function
        
---
        
Analyzed three types of systems:
alpha -- an active cell simply gains an increment for every impulse
beta -- constant gain for each stimulus, distributed amongst the active cells
gamma -- there is a constant amount of weight, so increase for active cells go along with decreases in others
        
Rosenblatt compared the learning properties of these three setups
        
Given the precise structure of events is unknown, Rosenblatt reasons that a formulation in terms of probability theory is more appropriate than symbolic logic.
        
While those in the top-down tradition argue their theories can be refined to match the brain, Rosenblatt claims this is unlikely "in principle" even.
        
Rosenblatt does not just analyze a single layer system. His proposal involves possible multiple layers, and additional inhibitory signals between competing responses.
        
From Rosenblatt's theory, he thought you could predict neurological variables from learning curves, or learning curves from neurological variables.},
author = {Rosenblatt, F},
file = {:Users/Brenden/Documents/Mendeley/Rosenblatt - 1958 - The perceptron a probabilistic model for information storage and organization in the brain.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Perception},
month = nov,
number = {6},
pages = {386--408},
pmid = {13602029},
title = {{The perceptron: a probabilistic model for information storage and organization in the brain.}},
volume = {65},
year = {1958}
}
@article{Rosenholtz2009,
address = {New York, New York, USA},
author = {Rosenholtz, Ruth and Twarog, Nathaniel R. and Schinkel-Bielefeld, Nadja and Wattenberg, Martin},
doi = {10.1145/1518701.1518903},
file = {:Users/Brenden/Documents/Mendeley/Rosenholtz et al. - 2009 - An intuitive model of perceptual grouping for HCI design.pdf:pdf},
isbn = {9781605582467},
journal = {Proceedings of the 27th international conference on Human factors in computing systems - CHI '09},
keywords = {perceptual grouping},
mendeley-tags = {perceptual grouping},
pages = {1331},
publisher = {ACM Press},
title = {{An intuitive model of perceptual grouping for HCI design}},
year = {2009}
}
@article{Rosenthal2001,
author = {Rosenthal, O and Fusi, S and Hochstein, S},
journal = {Proceedings of the National Academy of Science},
pages = {4265--4270},
title = {{Forming classes by stimulus frequency: behavior and theory}},
volume = {98},
year = {2001}
}
@book{Rubinstein2008,
address = {Hoboken, New Jersey},
annote = {Reference regarding MCMC methods for traveling salesman problem
        
See page 189-192
        
http://books.google.com/books?hl=en&lr=&id=1-ffZVmazvwC&oi=fnd&pg=PR13&dq=MCMC+traveling+salesman&ots=-qa6g3wB_m&sig=-JFn0kZ8U9LnLUh3JBaroZ4EHjE#v=onepage&q=MCMC%20traveling%20salesman&f=false},
author = {Rubinstein, Reuven Y and Kroese, Dirk P},
edition = {Second},
publisher = {John Wiley \& Sons},
title = {{Simulation and the Monte Carlo method}},
year = {2008}
}
@article{Rumelhart85,
author = {Rumelhart, D E and Zipser, D},
journal = {Cognitive Science},
number = {1},
pages = {75--112},
title = {{Feature discovery by competitive learning}},
volume = {9},
year = {1985}
}
@book{Rumelhart1986,
address = {Cambridge, MA},
author = {Rumelhart, David E and McClelland, James L and {the PDP research Group}},
publisher = {MIT Press},
title = {{Parallel distributed processing: Explorations in the microstructure of cognition. Volume I.}},
year = {1986}
}
@article{Rumelhart1986a,
author = {Rumelhart, DE and Hinton, GE and Williams, RJ},
file = {:Users/Brenden/Documents/Mendeley/Rumelhart, Hinton, Williams - 1986 - Learning representations by back-propagating errors.pdf:pdf},
journal = {Nature},
keywords = {classic AI},
mendeley-tags = {classic AI},
number = {9},
pages = {533--536},
title = {{Learning representations by back-propagating errors}},
volume = {323},
year = {1986}
}
@article{Rumelhart1982,
author = {Rumelhart, DE and McClelland, JL},
file = {:Users/Brenden/Documents/Mendeley/Rumelhart, McClelland - 1982 - An interactive activation model of context effects in letter perception II. The contextual enhancement ef.pdf:pdf},
journal = {Psychological review},
keywords = {classic psychology,handwriting},
mendeley-tags = {classic psychology,handwriting},
number = {1},
pages = {60--94},
title = {{An interactive activation model of context effects in letter perception: II. The contextual enhancement effect and some tests and extensions of the model.}},
volume = {89},
year = {1982}
}
@article{Sabourin,
author = {Sabourin, L and Werker, J F and Bosch, L and Sebasti\'{a}n-Gall\'{e}s, N},
journal = {Developmental Science},
title = {{Perceiving vowels in a tight vowel space: evidence from monolingual infants}}
}
@article{Saffran1996,
abstract = {Learners rely on a combination of experience-independent and experience-dependent mechanisms to extract information from the environment. Language acquisition involves both types of mechanisms, but most theorists emphasize the relative importance of experience-independent mechanisms. The present study shows that a fundamental task of language acquisition, segmentation of words from fluent speech, can be accomplished by 8-month-old infants based solely on the statistical relationships between neighboring speech sounds. Moreover, this word segmentation was based on statistical learning from only 2 minutes of exposure, suggesting that infants have access to a powerful mechanism for the computation of statistical properties of the language input.},
annote = {Shows infants learn to segments non-sense words in a continuous stream, by either computing transition probabilities or word frequencies
                  
-------
intro        
Most theories of language emphasize experience-independent mechanisms
+ both necessary and dominant
+ poverty of the stimulus argument
        
Undeniable experience-dependent factors
+ learning phoneme caetgories
        
Task faced by all language learning
- segmenting fluent speech into words
+ boundaries are marked inconsistently by things like pauses
+ there is no invariant cue to word boundaries present in all languages
        
One cue that all langauges can use is the statistical structure of sound sequences, where regular transitions occur within words
+ previous studies have shown adults and children can use these probabilities to segment corupus of non-sense words
                  
Experiment        
8-month-old infants
- training corpus of sounds
- test stimuli of two types
1) items from training condition
2) items similar to training condition, but different in a crucial resepct
+ infants control presentation duration for test trial types, by sustained fixation on a blinking light
                  
Details        
familiarized with 2 minutes of continuous speech stream consistent ofr four three-syllable nonsense words, in random order
- only cues were transition probabilities, which were 1 within words and 0.33 between words
        
Testing
- one of four three-syllable strings on each test trials
+ two were words, and two were three-syllable "non words"
                  
Results        
longer listening time for non-words (dishabituation effect)
        
But, a simple sequential-order memorizer was enough to do this task
                  
Experiment 2
                
2 mins of training
        
Test:
- two words vs. two "part-words", created by joning the final syllable of a word to the first two syllables of aother word
        
Infant could only detect these if they learned the words in the training corpus
        
Again, significant novelty preference for non-sense word
                  
Discussion
                
Not much training experience
+ although it is concentrated, learning in the real world likely has other cues as well
        
Might be the abilities are better characterized as "innately biased statistical learning" rather than "innate knowledge"},
author = {Saffran, J R and Aslin, R N and Newport, E L},
file = {:Users/Brenden/Documents/Mendeley/Saffran, Aslin, Newport - 1996 - Statistical learning by 8-month-old infants.pdf:pdf},
issn = {0036-8075},
journal = {Science},
keywords = {Discrimination Learning,Humans,Infant,Language Development,Learning,Speech Perception,classic psychology,statistical learning},
mendeley-tags = {classic psychology,statistical learning},
month = dec,
number = {5294},
pages = {1926--8},
pmid = {8943209},
title = {{Statistical learning by 8-month-old infants.}},
volume = {274},
year = {1996}
}
@article{Sakamoto2008,
author = {Sakamoto, Y and Jones, M and Love, B C},
journal = {Memory and Cognition},
pages = {1057--1065},
title = {{Putting the Psychology Back into Psychological Models: Mechanistic vs. Rational Approaches.}},
volume = {36},
year = {2008}
}
@article{Sakoe1978,
author = {Sakoe, H. and Chiba, S.},
doi = {10.1109/TASSP.1978.1163055},
file = {:Users/Brenden/Documents/Mendeley/Sakoe, Chiba - 1978 - Dynamic programming algorithm optimization for spoken word recognition.pdf:pdf},
issn = {0096-3518},
journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
keywords = {classic AI,handwriting},
mendeley-tags = {classic AI,handwriting},
month = feb,
number = {1},
pages = {43--49},
title = {{Dynamic programming algorithm optimization for spoken word recognition}},
volume = {26},
year = {1978}
}
@inproceedings{SalakhutdinovHinton2009,
author = {Salakhutdinov, R and Hinton, G E},
booktitle = {{12th Internationcal Conference on Artificial Intelligence and Statistics (AISTATS)}},
file = {:Users/Brenden/Documents/Mendeley/Salakhutdinov, Hinton - 2009 - Deep Boltzmann Machines.pdf:pdf},
title = {{Deep Boltzmann Machines}},
year = {2009}
}
@inproceedings{Salakhutdinov2011,
author = {Salakhutdinov, Ruslan and Tenenbaum, Joshua B and Torralba, Antonio},
booktitle = {{Advances in Neural Information Processing Systems 24}},
file = {:Users/Brenden/Documents/Mendeley/Salakhutdinov, Tenenbaum, Torralba - 2011 - Learning to learn with Compound HD Models.pdf:pdf},
title = {{Learning to learn with Compound HD Models}},
year = {2011}
}
@techreport{Salakhutdinov2010,
abstract = {MIT-CSAIL-TR-2010-052},
author = {Salakhutdinov, Ruslan and Tenenbaum, Joshua B and Torralba, Antonio},
booktitle = {Work},
file = {:Users/Brenden/Documents/Mendeley/Salakhutdinov, Tenenbaum, Torralba - 2010 - One-Shot Learning with a Hierarchical Nonparametric Bayesian Model.pdf:pdf},
institution = {MIT},
title = {{One-Shot Learning with a Hierarchical Nonparametric Bayesian Model}},
year = {2010}
}
@article{Salakhutdinov2013,
abstract = {We introduce HD (or &#x201C;Hierarchical-Deep&#x201D;) models, a new compositional learning architecture that integrates deep learning models with structured hierarchical Bayesian (HB) models. Specifically, we show how we can learn a hierarchical Dirichlet process (HDP) prior over the activities of the top-level features in a deep Boltzmann machine (DBM). This compound HDP-DBM model learns to learn novel concepts from very few training example by learning low-level generic features, high-level features that capture correlations among low-level features, and a category hierarchy for sharing priors over the high-level features that are typical of different kinds of concepts. We present efficient learning and inference algorithms for the HDP-DBM model and show that it is able to learn new concepts from very few examples on CIFAR-100 object recognition, handwritten character recognition, and human motion capture datasets.},
author = {Salakhutdinov, Ruslan and Tenenbaum, Joshua B and Torralba, Antonio},
doi = {10.1109/TPAMI.2012.269},
file = {:Users/Brenden/Documents/Mendeley/Salakhutdinov, Tenenbaum, Torralba - 2013 - Learning with Hierarchical-Deep Models.pdf:pdf},
issn = {1939-3539},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {8},
pages = {1958--71},
pmid = {23787346},
title = {{Learning with Hierarchical-Deep Models}},
volume = {35},
year = {2013}
}
@article{Salzle2010,
author = {S\"{a}lzle, Martin and Keane, Mark T},
file = {:Users/Brenden/Documents/Mendeley/S\"{a}lzle, Keane - 2010 - Inferring Metaphoric Structure from Financial Articles Using Bayesian Sparse Models.pdf:pdf},
keywords = {analogy,argument features,bayesian inference,corpus analysis,emergent structure,metaphor,metaphor hierarchies,semantic cognition,similarity,sparse representation,spatial,structure discovery,unsupervised learning},
pages = {2252--2257},
title = {{Inferring Metaphoric Structure from Financial Articles Using Bayesian Sparse Models}},
year = {2010}
}
@article{Samuelson1999,
abstract = {This paper examines children's early noun vocabularies and their interpretations of names for solid and non-solid things. Previous research in this area assumes that ontology, category organization and syntax correspond in the nouns children learn early such that categories of solid things are organized by shape similarity and named with count nouns and categories of non-solid things are organized by material similarity and named with mass nouns. In Experiment 1 we examine the validity of this assumption in a corpus of early-learned nouns and conclude that one side of the solidity-syntax-category organization mapping is favored. In our second experiment we examine the relation between early noun vocabulary development and novel word generalization. We find that children between 17 and 33 months of age do not systematically generalize names for solid things by shape similarity until they already know many nouns, and do not systematically generalize names for non-solid substances by material similarity. The implications for children's acquisition of the ontological distinction, count/mass syntax, and novel nouns are discussed.},
author = {Samuelson, L K and Smith, L B},
file = {:Users/Brenden/Documents/Mendeley/Samuelson, Smith - 1999 - Early noun vocabularies do ontology, category structure and syntax correspond.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Age Factors,Child,Humans,Infant,Language,Preschool,Random Allocation,Verbal Learning,Vocabulary,shape bias},
mendeley-tags = {shape bias},
month = nov,
number = {1},
pages = {1--33},
pmid = {10536222},
title = {{Early noun vocabularies: do ontology, category structure and syntax correspond?}},
volume = {73},
year = {1999}
}
@inproceedings{Sanborn2006,
author = {Sanborn, A N and Griffiths, T L and Navarro, D J},
booktitle = {Proceedings of the 28th Annual Conference of the Cognitive Science Society},
title = {{A more rational model of categorization}},
year = {2006}
}
@inproceedings{Sanborn2009,
annote = {We have physical expectations about the world
        
Mass judgments with collisions
+ what was the mass, after the collision?
        
Vary speed, and masses
        
Possible heuristics:
- object with faster final speed is lighter
- object that ricochets is lighter
        
Their model: noisy newton
+ noisy perception of observable variable
+ infer which is heavier
        
The motor object bias:
- People seem to expect that heavier objects will move faster, but this is strange, since the same force would move it slower
+ Can you capture this with a prior on the initial/final vecolicty? -- such that heavier objects move faster
        
Causality judgment (MIchotte): Did one block cause the other block to move?
- pretty good at predicting these judmgnets as well
        
        
      },
author = {Sanborn, Adam N and Griffiths, Thomas L},
booktitle = {Proceedings of the 31st Annual Conference of the Cognitive Science Society},
file = {:Users/Brenden/Documents/Mendeley/Sanborn, Griffiths - 2009 - A Bayesian Framework for Modeling Intuitive Dynamics.pdf:pdf},
keywords = {bayesian modeling,causality,changes in physical variables,collisions,have col-,lected data on how,mass judgments,perception,relate to the,studies in this area,were moving independently},
title = {{A Bayesian Framework for Modeling Intuitive Dynamics}},
year = {2009}
}
@inproceedings{Sanborn2008,
annote = {Can this be used to test sampling assumptions about active learning, when doing MCMC?
        
As long as you could visualize what the "current hypothesis" was and propose a new one, you could then have them do active learning to help discriminate the hypotheses
        
------------
        MCMC        
        
Baker acceptance function: if you assume proposals are symmetric, then acceptance is just based on "probability matching" basically
        
With assumptions about the "alternative" distribution that people might be drawing examples from, if not the category, this rule reduces to the "Luce choice rule"
        
Ask "which item had come from the category"
      },
author = {Sanborn, Adam N and Griffiths, Thomas L},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:Users/Brenden/Documents/Mendeley/Sanborn, Griffiths - 2008 - Markov Chain Monte Carlo with People.pdf:pdf},
keywords = {mcmc with people},
mendeley-tags = {mcmc with people},
title = {{Markov Chain Monte Carlo with People}},
year = {2008}
}
@article{Sanborn2010,
abstract = {Rational models of cognition typically consider the abstract computational problems posed by the environment, assuming that people are capable of optimally solving those problems. This differs from more traditional formal models of cognition, which focus on the psychological processes responsible for behavior. A basic challenge for rational models is thus explaining how optimal solutions can be approximated by psychological processes. We outline a general strategy for answering this question, namely to explore the psychological plausibility of approximation algorithms developed in computer science and statistics. In particular, we argue that Monte Carlo methods provide a source of rational process models that connect optimal solutions to psychological processes. We support this argument through a detailed example, applying this approach to Anderson's (1990, 1991) rational model of categorization (RMC), which involves a particularly challenging computational problem. Drawing on a connection between the RMC and ideas from nonparametric Bayesian statistics, we propose 2 alternative algorithms for approximate inference in this model. The algorithms we consider include Gibbs sampling, a procedure appropriate when all stimuli are presented simultaneously, and particle filters, which sequentially approximate the posterior distribution with a small number of samples that are updated as new data become available. Applying these algorithms to several existing datasets shows that a particle filter with a single particle provides a good description of human inferences.},
author = {Sanborn, Adam N and Griffiths, Thomas L and Navarro, Daniel J},
doi = {10.1037/a0020511},
file = {:Users/Brenden/Documents/Mendeley/Sanborn, Griffiths, Navarro - 2010 - Rational approximations to rational models alternative algorithms for category learning.pdf:pdf},
issn = {1939-1471},
journal = {Psychological Review},
keywords = {Algorithms,Cognition,Discrimination (Psychology),Humans,Learning,Models,Monte Carlo Method,Probability,Psychological,Statistical,perceptual grouping},
mendeley-tags = {perceptual grouping},
month = oct,
number = {4},
pages = {1144--67},
pmid = {21038975},
title = {{Rational approximations to rational models: alternative algorithms for category learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21038975},
volume = {117},
year = {2010}
}
@article{Sattath1977,
author = {Sattath, Shmuel and Tversky, Amos},
file = {:Users/Brenden/Documents/Mendeley/Sattath, Tversky - 1977 - Additive Similarity Trees.pdf:pdf},
journal = {Psychometrika},
keywords = {clustering,development of theories for,explaining similarity relations and,multidimensional scaling,of proximity data are,proximity,research on the representation,the,the construc-,the two goals of},
number = {3},
title = {{Additive Similarity Trees}},
volume = {42},
year = {1977}
}
@inproceedings{Savin,
annote = {Synapitc correlations in the cortex
- two nuerons, that synapse onto the same post-synaptic neuron, have strengths correlated at about r=0.2
        
Look at this correlation for a few different configurations
        
Memory retriveal
probability of recalling an item, where we have the weights and the recall cue
        
- we have noise model on recall cue, and also a model of how the items influence the weights
        
Can we imporve recall performance if we take into account synaptic correlations?
        
1) with covariance rule, where you increase weight if responses are correlated, 
- no, you get essentially the same performance
2) wiht hebb rule, you do need to account for the weight correlations
3) with Fusi-style synaptic learning, again, it helps to pay attention to weighted correlations
        
synaptic correlations need to be taken into account for recall},
author = {Savin, Cristina and Dayan, P and Lengyel, M\'{a}t\'{e}},
booktitle = {Advances in Neural Information Processing Systems 26},
file = {:Users/Brenden/Documents/Mendeley/Savin, Dayan, Lengyel - Unknown - Correlations strike back (again) the case of associative memory retrieval.pdf:pdf},
pages = {1--9},
title = {{Correlations strike back (again): the case of associative memory retrieval}}
}
@inproceedings{Savova2009,
annote = {We parse the world in very rich ways -- so much beyond pixels.
        
We have generative, structural, grammar-based representations that help us parse scence
        
Experiment: 
-- Objects are generated from grammars, and these objects are overlayed on each other and partially occluded. 
-- Participants were asked to parse the scene into objects.
-- Performance improved with more examples, and decreased with recurisve rules
        
Grammar model fits well, and super-grammar fits better for more examples.},
author = {Savova, Virginia and Jakel, Frank and Tenenbaum, Joshua B},
booktitle = {{Proceedings of the 31st Annual Conference of the Cognitive Science Society}},
file = {:Users/Brenden/Documents/Mendeley/Savova, Jakel, Tenenbaum - 2009 - Grammar-based object representations in a scene parsing task.pdf:pdf},
keywords = {computational modeling,part-based models,visual representations},
mendeley-tags = {part-based models},
title = {{Grammar-based object representations in a scene parsing task}},
year = {2009}
}
@inproceedings{Savova2008,
annote = {Visual objects are complex:
        
- faces have obligatory parts, while the number of windows for houses, etc. can change
 -- how is one shot learning possible with rich, complex categories?
        
constellation models fail for houses, because you have to choose a number of parts. How many parts are there?
        
Houses are like sentences, in that they have a decomposition into parts. Each wing has a garage door, a garage door has windows, etc.  Just like sentences have NPs and VPs. 
        
Humans need a lot of linguistic input to acquire gramnar. But you need far fewer examples for houses
                  
Experiment: 
Stimuli were shapes embded in other shapes, like circles within circles. They were generated by context free grammars.
        
Classification can be done by marginalizing over gammars, to get a probability of generalizing to a new example.
                  
Results        
Correlation r=.67 with standard categorization model, but .82 when representativeness is taken into account.
        
Figures are not really interpretable},
author = {Savova, Virginia and Tenenbaum, Joshua B},
booktitle = {{Proceedings of the 30th Annual Conference of the Cognitive Science Society}},
file = {:Users/Brenden/Documents/Mendeley/Savova, Tenenbaum - 2008 - A Grammar-Based Approach to Visual Category Learning.pdf:pdf},
keywords = {grammar,object categorization,one-shot learning,part-based models,vision},
mendeley-tags = {one-shot learning,part-based models},
title = {{A Grammar-Based Approach to Visual Category Learning}},
year = {2008}
}
@inproceedings{Saxe2013,
annote = {Why do neural networks experiene stage-like changes in development, like people?
        
What aspects have to be present?
+ non-linear activations?
+ just the input?
        
Model is a three layer linear network
        
Only sensitive to correlations, is enough to drive stage-like behavior of hiearachies?
        
SVD gives
- a representation for each object
- a representation for each feature'
- diagonal matrix that indicates most important dimensions
        
Compute batch updates to weights, which show they are sensitive only to correlations, and then derive close form expressions that relates the weights at any time to input-output modes indentified by the singular value decomposition
SVD:
        
Shows modes, in the weights, as a function of time. Shows a tight fit of prediciton and theory
        
Networks with only input-output connections and no hidden layers are not capable of stage-like transistions
                  
Learning hierarchical data
                
Tree structure of items, where features are generated from a diffusion process
        
If you compute an SVD of the generated data matrix, the largest singular vectors are the ones that code for coarseer distinctions in the hiearchy 
        
Thus, they are necessarily learned first by the network},
author = {Saxe, Andrew M and Mcclelland, James L and Ganguli, Surya},
booktitle = {Proceedings of the 35th Annual Meeting of the Cognitive Science Society (CogSci2013)},
file = {:Users/Brenden/Documents/Mendeley/Saxe, Mcclelland, Ganguli - 2013 - Learning hierarchical category structure in deep neural networks.pdf:pdf},
keywords = {hierarchical generative models,learning dynamics,neural networks,semantic cognition},
title = {{Learning hierarchical category structure in deep neural networks}},
year = {2013}
}
@article{Schapiro2013,
abstract = {Our experience of the world seems to divide naturally into discrete, temporally extended events, yet the mechanisms underlying the learning and identification of events are poorly understood. Research on event perception has focused on transient elevations in predictive uncertainty or surprise as the primary signal driving event segmentation. We present human behavioral and functional magnetic resonance imaging (fMRI) evidence in favor of a different account, in which event representations coalesce around clusters or 'communities' of mutually predicting stimuli. Through parsing behavior, fMRI adaptation and multivoxel pattern analysis, we demonstrate the emergence of event representations in a domain containing such community structure, but in which transition probabilities (the basis of uncertainty and surprise) are uniform. We present a computational account of how the relevant representations might arise, proposing a direct connection between event learning and the learning of semantic categories.},
author = {Schapiro, Anna C and Rogers, Timothy T and Cordova, Natalia I and Turk-Browne, Nicholas B and Botvinick, Matthew M},
doi = {10.1038/nn.3331},
file = {:Users/Brenden/Documents/Mendeley/Schapiro et al. - 2013 - Neural representations of events arise from temporal community structure.pdf:pdf;:Users/Brenden/Documents/Mendeley/Schapiro et al. - 2013 - Neural representations of events arise from temporal community structure(2).pdf:pdf},
issn = {1546-1726},
journal = {Nature neuroscience},
month = feb,
number = {4},
pages = {486--492},
pmid = {23416451},
publisher = {Nature Publishing Group},
title = {{Neural representations of events arise from temporal community structure.}},
volume = {16},
year = {2013}
}
@article{Scheepers2003,
author = {Scheepers, Christoph},
doi = {10.1016/S0010-0277(03)00119-7},
file = {:Users/Brenden/Documents/Mendeley/Scheepers - 2003 - Syntactic priming of relative clause attachments persistence of structural configuration in sentence production.pdf:pdf},
issn = {00100277},
journal = {Cognition},
keywords = {relative clause attachment,sentence production,syntactic priming},
month = oct,
number = {3},
pages = {179--205},
title = {{Syntactic priming of relative clause attachments: persistence of structural configuration in sentence production}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0010027703001197},
volume = {89},
year = {2003}
}
@article{Schmidt2009,
author = {Schmidt, Mark and {Van Den Berg}, Ewout and Friedlander, Michael P and Murphy, Kevin},
file = {:Users/Brenden/Documents/Mendeley/Schmidt et al. - 2009 - Optimizing Costly Functions with Simple Constraints A Limited-Memory Projected Quasi-Newton Algorithm.pdf:pdf},
journal = {{Proceedings of the 12th International Conference on Artificial Intelligence and Statistics (AISTATS)}},
keywords = {optimization,sparsity},
mendeley-tags = {optimization,sparsity},
title = {{Optimizing Costly Functions with Simple Constraints: A Limited-Memory Projected Quasi-Newton Algorithm}},
year = {2009}
}
@article{Schmidt2009a,
author = {Schmidt, Michael and Lipson, Hod},
file = {:Users/Brenden/Documents/Mendeley/Schmidt, Lipson - 2009 - Distilling Free-Form Natural Laws.pdf:pdf},
journal = {Science},
number = {324},
pages = {81--85},
title = {{Distilling Free-Form Natural Laws}},
volume = {324},
year = {2009}
}
@article{Schmidt1975,
annote = {        introduction        
        
- closed loop motor theories: feedback is given, feedback is checked aginst reference for correctness, errors are corrected
- not a lot of emphasis on testing the theories
        
Adam's theory
- two states of memory: memory trace and perceptual trace
- memory trace: like recall memory, choosing initial direction and early movements
- perceptual trace: like recognition memory, past experience with feedback and snesory consequences of movement
- during movement, incoming feedback is compared to pereptual trace
+ if the limb is in the correct final location, he stops
+ over time, the perceptual trace is strengthened and accuracy improves
                  
criticisms:        
how does learning take place? Since you are already minimizing error to the internal response
- you must compare movement to a reference "motor program", but we would need a huge variety of these (100,000 for just phonemes)
- we don't make movements in exactly the same way each time
                  
new theory
                
- motor program: the idea that people have a set of stored muscle commands ready for action
+ Lashley: patient with back wound had no feeling, but could still execute motor actions
+ stored commands are structured before movmeent, so the entire sequence can be carried out with peripheral feedback
+ evidence: feedback loop seems slow compared to the movement
++ takes 100 ms to initiate and stop a motor movement, meaning the decision to stop must have been made prior to the initiation
+++ serious problem for closed-loop theories, but you must show that movement is possible without feedback
        
theory modification: originally, every movement needs its own motor program
+ needs huge storage
+ generalized motor programs. there could be a single program for the many ways to throw a baseball
++ parameters can be set (fast/slow), differene forces, etc.
++ also, the program can be minor corrections (using spindle sysetm) in the absence of environemnt feedback
        
Challenge of learning: develop open-loop programs for movements to free himself from feedback involved
                  
schema: some abstract notion of the concept (they cite Posner and Keele)
        
movements require: initial conditions, response specifications (like how fast), sensory consequences (from the era, eyes), response outcome (did the dart hit the target?). Movements can be clustered based on these attributes, to form schemas
        
when faced with a response for which he has a type, he has the initial conditions and the desired outcome. He can then retrive the response specifications from teh scehma.
+ this allows novely, generation
+ during movement, the schema's expected consequences can be compared with the observed ones
        
You can have subjective reinforcement, where the schema predicts the outcome of the movement and compare it to actuality
        
This can be used to update the schema rules
        
open loop: response to changing environemnt, like wrestingl
closed loop: response to relatively constant environment
        
in schema theory, there is no real difference -- just have environment uncertainty. Eventually you must choose a "close-loop" action in the open scenario
        
previous theories have difficulty doing something new. How do you "jump further" than ever before? The perceptual trace is just the central tendency of the past. Now you can set the parameter as different.
                  
evidence        
- people can write their signature on a check or huge ona blackboard, without problems
+ of course, there is quite different muscalature
+ you have a broader motor program, that needs additional specification
+ plenty of evidence for the transfer of motor learning
+ you can perform novel movements, liek shooting from a new place on a basketball court
        
Some evidence that high-variablitiy training supports more transfer (the program is more general)
        
Schema may not just be a central tendency -- relations between outcome and sensory consequences
                  
future directions
                
should test whether schema are formed easily in the motor domain, (not just visual)
        
perhaps relevant in movement education: a variety of movements should be most useful},
author = {Schmidt, Richard A},
file = {:Users/Brenden/Documents/Mendeley/Schmidt - 1975 - A schema theory of discrete motor skill learning.pdf:pdf},
journal = {Psychological Review},
keywords = {classic psychology,handwriting,motor programs},
mendeley-tags = {classic psychology,handwriting,motor programs},
number = {4},
title = {{A schema theory of discrete motor skill learning}},
volume = {82},
year = {1975}
}
@article{Schooler1993,
author = {Schooler, Jonathan W. and Ohlsson, Stellan and Brooks, Kevin},
doi = {10.1037//0096-3445.122.2.166},
file = {:Users/Brenden/Documents/Mendeley/Schooler, Ohlsson, Brooks - 1993 - Thoughts beyond words When language overshadows insight.pdf:pdf},
issn = {0096-3445},
journal = {Journal of Experimental Psychology: General},
keywords = {eureka},
mendeley-tags = {eureka},
number = {2},
pages = {166--183},
title = {{Thoughts beyond words: When language overshadows insight.}},
volume = {122},
year = {1993}
}
@article{Schultz1997,
abstract = {The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.},
annote = {Animals need a way to predict future reward, so they can make decisions.
        
Rescola-Wagner model is one account of pairing stimuli with rewards, and the "blocking" phenomenon
        
Mid-brain dopaminergic activity has long been associated with reward.
- response to single neurons is transiet, in that it only lasts for a few presentations.
- after pairing, the neurons respond after the cue onset, rather than after the reward
- also, if the reward then fails to come, the firing rate goes way down..
        
Computational theory
- TD algorithm
+ the goal of learning is to use sensory cutes to predict the discounted sum of all future rwards V(t)
+ this is an important generlaization of predicting the current reward, like Rescorla-Wagner
+ markov assumption: reward depends only on the immediate sensory cues
+ it would be tough to remember the weights over time, to get an optimal prediction
        
Recurve defintion of V(t)
+ expectatino of current reward + future V(t+1)
        
TD error: an error in the estimated preditions
+ this is used to improve the estimate of V(t)
        
There seems to be temporal labels constructed in neural tissue, where the dopmanine system can respond at arbitrary times after the stimulus onset (needs to represent time of cue and time of reward)
        
To account for this, each sensory cue is a vector of signals, where the element of the vector that is on encodes botha tthe the light is on and th etime.
                  
comparing model and data        
- the dopmanine area receives highly convergent input from many brain regions (the different input modalities)
- you get the same shift from the time of reward to the time of the stimulus
        
temporal credit assimgnet problem: when the rat is moving through a maze, and makes a mistakte and doesn't get the reward, which was the action that caused the problem?
+ one solution is to describe the value at each state -- so you know where you went wrong (a policy)
+ the rat is correct once it's preditions errors are 0
      },
author = {Schultz, W and Dayan, P and Montague, P R},
file = {:Users/Brenden/Documents/Mendeley/Schultz, Dayan, Montague - 1997 - A neural substrate of prediction and reward.pdf:pdf},
issn = {0036-8075},
journal = {Science},
keywords = {Algorithms,Animals,Computer Simulation,Conditioning (Psychology),Cues,Dopamine,Dopamine: physiology,Learning,Mesencephalon,Mesencephalon: physiology,Models,Neurological,Neurons,Neurons: physiology,Rats,Reward,classic psychology},
mendeley-tags = {classic psychology},
month = mar,
number = {5306},
pages = {1593--9},
pmid = {9054347},
title = {{A neural substrate of prediction and reward}},
volume = {275},
year = {1997}
}
@article{Schultz2004,
abstract = {Neurons in a small number of brain structures detect rewards and reward-predicting stimuli and are active during the expectation of predictable food and liquid rewards. These neurons code the reward information according to basic terms of various behavioural theories that seek to explain reward-directed learning, approach behaviour and decision-making. The involved brain structures include groups of dopamine neurons, the striatum including the nucleus accumbens, the orbitofrontal cortex and the amygdala. The reward information is fed to brain structures involved in decision-making and organisation of behaviour, such as the dorsolateral prefrontal cortex and possibly the parietal cortex. The neural coding of basic reward terms derived from formal theories puts the neurophysiological investigation of reward mechanisms on firm conceptual grounds and provides neural correlates for the function of rewards in learning, approach behaviour and decision-making.},
annote = {Rewards come through the senses -- they are not a primary thing.
        
Rewards that are fully predicted do not seem to lead to learning (non-Hebbian), but rather Rescola-Wagner like
        
Relationship to game theory, where agents act to maximize expected rewward
        
Neurons coding for
receipt of reward: orbitofrontal cortex, amygdala, and stiatum
expectation of reward: other neurons in these structures
movement prep: dorsolateral prefrontal cortex and stiatum
        
Dopamine neurons seem to predict reward, where they respond before reward, during the uncertain period, and at the time of the rward
      },
author = {Schultz, Wolfram},
doi = {10.1016/j.conb.2004.03.017},
file = {:Users/Brenden/Documents/Mendeley/Schultz - 2004 - Neural coding of basic reward terms of animal learning theory, game theory, microeconomics and behavioural ecology.pdf:pdf},
issn = {0959-4388},
journal = {Current opinion in neurobiology},
keywords = {Animal,Animal: physiology,Animals,Behavior,Brain,Brain: cytology,Brain: physiology,Decision Making,Decision Making: physiology,Economics,Game Theory,Humans,Learning,Learning: physiology,Neurons,Neurons: physiology,Reward,classic psychology},
mendeley-tags = {classic psychology},
month = apr,
number = {2},
pages = {139--47},
pmid = {15082317},
title = {{Neural coding of basic reward terms of animal learning theory, game theory, microeconomics and behavioural ecology.}},
volume = {14},
year = {2004}
}
@article{Schulz2012,
abstract = {Analogies between scientific theories and children's folk theories have been central to the study of cognitive development for decades. In support of the comparison, numerous studies have shown that children have abstract, ontologically committed causal beliefs across a range of content domains. However, recent research suggests that the comparison with science is informative not only about how children represent knowledge but also how they acquire it: many of the epistemic practices essential to and characteristic of scientific inquiry emerge in infancy and early childhood.},
annote = {Child as scientist metaphor. But not only in terms of knowledge, but also how they acquire that knowledge.
                  
intro
                
sciences is a modern invention and practiced only by a tiny minority, so it's a strange place to look. But it often gets the world right
        
Science has a particular set of methodological tools that it uses, and you have to follow this method to have a chance at getting it right
        
Thesis: these are not scientific abilities, but general human abilities
+ existence proof that these core epistmetic abilities emerge early in childhood
        
examples of scientific discovery in children:
backwards blocking, to infer the right causal explanation
        
theories provide guidance for generalizing from little data
        
hierarchical bayesian models: section is pretty badly writte, not clear what is hierarchical here, and she conflates multiple hypotheses with hierarchy
- misuse of structural forms example
                  
infering unobserved variables
                
preschoolers assume perfect prediction if you know ause and effect, in essence, determinism
        
A probabilistc cause, they infer the cause is sometimes missing or an inhibitor
        
They will repeat determinstic causes, but explore in probabilistic cases. Thus, it seems like they are searching for hidden variables.
        
        selective exploration and isolating variables
          
        play is not driven by superificial apperance, but by formal properties of the evidence
        
consistent with idea that learners shouldbe curious about causal hypotheses when the posterior prob. of a small number of hypotheses is equivalent
(like in cases when evidence is surprising)
        
children with an incorrect theory of mass choose to explore a familiar block again that balances weirdly to them
        
Exploration is promoted by confounded evidnece
        
Given ambiguous evidnece, children selectively perform interventions that isolate competing candidate cuaes and maximize information gain. If they can't figure out which of two beads make a box go off, they design new interventinos to test that
        
        sampling processes
          
        except red balls to come from boxes with mostly red balls, etc.
        
also sensitive to different sampling process, preferences, tc.
                  
learning from others
                
new scientsts are informed by past research
        
if a teacher freely demonstrates one function of a toy, they shouldn't look for more, but if you are interuppted or taught by a naive agent, you might continue to serach
        
        conclusion
                
There is not general law, Hebb's rule, Bayes' rule, etc. that can do justice to the type of learning the children are capable of and readily do. How can we make a unified computational account?
        
Do any changes in inductive reasoning ability happen over time?
        
Rather than a dumb random search, children are very systematic, something more like error maps },
author = {Schulz, Laura},
doi = {10.1016/j.tics.2012.06.004},
file = {:Users/Brenden/Documents/Mendeley/Schulz - 2012 - The origins of inquiry inductive inference and exploration in early childhood.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Child,Child Behavior,Child Development,Child Development: physiology,Exploratory Behavior,Humans,Infant,Learning,Preschool,Problem Solving,Science,Science: methods,causal reasoning},
mendeley-tags = {causal reasoning},
month = jul,
number = {7},
pages = {382--9},
pmid = {22721579},
publisher = {Elsevier Ltd},
title = {{The origins of inquiry: inductive inference and exploration in early childhood.}},
volume = {16},
year = {2012}
}
@incollection{SchvaneveldtDurso1989,
author = {Schvaneveldt, R W and Durso, F T and Dearholt, D W},
booktitle = {The psychology of learning and motivation: Advances in research and theory},
editor = {Bower, G},
file = {:Users/Brenden/Documents/Mendeley/Schvaneveldt, Durso, Dearholt - 1989 - Network structures in proximity data.pdf:pdf},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {249-284},
publisher = {Academic Press},
title = {{Network structures in proximity data}},
volume = {24},
year = {1989}
}
@article{Schwarz1978,
annote = {This paper introduced the Bayesian Information Criterion (BIC).
        
The derivation here is complicated, but it can also be derived by taking the Laplace approximation to an integral and taking the limit as the number of data points (n) approaches infinity.},
author = {Schwarz, Gideon},
file = {:Users/Brenden/Documents/Mendeley/Schwarz - 1978 - Estimating the Dimension of a Model.pdf:pdf},
journal = {The Annals of Statistics},
number = {2},
pages = {461--464},
title = {{Estimating the Dimension of a Model}},
volume = {6},
year = {1978}
}
@article{Schyns1991,
author = {Schyns, P G},
journal = {Cognitive Science},
pages = {461--508},
title = {{A Modular Neural Network Model of Concept Acquisition}},
volume = {15},
year = {1991}
}
@article{SchynsGoldstone1998,
annote = {Schyns and Rodet (1997) -- Cells either had feature X, feature Y, or a combined XY feature.
        
Subjects were tested on the perception of X-Y, where both features are present but disjoint.
        
Learning cateogires in the order X -> Y -> XY results in separate, but XY -> X -> Y results in together.
        
Pevtzow and Goldstone (1994). Learned different feature representations, depending on how the objects were partitioned into categories. Which features were learned were tested with part/whole judgements, indicating whether a part appears in the whole. There is a reaction time idfference between the categoriation groups.},
author = {Schyns, P G and Goldstone, R L and Thibaut, J.-P.},
file = {:Users/Brenden/Documents/Mendeley/Schyns, Goldstone, Thibaut - 1998 - The development of features in object concepts.pdf:pdf},
journal = {Behavioral and Brain Sciences},
keywords = {part-based models},
mendeley-tags = {part-based models},
pages = {1--54},
title = {{The development of features in object concepts}},
volume = {21},
year = {1998}
}
@article{Schyns1997,
annote = {Schyns and Rodet (1997) -- Cells either had feature X, feature Y, or a combined XY feature.
        
Subjects were tested on the perception of X-Y, where both features are present but disjoint. 
        
Learning cateogires in the order X -> Y -> XY results in separate, but XY -> X -> Y results in together.
        
Experiment 1:
Groups were either X then XY, or XY then X
        
Tested on X-Y. The "X then XY" group, it was categorized as X 44% of the time. In the XY then X group, it was cateogized as X arond 84% of the time.
        
Preliminary experiment:
They recorded subjects' free parsing, where they coul draw outlines around the cells' parts with a compute rmouse
        
      },
author = {Schyns, Philippe G. and Rodet, Luc},
doi = {10.1037/0278-7393.23.3.681},
file = {:Users/Brenden/Documents/Mendeley/Schyns, Rodet - 1997 - Categorization creates functional features.pdf:pdf},
issn = {0278-7393},
journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
keywords = {part-based models},
mendeley-tags = {part-based models},
number = {3},
pages = {681--696},
title = {{Categorization creates functional features.}},
volume = {23},
year = {1997}
}
@article{Sederberg2011,
abstract = {Recent work by Hupbach, Gomez, Hardt, and Nadel (Learning & Memory, 14, 47-53, 2007) and Hupbach, Gomez, and Nadel (Memory, 17, 502-510, 2009) suggests that episodic memory for a previously studied list can be updated to include new items, if participants are reminded of the earlier list just prior to learning a new list. The key finding from the Hupbach studies was an asymmetric pattern of intrusions, whereby participants intruded numerous items from the second list when trying to recall the first list, but not viceversa. Hupbach et al. (2007; 2009) explained this pattern in terms of a cellular reconsolidation process, whereby first-list memory is rendered labile by the reminder and the labile memory is then updated to include items from the second list. Here, we show that the temporal context model of memory, which lacks a cellular reconsolidation process, can account for the asymmetric intrusion effect, using well-established principles of contextual reinstatement and item-context binding.},
annote = {memory reconsolidation: reminding of a memory makes it vulneralbe to intrusions and other modifications
        
They model this with the TCM (temporal context model)
        
      },
author = {Sederberg, Per B and Gershman, Samuel J and Polyn, Sean M and Norman, Kenneth a},
doi = {10.3758/s13423-011-0086-9},
file = {:Users/Brenden/Documents/Mendeley/Sederberg et al. - 2011 - Human memory reconsolidation can be explained using the temporal context model.pdf:pdf},
issn = {1531-5320},
journal = {Psychonomic bulletin & review},
keywords = {Cues,Humans,Learning,Mental Recall,Models, Psychological,Serial Learning,Time Factors},
month = jun,
number = {3},
pages = {455--68},
pmid = {21512839},
title = {{Human memory reconsolidation can be explained using the temporal context model.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3432313&tool=pmcentrez&rendertype=abstract},
volume = {18},
year = {2011}
}
@article{Sejnowski1987,
annote = {classic paper on NETtalk

        

        
------
speaking english text is a problem that shares interesting structure with many AI tasks, in that it seems rule-like with some exceptions

        
converts strings of letters to string of phonemes, where network learns rules and absorbs many exceptions

        
one layer of hidden units, and back-propagation used for learning

        
          
representation:

        
input alyer: 7 groups, where each group encodes one letter
- local encoding

        
output layer: correct phoneme of the center, or 4th, letter of the window (the other six letters provide context)
- step through the word letter-by-letter
- phonemes repreented by 21 articulatory features (thus this is distributed)

        
          
learning

        
        
two texts were used for training:
- phonetic transcritpions of continuous speech of ac hild
- and Webster's dictionry

        
when moving text through the window, several words could be present at a time

        
          
parametrs

        
        
10,000 learned weights

        
when reading off the output, the phoneme with the smallest angle with the output was chosen as the best guess

        
          
results

        
        
performance increased quickly, and then continued at a slower rate (power law learning, which is characteristic of human skill learning)
- vowels vs. consontants were distinguished early (first stage of learning, where all vowels were globbed together)

        
performance was 78% of new wors, and 95% correct on the training corupus

        
damage:

        
graceful degradation, and re-learning is faster than learning in the original case

        
without hidden units:
- performane satures at 82% -- but what was generalization? they don't say

        
          
analysis of hidden units

          

        there is not enough capacity to store all of the words in the dictionary, so compression is possible due to redundancy

        
about 20% of hidden units are active for any given word

        
if you do hierarhical clustering of hidden representations, you get similar structures (consontant vs vowel distinction), even for different network architectures

        

        
          
summary

        
        
with simple constraints on the input representation, the network reaches a significant level of performance, and it is resistant to damage

        
also, children learn in two steps, where they first learn to speak and then they learn to read 
- so it's not a good model o this process

        
- optimal schedule for teaching NETtalk new words is to alternate new and old words (but see catastrophic interference, which was researched leater)

        

      },
author = {Sejnowski, TJ and Rosenberg, CR},
file = {:Users/Brenden/Documents/Mendeley/Sejnowski, Rosenberg - 1987 - Parallel networks that learn to pronounce English text.pdf:pdf},
journal = {Complex systems},
keywords = {classic AI,classic psychology},
mendeley-tags = {classic AI,classic psychology},
pages = {145--168},
title = {{Parallel networks that learn to pronounce English text}},
volume = {1},
year = {1987}
}
@inproceedings{Selfridge1958,
address = {London},
annote = {Classic in AI on learning with deep networks.
---
        
Cognitive demons inspect various aspects of the stimulus and make a decision. The input to the next layer of demons are weighted sums of the previous layers.
        
Learning was conceived as error minimization. Rather than calculating the gradient analytically, one looks at several random directions and picks the best.
        
Sub-demons could be evaluated by looking at their worth (weights), and mutating/combining good dones, much like a genetic algorithm.
        
      },
author = {Selfridge, Oliver G},
booktitle = {Mechanisation of Thought Processes: Proceedings of a Symposium Held atthe National Physical Laboratory},
file = {:Users/Brenden/Documents/Mendeley/Selfridge - 1958 - Pandemonium A paradigm for learning.pdf:pdf},
keywords = {classic AI},
mendeley-tags = {classic AI},
pages = {513--526},
publisher = {HMSO},
title = {{Pandemonium: A paradigm for learning}},
year = {1958}
}
@article{Serre2007,
abstract = {Primates are remarkably good at recognizing objects. The level of performance of their visual system and its robustness to image degradations still surpasses the best computer vision systems despite decades of engineering effort. In particular, the high accuracy of primates in ultra rapid object categorization and rapid serial visual presentation tasks is remarkable. Given the number of processing stages involved and typical neural latencies, such rapid visual processing is likely to be mostly feedforward. Here we show that a specific implementation of a class of feedforward theories of object recognition (that extend the Hubel and Wiesel simple-to-complex cell hierarchy and account for many anatomical and physiological constraints) can predict the level and the pattern of performance achieved by humans on a rapid masked animal vs. non-animal categorization task.},
author = {Serre, Thomas and Oliva, Aude and Poggio, Tomaso},
doi = {10.1073/pnas.0700622104},
file = {:Users/Brenden/Documents/Mendeley/Serre, Oliva, Poggio - 2007 - A feedforward architecture accounts for rapid categorization(2).pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Adult,Humans,Models,Neurological,Pattern Recognition,Photic Stimulation,Psychophysics,Recognition (Psychology),Visual,Visual Perception,Visual Perception: physiology,Visual: physiology},
month = apr,
number = {15},
pages = {6424--9},
pmid = {17404214},
title = {{A feedforward architecture accounts for rapid categorization.}},
volume = {104},
year = {2007}
}
@article{Shafto2011,
abstract = {Most natural domains can be represented in multiple ways: we can categorize foods in terms of their nutritional content or social role, animals in terms of their taxonomic groupings or their ecological niches, and musical instruments in terms of their taxonomic categories or social uses. Previous approaches to modeling human categorization have largely ignored the problem of cross-categorization, focusing on learning just a single system of categories that explains all of the features. Cross-categorization presents a difficult problem: how can we infer categories without first knowing which features the categories are meant to explain? We present a novel model that suggests that human cross-categorization is a result of joint inference about multiple systems of categories and the features that they explain. We also formalize two commonly proposed alternative explanations for cross-categorization behavior: a features-first and an objects-first approach. The features-first approach suggests that cross-categorization is a consequence of attentional processes, where features are selected by an attentional mechanism first and categories are derived second. The objects-first approach suggests that cross-categorization is a consequence of repeated, sequential attempts to explain features, where categories are derived first, then features that are poorly explained are recategorized. We present two sets of simulations and experiments testing the models' predictions about human categorization. We find that an approach based on joint inference provides the best fit to human categorization behavior, and we suggest that a full account of human category learning will need to incorporate something akin to these capabilities.},
author = {Shafto, Patrick and Kemp, Charles and Mansinghka, Vikash and Tenenbaum, Joshua B},
doi = {10.1016/j.cognition.2011.02.010},
file = {:Users/Brenden/Documents/Mendeley/Shafto et al. - 2011 - A probabilistic model of cross-categorization.pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
keywords = {cross-categorization},
month = jul,
number = {1},
pages = {1--25},
pmid = {21377146},
publisher = {Elsevier B.V.},
title = {{A probabilistic model of cross-categorization.}},
volume = {120},
year = {2011}
}
@article{Shannon1949,
annote = {pioneering paper in information theory

        
Noisy channel:
-destination
-noise
-receiver

        

      },
author = {Shannon, CE},
file = {:Users/Brenden/Documents/Mendeley/Shannon - 1949 - Communication in the Presence Noise.pdf:pdf},
journal = {Proceedings of the IRE},
keywords = {classic AI},
mendeley-tags = {classic AI},
number = {1},
pages = {10--21},
title = {{Communication in the Presence Noise}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1697831},
volume = {37},
year = {1949}
}
@article{Shepard1980,
author = {Shepard, R N},
file = {:Users/Brenden/Documents/Mendeley/Shepard - 1980 - Multidimensional scaling, tree-fitting, and clustering.pdf:pdf},
journal = {Science},
pages = {390--398},
title = {{Multidimensional scaling, tree-fitting, and clustering}},
volume = {210},
year = {1980}
}
@article{Shepard1961,
author = {Shepard, R N and Hovland, C L and Jenkins, H M},
journal = {Psychological Monographs},
number = {13, Whole No. 517},
title = {{Learning and memorization of classifications.}},
volume = {75},
year = {1961}
}
@article{Shepard1967,
annote = {Shows memory capacity is larger than previously thought

        
Design:
- 612 visual stimuli, one at a time at their own rate, and then test series of 68 pairs each of which contained on new stimulus (not shown) and one old stimulus (shown)
- this avoid the problem of a response bias

        
Stimuli:
- words: 600 common nouns and adjectives
- sentences: 
- pictures: 

        
results: (mean percent correct)
- words: 88.4%
- sentences: 89%
- pictures: 96.7%

        
Information theory (Shannon) provides a basis for understanding memory, but only if it is coupled with a substantive model for the recognition process},
author = {Shepard, RN},
file = {:Users/Brenden/Documents/Mendeley/Shepard - 1967 - Recognition Memory for Words, Sentences, and Pictures.pdf:pdf},
journal = {Journal of verbal Learning and verbal Behavior},
pages = {156--163},
title = {{Recognition Memory for Words, Sentences, and Pictures}},
volume = {6},
year = {1967}
}
@article{Shepard1987,
annote = {Shepard proposes a universal law of generalization, where you have an exponential relationship between the stimulus observed and the probabiltiy of response -- if distance is taken in psychological space
        
1) Build psychological space using MDS, perhaps with a confusability matrix},
author = {Shepard, Roger N},
file = {:Users/Brenden/Documents/Mendeley/Shepard - 1987 - Toward a Universal Law of Generalization for Psychological Science.pdf:pdf},
journal = {Science},
keywords = {generalization,one-shot learning},
mendeley-tags = {generalization,one-shot learning},
number = {4820},
pages = {1317--1323},
title = {{Toward a Universal Law of Generalization for Psychological Science}},
volume = {237},
year = {1987}
}
@article{Shepard1971,
author = {Shepard, Roger N and Metzler, Jacqueline},
file = {:Users/Brenden/Documents/Mendeley/Shepard, Metzler - 1971 - Mental rotation of three-dimensional objects.pdf:pdf},
journal = {Science},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {3972},
pages = {701--703},
title = {{Mental rotation of three-dimensional objects}},
volume = {171},
year = {1971}
}
@article{Shiffrin1997,
annote = {Classic model of explicit, episodic, recognition memory
        
Items have features, and on a presentation, you encode features probabilistically (you can have failures of encoding). During recognition, you calculate the probability of old vs. new},
author = {Shiffrin, Richard M and Steybers, Mark},
file = {:Users/Brenden/Documents/Mendeley/Shiffrin, Steybers - 1997 - A model of recognition memory REM-retrieving effectively from memory.pdf:pdf},
journal = {Psychonomic Bulletin and Review},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {2},
pages = {145--166},
title = {{A model of recognition memory: REM-retrieving effectively from memory}},
volume = {4},
year = {1997}
}
@inproceedings{Shultz2004,
author = {Shultz, Thomas R and Vogel, Abbie},
booktitle = {Proceedings of the 26th Annual Conference of the Cognitive Science Society},
file = {:Users/Brenden/Documents/Mendeley/Shultz, Vogel - 2004 - A Connectionist Model of the Development of Transitivity Psychology of Transitivity.pdf:pdf},
pages = {1243--1248},
title = {{A Connectionist Model of the Development of Transitivity Psychology of Transitivity}},
year = {2004}
}
@inproceedings{Simard1992,
annote = {Check out elastic matching, deformable templates, etc.
        
Introduction
        
nearest neighbors suffers from simple transformations, like translations and scaling
        
Idea is to come up with a distance metric that is invariant to certain kinds of transformations
        
Say you want to make a distance metric invariant to rotation. Map out a small section of the manifold, which is highly non-linear in pixel space.
        
Then approximate it with a linear function in pixel space. This rules out the possibility of large rotations, like transforming a 6 into a 9
        
Distance is defined as the minimum distance between two points on the manifold. This is very hard to solve in general, and besides, true invariance is not desirable sinace 6 and 9 would e fonsued
        
Analytically derive solution to optimal distance
                  
Results
                
Synthetic example with translation, shows that tangent distance helps with the drop-off
                  
Digit recognition
                
Rather than computing all pairwise tangent distances, Euclidean distance is used as a pre-filter.
-- Perhaps I can use the affine warp model as a way to approximate this in HBPL?
        
6 different transformations wer chosen, including X and Y translations, rotation, scaling, thickening or thinning, etc., sheering
        
        USPS        
Found that tangent distance outperformed neural nets, and at a human-like level\
                  
NIST        
Overall winner on NIST training database, over 25 competitor algorithms
        
not that far from human-level performance
        
      },
author = {Simard, Patrice and LeCun, Yann and Denker, John S},
booktitle = {Advances in Neural Information Processing Systems 5},
file = {:Users/Brenden/Documents/Mendeley/Simard, LeCun, Denker - 1992 - Efficient pattern recognition using a new transformation distance.pdf:pdf},
keywords = {handwriting,neural networks},
mendeley-tags = {handwriting,neural networks},
pages = {50--58},
title = {{Efficient pattern recognition using a new transformation distance}},
year = {1992}
}
@article{Simoncelli2001,
author = {Simoncelli, Eero P and Olshausen, Bruno A},
file = {:Users/Brenden/Documents/Mendeley/Simoncelli, Olshausen - 2001 - Natural image statistics and neural representation.pdf:pdf},
journal = {Annual review of neuroscience},
keywords = {1954,1961,and barlow,are exposed,attneave,both evolutionary and developmental,efficient coding,independence,long been assumed that,of the,processes,proposed that,redundancy reduction,s abstract it has,sensory neurons are adapted,signals to which they,sparsity in the brain,through,to the statistical properties,visual cortex},
mendeley-tags = {sparsity in the brain},
pages = {1193--1216},
title = {{Natural image statistics and neural representation}},
volume = {24},
year = {2001}
}
@inproceedings{Singla2008,
author = {Singla, Parag and Domingos, Pedro},
booktitle = {{Twenty-third Conference on Artificial Intelligence (AAAI-08)}},
file = {:Users/Brenden/Documents/Mendeley/Singla, Domingos - 2008 - Lifted First-Order Belief Propagation.pdf:pdf},
keywords = {graphical models},
mendeley-tags = {graphical models},
number = {Pearl},
pages = {1094--1099},
title = {{Lifted First-Order Belief Propagation}},
year = {2008}
}
@article{Siok2004,
author = {Siok, Wai Ting and Perfetti, Charles A and Jin, Zhen and Tan, Li Hai},
doi = {10.1038/nature02709.1.},
file = {:Users/Brenden/Documents/Mendeley/Siok et al. - 2004 - Biological abnormality of impaired reading is constrained by culture.pdf:pdf},
journal = {Nature},
keywords = {handwriting},
mendeley-tags = {handwriting},
pages = {71--76},
title = {{Biological abnormality of impaired reading is constrained by culture}},
volume = {431},
year = {2004}
}
@article{Sloman1996,
annote = {People have talked about two systems of reasoning for centuries. 
        
But there are inconsistent definitions, and it is hard to nail this down empirically
                  
associative system        
based on simliarity and temporal structure
- if X has wings, it can probably fly
this can be an association, although it is also a rule
        
the generality of rules are both their strength and their weakness
                  
rule-based system        
productivity: in Fodor's sense, if john loves mary you can represent mary loves john
        
rule-based systems are most obviously productive, since they contain variables
        
sloman considers rules in reasoning, since other abilities might be special purpose
        
mental models, and logic, are methods for transforming configurations of symbols in ways that perserve turth
                  
dicussion
                
associative: seems to operate reflexively
+ only result is conscious
        
rule-based: captures structure that is logical, hierarchical, and causal-mechanical
+ entire process is conscious
                  
explanations vs predictions  in science
        
but consciousness is not a sure thing. "ah ha" moments are not necessarily associative
        
        a connectionist proposal
                
the intuitive processes might be only fully analyzed at the subconceptual level, more molecular than concepts
        
advantanges of this sub-concept representation:
- not only represent it, but its features
- automatic notion of similarity (connectionist, feature-overlap)
- context dependent
        
inference might be performed by the single settling of a network
        
rules are not as limited: they can perform new analyses
        
symbol: provides a remote access path to the full represent of a object
        
Hinton:
you can leap between these various representations in a hierarhcy of concepts, and you need a separate mechanism for that
                  
empirical evidence        
- concepts is the best current case study for this
        
protoype,exemplar theories are motivated by similarity-based processes
        
theory-based: not all similariy. a mechanical monkey looks a lot like a real one, but children don't project properties.
+ concepts are central elements of a web of interconneceted beleliefs, or lay theories (Carey)
+ Keil's evidence on changing the surface features of an object
+ people want to understand the origins, not throw things into bins (Keil)
                  
evidence for dissocaition        
Rips (1989). A 3-inch circle is more similar to a quarter, but more likely to be a pizza. Thus, similarity is not the basis of categorization awlays
                  
the case for rules        
Modus ponens, A & B therefore A, etc. are extremely intuitive and have tons of empirical support
- several review papers on applying abstract rules
                  
similtaneously contradictory belief        
- a whale is like a fish, but it is a mammal
- a judge overcomming intuition to rule consistent with the alw
- Muller-Lyer illusion, where perception and knowledge can derive from disinct systems
        
judgement:
- Linda the bank teller (Kahneman and Tversky)
+ people that get it wring, few attempt to defend their respone when it is pointed out
++ "opinion" vs. "reasoned conclusion"
        
- same thing with tautology arguments in property induction. There are differences in strenght, even if they are all true
+ Sloman's model can account for these
        
- Wason's card sorting task is another example
                  
empirical concclusions
                
again, worked with reasoning problems as to avoid the problem of domain-specific hardware (vision, language, motor control, etc.)
        
direction empirical evidence for dual systems
                  
dual operation: although we recognize the validity of the logical argument, the similairty-based answer still seems tempting
          
Discussion
                
this is not hte asme as induction vs. dedution, and fallacies can exist in both
        
Most rule-based knowledge is cultural
        
Rule-theorists believe people try to construct a world that is coherent, a global rule-based theory
        
To emphasize the goal depenency of the way human beings determine what is essential, I say we aim for explanatory coherence, rather than conceptual coherence.
- for the most part, people can rely on the world to maintain coherence
                  
conclusion        
the fact that people are pulled in two directions at once suggests two forces pulling
        
        
        
      },
author = {Sloman, Steven A},
file = {:Users/Brenden/Documents/Mendeley/Sloman - 1996 - The Empirical Case for Two Systems of Reasoning.pdf:pdf},
journal = {Psychological Bulletin},
keywords = {classic psychology,feature prediction},
mendeley-tags = {classic psychology,feature prediction},
number = {1},
pages = {3--22},
title = {{The Empirical Case for Two Systems of Reasoning}},
volume = {119},
year = {1996}
}
@book{Smith1981,
address = {Cambridge, MA},
author = {Smith, E E and Medin, D L},
publisher = {Harvard University Press},
title = {{Categories and concepts}},
year = {1981}
}
@book{Smith1981a,
address = {Cambridge, MA},
annote = {Well-known quote: "Without concepts, mental life would be chaotic"
        
1. Classical view around since Aristotle, but recent criticism of this approach.
Why use object concepts?
1. Mathematical concepts like "square" seem biased towards classical view
2. Other abstract concepts, "love", no one has good definitions. So it's biased against classical view
                  
Classical view        
        
Four main criticisms:
-- exclusion of functional features
-- existsence of disjunction concepts
-- existance of unclear cases
-- failure to specify defining features
        
- Aristotle, Hull, Bruner, etc...
- Some have argued that it should only include structural features, not functional features. But Smith and Medin belive functional features should be included
- Some say you can't have disjunction concepts: but what about a baseball stroke? swing or a called stroke
-- the last criticism is the strongest one, since we have made little empirical progress
        
Mostly experimental findings showed the theory is untenable
-- typicality ratings are consistent, predict speed of category verification},
author = {Smith, Edward E and Medin, Douglas L},
file = {:Users/Brenden/Documents/Mendeley/Smith, Medin - 1981 - Categories and Concepts.pdf:pdf},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
publisher = {Harvard University Press},
title = {{Categories and Concepts}},
year = {1981}
}
@article{Smith1974,
annote = {Presented early data and theory, for why prototypical exemplars are responded to more quickly in a category verification task.
        
---
        Set-theoretic models        
Meyer, 1970, Schaeffer and Wallance: 
where concepts are represented by sets of attributes
to verify "a robin is a bird", you determine whether every attribute of bird is also an attribute of robin
But you get necessary and sufficient problem.
        
        Their model        
features are not necessary and sufficient. Some are more or less defining or accidental. 
Step 1: consider all features, regardless of definingness
Step 2: then restricts his attention to only features that are above some lower bound of definingness
        
Linguistic hedges (Lakoff) can help determine which exemplars are prototypical.
                  
Evidence:        
--typicality ratings, which are not based on defining features, but rather the characteristic ones
-- Network models can only account for typicality in an ad-hoc way.
                  
Task        
category verification.
        
        Model        
-- each dimension has a weight, which is definingness
-- items have a distribution of values on each dimension, and at any given time, you represent one sample
When you decide:
Stage 1: Compare all the featuers, defining or not. If you are above some threshold, or below some threshold, respond yet or no
Stage 2: If you are in the intermediate range, comapre the defining features.
                  
Effects        
Can account for rapid "negative" responses, if there is little feature overlap. This is not capture by semantic nets},
author = {Smith, Edward E and Shoben, Edward J and Rips, Lance J},
file = {:Users/Brenden/Documents/Mendeley/Smith, Shoben, Rips - 1974 - Structure and process in semantic memory A feature model of semantic decisions.pdf:pdf},
journal = {Psychological Review},
keywords = {classic psychology,classics on concepts},
mendeley-tags = {classic psychology,classics on concepts},
number = {3},
pages = {214--241},
title = {{Structure and process in semantic memory: A feature model of semantic decisions}},
volume = {81},
year = {1974}
}
@inproceedings{Smith2012,
annote = {Human physics as Newtonina dynamics with uncertainty
        
Questions:
Do we need the noise?
Is there a rational inference or heuristics?
        
Experiment: Game of ping-pong
Ball bounces then occluded.
You must try to guess where it goes blindly
        
If the ball bounces of the wall, then this is likely a source of noise. Thus, if poeple are worse at the bounce trials, they need noise (duh?)
        
Types of uncertainty:
- position, velocity, movement, bounce uncertainy, etc.
        
There seems to be a center bias (want to keep your paddle in the center). 
        
Comparsion: heuristic oracle
+ you know where the ball is going to go
+ with some shift towards the center
        
Both models fit to 3/4 of data, predit the last 1/4.
        
The simulation model fits much better. It can pick out the easier/more difficult trials
        
Which noise were the most important? bounce noise, and noise in initial direction/velocity
        
It's weird, because the center bias isn't a particularly good idea. },
author = {Smith, Kevin and Vul, Edward},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Smith, Vul - 2012 - Sources of uncertainty in intuitive physics.pdf:pdf},
title = {{Sources of uncertainty in intuitive physics}},
year = {2012}
}
@article{smith-etal02,
annote = {Why is word learning hard?
+ Quine's "Gavagi" problem
        
The solution must be "prior knowledge"
- Most commonly innate constraints
- This paper suggests "learning to learn"
        
Learning to learn
- "shape bias" : the first 300 nouns youn children learn are objects organized by shape, rather than size, color, texture
        
Model
- "balls" are round, cups are cup-shaped, etc.
- higher order generalization: "_'s" are "_-shaped"
        
If toddler's learn this, can they be taught it early?
- authors wanted to test theory, but their method suggests a new product          
          
Experiment 1        
        
16 children
17 months old at start of the study
        
Step 1: training
        
4 categories with 2 objects each
        
7 weeks of once-a-week play sessions in which each child in the training group was taught four novel names "wif", "zup" "dax" and "lug"
- each name had 2 unique objects
- differed in color and material, but not shape
        
features
- material (wood, metal, cloth, sponge)
- color
- shape
- size(?) could be added. here it was fixed
        
Training procedure:       
- Played with two exemplars of each object together, separate from others (for 5 mins)
- "This is a dax. Let's put the daxes in the wagon" (named at least 10 times)
- Five minutes into playtime, they brought in another object, who matched in color with one and texture with the other. then says "that's not a dax"
        
Test procedure: first-order generalization
- Tested at Week 8
- "This is a zup" (trained item), where is another?
- three choice objects, where one matched in shape, another in color, and another in texture
        
Test procedure: higher-order generaltization
- Tested week 9
- "this is a zup" (new item), where is another?
- objects had novel names, and different colors, textures, and shapes than objects in the traning categories
- 3 choices, again matching each feature
        
Step 4: Parents of children in the training group completed the same vocabulary check-lists in Week 1 and Week 8
        
Control condition got no training, but same tests at Week 8 and 9
        
        Results:        
        
first-order generalizaiton:
exp: shape by 88% of time
control: shape 36% of time
        
second-order genearlizatoin
exp: shape by 70% of time
control: shape by 36% of time
        
vocabularly grwoth:
exp: learned about 41.4 object names (starting at less than 20)
contorl learned about 13.8 object names          
About a 3-fold increase!        
        
This was not the case for non-object words
                  
Experiment 2        
        
Possible problem with Experiment 1:
- Children in the training condition went to the lab more, maybe parents more engaged somehow
        
Conditions (with better controls)
1) Replication of experiment 1
2) Categories were organized by color and texture
3) Non-name condition, children played with the same objects as experiment 1, but no names were provided
        
        Results:        
        
first order generalization (known object)
- replication: chose shape 66% of time
- color and texture groups, generalized by their repspective property 67% of the time
- no-name: 62% of time
        
higher-order generalitization (new object)
- replication: 65% gen. to shape
- other conditions did not differ from chance
        
vocabularly growth (measured each week):
exp: learned about 50 object names
control, no name: learned about 20 object names
contorl, other biases: learned about 15 object names (poor toddlers - hope they are ok)          
Again, around a 3x increase        
        
        Discussion
                
Amazing result: teaching children names for only 4 categories accelerates learning outside of the lab
+ very rare in psychology
        
Learning tunes attention:
- as implemented by exemplar models, Alcove, etc.
        
Could you replace artificial objects with real objects, and still get this effect?
 + assuming objects are perfeclty organized by shape
        
      },
author = {Smith, L B and Jones, S S and Landau, B and Gershkoff-Stowe, L and Samuelson, L},
file = {:Users/Brenden/Documents/Mendeley/Smith et al. - 2002 - Object Name Learning Provides On-the-Job Training for Attention.pdf:pdf},
journal = {Psychological Science},
keywords = {baby toolbox,shape bias,word learning},
mendeley-tags = {baby toolbox,shape bias,word learning},
pages = {13--19},
title = {{Object Name Learning Provides On-the-Job Training for Attention}},
volume = {13},
year = {2002}
}
@article{Smith2005,
author = {Smith, Linda B.},
doi = {10.1016/j.dr.2005.11.001},
file = {:Users/Brenden/Documents/Mendeley/Smith - 2005 - Cognition as a dynamic system Principles from embodiment.pdf:pdf},
issn = {02732297},
journal = {Developmental Review},
keywords = {cognition,coming into existence of,complex systems composed of,concepts,development,dynamic systems,embedded within,embodied cognition,forms through ongoing intrinsic,idea of dynamic sys-,is fundamental to the,new,processes,tems,the idea of emergence,the temporary but coherent,very many individual elements},
mendeley-tags = {embodied cognition},
month = sep,
number = {3-4},
pages = {278--298},
title = {{Cognition as a dynamic system: Principles from embodiment}},
volume = {25},
year = {2005}
}
@article{Smith1992,
author = {Smith, Linda B. and Jones, Susan S. and Landau, Barbara},
doi = {10.1037//0012-1649.28.2.273},
file = {:Users/Brenden/Documents/Mendeley/Smith, Jones, Landau - 1992 - Count Nouns, Adjectives, and Perceptual Properties in Children's Novel Word Interpretations.pdf:pdf},
issn = {0012-1649},
journal = {Developmental Psychology},
number = {2},
pages = {273--286},
title = {{Count Nouns, Adjectives, and Perceptual Properties in Children's Novel Word Interpretations}},
volume = {28},
year = {1992}
}
@article{Smith2003,
author = {Smith, Linda B. and Thelen, Esther},
doi = {10.1016/S1364-6613(03)00156-6},
file = {:Users/Brenden/Documents/Mendeley/Smith, Thelen - 2003 - Development as a dynamic system.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
month = aug,
number = {8},
pages = {343--348},
title = {{Development as a dynamic system}},
volume = {7},
year = {2003}
}
@inproceedings{Smith,
author = {Smith, Nathaniel J and Goodman, Noah D and Frank, Michael C},
booktitle = {Advances in Neural Information Processing Systems 26},
file = {:Users/Brenden/Documents/Mendeley/Smith, Goodman, Frank - Unknown - Learning and using language via recursive pragmatic reasoning about other agents.pdf:pdf},
title = {{Learning and using language via recursive pragmatic reasoning about other agents}}
}
@article{Smith1993,
annote = {Relevance: if we show example characters to people before creative task, they are likely to be biased towards those examples to some extent. EVEN if you explicitly tell them to make examples as different as possible
        
-----
How do we do creative thinking?
        
People were asked to think of new and creative exemplars of toys and creatures on imaginary planet like Eathy
        
Does prior exerperience effect the creative generation task?
- they might be useful demonstrations
- or they might be damaging, counterproductive "cognitive fixation"
+ might be stuck on old solutions
        
In memory models, output interference from list cues might complete with other cues
        
Ward's tasks provides evidence thiat examples may hurt you, since aliens were based strongly on other examples
        
        Experiment 1
                
Design as many new creatures or toys as you can in 20 minutes
        
In one condition, 3 examples were displayed (90 seconds), and then removed from sight and not seen again
        
Instructed that duplication is not permitted
        
        Results:
                
People were about twice as likely, for many attributes of the shown examples, to use those attributes if shown the exampels
        
Thus, seeing examples seemed to stifle creativitiy
                  
Experiment 2:
                
Same thing, but with 23 minute delay between showing examples and doing the task
        
no difference in result
                  
Experiment 3        
        
Same, but changing instructions
        
conditions:
1) control (as before)
2) standard examples (as before)
2) ideas should be as different as possible
3) ideas should be as similar as possible
        
Result: 
        
the control group had lower overall conformity than the examples/diverge group! Telling subjets to generate as different as possible does not eliminate the conformity effect
        
      },
author = {Smith, Steven M and Ward, Thomas B and Schumacher, Jay S},
file = {:Users/Brenden/Documents/Mendeley/Smith, Ward, Schumacher - 1993 - SmithWardSchumacher1993.pdf.pdf:pdf},
journal = {Memory \& cognition},
keywords = {classics on concepts,exemplar generation},
mendeley-tags = {classics on concepts,exemplar generation},
number = {6},
pages = {837--845},
title = {{SmithWardSchumacher1993.pdf}},
volume = {21},
year = {1993}
}
@inproceedings{Socher2011,
annote = {Uses a recursive neural network for scene and sentence parsing
        
This idea resemble's Jordan Pollack's recursive neural network
        
The model gets input that is an over-segmentation of an image
and the valid segment labels. It has an equivalence class
of proper binary trees that combine with a labeled region first.
        
It defines it's own scoring metric, that takes the best tree in the
training class and maximizes a margin with the best tree not in the training class.
        
When it gets a test input, it does greedy merges of regions
using the higher-level representations of the merged regions.
        
This leads to very nice parses of new scenes.
        
You can then take the higher-level representations and
train them to do classificaton (with an SVM, for instance)
        
Questions:
-- 
      },
author = {Socher, Richard and Lin, Cliff Chiung-Yu and Ng, Andrew Y and Manning, Christopher D},
booktitle = {Proceedings of the 28th International Conference on Machine Learning},
file = {:Users/Brenden/Documents/Mendeley/Socher et al. - 2011 - Parsing Natural Scenes and Natural Language.pdf:pdf},
keywords = {NLP,neural networks,recursion},
mendeley-tags = {NLP,neural networks,recursion},
title = {{Parsing Natural Scenes and Natural Language}},
year = {2011}
}
@article{Sodian1991,
author = {Sodian, B and Zaitchik, D and Carey, S},
file = {:Users/Brenden/Documents/Mendeley/Sodian, Zaitchik, Carey - 1991 - Young Children's Differentiation of Hypothetical Beliefs from Evidence.pdf:pdf},
journal = {Child Development},
keywords = {active learning},
mendeley-tags = {active learning},
pages = {753--766},
title = {{Young Children's Differentiation of Hypothetical Beliefs from Evidence}},
volume = {62},
year = {1991}
}
@article{Solomon1994,
author = {Solomon, Joshua A and Pelli, Denis G},
file = {:Users/Brenden/Documents/Mendeley/Solomon, Pelli - 1994 - The visual filter mediating letter identification.pdf:pdf},
journal = {Nature},
keywords = {handwriting},
mendeley-tags = {handwriting},
pages = {395--397},
title = {{The visual filter mediating letter identification}},
volume = {369},
year = {1994}
}
@article{Sommerville2005,
abstract = {An intervention facilitated 3-month-old infants' apprehension of objects either prior to (reach first), or after (watch first) viewing another person grasp similar objects in a visual habituation procedure. Action experience facilitated action perception: reach-first infants focused on the relation between the actor and her goal, but watch-first infants did not. Infants' sensitivity to the actor's goal was correlated with their engagement in object-directed contact with the toys. These findings indicate that infants can rapidly form goal-based action representations and suggest a developmental link between infants' goal directed actions and their ability to detect goals in the actions of others.},
author = {Sommerville, Jessica a and Woodward, Amanda L and Needham, Amy},
doi = {10.1016/j.cognition.2004.07.004},
file = {:Users/Brenden/Documents/Mendeley/Sommerville, Woodward, Needham - 2005 - Action experience alters 3-month-old infants' perception of others' actions.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Attention,Awareness,Child Psychology,Comprehension,Concept Formation,Female,Goals,Habituation,Hand Strength,Humans,Imitative Behavior,Infant,Male,Orientation,Pattern Recognition,Personal Construct Theory,Psychomotor Performance,Psychophysiologic,Visual},
month = may,
number = {1},
pages = {B1--11},
pmid = {15833301},
title = {{Action experience alters 3-month-old infants' perception of others' actions.}},
volume = {96},
year = {2005}
}
@article{Spelke1990,
annote = {Spelke objects: connected wholes, move separately, maintain size and shape, act only on contact
        
four principles
- cohesion
- boundedness
- rigidity
- no action at a distance
        
Adults use other cues, like color, texture, and perceptual goodness, that infants don't use. For instance, two different colored thigns moving together is just one object for infants
        
-----
Many computer vision systems don't try to segment the visual array into objects-- just operate on the whole array
        
But infants seem to do this.
                  
perception
                
Infants perceive a background object, which has an occluder infront of it, as a whole if the occluder moves
+ it is not effected much by visual properies
        
Experiment with rod behind box. Infants are more surprised at the fragmented rod
        
Infants perceive objects as differenet if they move separately, or they are spatially separated
        
But there is no evidence they use maximally regular visual characteristics. Objects of different colors are one unit if they move together.
        
Infants can perceive Gestalt relatoins in other types of experiments, so it's not visual accuity
        
There is also no single time in development when humans begin to perceive all of the Gestalt cues
        
---
        
Some of the same results, like bar behind the occluder, hold up if the task is haptic rather than visual
        
Discontinuity in objet motion helps infants to segment how many objects there are.
                  
conclusions
                
these principles are not sufficient for object segmentation (cannot segment a horse from rider)
- other principles must be opearting
        
object perception may be closely related to intuitive physics
        
adult understanding likely enriches the early abilities, but doesn't replace them
        
object perception is very differen tthan edge-detection or texture segmentation.
        
three proposals for mature object recognition
        
1) maybe people avoid some of the problems of machines, operating at this low-level, by using motion cues
        
2) object segmentatino as a precursor to object recognition
        
3) understanding object perception adn physical knowledge are deeply related},
author = {Spelke, Elizabeth S.},
doi = {10.1207/s15516709cog1401_3},
file = {:Users/Brenden/Documents/Mendeley/Spelke - 1990 - Principles of Object Perception.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
month = jan,
number = {1},
pages = {29--56},
title = {{Principles of Object Perception}},
volume = {14},
year = {1990}
}
@article{Spencer2006,
abstract = {Three experiments tested whether geometric biases--biases away from perceived reference axes--reported in spatial recall tasks with pointing responses generalized to a recognition task that required a verbal response. Seven-year-olds and adults remembered the location of a dot within a rectangle and then either reproduced its location or verbally selected a matching choice dot from a set of colored options. Results demonstrated that geometric biases generalized to verbal responses; however, the spatial span of the choice set influenced performance as well. These data suggest that the same spatial memory process gives rise to both response types in this task. Simulations of a dynamic field model buttress this claim. More generally, these results challenge accounts that posit separate spatial systems for motor and verbal responses.},
author = {Spencer, John P and Simmering, Vanessa R and Schutte, Anne R},
doi = {10.1037/0096-1523.32.2.473},
file = {:Users/Brenden/Documents/Mendeley/Spencer, Simmering, Schutte - 2006 - Toward a formal theory of flexible spatial behavior geometric category biases generalize across poi.pdf:pdf},
issn = {0096-1523},
journal = {Journal of experimental psychology. Human perception and performance},
keywords = {Adult,Age Factors,Child,Form Perception,Form Perception: physiology,Generalization (Psychology),Generalization (Psychology): physiology,Hand,Humans,Memory,Mental Recall,Mental Recall: physiology,Movement,Movement: physiology,Psychological,Psychological Theory,Psychological: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Recognition (Psychology),Recognition (Psychology): physiology,Short-Term,Short-Term: physiology,Signal Detection,Spatial Behavior,Spatial Behavior: physiology,Verbal Behavior,Verbal Behavior: physiology,spatial reasoning},
mendeley-tags = {spatial reasoning},
month = apr,
number = {2},
pages = {473--90},
pmid = {16634683},
title = {{Toward a formal theory of flexible spatial behavior: geometric category biases generalize across pointing and verbal response types.}},
volume = {32},
year = {2006}
}
@article{Sperling1960,
annote = {Main question:
What is available to memory, after a short glance? What is seen in a short glance?

        
--

        

        
More is seen than can be remembered

        
Letters were arranged in a grid
You can only report about 4.5 on average

        
But if you are cued to report a certain row, you can almost report all of them. Thus, people see it all, and it's available for report for a short instance

        
General method:
50 ms},
author = {Sperling, George},
file = {:Users/Brenden/Documents/Mendeley/Sperling - 1960 - The Information Available in Brief Visual Presentations.pdf:pdf},
journal = {Psychological Monographs: General and Applied},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {11},
pages = {1--29},
title = {{The Information Available in Brief Visual Presentations}},
volume = {74},
year = {1960}
}
@inproceedings{Srivastava,
annote = {Images are often annoated with text.
        
Also, sensory perception is inherently mulit-modal. 
        
Can you combine input data from multiple modalities?
        
By learning a joint density, you can fill in a missing modality, and thus do image annotation or image retrieval
- This could be done by doing nearest neighbor with the inferred image and real images
        
Can mix together binary, gaussian units, and repllicated softmax units
                  
modeling tasks
                
generating missing modalities: can sample values of missing visible variables, using gibbs
        
inferring a hidden distribution: variational inference using a fully-factored distribution. Parametrs are not analytical, but estimated with MCMC based stochastic approximation.},
author = {Srivastava, Nitish and Sala},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:Users/Brenden/Documents/Mendeley/Srivastava, Sala - 2012 - Multimodal Learning with Deep Boltzmann Machines.pdf:pdf},
title = {{Multimodal Learning with Deep Boltzmann Machines}},
year = {2012}
}
@inproceedings{Srivastava2013,
author = {Srivastava, Nitish and Salakhutdinov, Ruslan},
booktitle = {Advances in Neural Information Processing Systems 26},
file = {:Users/Brenden/Documents/Mendeley/Srivastava, Salakhutdinov - 2013 - Discriminative Transfer Learning with Tree-based Priors.pdf:pdf},
keywords = {one-shot learning},
mendeley-tags = {one-shot learning},
title = {{Discriminative Transfer Learning with Tree-based Priors}},
year = {2013}
}
@article{St.John1990,
author = {{St. John}, Mark F. and McClelland, James L.},
doi = {10.1016/0004-3702(90)90008-N},
file = {:Users/Brenden/Documents/Mendeley/St. John, McClelland - 1990 - Learning and applying contextual constraints in sentence comprehension.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
month = nov,
number = {1-2},
pages = {217--257},
title = {{Learning and applying contextual constraints in sentence comprehension}},
volume = {46},
year = {1990}
}
@article{Sternberg2013,
abstract = {Making new breakthroughs in understanding the processes underlying human cognition may depend on the availability of very large datasets that have not historically existed in psychology and neuroscience. Lumosity is a web-based cognitive training platform that has grown to include over 600 million cognitive training task results from over 35 million individuals, comprising the largest existing dataset of human cognitive performance. As part of the Human Cognition Project, Lumosity's collaborative research program to understand the human mind, Lumos Labs researchers and external research collaborators have begun to explore this dataset in order uncover novel insights about the correlates of cognitive performance. This paper presents two preliminary demonstrations of some of the kinds of questions that can be examined with the dataset. The first example focuses on replicating known findings relating lifestyle factors to baseline cognitive performance in a demographically diverse, healthy population at a much larger scale than has previously been available. The second example examines a question that would likely be very difficult to study in laboratory-based and existing online experimental research approaches at a large scale: specifically, how learning ability for different types of cognitive tasks changes with age. We hope that these examples will provoke the imagination of researchers who are interested in collaborating to answer fundamental questions about human cognitive performance.},
author = {Sternberg, Daniel a and Ballard, Kacey and Hardy, Joseph L and Katz, Benjamin and Doraiswamy, P Murali and Scanlon, Michael},
doi = {10.3389/fnhum.2013.00292},
file = {:Users/Brenden/Documents/Mendeley/Sternberg et al. - 2013 - The largest human cognitive performance dataset reveals insights into the effects of lifestyle factors and agi.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in human neuroscience},
keywords = {aging,cog,cognition,cognitive enhancement,fluid intelligence,learning,lifestyle factors},
month = jan,
number = {June},
pages = {292},
pmid = {23801955},
title = {{The largest human cognitive performance dataset reveals insights into the effects of lifestyle factors and aging}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3687527&tool=pmcentrez&rendertype=abstract},
volume = {7},
year = {2013}
}
@article{Sternberg2012,
abstract = {How do humans learn contingencies between events? Both pathway-strengthening and inference-based process models have been proposed to explain contingency learning. We propose that each of these processes is used in different conditions. Participants viewed displays that contained single or paired objects and learned which displays were usually followed by the appearance of a dot. Some participants predicted whether the dot would appear before seeing the outcome, whereas other participants were required to respond quickly if the dot appeared shortly after the display. In the prediction task, instructions guiding participants to infer which objects caused the dot to appear were necessary in order for contingencies associated with one object to influence participants' predictions about the object with which it had been paired. In the response task, contingencies associated with one object affected responses to its pair mate irrespective of whether or not participants were given causal instructions. Our results challenge single-mechanism accounts of contingency learning and suggest that the mechanisms underlying performance in the two tasks are distinct.},
annote = {Contingency learning task, where an instructions manipulation (making it more causal) matters in a prediction task but not a fast-paced RT version of the same experiment

        
--------
contingency learning:
- path-strengthening accounts
- explicit inference of causal relations

        
Some think that inference-based tasks can provide a complete account of contingency learning

        
indirect effects: the two accounts make different predictions here

        
blocking:
x1 + x2 -> E
x1 ->  E
effect: leads to x2 being reduced

        
screening:
x1 + x2 -> E
x1 -> not E
effect: x2 strength is increased

        
Both accounts can predict indirect effects, but screening should produce a stronger effect for an inference-based proecess

        
In an inference based account, there is a necessary presumption that causes act independenlty

        
past work: since inference requires mental resources, distractors tasks weaken the inference. Also, should be influencd by instructions

        
path-strengthening should not be affected by instructions

        
Hypothesis:
- with lots of time, participants should do inference task, if they are given instructions
- with little time, instructions shouldln't matter

        
conditions

        
1) causal framing vs. object framing
2) fast-paced (RT) vs. unlimited time prediction task

        
          
method

        
        
48 in prediction task
96 in RT task

        
          
materials

        
        
same stimulin both task (clipart)

        
for RT task, do appeared, and then respond as quickly as possible afterwards -- which shows degree of expectation

        
blocking set: dot follwed 90% of the time for x1 + x2
(so noisey)

        
          
results:

        
        
With the causal framing, in the prediction task, there was a stronger effect of screening off than with the object framing

        
However, framing did not matter in the RT task

        
          
discussion

        
        
indirect effects are driven by inference-based process in the predictoin tsak, but not the fast RT task

        
The computational-level analyses of both tasks is the same -- so it would have to predict why you get different types of performance with different task demands

        
an exemplar model fits data in the prediction task well, when you have just the object-framing},
author = {Sternberg, Daniel a and McClelland, James L},
doi = {10.1177/0956797611429577},
file = {:Users/Brenden/Documents/Mendeley/Sternberg, McClelland - 2012 - Two mechanisms of human contingency learning.pdf:pdf},
issn = {1467-9280},
journal = {Psychological science},
keywords = {Association Learning,Association Learning: physiology,Cues,Humans,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,causal reasoning},
mendeley-tags = {causal reasoning},
month = jan,
number = {1},
pages = {59--68},
pmid = {22198929},
title = {{Two mechanisms of human contingency learning.}},
volume = {23},
year = {2012}
}
@article{Stevenage1998,
author = {Stevenage, S V},
journal = {British Journal of Psychology},
pages = {39--57},
title = {{Which twin are you? A demonstration of induced categorical perception of identical twin faces}},
volume = {89},
year = {1998}
}
@inproceedings{Stewart2012,
annote = {Basic operatoins
        
- convert input vector into spiking neurons, where activity is coded by a preferred vector
- can use optimal linear decoder to reconstruct vector form spikes
- can set weights w, between layers, to correspond to matrix multiplication with a certain matrix m
        
This allows us to convert high-level alogrithm written as vectors into detailed spiking neurons
        
Memory can be incoded by a current connection with the identity matrix
        
action selection: a neural production system
- you can convert rules into functions, and use the resulting synaptic connection weights betwee cortex, basal ganglia, and thalamus
                  
Task 1: digit recognition        
Recognition accuracy, on MNIST, is about 94% correct. It responds by producing the digit in a canonical style.
                  
Task 2: tracing from memory        
do digit recognition, but draw its response in the same style as the original input
        
This looks okay, not great. Genreally captures the slant, or the loops in a 2 (or not) etc.
                  
Task 3: Serial working memory        
Can record a sequence of digits, with a single population of working memory neruosn
- You have representations for each serial position, and convolve the number seen with the position marker
- as sequence gets long, accuray decreaes, and it has both primacy and recency effets
                  
Task 4:        Question answering        
Show sequence, ask what is in position 5, and correlatoin the 5 marker with the stored trace, to retrieve the right answer
        
Also, can query "what positin was the digit 6?" By circular correlatoin with the 6 representation
                  
Task 5: Addition by counting        
USes several working memory stores, and increments the number as many times as it says to by 1
                  
Task 6: Pattern completion        
Can convert 0094 -> 94
and then do it for arbitrary patterns
                  
Discussion
                
All weights were anlytically dervied -- how could they be learned?
        
reinforcement learning account, described in another paper
        
      },
author = {Stewart, Terrence C and Choo, Feng-Xuan and Eliasmith, Chris},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Stewart, Choo, Eliasmith - 2012 - Spaun A Perception-Cognition-Action Model Using Spiking Neurons.pdf:pdf},
keywords = {as a,cognitive architecture,cognitive control,consists of idealized and,digits and symbols,figure 1a,hand-written,input to the model,neural engineering,spiking neurons,these images are given,whole-brain systems},
pages = {1018--1023},
title = {{Spaun: A Perception-Cognition-Action Model Using Spiking Neurons}},
year = {2012}
}
@phdthesis{Stromsten2002,
author = {Stromsten, S B},
school = {Stanford University},
title = {{Classification learning from both classified and unclassified examples}},
year = {2002}
}
@article{Stromswold1996,
abstract = {Positron Emission Tomography (PET) was used to determine regional cerebral blood flow (rCBF) when eight normal right-handed males read and made acceptability judgments about sentences. rCBF was greater in Broca's area (particularly in the pars opercularis) when subjects judged the semantic plausibility of syntactically more complex sentences as compared to syntactically less complex sentences. rCBF was greater in left perisylvian language areas when subjects had to decide whether sentences were semantically plausible than when subjects had to decide whether syntactically identical sentences contained a nonsense word. The results of this experiment suggest that overall sentence processing occurs in regions of the left perisylvian association cortex. The results also provide evidence that one particular aspect of sentence processing (the process that corresponds to the greater difficulty of comprehending center-embedded than right-branching relative clause sentences) is centered in the pars opercularis of Broca's area. This process is likely to be related to the greater memory load associated with processing center-embedded sentences.},
author = {Stromswold, K and Caplan, D and Alpert, N and Rauch, S},
doi = {10.1006/brln.1996.0024},
file = {:Users/Brenden/Documents/Mendeley/Stromswold et al. - 1996 - Localization of syntactic comprehension by positron emission tomography.pdf:pdf},
issn = {0093-934X},
journal = {Brain and language},
keywords = {Adult,Frontal Lobe,Frontal Lobe: blood supply,Frontal Lobe: physiology,Frontal Lobe: radionuclide imaging,Humans,Language,Male,Reaction Time,Regional Blood Flow,Semantics,Tomography, Emission-Computed},
month = mar,
number = {3},
pages = {452--73},
pmid = {8653390},
title = {{Localization of syntactic comprehension by positron emission tomography.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8653390},
volume = {52},
year = {1996}
}
@inproceedings{Stuhlmuller2010,
annote = {Many types of real objects: car, house, tree, human body have rich interal structure, more so than just a prototype},
author = {Stuhlmuller, Andreas and Tenenbaum, Joshua B and Goodman, Noah D},
booktitle = {{Proceedings of the Thirty-Second Annual Conference of the Cognitive Science Society}},
file = {:Users/Brenden/Documents/Mendeley/Stuhlmuller, Tenenbaum, Goodman - 2010 - Learning Structured Generative Concepts.pdf:pdf},
keywords = {part-based models,program induction},
mendeley-tags = {part-based models,program induction},
title = {{Learning Structured Generative Concepts}},
year = {2010}
}
@inproceedings{Sudderth2005,
annote = {Transformed Dirichlet Process (TDP): Extension of the HDP. Groups are defined by a mixture model, which shares mixture components between groups (this is a standard HDP). 
        
However, this means the parameters must be exactly shared between groups. The TDP allows a mixture component (shared between groups) to have a separate transformation for each group (like a translation, etc.).
        
This is motivated by visual scene understanding, where the component "car" should be allowed to appear in multiple locations in th e image.
        
      },
author = {Sudderth, Erik B and Torralba, Antonio and Freeman, William T and Willsky, Alan S},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:Users/Brenden/Documents/Mendeley/Sudderth et al. - 2005 - Describing Visual Scenes using Transformed Dirichlet Processes.pdf:pdf},
keywords = {non-parametric Bayes,one-shot learning,part-based models},
mendeley-tags = {non-parametric Bayes,one-shot learning,part-based models},
title = {{Describing Visual Scenes using Transformed Dirichlet Processes}},
year = {2005}
}
@article{Sudderth2008,
annote = {Unlike traditional hiearchical DP, transformed DPs allow a transformation of each part before it is instaniated in the image. This allows for much richer sharing, where parts can appear in multiple places. 
        
Object classes are a collection of parts (a mixture model), which are shared across the different object classes (a global mixture). Each part defines a distribution on features (like SIFT) and locations. Thus, an image (and it's set of features) is a draw from the object-class-specific mixture.
        
---
Transformed Dirichlet Process (TDP): Extension of the HDP. Groups are defined by a mixture model, which shares mixture components between groups (this is a standard HDP). 
        
However, this means the parameters must be exactly shared between groups. The TDP allows a mixture component (shared between groups) to have a separate transformation for each group (like a translation, etc.).
        
This is motivated by visual scene understanding, where the component "car" should be allowed to appear in multiple locations in the image.
        
--
Share information in three ways
1) parts define a common low-level feature vocabularly
2) objects are defined using a common set of parts
3) object appearance information is shared
        
This sharing can be useful for learning from just a few examples.
        
Based on transformed Dirichelt Processes (TDP), which is an extension of HDPs to transformations
        
Traditional topic models, if trying to model the appearance and location of features as a bag of featues, would need a different "topic" for each location of an object. Clearly this isn't practical.
        
Instead, they model the object position as a transforation, relative to a canonical reference frame. You can also have intvertible affine transformations.},
author = {Sudderth, Erik B and Torralba, Antonio and Freeman, William T and Willsky, Alan S},
doi = {10.1007/s11263-007-0069-5},
file = {:Users/Brenden/Documents/Mendeley/Sudderth et al. - 2008 - Describing Visual Scenes Using Transformed Objects and Parts.pdf:pdf},
journal = {International Journal of Computer Vision},
keywords = {classic AI,context,dirichlet process,graphical models,hierarchical dirichlet process,non-parametric Bayes,object recognition,part-based models,scene analysis,transformation},
mendeley-tags = {classic AI,non-parametric Bayes,part-based models},
title = {{Describing Visual Scenes Using Transformed Objects and Parts}},
volume = {77},
year = {2008}
}
@article{Suen1983,
annote = {Left-handers are worse at recognizing letters, in a variety of scripts, when compared with right handers. (about 10% worse)
        
Right-handers also write letters that are more recognizable, when compared to left-handers.
        
----
        
Also asked participants to write very characters from foreign alphabets, using a particular model way of drawing it.},
author = {Suen, Ching Y},
file = {:Users/Brenden/Documents/Mendeley/Suen - 1983 - Handwriting generation, perception, and recognition.pdf:pdf},
journal = {Acta Psychologica},
keywords = {handwriting},
mendeley-tags = {handwriting},
pages = {295--312},
title = {{Handwriting generation, perception, and recognition}},
year = {1983}
}
@article{Sulin1974,
author = {Sulin, Rebecca A and Dooling, D James},
doi = {10.1037/h0036846},
file = {:Users/Brenden/Documents/Mendeley/Sulin, Dooling - 1974 - Intrusion of a thematic idea in retention of prose.pdf:pdf},
issn = {0022-1015},
journal = {Journal of Experimental Psychology},
number = {2},
pages = {255--262},
title = {{Intrusion of a thematic idea in retention of prose}},
volume = {103},
year = {1974}
}
@article{Summerfield2012,
annote = {Evidence for predictive codes in categorization task.
        
How do we decide whether something is a face vs. a house vs. a car? Drift-diffusion model assumes we passively acquire evidence. But another model assumes we have a predictive store (like images of faces), and we compare incoming stimuli to this (like an exemplar model?)
        
To test, they had participants see faces vs. houses vs. cars each embedded in lots of noise (66% correct). They were looking for one type (faces or houses) vs. the others.
        
There was frontal activation for type of task (faces vs. houses), which used the same stimuli. This is evidence for a predictive store. Other areas are active for faces.},
author = {Summerfield, Christopher and Egner, Tobias and Greene, Matthew and Koechlin, Etienne and Mangels, Jennifer and Hirsch, Joy},
file = {:Users/Brenden/Documents/Mendeley/Summerfield et al. - 2012 - Predictive Codes for Forthcoming Perception in the Frontal Cortex.pdf:pdf},
journal = {Science},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {5803},
pages = {1311--1314},
title = {{Predictive Codes for Forthcoming Perception in the Frontal Cortex}},
volume = {314},
year = {2012}
}
@article{Sun2009,
author = {Sun, Wenguang and Cai, T Tony},
file = {:Users/Brenden/Documents/Mendeley/Sun, Cai - 2009 - Large-scale multiple testing under dependence.pdf:pdf},
journal = {Journal of the Royal Statistical Society Series B},
keywords = {compound decision problem,false discovery rate,hidden markov models,local,multiple testing under dependence,significance index,statistics},
mendeley-tags = {statistics},
title = {{Large-scale multiple testing under dependence}},
volume = {71},
year = {2009}
}
@unpublished{Szegedy2013,
annote = {Weird discovery 1:
Often, the top-level units are interpreted by finding the images in the training set for which they are maximally activated

        
But, if you take a random projection across the top-level units (a unit vector v), and see where this is most activated, you get a very similar response. This suggests the top-level space is still distributed, and individual units are not playing easily identifiable roles

        
Weird discovery 2:

        
Optimization problem where you try to find a minimal perturbation that classifiers an image as someting else
+ often you get an image that is so similar you can't perceive the difference, but you can assign it to arbitrary classes

        
these images often produce errors on other networks with different hyper-parameters and architectures (but to a smaller extent)

        
It can even work for a network given a different training set -- this is very weird... so is it just doing a fancy nearest neighbors?

        

      },
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6199v1},
author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
eprint = {arXiv:1312.6199v1},
file = {:Users/Brenden/Documents/Mendeley/Szegedy et al. - 2013 - Intriguing properties of neural networks.pdf:pdf},
title = {{Intriguing properties of neural networks}},
url = {http://arxiv.org/abs/1312.6199},
year = {2013}
}
@article{Tan2005,
abstract = {Language development entails four fundamental and interactive abilities: listening, speaking, reading, and writing. Over the past four decades, a large body of evidence has indicated that reading acquisition is strongly associated with a child's listening skills, particularly the child's sensitivity to phonological structures of spoken language. Furthermore, it has been hypothesized that the close relationship between reading and listening is manifested universally across languages and that behavioral remediation using strategies addressing phonological awareness alleviates reading difficulties in dyslexics. The prevailing view of the central role of phonological awareness in reading development is largely based on studies using Western (alphabetic) languages, which are based on phonology. The Chinese language provides a unique medium for testing this notion, because logographic characters in Chinese are based on meaning rather than phonology. Here we show that the ability to read Chinese is strongly related to a child's writing skills and that the relationship between phonological awareness and Chinese reading is much weaker than that in reports regarding alphabetic languages. We propose that the role of logograph writing in reading development is mediated by two possibly interacting mechanisms. The first is orthographic awareness, which facilitates the development of coherent, effective links among visual symbols, phonology, and semantics; the second involves the establishment of motor programs that lead to the formation of long-term motor memories of Chinese characters. These findings yield a unique insight into how cognitive systems responsible for reading development and reading disability interact, and they challenge the prominent phonological awareness view.},
annote = {Reading ability of Chinese children (ages 7-10) is more strongly predicted by their writing ability than their awareness of phonemes.
        
----
Most theories of language learning maintain the centrality of phnological sensitivity. Thus, reading builds on spoken language abilities.
        
Chinese is different, since many of the phonemes sound the same, and they are insufficient to access semantic of a printed character.
        
For instance, "shi" maps to many different characters and many different meanings.
        
Teaching methods in schools usually involve writing a character many types, and facilities children's awareness of internal structure.
                  
Experiment 1
                
Subjets: school children from 7-10
        
Method:
Tested children on 
1) speed writing
2) phonological discrimination, or ability to delete syllables
3) Rapid automatized naming for simple digits
        
There abilities were used to predict reading ability of Chinese characters.
        
Partially out estimate of IQ, writing ability was the strongest predictor of reading ability.          
          
Experiment 2:        
Is it learning about internal structure, or a general motor competency, that influences reading?
Comapred students on the ability to draw pseudocharacters (that followed Chinese ortogrpahic constraints) and also other symbols, to see which predicts reading performance.
        
Both were significantly correlated with reading ability, but pseudocharaters more strongly. Also, there was a lag, such that picture drawing correlated more strongly for intermediate rather than beginning readers.
        
This provides some evidence for both an orthographic and a motor-based influence in writing.
        
Previous research has shown that copying of characters does not predict writing in English, but here they show the opposite results for Chinese.},
author = {Tan, Li Hai and Spinks, John a and Eden, Guinevere F and Perfetti, Charles a and Siok, Wai Ting},
doi = {10.1073/pnas.0503523102},
file = {:Users/Brenden/Documents/Mendeley/Tan et al. - 2005 - Reading depends on writing, in Chinese.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Asian Continental Ancestry Group,Child,China,Cognition,Cognition: physiology,Humans,Language,Language Tests,Learning,Learning: physiology,Models,Psychological,Reading,Regression Analysis,Semantics,Writing,embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
month = jun,
number = {24},
pages = {8781--5},
pmid = {15939871},
title = {{Reading depends on writing, in Chinese.}},
volume = {102},
year = {2005}
}
@article{Tanaka1991,
annote = {The psychological status of the basic level: can it be modified by experience?
        
Main findings
In the domain of expertise,
a) subordinate-level differentiated like basic level
b) subordinate-level names were used as frequently as basic level names
c) subordinate-level categorization was a fast as basic level
        
---
-Rosch used a working assumption that the basic level is bundles in the perceived world.
-But this is not indepdent of the mind
        
        Experiment 1: Feature lists        
Subjects were dog experts or bird experts -- belong to club, and recommended by other members
Instructions: list as many attributes that you can think of to describe th objects
Design: compare the bird experts for dogs and birds, versus the dog experts for the same
Results: People listed as many new features in the expert domain
        
Other analysis:
-- bird experts listed more new behaviors at the subordinate level, comapred to dogs
-- the amount of part information listed at the levels distinguish dog experts and novices, but not bird experts and novices
                  
Experiment 2:  Free naming study        
Instructions: asked to name four dog and bird exemplars as quickly as possible
Stimuli: very common birds and dogs
Results: Both groups were more likely to use subordinate name, but more so for the bird experts.
This is because naming is more central to bird watching, than for dog experts.
                  
Experiment 3: Category Verificationg
Usual effect: people are fastest at respond to the basic level
-- Instructions: respond yes/no to a name and picture pair
-- Subjects were familiarized with range of stimuli beforehand
-- Results: experts are as fast as the basic level, for their domain of expertise},
author = {Tanaka, James W and Taylor, Marjorie},
doi = {10.1016/0010-0285(91)90016-H},
file = {:Users/Brenden/Documents/Mendeley/Tanaka, Taylor - 1991 - Object Categories and Expertise Is the Basic Level in the Eye of the Beholder.pdf:pdf},
issn = {00100285},
journal = {Cognitive Psychology},
keywords = {classic psychology,classics on concepts,perceptual expertise},
mendeley-tags = {classic psychology,classics on concepts,perceptual expertise},
month = jul,
number = {3},
pages = {457--482},
title = {{Object Categories and Expertise: Is the Basic Level in the Eye of the Beholder?}},
volume = {23},
year = {1991}
}
@article{TanenhausMichaelKSpivey-KnowltonMichaelJEberhardKathleenMSedivy1995,
author = {Tanenhaus, Michael K and Spivey-Knowlton, Michael J and Eberhard, Kathleen M and Sedivy, Julie C},
file = {:Users/Brenden/Documents/Mendeley/Tanenhaus et al. - 1995 - Integration of Visual and Linguistic Information in Spoken Language Comprehension.pdf:pdf},
journal = {Science},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {5217},
pages = {1632--1634},
title = {{Integration of Visual and Linguistic Information in Spoken Language Comprehension}},
volume = {268},
year = {1995}
}
@article{Transactions1990,
author = {Tappert, C C and Suen, Ching Y and Wakahara, T},
file = {:Users/Brenden/Documents/Mendeley/Tappert, Suen, Wakahara - 1990 - The State of the Art in On-Line Handwriting.pdf:pdf},
journal = {{IEEE Transactions on Pattern Analysis and Machine Intelligence}},
keywords = {handwriting},
mendeley-tags = {handwriting},
number = {8},
pages = {787--808},
title = {{The State of the Art in On-Line Handwriting}},
volume = {12},
year = {1990}
}
@article{Teglas2011,
abstract = {Many organisms can predict future events from the statistics of past experience, but humans also excel at making predictions by pure reasoning: integrating multiple sources of information, guided by abstract knowledge, to form rational expectations about novel situations, never directly experienced. Here, we show that this reasoning is surprisingly rich, powerful, and coherent even in preverbal infants. When 12-month-old infants view complex displays of multiple moving objects, they form time-varying expectations about future events that are a systematic and rational function of several stimulus variables. Infants' looking times are consistent with a Bayesian ideal observer embodying abstract principles of object motion. The model explains infants' statistical expectations and classic qualitative findings about object cognition in younger babies, not originally viewed as probabilistic inferences.},
author = {T\'{e}gl\'{a}s, Erno and Vul, Edward and Girotto, Vittorio and Gonzalez, Michel and Tenenbaum, Joshua B and Bonatti, Luca L},
doi = {10.1126/science.1196404},
file = {:Users/Brenden/Documents/Mendeley/T\'{e}gl\'{a}s et al. - 2011 - Pure reasoning in 12-month-old infants as probabilistic inference.pdf:pdf;:Users/Brenden/Documents/Mendeley/T\'{e}gl\'{a}s et al. - 2011 - Pure reasoning in 12-month-old infants as probabilistic inference(2).pdf:pdf},
issn = {1095-9203},
journal = {Science},
keywords = {Bayes Theorem,Child Development,Cognition,Female,Humans,Infant,Male,Models,Monte Carlo Method,Probability,Statistical,Visual Perception},
month = may,
number = {6033},
pages = {1054--9},
pmid = {21617069},
title = {{Pure reasoning in 12-month-old infants as probabilistic inference.}},
volume = {332},
year = {2011}
}
@article{Teh2006,
annote = {Introduced the Hierarchical Dirichlet Process (HDP). Useful for when data comes from a set of groups, but you want to allow sharing between the groups.
        
Example: supervised categorization. If you want a cluster model to represent a category (between an exemplar and prototype), then you have a cluster model. The HDP allows the sharing of clusters between categories.},
author = {Teh, Yee Whye and Jordan, Michael I and Beal, Matthew J and Blei, David M},
doi = {10.1198/016214506000000302},
file = {:Users/Brenden/Documents/Mendeley/Teh et al. - 2006 - Hierarchical Dirichlet Processes.pdf:pdf},
journal = {Journal of the American Statistical Association},
keywords = {classic AI,clustering,hierarchical model,markov chain monte carlo,mixture model,non-parametric Bayes,nonparametric bayesian statistics},
mendeley-tags = {classic AI,non-parametric Bayes},
number = {476},
pages = {1566--1581},
title = {{Hierarchical Dirichlet Processes}},
volume = {101},
year = {2006}
}
@phdthesis{Tenenbaum1999,
annote = {To read:
Vapnik, 1995; Valiant, 1984 etc.
Keil, 1979, M constraint                  
        
My thesis: how do we learn complex concepts from just one or a few examples? Previous work has shown how we learn complex concepts, or learn quickly, but those only use the simplest concepts.
-- 
        
Summary:
        
Bayesian model of concept learning, applied to 3 case studies:
1) 2D box concepts
2) Word learning
3) Number game
        
Human concept learning is fundamentally a problem of learning from just a few positive examples, where most computational models of learning involve many positive and negative examples.
        
Josh's studies typically presented all "training data" at once, so as not to confound memory and generalization like most category learning tasks
        
For word learning, generalization an asymptote after just 3 examples, and become all or none.
        
Says that people are particularly puzzling from standpoint of learning theory, since they learn rich concepts from very little data
+ But while the these explores learning very simple concepts from little data, it doesn't deliver on how people learn rich concepts
        
Also, Josh only really deals with "classical concepts" that can be defined by a rule.
        
----
Introduction        
Children can learn concepts from very limited evidence, and we still don't understand this ability
+ only need a few positive examples
+ computers don't come close to the everyday achievements of any child
        
Goals
1) account for how concept learning is even possible
2) explain most central empirical phenoma
3) suggest how artificial systems can begin to approach people's abilities
        
contributes to "rational" cognitive science, not a mechanistic theory
- it is a theory of knowledge, in the traditions of Chomsky and Marr, and computation
        
Message for psychologists:
- think more like computer scientists, focusing on analysis of hard computational problem
Message for computer scientist:
- think more like psychologists, focusing on learning situations that play the most important roles in human cognition and evaluating our models here
        
Both fields have tendency to focus on problems that are more tractable than relevant, which is probably wise
        
Confronts some classical questions of concept learning and induction:
- more pre-existing knowledge or statistical force?
- rules or similarity?
In all these situations, the only reasonable answer is "Both"
Bayes allows much more penetrating versions of these questions
        
Chapter 1
        
Vocabulary and background
        
Parents most often provide positive labels "see the doggie" but rarely negative (that is not a dog)
+ however, don't they get implicit negative evidence through other labels?
        
Thesis focuses on small number of positive examples sampled at random from a concept, because that is the basic situation in word learning
+ but want to be able to leave room for negative evidence
        
Number game        
- If 6 is in the concept, that's not enough information
- 2,8,64, this is enough, perhaps powers of 2
amazingly, the concept sharpens very quickly
        
There are billions of possible subsets, yet we have narrowed in on just one
        
This game highlights the essential inductive challenge
        
Learning to use words, learning scene concepts, and guessing numerical concepts have, at their core, the same computational problem: they all require the learner to infer "how far" and "in what ways" should we generalize a concept
        
the major result in computational learning theory:
- the broader and more cpomlex the range of concepts a learner is capable of acquiring, the more examples you need (see Vapnik, 1995)
- human concept learning is a thorny challenge from this perspective, needing to learn rich concepts from just a few examples
+ on their own, these problems would be much less difficult
        
This is the great challenge of machine concept learning
        
        Rule-based approaches to induction (and why they don't work)
        
      Classic rule models consider only a small set of candidates for the concept extension, those consistent with prior knowledge
+ try to rule out other hypotheses
+ See Hovland
+ cannot generalize from just a few examples
        
There needs to be prior knowledge to learn from a few examples:
Goodman (1955) "all emeralds are green" is just as consistent with "all emeralds are grue", where grue is green before year 200 and blue afterwards
        
Cognitive development researchers have seized on the importance of constraints for learning
+ M-constraint (Keil, 1979)
        
Real problem of rule-based approach is that is tries to force induction into rigorous but too-narrow world of deductive inference
        
Ranked hypothesis elimination - a priori ranking of likelihood of hypotheses, and choose the best one at any given point
+ but people do not make up their minds from just onedata point
+ you might want to change ranking as data comes in -- but you need a formal account of this, and Bayes provides one such answer
        
Why doesn't it work?
-We don't generalize by just one hypothesis
-We learn very quickly from just a few examples
        
Similarity based approach (and why it doesn't work either)
        
Philosophers since Hume has been interested in similarity, and Wittgenstein (1953) suggets a "family resemblance" view of concepts
        
Relates to exemplar theories of classification
+ also nearest neighbors in machine learning
+ most of these were developed for discriminative machine learning, and you need negative examples to do something useful with it (is this true for exemplar models? -- depends on what the task is)
        
But successfully captures not "all-or-none" patterns seen with rule-based learing
        
How do you evaluate similarity fo an example to a set? 
+ there isn't an established way (what about exemplar rule?.. I guess you still have to combine it), but you culd do total, average, max, etc.
        
Doesn't work for number game, since 32 becomes more likely after [2,8,16,64] rather than just [16], altough it is not more smimilar to these new numbers
+ some cases seem more like max similarity, other more like average
        
You can make similarity more flexibile with an exemplar model an features, where you learn feature weights
+ but how do you assign weights to rules? Same problem was rule-based learning and a priori ordering
        
Two strategies for builing a more complete theory
        
1) Unified
Combine aspets of both rules and similarity, by putting probabilities on rule-based approach, explaining why generalization sometimes looks rule-like and other times does not
+ why use rules as basis, not similarity? 
++ we have a strong intuition that rules play an important role, and it was the only game in town for Goodnow et al.
        
Essentialism is our attempt to rescue rule-based concept learning, even if we don't know the rule, we still believe there is one
        
Rules are not a sufficient basis for concepts, but give the number of smart people who have argued for them, there might be something about it worth keeping
        
Rules can be combined, in compositional ways, which people like Fodor believe are essential qualities of concepts
        
Features are rules in disguise, where they pick out sets of concepts
        
Non-trivial general finding of MDS is that generalization can be derived as an exponential decaying function of distance in psychological space
+ this can be derived as the probability of them both belonging to an arbitrarily chosen "consequential region" of psychological space
        
Strategy 2: a modular theory
        
Acknowledge importance of both, and treat them as separate (with a controller perhaps)
+ Ashby?
        
Similar proposals in reasoning
(Sloman,1996) and language (Pinker, 1991)
        
Even if we know there were these two modules, we would still have a lot of questions:
- why is it divided into two systems?
- why are there just two?
- how does each learn from examples?
- how do they interact?
        
Chapter 2: A solution proposed
        
Two different theories (rules and similarity) account for different aspects
        
Draws on a lot of different influences of this model
        
Need notion of "Generative model" of data to have a suspicious coincidence
        
Strong sampling: label + concept -> example
Weak sampling: example + concept -> label
        
H: hypothesis space
X: observation space
        
Size principle operates in the strong sampling case, to explain why tighter hypotheses get more weight
        
the prior
        
Can be highly dependent on the situation. If data from the number game were instead healthy cholesterol levels, we would have different expectations
        
the likelihood
        
Different learning scenarios:
strong sampling, weak sampling, feedback (learner uses concepts, get reinforcement), helpful teacher (must be optimally informative)
        
with strong sampling, we get the size principle
        
You can predict new data points by computing the posterior predictive distribution (the probability of generalization)
        
Alternative to the size principle is to use binary likelihoods (P(X|H) = 1 or 0). But how is this a valid density? Implicity, we have a P(L|,XH) P(X) P(H) here, where X comes from an independent process. This would just cancel out in the denominator in Bayes rule
        
incorporating other models
- rule-based hypothesis
- ranked rules is like the prior on rules
- MIN: rule to choose the smallest concept is a special case of the size principle
+ problem with MIN: it can only become broader over time, which becomes equivalent after enough samples. But it is just too conservative to model people
++ Related to Feldman's work
- MAP algorithm: 
- Weak Bayes: corresponds to feature based models, where you count up the number of features (hypotheses) they share, and if they have a prior, they are weighted. This then shows the amount of generalization.
++ But you don't get the rapid generalization you need
        
Case study 1: Learning concepts in a continuous feature space
        
Case studies show fit to human data, and explain how different hypothesis spaces can bring different types of behavior (more rule like or similarity like, perhaps)
        
Why would have a square 2D concept? Maybe healthy levels of cholesterol and insulin
        
Also, directly inspired by Shepart, which used 2D axis-aligned rectangle concepts
        
Other models
-similarity could be exponential decaying function of city-block distance
-min rule is like that used in Bruenr and Feldman
        
Main difference between this and number game is continuous space, but all machinery of probability theory carries over to continuous spaces
+ still get a size principle in continuous space
        
Can put uninformative prior on scale and length of hypotheses, or maximum entropy if we know an expected size, etc.
        
We get exponential fall-off because small hypotheses exert more weight than large ones,
+ broad pattern of generalization from a few examples, but much sharper generalization when we have many examples, since likelihood goes to the nth power
        
This is a bit like "shrinking" or "broadening" dimensions in an exemplar model, and some models can learn these parameters, but they typically need many examples (positive and negative) to dos 
        
Experiment 1
Showed participants 200 trials, where each one was a different concept. 
+ shows all examples, so it doesn't confound induction with memory
        
Showed points generated from rectangle, and they were asked to guess the rectangle as accurately as possible
        
Think of point as health blood levels of two different substances, and these were randomly chosen healthy individuals
+ 24 practice trials were they were shown after their guess the "true" rectangle that the dots were from
++ could they just learn the task here?
        
Results:
        
Looked at the "range spanned by n examples" plotted against the extent of generalization from those n
- people generalize more with less data, and more when the range is increased. 
- however, the simple models don't do either of these things, and generalize in a flat way regardless of range or number of data points
        
- uninformative prior doesn't capture the right non-linear dependence, but the expected range prior does
        
Training artifact?
        
24 examples wouldn't be enough to learn an arbitrary smooth real-function of two variables, which is how the data was anaylzed
+ but people can learn a new concept from one example?
        
If you fit a linear model to these statistics, none of the trends people seemed to express come out at all clearly
        
Individual subjects were very consistent
        
Was it due to the particular graphical user interface?
        
Experiment 2
        
Same thing, but using straightforward numerical representation
        
Only showed one set of numbers per trial, rather than two dimensions
        
Otherwise, same cover story
        
Critiques of the Bayesian approach
        
Computation: intractable for realistic problems
- but in this case, they were able to compute exact expressions for the integrals
+ closed form solution depends on only a few obvious characteristics
        
Make strong assumptions about hypotheses, and have no good way to explain data if they are violated
+But Josh seems this as a point in their favor for human concepts
+humans need strong assumptions to learn from very little
+ PAC framework needs 100 examples to get below 5% error wit95% confidence, but most learning for people happen between 2 and 10 examples
+ If we want model to learn fast, like people, they will have to be incorrect sometimes
        
Data  driven vs. knowledge driven
        
Data drive most often embraced by category learning in artificial environments, while knowledge drive is embraced by researchers studying natural concepts (Murphy, Medin, Carey, Fodor)
        
Bayes takes both knowledge and data seriously.
        
Switch enzyme in blood to environment toxin level, and you get very different inferences -- shows importance of prior knowledge
        
Chapter 4: Learning words
        
Previous study was so simple that it was also it's most obvious shortcoming.
        
Quine's Gavagi problem
        
Carey, Markman, Bloom etc. have all studied fast mapping to some extent
        
constraints tradition
Markman's taxonomic bias helps child link "dog" to either labradaors, dogs, animals, or mammals in a tree, rather than black things or thematic things
+ also, mutual exclusivity, where if something is called a "dog", we shouldn't attach the word "cat" to it as well
+ also, the Basic level constraint in the word learning, which would help solve the induction problem
++ but how do we learn all the other words we know then?
        
data-drive tradition
- Smith: generalization based on similarity in feature space
- shape bias, which children show initially (but it does not apply to animate objects which are known to change shape spontaneously)
        
Task with "natural-like" taxonomies for which we want to learn a new word
        
superordinate level categories: vegetable, vehicles, animals,
+ also had one basic level match and one sub-ordinate match
        
Received different labeled sets including
1 subordinate
3 subordinates (same exact objet(
3 basic
3 superordiantes
        
On each trial, participants given a few "blickets" were asked to pick out the other objets in its extension
        
Similarity ratings aftewards
        
        
results
        
shaper generalization when observing more examples, from just a single category
- different qualitative patterns, which go beyond results in the literature
        
Models of concept learning applied to learning words
        
Normazlied measure of similarity for all pairs of objects
        
Assumed people use hypotheses they used for designing stimuli?
        
hierarchical clustering with average-link clustering, where distinctiveness is in terms of distance of the clusters
- only get tree structure, which is equivalent to the M-constraint
        
Models based on rules
        
Min rule, or pick smallest hypothesis consistent with all examples, has been proposed (Berwicik, Clark)
- works for trials where people generalized in all or ntohig fashion, but does not work when you only have one label
        
Seems like participants did not infer a single rule
        
Similarity models
        
Average similarity performs poorly, where 1 vs 3 examples have the same predictions
        
Strong Bayesian mdoel
        
Prior: branch length, or height(parent) - hiegh(node), which is a measure of distinctiveness
        
Likelihood (1/hieght) of cluster (or average within-class similarity)
        
Leads to a much better fit, which gets even better with a basic level bias
        
People treat words as if they are picking out an objet from that word's extension, at random (is this really accurate?)
        
Exemplar models, Krushke, etc. have not shown their models to be applicable to the biggest challenges like learning words for natural object kinds
        
John Stuart Mills: sometimes a single case is good enough for induction, in other cases, a huge number isn't good enough. How is this possible?
        
In word learning, generalizations are all-or-none after only three examples!
        
Discussion
        
Generalization is faster in word learning study than in rectangles, because the hypotheses are less overlapping
        
In Feldman (1997), generalization was always one-shot, since the smaller hypotheses were essentially infinitely smaller
+ people restrict their generalization to the most specific categories 90% of the trials in Feldman
        
Chapter 3: The number game
        
additive clustering: representing similarity between two objects as a sum over features and weights, whether they get the weight if they both have features
+ this can be used to put weights on hypotheses in a prior
        
You can do this for all pairwise similarities of numbers 0-9, but not for all numbers between 0-100. But you can use the same types of hypotheses
        
Distribute weight hierarchically:
- math vs. magnitude properties: first weight that split
- magnitude: erlang distribution (free parameters)
-
Patterns of generalization: rules and similarity
        
Depending on the examples, it can exhibit rule like behavior. Otherwise, it generalizes with a simple similarity gradient
        
Experiment
        
Given examples of numbers program accepts
- given 30 probe numbers, between 1 and 100, and rate each one on a scale 1 to 7, with a corresponding probability of acceptance
        
Model parameters were chosen based on intuition before experiment, but not adjusted afterwards
        
Discussion
        
Might need hyppothes that are bounded within a particular range of 10
        
"3 times a charm", having 3 identical observations is generally much more powerful than just 2 -- could be explanation of that
        
Tversky's model of similarity has interpretation in BAyesian generalization function:
where there is a tradeoff between number of hypotheses consistent with both data points, compared to number of hypotheses (features) consistent with one and not the other (the observed point, not the test point)
        
Also predicts asymmetry of generalization that you get with Tversky's model, without having to fit special parameters
        
Chapter 6: Summary and conclusions
        
How can people acquire such a rich range of possible concepts from the very limited evidence -- one or a few positive examples?
        
Major contributions
        
How is concept learning possible?
+ previous accounts, rule and similarity based, have run into trouble
        
Quantitative modeling of generalization
- a few domains, and few free parameters, same framework
        
The appearance of rule-like and similarity-like generalization
- all or none generalization, vs fuzzy hypothesis averaging, and size principle allows for transition
        
The interaction of prior knowledge and observed examples in concept learning
- the importance of prior knowledge and intuitive theories is critical (Murphy & Medin, Carey, etc.)
- framework allows for domain-specific prior knowledge and general-purpose statistical principles
        
Other directions
        
ASpects that do not map well to human behavior:
- order dependence
+ either approximate inference, or models that do not make stationary assumptions
        
Implications for machine learning
- don't be so afraid at jumping to conclusions, like traditional learning theories
        
Where do the prior come from?
- they could be learned through unsupervised learning
(which was Charles's thesis)
        
What makes a good example of a concept?
- even "odd number" has typicality gradient
        
Are people Bayesian?
        
What about Kahneman and Tversky?
        
The brain has evolved mechanisms for solving particular computational problems, like generalizing concepts from very limited evidence
- also vision, motor control, language, etc.
        
May work best in domains evolution has had the time and reason to engineer good computational solutions
        
Many heated contemporary debates about concepts dissolve or yield real ground on a Bayesian analysis.
        
"I think we are far from seeing the full impact of Bayes on the study of the mind"
      },
author = {Tenenbaum, J B},
file = {:Users/Brenden/Documents/Mendeley/Tenenbaum - 1999 - A Bayesian Framework for Concept Learning.pdf:pdf},
school = {MIT},
title = {{A Bayesian Framework for Concept Learning}},
year = {1999}
}
@article{Tenenbaum2000b,
abstract = {Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs-30,000 auditory nerve fibers or 10(6) optic nerve fibers-a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.},
author = {Tenenbaum, J B and de Silva, V and Langford, J C},
doi = {10.1126/science.290.5500.2319},
file = {:Users/Brenden/Documents/Mendeley/Tenenbaum, de Silva, Langford - 2000 - A global geometric framework for nonlinear dimensionality reduction.pdf:pdf},
issn = {0036-8075},
journal = {Science},
keywords = {Algorithms,Artificial Intelligence,Face,Humans,Mathematics,Pattern Recognition,Visual,Visual Perception},
month = dec,
number = {5500},
pages = {2319--23},
pmid = {11125149},
title = {{A global geometric framework for nonlinear dimensionality reduction.}},
volume = {290},
year = {2000}
}
@article{Tenenbaum2000c,
abstract = {Perceptual systems routinely separate "content" from "style," classifying familiar words spoken in an unfamiliar accent, identifying a font or handwriting style across letters, or recognizing a familiar face or object seen under unfamiliar viewing conditions. Yet a general and tractable computational model of this ability to untangle the underlying factors of perceptual observations remains elusive (Hofstadter, 1985). Existing factor models (Mardia, Kent, & Bibby, 1979; Hinton & Zemel, 1994; Ghahramani, 1995; Bell & Sejnowski, 1995; Hinton, Dayan, Frey, & Neal, 1995; Dayan, Hinton, Neal, & Zemel, 1995; Hinton & Ghahramani, 1997) are either insufficiently rich to capture the complex interactions of perceptually meaningful factors such as phoneme and speaker accent or letter and font, or do not allow efficient learning algorithms. We present a general framework for learning to solve two-factor tasks using bilinear models, which provide sufficiently expressive representations of factor interactions but can nonetheless be fit to data using efficient algorithms based on the singular value decomposition and expectation-maximization. We report promising results on three different tasks in three different perceptual domains: spoken vowel classification with a benchmark multi-speaker database, extrapolation of fonts to unseen letters, and translation of faces to novel illuminants.},
author = {Tenenbaum, J B and Freeman, W T},
file = {:Users/Brenden/Documents/Mendeley/Tenenbaum, Freeman - 2000 - Separating style and content with bilinear models.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Face,Humans,Learning,Linear Models,Neural Networks (Computer),Pattern Recognition,Speech Perception,Visual,classic AI,classic psychology},
mendeley-tags = {classic AI,classic psychology},
month = jun,
number = {6},
pages = {1247--83},
pmid = {10935711},
title = {{Separating style and content with bilinear models.}},
volume = {12},
year = {2000}
}
@article{Tenenbaum2001,
abstract = {Shepard has argued that a universal law should govern generalization across different domains of perception and cognition, as well as across organisms from different species or even different planets. Starting with some basic assumptions about natural kinds, he derived an exponential decay function as the form of the universal generalization gradient, which accords strikingly well with a wide range of empirical data. However, his original formulation applied only to the ideal case of generalization from a single encountered stimulus to a single novel stimulus, and for stimuli that can be represented as points in a continuous metric psychological space. Here we recast Shepard's theory in a more general Bayesian framework and show how this naturally extends his approach to the more realistic situation of generalizing from multiple consequential stimuli with arbitrary representational structure. Our framework also subsumes a version of Tversky's set-theoretic model of similarity, which is conventionally thought of as the primary alternative to Shepard's continuous metric space model of similarity and generalization. This unification allows us not only to draw deep parallels between the set-theoretic and spatial approaches, but also to significantly advance the explanatory power of set-theoretic models.},
author = {Tenenbaum, J B and Griffiths, T L},
file = {:Users/Brenden/Documents/Mendeley/Tenenbaum, Griffiths - 2001 - Generalization, similarity, and Bayesian inference.pdf:pdf},
issn = {0140-525X},
journal = {Behavioral and Brain Sciences},
keywords = {Bayes Theorem,Cognition,Concept Formation,Generalization (Psychology),Humans,Learning,Models,Psychological,generalization,one-shot learning},
mendeley-tags = {generalization,one-shot learning},
number = {4},
pages = {629--40},
pmid = {12048947},
title = {{Generalization, similarity, and Bayesian inference.}},
volume = {24},
year = {2001}
}
@inproceedings{Tenenbaum1999a,
annote = {How you can learn a new concept from just one or a handful of positive examples?
- most machine learning approaches don't do this, but people readily do
        
size principle: smaller hypotheses are more likely than larger hypotheses
        
likelihood: size principle based on size of hypothesis
prior: uniformative prior, where we have no a priori reason to prefer any reactangle over another
        
----
        
If you have a weak bayesian model, where the data is generated by an arbitrary process that has nothing to do with the concept, then you have a likelihood of 1 (well, it is proportional to, but you have to normalie)
                  
task:
                
shown set of dots, and then guess where the rectangle is
        
"practice trials" : where people saw the true concept, after they guessed where the rectangle was
.. hmmm... I think it could rule out a lot of models from this
                  
results:
                
looked at extent of generalization, from closest point r, as the number of datapoints increased and the range of the datapoints increased
        
one free parameter, which is the expected-size of concepts in the domain
      },
author = {Tenenbaum, Joshua B},
booktitle = {Advances in Neural Information Processing Systems 11 (NIPS)},
file = {:Users/Brenden/Documents/Mendeley/Tenenbaum - 1999 - Bayesian modeling of human concept learning.pdf:pdf},
keywords = {one-shot learning},
mendeley-tags = {one-shot learning},
title = {{Bayesian modeling of human concept learning}},
year = {1999}
}
@inproceedings{Tenenbaum2001a,
annote = {What is representativeness? It is not defined by Kahneman and Tversky -- but it is a central psychological construct
        
People tend to find intermediate samples, in terms of spread, as the most representative},
author = {Tenenbaum, Joshua B and Griffiths, Thomas L},
booktitle = {Proceedings of the 23rd Annual Conference of the Cognitive Science Society},
file = {:Users/Brenden/Documents/Mendeley/Tenenbaum, Griffiths - 2001 - The Rational Basis of Representativeness.pdf:pdf},
title = {{The Rational Basis of Representativeness}},
year = {2001}
}
@article{Tenenbaum2006,
abstract = {Inductive inference allows humans to make powerful generalizations from sparse data when learning about word meanings, unobserved properties, causal relationships, and many other aspects of the world. Traditional accounts of induction emphasize either the power of statistical learning, or the importance of strong constraints from structured domain knowledge, intuitive theories or schemas. We argue that both components are necessary to explain the nature, use and acquisition of human knowledge, and we introduce a theory-based Bayesian framework for modeling inductive learning and reasoning as statistical inferences over structured knowledge representations.},
author = {Tenenbaum, Joshua B and Griffiths, Thomas L and Kemp, Charles},
file = {:Users/Brenden/Documents/Mendeley/Tenenbaum, Griffiths, Kemp - 2006 - Theory-based Bayesian models of inductive learning and reasoning.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
keywords = {*bayes theorem,*models,*physiology,association learning,brain,cognition,comprehension,concept formation,generalization (psychology),humans,intuition,learning,physiology,probability theory,problem solving,statistical,verbal learning},
number = {7},
pages = {309--318},
title = {{Theory-based Bayesian models of inductive learning and reasoning}},
volume = {10},
year = {2006}
}
@article{Tenenbaum2011,
abstract = {In coming to understand the world-in learning concepts, acquiring language, and grasping causal relations-our minds make inferences that appear to go far beyond the data available. How do we do it? This review describes recent approaches to reverse-engineering human learning and cognitive development and, in parallel, engineering more humanlike machine learning systems. Computational models that perform probabilistic inference over hierarchies of flexibly structured representations can address some of the deepest questions about the nature and origins of human thought: How does abstract knowledge guide learning and reasoning from sparse data? What forms does our knowledge take, across different domains and tasks? And how is that abstract knowledge itself acquired?},
author = {Tenenbaum, Joshua B and Kemp, Charles and Griffiths, Thomas L and Goodman, Noah D},
doi = {10.1126/science.1192788},
file = {:Users/Brenden/Documents/Mendeley/Tenenbaum et al. - 2011 - How to grow a mind statistics, structure, and abstraction(2).pdf:pdf;:Users/Brenden/Documents/Mendeley/Tenenbaum et al. - 2011 - How to grow a mind statistics, structure, and abstraction.pdf:pdf},
issn = {1095-9203},
journal = {Science},
keywords = {Artificial Intelligence,Bayes Theorem,Cognition,Concept Formation,Humans,Knowledge,Learning,Models,Statistical,Theory of Mind,Thinking},
month = mar,
number = {6022},
pages = {1279--85},
pmid = {21393536},
title = {{How to grow a mind: statistics, structure, and abstraction.}},
volume = {331},
year = {2011}
}
@article{Thelen2001,
abstract = {The overall goal of this target article is to demonstrate a mechanism for an embodied cognition. The particular vehicle is a much-studied, but still widely debated phenomenon seen in 7-12 month-old-infants. In Piaget's classic "A-not-B error," infants who have successfully uncovered a toy at location "A" continue to reach to that location even after they watch the toy hidden in a nearby location "B." Here, we question the traditional explanations of the error as an indicator of infants' concepts of objects or other static mental structures. Instead, we demonstrate that the A-not-B error and its previously puzzling contextual variations can be understood by the coupled dynamics of the ordinary processes of goal-directed actions: looking, planning, reaching, and remembering. We offer a formal dynamic theory and model based on cognitive embodiment that both simulates the known A-not-B effects and offers novel predictions that match new experimental results. The demonstration supports an embodied view by casting the mental events involved in perception, planning, deciding, and remembering in the same analogic dynamic language as that used to describe bodily movement, so that they may be continuously meshed. We maintain that this mesh is a pre-eminently cognitive act of "knowing" not only in infancy but also in everyday activities throughout the life span.},
annote = {A-not-B error. It is not a problem with the infant's concept of objects and other static mental structures, but is better understood as a coupled dynamics of the ordinary processes of goal-directed actions
        
main claim: knowing and acting are NOT modular and dissociable. Indeed, the cornerstone of the modeling is that "knowing" is perceiving, moving, and remembering over time. Errors should be understood as a coupled process.
        
Thought: There is a general disconnect between infant perception procedures, and when the knowledge becomes more expclit/action based. All something like an emergent method?
        
--
        
finding a commno language for behavior, body, and brain is the first step to banishing the specter of dualism
        
In infant literature, there has been a lot of effort to unearth the "real" cognitive competencies, unfetered by performance. But here they argue this distinction is untenable
        
A-not-B error: infants between 7-12 months. They search in one location, but cannot switch their search if the toy is then switched
        
It is very robust in the canonical form, but it can be disrupted by small variations:
- visual properties of the hiding locations (distance, distinctiveness, number, transparency of covers)
- the delay between hiding and searching
- whether search involves reaching or just looking
- other landmarks in the enrivonrment
- the importance of the object being searched for
- whether it's done at home or in th elab
- amount of crawling expreince for the infant
        
This poses a serious challenge to Piaget's original interpretation.
        
There is a general disconnect between infant perception procedures, and when the knowledge becomes more expclit/action based. All something like an emergent method?
        
Smith: this may not be about objects at all. Even without a  hidden object (infants are just cued to pick a certain container), they make the error
                  
Main claim:        
knowing and acting are NOT modular and dissociable. Indeed, the cornerstone of the modeling is that "knowing" is perceiving, moving, and remembering over time. Errors should be understood as a coupled process.
        
Experiment:
It is necessary to have some pre-training, where the infant learns what it means to reach for a hidden object
        
Model:
product: a decision field, which controls the rearching behavior
- specific cue to reach to A or B (transient and must be remembered)
- memory dynamics which biases the field
(parameters can be derived from the data)
        
embodied approach, where the mental events are in the same dynamic language as the movement itself: continuos and time-based
        
u(x,t): The motor values the baby can continually specify to move in a direction
S(x,t): The reach direction specifying A or B
h: resting level, if it is low, only large inputs predominate (more by input, less by interation) This is a very important parameter
        
Have cooperative activity, where similar states in the field support eachother, but different states are inhibitory. 
You integrate over the space of the field, where activity close by increase and others decrease. There is also a non-linear threshold here.
        
S(x,t) has three inputs
- S_task: persiting task environemnt (like that there are two bins)
- S_specific: cued box
- S_memory: previous boxes
        
Task: two Gaussians with mass right on the boxes.
Specific: Gaussian on the cued box, but it differes because it is a time-limited input to the field
        
Results: fit the parameters to the experimental data.
        
Accounts for delay period, if the infant could reach without decay, they would be able to maintain activity
        
A change in one parameter (h) creates instability that drives the filed into a new regime
- is it just "maturational?"
- better control of reaching?
        
Limitations
- it blurs the distinction between "knwoing" and "acting"
- can semantic content be represtend in the same fluid, continuous, the time-based spaces?
        
        
Conclusion
-- there is no such thing as an "object concept", some causal structure that generates a thought or behavior
-- when we search for our keys, it's not that we have some disembodied belief about the permanence of objects. It's that they have just never vaporized in the past
        
Criticism:
Markman: this may not be a representative task, since perceptual and motor processing is si important. So they didn't make the case that A-not-B is representative. There needs to be an application in the more traditional purview of cognitive science, with representation-hungry problems. Also, is this is psychological explanation, or a complex description of behavior? What is the parameter "h" in their model? They are unable to make it specific.
      },
author = {Thelen, E and Sch\"{o}ner, G and Scheier, C and Smith, L B},
file = {:Users/Brenden/Documents/Mendeley/Thelen et al. - 2001 - The dynamics of embodiment A field theory of infant perseverative reaching.pdf:pdf},
issn = {0140-525X},
journal = {The Behavioral and brain sciences},
keywords = {Child Development,Child Development: physiology,Cognition,Cognition: physiology,Concept Formation,Concept Formation: physiology,Hand,Hand: physiology,Humans,Infant,Motor Skills,Motor Skills: physiology,Movement,Movement: physiology,Psychological Theory,classic psychology,embodied cognition},
mendeley-tags = {classic psychology,embodied cognition},
month = feb,
number = {1},
pages = {1--34; discussion 34--86},
pmid = {11515285},
title = {{The dynamics of embodiment: A field theory of infant perseverative reaching}},
volume = {24},
year = {2001}
}
@inproceedings{Thibaux2007,
author = {Thibaux, Romain and Jordan, Michael I},
booktitle = {Proceedings of the Tenth Conference on Artificial Intelligence and Statistics (AISTATS)},
file = {:Users/Brenden/Documents/Mendeley/Thibaux, Jordan - 2007 - Hierarchical Beta Processes and the Indian Buffet Process.pdf:pdf},
keywords = {non-parametric Bayes},
mendeley-tags = {non-parametric Bayes},
title = {{Hierarchical Beta Processes and the Indian Buffet Process}},
year = {2007}
}
@article{Tibshirani1996,
author = {Tibshirani, Robert},
file = {:Users/Brenden/Documents/Mendeley/Tibshirani - 1996 - Regression shrinkage and selection via the lasso.pdf:pdf},
journal = {Journal of the Royal Statistical Society Series B},
keywords = {sparsity},
mendeley-tags = {sparsity},
number = {1},
pages = {267--288},
title = {{Regression shrinkage and selection via the lasso}},
volume = {58},
year = {1996}
}
@article{Tipper1985,
abstract = {A priming paradigm was employed to investigate the processing of an ignored object during selection of an attended object. Two issues were investigated: the level of internal representation achieved for the ignored object, and the subsequent fate of this representation. In Experiment 1 a prime display containing two superimposed objects was briefly presented. One second later a probe display was presented containing an object to be named. If the ignored object in the prime display was the same as the subsequent probe, naming latencies were impaired. This effect is termed negative priming. It suggests that internal representations of the ignored object may become associated with inhibition during selection. Thus, selection of a subsequent probe object requiring these inhibited representations is delayed. Experiment 2 replicated the negative priming effect with a shorter inter-stimulus interval. Experiment 3 examined the priming effects of both the ignored and the selected objects. The effect of both identity repetition and a categorical relationship between prime and probe stimuli were investigated. The data showed that for a stimulus selected from the prime display, naming of the same object in the probe display was facilitated. When the same stimulus was ignored in the prime display, however, naming of it in the probe display was again impaired (negative priming). That negative priming was also demonstrated with categorically related objects suggests that ignored objects achieve categorical levels of representation, and that the inhibition may be at this level. A priming paradigm was employed to investigate the processing of an ignored object during selection of an attended object. Two issues were investigated: the level of internal representation achieved for the ignored object, and the subsequent fate of this representation. In Experiment 1 a prime display containing two superimposed objects was briefly presented. One second later a probe display was presented containing an object to be named. If the ignored object in the prime display was the same as the subsequent probe, naming latencies were impaired. This effect is termed negative priming. It suggests that internal representations of the ignored object may become associated with inhibition during selection. Thus, selection of a subsequent probe object requiring these inhibited representations is delayed. Experiment 2 replicated the negative priming effect with a shorter inter-stimulus interval. Experiment 3 examined the priming effects of both the ignored and the selected objects. The effect of both identity repetition and a categorical relationship between prime and probe stimuli were investigated. The data showed that for a stimulus selected from the prime display, naming of the same object in the probe display was facilitated. When the same stimulus was ignored in the prime display, however, naming of it in the probe display was again impaired (negative priming). That negative priming was also demonstrated with categorically related objects suggests that ignored objects achieve categorical levels of representation, and that the inhibition may be at this level.},
author = {Tipper, Steven P.},
doi = {10.1080/14640748508400920},
file = {:Users/Brenden/Documents/Mendeley/Tipper - 1985 - The negative priming effect Inhibitory priming by ignored objects.pdf:pdf},
issn = {0272-4987},
journal = {The Quarterly Journal of Experimental Psychology Section A},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
month = nov,
number = {4},
pages = {571--590},
publisher = {Psychology Press},
title = {{The negative priming effect: Inhibitory priming by ignored objects}},
volume = {37},
year = {1985}
}
@article{TorralbaMurphy2007,
annote = {Rather than training a bunch of separate classifiers, classifiers are trained jointly, in a way that they share features.
        
Traditionarlly, you have a separate classifer for each object, which is also applied at separate scales. For different views, you have yet another set of classifiers.
        
Key insights:
- you need less training data
- faster at runtime, since you don't have to compute separate features for each classifiers
- you get more generic features, rather than highy class-specific features
        
On each round of boosting, you choose a subset of classes, and then an optimal feature, for improviing performance. This way you share the features.
        
This is a lot like neural networks, like a convolutional net trained on character recognition, which inherently share features across all of the classes.
        
Results: their method outperforms standard boosting (a state-of-the-art method), when controlling for computational cost (the number of features)
      },
author = {Torralba, A and Murphy, K P and Freeman, W T},
file = {:Users/Brenden/Documents/Mendeley/Torralba, Murphy, Freeman - 2007 - Sharing visual features for multiclass and multiview object detection.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {5},
pages = {854--869},
title = {{Sharing visual features for multiclass and multiview object detection}},
volume = {29},
year = {2007}
}
@article{Treisman1998,
abstract = {The seemingly effortless ability to perceive meaningful objects in an integrated scene actually depends on complex visual processes. The 'binding problem' concerns the way in which we select and integrate the separate features of objects in the correct combinations. Experiments suggest that attention plays a central role in solving this problem. Some neurological patients show a dramatic breakdown in the ability to see several objects; their deficits suggest a role for the parietal cortex in the binding process. However, indirect measures of priming and interference suggest that more information may be implicitly available than we can consciously access.},
annote = {Binding problem: how color, shape, motion, etc. are bound together to perceive an object
        
The problem isn't necessarily an obvious one, which is testimony to how good our brain is at it
        
But there are selective deficits.
        
You cannot just code for all possible combinations.
        
Synchrony is a way to hold onto the combinations, but we need a way to find out what the binding is
        
Main thesis: spatially selective attention plays a role in binding. We encode one object at a time, selected on location. By excluding stimuli from other locations, we bind the properties together. Then features are entered, without binding errors, into the object representations.
        
But other types of information can be accessed directly from the feature maps.
        
Evidence
-- illusory conjunctions, or thinking that a color and a letter were together, when they werent
-- You can get whole illusory shapes, by adding parts of various objects together
-- visual search: parallel vs. serial search, where targets are conjunctions of features
-- parietal lesions: difficult to bind at all, with multiple objects. He was terrible at conjuntion search
        
Simultanagnosia: trouble seeing multiple things at once. This can be helped by looking through a tube, which helps the binding problem},
author = {Treisman, Anne},
doi = {10.1098/rstb.1998.0284},
file = {:Users/Brenden/Documents/Mendeley/Treisman - 1998 - Feature binding, attention and object perception.pdf:pdf},
issn = {0962-8436},
journal = {Philosophical Transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Attention,Attention: physiology,Humans,Parietal Lobe,Parietal Lobe: physiology,Pattern Recognition,Psychomotor Performance,Psychomotor Performance: physiology,Visual,Visual Perception,Visual Perception: physiology,Visual: physiology,attention,classic psychology},
mendeley-tags = {attention,classic psychology},
month = aug,
number = {1373},
pages = {1295--306},
pmid = {9770223},
title = {{Feature binding, attention and object perception.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1692340&tool=pmcentrez&rendertype=abstract},
volume = {353},
year = {1998}
}
@article{Treisman1960,
abstract = {Abstract Two messages were presented dichotically and subjects were asked to ?shadow? whatever they heard on one ear. Somewhere in the middle the two passages were switched to the opposite ears. Subjects occasionally repeated one or two words, at the break, from the wrong ear, but never transferred to it for longer than this. The higher the transition probabilities in the passage the more likely they were to do this. One explanation might be that the ?selective filter? (Broadbent, 1958) acts by selectively raising thresholds for signals from the rejected sources rather than acting as an all-or-none barrier. Abstract Two messages were presented dichotically and subjects were asked to ?shadow? whatever they heard on one ear. Somewhere in the middle the two passages were switched to the opposite ears. Subjects occasionally repeated one or two words, at the break, from the wrong ear, but never transferred to it for longer than this. The higher the transition probabilities in the passage the more likely they were to do this. One explanation might be that the ?selective filter? (Broadbent, 1958) acts by selectively raising thresholds for signals from the rejected sources rather than acting as an all-or-none barrier.},
annote = {During dichronic listening, you are shadowing one ear vs. another. If midway through, the passags are switched between the ears, you tend to follow the semantically coherent one (although the effect is small)
        
--
        
This is a problem for Broadbent's filter model, which claims you wouldn't have heard it.
        
Before break: 5 words before break
After break: 5 words after break
Baseline: generally during the passage
        
People had many more intrusions after the break
        
But the intrusions are small, and not sufficient to completely change which ear is used
        
More of a threshold than a filter},
author = {Treisman, Anne M.},
doi = {10.1080/17470216008416732},
file = {:Users/Brenden/Documents/Mendeley/Treisman - 1960 - Contextual cues in selective listening.pdf:pdf},
issn = {0033-555X},
journal = {Quarterly Journal of Experimental Psychology},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
month = oct,
number = {4},
pages = {242--248},
publisher = {Psychology Press},
title = {{Contextual cues in selective listening}},
volume = {12},
year = {1960}
}
@article{Treisman1980,
abstract = {A new hypothesis about the role of focused attention is proposed. The feature-integration theory of attention suggests that attention must be directed serially to each stimulus in a display whenever conjunctions of more than one separable feature are needed to characterize or distinguish the possible objects presented. A number of predictions were tested in a variety of paradigms including visual search, texture segregation, identification and localization, and using both separable dimensions (shape and color) and local elements or parts of figures (lines, curves, etc. in letters) as the features to be integrated into complex wholes. The results were in general consistent with the hypothesis. They offer a new set of criteria for distinguishing separable from integral features and a new rationale for predicting which tasks will show attention limits and which will not.},
annote = {Looks like color, edges, etc. are processed independently in early cortex. How is this information combined to form experience? (the binding problem)
        
Theory: attention is required as a glue to bind the features together, to form a unitary object. Thus, attention is necessary for perceiving conjunctions correctly. The binding problem can be solved by just looking at one thing at a time.
        
How is this reconciled with the richness of scene perception? Maybe we don't see that much detail for full scenes--an informed halluciation.
        
---
Criteria for separable features: they require attention for integration
        
Evidence:
1) Serial scan for conjunction, but parallel scan for single dimension
2) Gestalt grouping -- which is preattentive-- should only work with separable features, not conjunctions of features
3) Illusory conjuctions -- falsely remembering that a familiar color and a familiar shape were combined
4) Locating an object must precede identification for conjunctions, but not for independent features
5) Interference should only depend on independent features
        
        Experiment 1: Search for a conjunction (green T) or a feauture (Green or T). Same distracters in either case. If you increase the number of distractors, only conjunction search gets worse, and it does so linearly.
        
Termination process may be different in feature search. It looks far more linear.
        
Practice produces no qualitative change. Thus, there may be built in neural constraints on processing conjunctions.
                  
Experiment 2: If you make it harder to discriminate the distractors from targets, you may be able to change the slope of the line. The answer is yes, (like green vs. blue colors)
                  
Experiment 3: There is another difference between feature and conjunctions -- since conjunctions share a featuer with all objects in the display, and disjunctions only with half. The replicated this similariy structure, using unidmensional stimuli where you don't need conjunctions. This cannot explain the pattern of results.
                  
Experiment 4: There is some debate over whether letters are preceived serially or in parallel. Treisman predicts it depends on a letter (R in a sea of P and Q would be hard, since the features can form illusory conjunctions). So here, the slope should be more similar (compared to distractors P and B). This was indeed found
                  
Experiment 5,6,7: You cannot perceive a boundary between objects, if made by conjuction stimuli (or it is much harder to)          
          
Experiment 8,9: Identification (not read)          
          
Discussion        
        
Why can't you do a conjunction of feature maps, in parallel? Attention cannot be focused simulatensouly on a number of different locations.
        
How is this reconciled with the richness of experience? Maybe the richness at the scene level is an informed halluciation. There are lots of cool features, but it's really not that accurate.},
author = {Treisman, Anne M. and Gelade, Garry},
doi = {10.1016/0010-0285(80)90005-5},
file = {:Users/Brenden/Documents/Mendeley/Treisman, Gelade - 1980 - A feature-integration theory of attention.pdf:pdf},
issn = {00100285},
journal = {Cognitive Psychology},
keywords = {attention,classic psychology},
mendeley-tags = {attention,classic psychology},
month = jan,
number = {1},
pages = {97--136},
title = {{A feature-integration theory of attention}},
volume = {12},
year = {1980}
}
@article{Treisman1982,
abstract = {In perceiving objects we may synthesize conjunctions of separable features by directing attention serially to each item in turn (A. Treisman and G. Gelade, Cognitive Psychology, 1980, 12, 97–136). This feature-integration theory predicts that when attention is diverted or overloaded, features may be wrongly recombined, giving rise to “illusory conjunctions.” The present paper confirms that illusory conjunctions are frequently experienced among unattended stimuli varying in color and shape, and that they occur also with size and solidity (outlined versus filled-in shapes). They are shown both in verbal recall and in simultaneous and successive matching tasks, making it unlikely that they depend on verbal labeling or on memory failure. They occur as often between stimuli differing on many features as between more similar stimuli, and spatial separation has little effect on their frequency. Each feature seems to be coded as an independent entity and to migrate, when attention is diverted, with few constraints from the other features of its source or destination.},
author = {Treisman, Anne and Schmidt, Hilary},
doi = {10.1016/0010-0285(82)90006-8},
issn = {00100285},
journal = {Cognitive Psychology},
month = jan,
number = {1},
pages = {107--141},
title = {{Illusory conjunctions in the perception of objects}},
volume = {14},
year = {1982}
}
@article{Trommershauser2003,
abstract = {We present two experiments that test the range of applicability of a movement planning model (MEGaMove) based on statistical decision theory. Subjects attempted to earn money by rapidly touching a green target region on a computer screen while avoiding nearby red penalty regions. In two experiments we varied the magnitudes of penalties, the degree of overlap of target and penalty regions, and the number of penalty regions. Overall, subjects acted so as to maximize gain in a wide variety of stimulus configurations, in good agreement with predictions of the model.},
annote = {People perform near optimally when trying to click a target in the presence of danger zones.
        
This suggests they know their own movement error, the specifics of the task, and can compute an optimal strategy efficiently
        
-----
We constantly have to make decisions that tradeoff risk and reward
        
A striker in soccer must decide whether to aim away from the goalie, to make it harder to block, while risking missing the goal entirely. Decision must be made in seconds
        
Motor planning: seletcing a single trajectory to minimize some notion of biomechanical cost
- but these models do not predict goal posture, which is what concerns this paper
- also must take into acount extrinic risks and rewards
        
Thus, in their model, there are terms for biomechanical cost and for not responding in time.
        
Optimal strategy is one that maximizes expected gain
        
For simpliciation, they just include the terms for the probability of hitting either the reward or danger region, given variability in the executed strategy. Can assume gaussian distribution around desired pointing target
        
Example: say the penalty and reward circle overlap. The stronger the penalty, the further away from that side you should aim
                  
Expeirment
- the distance between the target region and the penalty region was varied from trial to trial
- whole display moves to minimize pre-planned movements
- had 700 ms to respond
- size of the penalty varied in blocks, either the same as the good region or 5 times more
        
Optimal Observer was fit to each subject, and compared to see if their data was sigificantly different
        
Subjects used all of the time available
        
Plot aiming points versus optimal observer, and some subjects deviated from optimal, but some were close. However, performance was not significantly different than the optimal model
                  
Discussion
                
How was performance so good? People must represent their movement uncertainty, and the motor system can effectively select the motor strategy that maximizes expected gain
        
Did people get better over time? Like, using a hill-climbing RL learnier. But this was not the case, and there was no discernable trend in performance
                  
Experiment 2        
        
How well do people generalize to novel setups?
        
Here, the reward varied from trial to trial
        
There are some overall deviations, like one subject did not shift there distributions far enough
        
Overall, the model fits rather well, even though there were only 16 practice trials for these new configs. and no learning effects
                  
Discussion
          
        All subjects performed in a way consistent with the model
        
More complex tasks did not have higher variability, suggesting that the variance is due to motor area rather than task planning error},
author = {Trommersh\"{a}user, Julia and Maloney, Laurence T and Landy, Michael S},
file = {:Users/Brenden/Documents/Mendeley/Trommersh\"{a}user, Maloney, Landy - 2003 - Statistical decision theory and the selection of rapid, goal-directed movements.pdf:pdf},
issn = {1084-7529},
journal = {Journal of the Optical Society of America. A, Optics, image science, and vision},
keywords = {Adult,Decision Theory,Female,Goals,Humans,Male,Models,Movement,Movement: physiology,Theoretical,Time Factors},
month = jul,
number = {7},
pages = {1419--33},
pmid = {12868646},
title = {{Statistical decision theory and the selection of rapid, goal-directed movements.}},
volume = {20},
year = {2003}
}
@article{Trommershauser2008,
abstract = {We discuss behavioral studies directed at understanding how probability information is represented in motor and economic tasks. By formulating the behavioral tasks in the language of statistical decision theory, we can compare performance in equivalent tasks in different domains. Subjects in traditional economic decision-making tasks often misrepresent the probability of rare events and typically fail to maximize expected gain. By contrast, subjects in mathematically equivalent movement tasks often choose movement strategies that come close to maximizing expected gain. We discuss the implications of these different outcomes, noting the evident differences between the source of uncertainty and how information about uncertainty is acquired in motor and economic tasks.},
annote = {Why are people so bad at one-shot lotteries (propsect theory, etc.), yet they can rapidly choose between lotteries in a motor task and perform quite well.
        
What is the difference? This isn't really answered
        
When choosing a target during reaching, particpants are optimizing the probability of hitting each region, while the reward function is fixed. This is different than manipulating both the reward/probabilties, like in traditional K&T studies
        
What exactly is the difference? Is it something about the continuous optimization in this space?
        
-----
Decision making tasks in which people are decidely sub-optimal, people are much better in solving an equivalent motor task
        
Decision making task: Two lotteries, where one is risky with high payout and the other is not
        
Motor task: equivalent motor task, where people are much better at the complex decisions
                  
problems in decision making        
Prospect theory: exaggerated aversion to losses. Also, people tend to exaggaerate the frequency of low-frequenc events. Accounted for by a probability weighting function in decisino making
        
        motor task        
Short amount of time to make a movement, with a target region (green) and a bad region (red)
        
By choosing where to aim, they are choosing between a large number of possible lotteries implicity, where you have different probabilities of hitting the different regions, depending on where you point
        
In many cases, people choose strategies that come close to maximizing expected gain. However, there are some variants where people aren't optimal, like if the optimal location is to aim outside the target
        
It does not seem that they create a strategy through trial and error. Instead, after trained to be pointing experts, they quickly adapt to new trade-offs  -- the strategies become stable quickly. Thus, they just have to learn about their motor variability, and can apply it to novel tasks.
        
Strange that people are bad at decision making bets, even when the probabilities and rewards are given explicity. IF there are repeated gambles, people can learn from their experience, but they dont need to in the motor tasks
        
Why do people do so well with motor tasks, and not one-shot gambles?},
author = {Trommersh\"{a}user, Julia and Maloney, Laurence T and Landy, Michael S},
doi = {10.1016/j.tics.2008.04.010},
file = {:Users/Brenden/Documents/Mendeley/Trommersh\"{a}user, Maloney, Landy - 2008 - Decision making, movement planning and statistical decision theory.pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Bayesian perception,Data Interpretation,Decision Making,Decision Theory,Humans,Movement,Risk Factors,Statistical,decision making},
mendeley-tags = {Bayesian perception,decision making},
month = aug,
number = {8},
pages = {291--7},
pmid = {18614390},
title = {{Decision making, movement planning and statistical decision theory.}},
volume = {12},
year = {2008}
}
@article{Trueswell1996,
author = {Trueswell, John C.},
doi = {10.1006/jmla.1996.0030},
file = {:Users/Brenden/Documents/Mendeley/Trueswell - 1996 - The Role of Lexical Frequency in Syntactic Ambiguity Resolution.pdf:pdf},
issn = {0749596X},
journal = {Journal of Memory and Language},
month = aug,
number = {4},
pages = {566--585},
title = {{The Role of Lexical Frequency in Syntactic Ambiguity Resolution}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0749596X96900303},
volume = {35},
year = {1996}
}
@article{TseCavanagh2000,
annote = {Pitted top-down vs. bottom-up constraints on how apparent motion of a line would be perceived.
        
Knowledge of the motor program for a character, as you learn from growing up in China, affects apparent motion for a character stroke.
        
--
Bottom-up were grouping cues, and top-down were expectation from stroke direction, since it was embedded in a chinese character.
        
Chinese subjets: 7/10 repoted left-to-right
American subjects: 10/10 reported right-to-left
        
In debriefing, most subjects said they were unable to see the motion as "all at once", even when told this was in fact how it appeared on the screen. They can't see it otherwise. So It's probably not demand characteristic.},
author = {Tse, P U and Cavanagh, P},
file = {:Users/Brenden/Documents/Mendeley/Tse, Cavanagh - 2000 - Chinese and Americans see opposite apparent motions in a Chinese character.pdf:pdf},
journal = {Cognition},
keywords = {embodied cognition,handwriting},
mendeley-tags = {embodied cognition,handwriting},
pages = {B27--B32},
title = {{Chinese and Americans see opposite apparent motions in a Chinese character}},
volume = {74},
year = {2000}
}
@inproceedings{Tsuchida2012,
annote = {Saliency map: maps of attention across space
        
bottom-up: constructed from perceptual input
top-down: includes modluations from current context
        
This mostly concerned with bottom-up
        
What about auditory saliency?
        
Reasonable base is just intensity.
        
Their model: base on Barlow's efficient coding
                
Combines both long-term statistics, adn tehr ecent past. 
        
SUN saleicny framework: rare signals are more salient (1/P(F)). Learn filters from ICA
        
Apply PCA to each filter band.
To estimate probability distribution they used a Gaussian mixture.
        
Captures basic phenomea:
short is more salient than long
second of repeated tone is less salient
        
Compared with human saliency ratings.},
author = {Tsuchida, T and Cottrell, Gary W},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society (Cogsci2012)},
file = {:Users/Brenden/Documents/Mendeley/Tsuchida, Cottrell - 2012 - Auditory Saliency using Natural Statistics.pdf:pdf},
title = {{Auditory Saliency using Natural Statistics}},
year = {2012}
}
@article{Tu2005,
annote = {Similar to parsing sentences in natural languages, this model parses images into an image graph -- with nodes for objects.
        
---
In computer vision, progress on individual modules (segmentation, edge detection) are reaching ceiling based on low-level cues. We may need to combine cues, and higher-level analyses, to improve
        
Discriminative methods need a common framework, in order to remove false alarms, amend missing objects, reconcile conflicts, etc.
        
This paper does this with a fully-generative model of images.
        
Data Driven MCMC framework, which approximate marginal probabilities of the latent variables with discriminative methods. Thus, DDMCMC propose aspects of the state, rather than whole states in a discriminative way.
                  
Data driven MCMC        
        
MCMC moves to:
- create nodes
- delete nodes
- change node attributes
        
Reversible pairs, where the kernel must have positive probability in both directions
        
Detailed balance is acheived using MH
        
It would be cool to select the ratio of Kernels, stochastically, based on the current image analysis
        
Since all of the sub-kernels obey detailed balance, so does the overall Kernel.
        
The KL-divegence between the posterior and before/after a Kernel gives a measure of effectiveness of the kernel. But can you actually compute this?
        
If there are multiple paths to transitionb etween two staets, W and W', then these can be treated as separate sub-Kernels, or you can compute the probability of each path and sum them. The first strategy is computationally easier but less efficient (see Appendix D). Both are "correct"
        
        Generative model (multiple parts)
        
1) Sample number of parts
2) Sample shape (location), type, and parameters of the shape
        
Pixels form non-overlapping image regions, which are the locations of the parts
        
Specific models for
1) text
2) faces
3) generic intensity models (constant, histogram, and shading with splines)
                  
MCMC algorithm
                
Move types
i) birth/death of face nodes
ii) borth or death of text characters
iii) splitting or merging of regions
iv) switching node attributes
v) boundary evolution
        
Discriminative methods
1) edge cues: based on edge detectors, they give proposals for region boundaries. Based on a finite set of possibilities, with an edge detector run at 3 scales
        
2) binarization cues for proposing boundaries for text characters
        
3) face region cues, provided by AdaBoost plus edge detection for localization of faces
        
4) Shape/region affinity cues based on the color histograms, showing how similar the regions are
        
Annealing needed to start the algorithm
        
Change move probabilities depending how many text/face hits are deteceted by AdaBoost.
        
Move Birth/Death of text:
- list of candidates from AdaBoost, which is a weighted set of partcles based on probability of detection. They have separate weights for adding and removing them
+ These AdaBoost weights are used to compute proposal probabilities for adding text, on this discrete set only.
+ For deleting characters, they calculate the weights based on the likelihood and prior for all possible text characters to delete.
+ COMMENT: so is only this discrete list of candidates possible?
        
Splitting/Mering regions can only occur along a discrete set of boundaries, as detected by Canny edge detection
        
QUESTION: How can you ever merge regions, if it has to be exactly aligned with one of the edges provided to the bottom-up model? With just a little bit of stochastic sampling, it would move away and merges would fail
        
Node attributes (type) can be changed as well.
                  
Training of discriminative methods (not read carefully)
                  
Experiments
                
They run MCMC and take the best sample. Takes about 10-20 minutes per image
        
They can synthesize new images from the parse tree, showing the image content that the model "understands"
        
There is no way to set the AdaBoost parameters so that it doesn't sometimes make errors. But these can be cleaned up in the generative framework afterwadrs
        
Just show a few examples, and they don't run any quantitative measures for comparsion.
      },
author = {Tu, Zhuowen and Chen, Xiangrong and Yuille, Alan L and Zhu, Song-chun},
file = {:Users/Brenden/Documents/Mendeley/Tu et al. - 2005 - Image Parsing Unifying Segmentation, Detection, and Recognition.pdf:pdf},
journal = {International Journal of Computer Vision},
keywords = {adaboost,classic AI,data driven markov chain,image parsing,image segmentation,mcmc,monte carlo,object detection,object recognition,part-based models,program induction},
mendeley-tags = {classic AI,mcmc,part-based models,program induction},
number = {2},
pages = {113--140},
title = {{Image Parsing: Unifying Segmentation, Detection, and Recognition}},
volume = {63},
year = {2005}
}
@incollection{Tu2006,
author = {Tu, Zhuowen and Yuille, Alan and Chen, Xiangrong},
booktitle = {Towards Category-Level Object Recognition},
editor = {Ponce, J and Herbert, M and Schmid, C and Zisserman, A},
file = {:Users/Brenden/Documents/Mendeley/Tu, Yuille, Chen - 2006 - Image Parsing Segmentation, Detection, and Recognition.pdf:pdf},
pages = {545--576},
publisher = {Springer},
title = {{Image Parsing: Segmentation, Detection, and Recognition}},
year = {2006}
}
@article{Chain2002,
annote = {Paper on data driven MCMC. Also useful for designin split/merge moves in general.
        
---
Unifying approach to image segmentation, where many current techniques are used to make bottom-up proposals.
        
Bayesian formulatoin:
Prior probability on segmentation is first:
choose K segments, choose their regions (which segment the image in a mutual exclusive way, and then choose their labeling (texture type) and then parameters for that labeling.
        
Four image patch models (grayscale):
1) constant shade
2) histogram of shades
3) texture model
4) spline model which builds a gradient
        
Each of these has a likelihood based on the image patches in the regions of interest.
        
MCMC: Diffusion moves (random moves within a sub-space of fixed dimensionality) and jump moves, which make random walks between the sub-spaces.
        
Move 1) Diffusion: Adjust boundary with a gradient/brownian motion movement (don't really undersand this)
        
Move 2) Diffusion: adjust patch parameters by taking a gradient step (How is this valid mcmc?!)
        
Move 3 ) Split/Merge. 
        
Route 1 split: Choose a region at random to split. Choose a canddiate splitting boundary, and then choose new parameteters for those two regions.
        
Route 2 split: chose region to split, choose new paremters for the two halves, and then decide where to split. This is better for breaking apart two zebra stripes, in a single region, into two regions.
        
For a merge, you simply combine the two regions and propose new parameters for that region
        
Data driven MCMC:
        
Propose new parameters, using the proposal distribution, by fitting EM cluster model to entire image. Each pixel is soft-clustered. These mixture models are combined, and a continuous distribution on parameters is formed by a Parzen window on each of the weighted mixing components.
        
Boundaries are proposed using edge detection somehow -- didn't read the details
                  
k-adventures: rather than keeping around all of the samples in an MCMC run, they keep around just K particles and weights. Using a Gausisan window around the partciles (in a varying dimensional model space..) they add each new sample to the set of K. They then greedily remove one, in a way that minimizes KL divergence. Very clever... I like this! Automatically figures out which of your samples are most representative.
                  
Results:        
segmentations look pretty good. And they can sample new images from a given segmentation, wih their forward model.},
author = {Tu, Zhuowen and Zhu, Song-chun},
file = {:Users/Brenden/Documents/Mendeley/Tu, Zhu - 2002 - Image Segmentation by Data-Driven Markov Chain Monte Carlo.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {classic AI,mcmc,part-based models},
mendeley-tags = {classic AI,mcmc,part-based models},
number = {5},
pages = {657--673},
title = {{Image Segmentation by Data-Driven Markov Chain Monte Carlo}},
volume = {24},
year = {2002}
}
@article{Turing1950,
annote = {Article that introduces the Turing Test, as a sufficient condition for "intelligent machines"
        
Of course, he doesn't have much of a positive argument for this (since Turing doesn't have such a machine), but he considers various objections to this notion in Turn},
author = {Turing, AM},
file = {:Users/Brenden/Documents/Mendeley/Turing - 1950 - Computing Machinery and Intelligence.pdf:pdf},
journal = {Mind},
keywords = {classic AI,classic psychology},
mendeley-tags = {classic AI,classic psychology},
number = {236},
pages = {433--460},
title = {{Computing Machinery and Intelligence}},
volume = {59},
year = {1950}
}
@article{Tversky1974,
abstract = {This article described three heuristics that are employed in making judgements under uncertainty: (i) representativeness, which is usually employed when people are asked to judge the probability that an object or event A belongs to class or process B; (ii) availability of instances or scenarios, which is often employed when people are asked to assess the frequency of a class or the plausibility of a particular development; and (iii) adjustment from an anchor, which is usually employed in numerical prediction when a relevant value is available. These heuristics are highly economical and usually effective, but they lead to systematic and predictable errors. A better understanding of these heuristics and of the biases to which they lead could improve judgements and decisions in situations of uncertainty.},
annote = {        Representativeness        
- What is the probabiliy that A belongs to B? 
- Usually this is based on representativeness...
- The probability that Steve is a librarian is assessed by the degree to which he is representative
- prior probability is ignored
- lawyers vs. engineer example: people ignore the base rates, which they are told
        
- sample size is ignored
+ the probability that the average high is over 6 feet for men was rated the same, for 1000,100, and10 men samples
+ thus, based on representativeness, not sample size
+ same with hospital example
        
- leads to misconceptions of chance, like sequences of coin flips
        
insensitivity to predictability
+ people read a description of a teacher during a lesson. PEople tend to rate the teacher the same on how they score compared to their peers currently, and how they will do in 5 years -- although clearly it has less predictability in 5 years and you should regress to the mean
        
regression to the mean
- have students take a IQ test twice. If you select the 10 best on the first test, they will probably do worse than expected on the second.
- flight training example, where they might conclude that negative reinforcement leads to better preformane on the next trial
                  
availability        
- people assess the risk of heart attacks among middle aged people by recalling examples
- but availability can be influenced by things other than frequency and probability... so it can lead to major mistakes
- like given a list of male and female names, where the men are more famous. Then ask people to rate the gender ratio -- you find it's biased towards availability
- Is "r" more common as the first letter or third letter in a word?
        
- imaginability
Ask people to guess how many ways to form committee's of "k" people from a group of 10
+ although 10 choose 8 and 10 choose 2 are the same, it's easier to come up with the latter, and people judge this as more probable
        
-illusory correlatoins
+ people dramatically over-estimate the strength of a correlation if it conforms to an intuitive theory (like supiciousness of a person, and peculiar drawing of the eyes in drawings in a psychological test)
                  
anchoring
- asked to estimate the percentage of African countries in the United Nations. People spin a wheel, and are asked if it is higher or lower than the first number. This then influences their later estimate.
- same with estiamte factorial functions in 5 seconds, when it's laid out from lowest to highest or highested to lowest.... huge effect
- people tend to understimate the probability of failure in complex systems, because they are anchored by the individual parts
                  
Discussion
- it's not surprising that people use simple heuristics
- it's surprising that people do not discover these fundamental statistical rules over a lifetime of experience
        
      },
author = {Tversky, A and Kahneman, D},
doi = {10.1126/science.185.4157.1124},
file = {:Users/Brenden/Documents/Mendeley/Tversky, Kahneman - 1974 - Judgment under Uncertainty Heuristics and Biases.pdf:pdf},
issn = {0036-8075},
journal = {Science},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
month = sep,
number = {4157},
pages = {1124--31},
pmid = {17835457},
title = {{Judgment under Uncertainty: Heuristics and Biases.}},
volume = {185},
year = {1974}
}
@incollection{Tversky1986,
address = {Amsterdam/Philadelphia},
annote = {People tend to list shared parts for attributes of the basic level categories, but less so for super-ordinate or sub-ordinate
        
Maybe shared parts is the best way for defining the basic level.
        
----
        
- How should a thing be named?
+ Why do we agree on the same name for an object?
Brown: we place it in the category with the widest utitlity, and use that name
        
Rosch: tradeoff between informativeness of a category, and economy: not having to omany
+ people don't provide much more information about the sub-oridinate level categories
        
Maybe this level is driven by parts?
        
Result: 
        
At the basic level, people produce many more attributes that are parts, compared to attributes that are non-parts. At other levels, there is less of a difference between parts and non-parts.
        
Parts also vary systematically in their "goodness"
        
Why parts? They play a functional role:
handle of a hammer, stem of an apple, etc.
        
Part structure is also important for scenes (Tversky & Hemenway, 1983)
        
Working hypothesis:
Partonomies do not support inferences, but similar parts have similar functions
        
        
        
        
      },
author = {Tversky, Barbara},
booktitle = {Noun Classes and Categorization},
editor = {Craig, Colette},
file = {:Users/Brenden/Documents/Mendeley/Tversky - 1986 - Components and Categorization.pdf:pdf},
keywords = {part-based models},
mendeley-tags = {part-based models},
pages = {63--75},
publisher = {John Benjamins Publishing Company},
title = {{Components and Categorization}},
year = {1986}
}
@article{Tversky1989,
annote = {Parts: natural units of perpception, and also natural units of function
+ similarity of parts likely indicates similarity of function
        
Children do not initially use taxonomic organization, they classiy based on perceptual or thematic features
        
Function can be inferred from shared parts: if it has a handle, you can hold it.
        
Why parts are related to teh basic level?
Clothing: as a super-category, they don't share parts, just the property of covering the body
Shirts share parts
but particular types of shirts share few additional parts
                  
Experiment 1:
                
Asked children (5 yr.) to group objects into categories, using things that "belong together"
        
Condition 1: emphasized shared parts
Condition 2: minized shared parts, but emphasized frequent/typical items
        
Analyze the groupings for whether the child used a taxonomic justification or not
        
Was the word frequency higher for the non-shared parts, rather than the other way around? Yes
        
Results:
Children both used more taxonomic groupin schemes, and justified their groupings in a taxonomic way, when using the stimuli with shared parts
          
Discussion        
Young children form superordinate taxonomic groupings more easily when the category members share parts, but it not easy to disentagle shapes from parts
        
Some parts are better than others (previous work)
        
Experiment 2: What makes a good part? How are they detected perceptually?
        
Internal part: not visible from shape (door of a house)
External part: affects the contour
        
Task: measured RT for time to detect a difference between two pictures, where a part was removed (line drawings)
        
Results: Huge difference, where external parts were about 2.3 seconds faster
        
Experiment 3: 
A part is missing from each picture. The child is taked with telling you what it is.
        
        
Results: Larger parts are more likely to be detected than smaler ones.
        
Clear increase in performance, from ages 4-11
        
Experiment 4: What's missing?
Replication, with small change in procedure. made more clear that it is a part missing from the object, rather than the picture.
        
Results:
major effect of age
Young children miss many parts,  particularly large ones
        
This suggests a role of perceptual salience.
        
Experiment 5: (4-5 yr olds)
generate parts of a common object, when cued by the object name (or shown a picture in a setting).
        
        
Results:
A few more parts were produced pictorially, but not many.
                  
General discusion
                
Children begint o perform well on the "whats missing task" at abot the same age they perform well on super-taxonomic classification
        
Both size and location of parts, then, affet their detection. In partonomies as in taxonomies, young chidlren appear to be affected more by perceptual information than more abstract functional information.
        
A restaurant script, like the ordering and paying scenes, can be subdivided, so this is a particullary good place for partonomic organziation
        
Some domains are strongly taxonomic, other partaonomic
        
Antropologists: different kinds of people
Medical researchers: differrents kinds of parts of people
        
History text books
One partonomic organization by country, by political, social, intellectual history
Another partonomic organization by time
This causes a tension
        
Just like a textbook needs to grapple with this, human memory also needs to grapple with it.
        
      },
author = {Tversky, Barbara},
file = {:Users/Brenden/Documents/Mendeley/Tversky - 1989 - Parts, Partonomies, and Taxonomies(2).pdf:pdf},
journal = {Developmental Psychology},
keywords = {part-based models},
mendeley-tags = {part-based models},
number = {6},
pages = {983--995},
title = {{Parts, Partonomies, and Taxonomies}},
volume = {25},
year = {1989}
}
@article{Tversky1984,
annote = {        taxonomy: the vertical organization of categories, ex: the "is a" relation. This supports inference of properties
        
        partonomy: the vertical organization of parts, ex: the "part-of" relation. This does not support the inference of properties, but instead it is an indication of function.
        
There is a close connection between the taxonomy and partonomy for objects -- where the partonomy picks out the priveledged level of classification.
        
The basic level is special because objects within a category tend to share parts, while objects in different categories don't share parts.
        
Also, people describe basic-level categories in terms of their parts (attribute listing), in a way that they do not for the sub-oridinate or super-oridinate levels. 
        
Parts also have a natural goodness, much like categories in general.
        
-----------
- Why is the basic level special? What is the explanation? Is it the psychological prevalence of parts?
        
- The special role of parts in determining the "basic" or preferred level of abstraction in a taxonomy.
        
Taxonomies of classification: gives us discrete labels, efficient organization, and provides powerful potential for inference
        
Basic level: share many attributes with eachother, and share few attributes with other entities. Thus, it is related to the structure of the perceived world. This is where informativeness is the greatest.
        
When looking at the attributes listed by subjects, one kind of feature seems to predominate: parts
                
Parts are often both perceptually identiable and serve a specialized function for the object. Many other features
        
Hypotheses:
- different objects at the basic level should differ in parts, but share other attributes
- subordinate objects belonging to the same basic level should share parts but differ on other things
        
Study 1: reanalyzed Rosch attribute listings, sorted by parts
        
What is a part? (segments of a whole that are less than the whole)
- one criterion: dictionary defintion
- second criterino: can be used in a "has a" sentence (A dog has a leg)
-3rd: asked subjects to desginate parts
- used "is made of" properties as parts
        
Results:
        
for object categories, parts have a sharp jump from super-ordinate to basic, while non-parts have a more gradual increase. Thus, are parts driving the basic level effect?
        
for biological categories, this is also true, except biological categories also share parts even at the superodinate level
        
Also, parts tend to be listed first during the basic level, but less so for the other levels
        
Also, oddly, subjets tend not to list parts for subordinate categories, even when they know they apply. Thus the data was analyzed with ammended and non-ammended tallies. 
+ why do they do this? Maybe Grice, it's not informative
        
Study 2: Do basic-level categories differ by parts?
        
Results: categories are the basic level are less likely to share parts, when compared to other attriutes
+ parts contribute more than non-parts to the naturalness of basic-level category cuts
+ This seems to be working against the notion of a super-rodinate category, but maybe thos share non-part features:
+ both parts and non-parts are equally associated with the typicality of a basic-level objet in its super-oridnate class
+ but only parts distinguish instances from eachother
        
Study 3: suborindate level categories share parts
+ do they share parts, but differ from eachother in other attributes?
++ implied by Grice interpretation of why people don't list parts for subordinate categories
        
Results: part-weights were stronger than non-part weights. So the hypothesis was confirmed
                  
Discussion: studies 1-3        
Parts are associated with the basic level, not the superordinate level, and few additional parts are listed at the subordinate level.
+ parts better index the "basicness" than other, purely functional or perceptual features
        
Study 4: Goodness of parts
There seems to be variable "goodness" of the parts listed
                  
partonomic: a part-whole relation, rather than a taxonomic relation
        
Just like goodness ratings show car is a better vehicile than boat, some parts should be better parts than others when compared to the whole
        
results: people tend to agree in teh goodness ratings of parts (correlations from .2 to .66)
        
Goodness correlated with the frequency of mentioning the parts. This provides some validation for the construct of goodness of a part.
                  
Discussion
                
AI and previous literature focused on the perceptual properties that distinguish parts, but here we are suggesting the fucntional/behavioral properties are key
        
Parts play a special role in the vertical organization of categories, distinguishing the basic level of reference.
        
Parts also play an important role in horizontal organization, making basic-level constrats salient
        
Good parts are functionally, perceptually salient. But this seems to be due to structure in the world
        
Structural descriptions may also play a critical role in our pereptual representations.
        
Parts are a more powerful theoretical concept than shape, because shape is not unique. Shape is rather determined by the parts, and parts can be important while not changing the shape.
        
While other sensory feature may be important for identification, parts may be more important for the conceptual core (Smith & Medin)
        
Children find part-whole relations easier than class inclusion, which may explain why the basic level is learned first (Markman)
        
More general and more specific categories do ot have a basis in part configuration... in the way that the basic level does
        
Partonomies do not allow inferences in the same way that taxonomies do...
        
Perceived part configuration, underlies both perceveid structure and perceived function. It seems to form a basis for intuitive causal reasoning and induction.
        
why is the basic level the most informative leve? The knowledge of function can be inferred from structure.
      },
author = {Tversky, Barbara and Hemenway, Kathleen},
file = {:Users/Brenden/Documents/Mendeley/Tversky, Hemenway - 1984 - Objects, Parts, and Categories.pdf:pdf},
journal = {Journal of Experimental Psychology: General},
keywords = {classic psychology,part-based models},
mendeley-tags = {classic psychology,part-based models},
number = {2},
pages = {169--191},
title = {{Objects, Parts, and Categories}},
volume = {113},
year = {1984}
}
@article{Ullman2012,
author = {Ullman, Tomer D. and Goodman, Noah D. and Tenenbaum, Joshua B.},
doi = {10.1016/j.cogdev.2012.07.005},
file = {:Users/Brenden/Documents/Mendeley/Ullman, Goodman, Tenenbaum - 2012 - Theory learning as stochastic search in the language of thought.pdf:pdf},
issn = {08852014},
journal = {Cognitive Development},
keywords = {algorithms,bayesian models,language of thought,mcmc},
month = oct,
number = {4},
pages = {455--480},
title = {{Theory learning as stochastic search in the language of thought}},
volume = {27},
year = {2012}
}
@article{Valentin1994,
author = {Valentin, Dominique and Abdi, Hervi and O'Toole, AJ and Cottrell, GW},
file = {:Users/Brenden/Documents/Mendeley/Valentin et al. - 1994 - Connectionist models of face processing A survey.pdf:pdf},
journal = {Pattern recognition},
keywords = {classic psychology},
mendeley-tags = {classic psychology},
number = {9},
pages = {1209--1230},
title = {{Connectionist models of face processing: A survey}},
volume = {27},
year = {1994}
}
@article{Vallabha2007,
author = {Vallabha, G K and McClelland, J L and Pons, F and Werker, J F and Amano, S},
file = {:Users/Brenden/Documents/Mendeley/Vallabha et al. - 2007 - Unsupervised learning of vowel categories from infant-directed speech.pdf:pdf},
journal = {Proceedings of the National Academy of Science},
number = {33},
pages = {13273--13278},
title = {{Unsupervised learning of vowel categories from infant-directed speech}},
volume = {104},
year = {2007}
}
@book{VanSommers1984,
annote = {Drawing is a multi-leveled system, much like language, that can be studied at the sentence level, phoneme level, etc.
        
      },
author = {{Van Sommers}, Peter},
keywords = {handwriting},
publisher = {Cambridge University Press},
title = {{Drawing and Cognition}},
year = {1984}
}
@article{Vandenberghe1996,
annote = {Semantic tasks seem to active a distributed semantic processing system shared by both words and pictures
        
Task:
-saw triplets of words or pictures
-one task, it was to pick the item in the same category
-- other task, matched for real-world size
-- third task (baseline), matched for physical size (on the page)
        
There is a common semantic system, which is activated for both tasks compared to baseline
- junction between parietal and temporal lobe
- between fusiform and IT cortex
        
There are also some areas specific to modalities
        
This area is near IT cortex in monkeys (the shared semantic system is), meaning it could have been adapated to attribute meanings to nouns
      },
author = {Vandenberghe, R and Price, C and Wise, R and Josephs, O and Frackowiak, R S J},
file = {:Users/Brenden/Documents/Mendeley/Vandenberghe et al. - 1996 - Functional anatomy of a common semantic system for words and pictures.pdf:pdf},
journal = {Nature},
keywords = {classic psychology,mental codes},
mendeley-tags = {classic psychology,mental codes},
pages = {254--256},
title = {{Functional anatomy of a common semantic system for words and pictures}},
volume = {383},
year = {1996}
}
@article{Vandist2009,
author = {Vandist, K and {De Schryver}, M and Rosseel, Y},
file = {:Users/Brenden/Documents/Mendeley/Vandist, De Schryver, Rosseel - 2009 - Semisupervised category learning The impact of feedback in learning the information-integration task.pdf:pdf},
journal = {Attention, Perception, and Psychophysics},
number = {2},
pages = {328--341},
title = {{Semisupervised category learning: The impact of feedback in learning the information-integration task}},
volume = {71},
year = {2009}
}
@misc{Vapnik,
abstract = {talk on Sept, 26},
annote = {IF you don't have a perfect sepating hyperplane, test error is bounded by 1/sqrt(n)
If you do have perfect separation, it's 1/n, which is much better
        
SVM is a perception where youahve
- max margin hyperlane, rather than any
- use kernels
        
if you don't have perfect separation, you have slack variables in your SVM
- but if you know the optimal slack variables, you can that you converge like you had perfect separation
        
Kernel both defines similarity space, and defines the expansion to the set of possible functions
        
Idea of SVM+
- you have two kernels for each of those functions
        
Example:
- pass in proteins in amino acid space, classify groups
- if you have privledged information, like the 3D structure, this can help you learn the kernel
        
Friday:
You cannot create intelligence for macines without creating culture for computers. },
author = {Vapnik, Vladimir},
title = {{Learning with nontrivial teacher: learning using privileged information}}
}
@inproceedings{Veselova2004,
annote = {One-shot learning of perceptual symbols
        
1) Input is lines and arcs},
author = {Veselova, Olya and Davis, Randall},
booktitle = {Proceedings of AAAI},
file = {:Users/Brenden/Documents/Mendeley/Veselova, Davis - 2004 - Perceptually Based Learning of Shape Descriptions for Sketch Recognition.pdf:pdf},
keywords = {handwriting,one-shot learning,sketch-understanding},
mendeley-tags = {handwriting,one-shot learning,sketch-understanding},
title = {{Perceptually Based Learning of Shape Descriptions for Sketch Recognition}},
year = {2004}
}
@article{Vigneau2006,
abstract = {The advent of functional neuroimaging has allowed tremendous advances in our understanding of brain-language relationships, in addition to generating substantial empirical data on this subject in the form of thousands of activation peak coordinates reported in a decade of language studies. We performed a large-scale meta-analysis of this literature, aimed at defining the composition of the phonological, semantic, and sentence processing networks in the frontal, temporal, and inferior parietal regions of the left cerebral hemisphere. For each of these language components, activation peaks issued from relevant component-specific contrasts were submitted to a spatial clustering algorithm, which gathered activation peaks on the basis of their relative distance in the MNI space. From a sample of 730 activation peaks extracted from 129 scientific reports selected among 260, we isolated 30 activation clusters, defining the functional fields constituting three distributed networks of frontal and temporal areas and revealing the functional organization of the left hemisphere for language. The functional role of each activation cluster is discussed based on the nature of the tasks in which it was involved. This meta-analysis sheds light on several contemporary issues, notably on the fine-scale functional architecture of the inferior frontal gyrus for phonological and semantic processing, the evidence for an elementary audio-motor loop involved in both comprehension and production of syllables including the primary auditory areas and the motor mouth area, evidence of areas of overlap between phonological and semantic processing, in particular at the location of the selective human voice area that was the seat of partial overlap of the three language components, the evidence of a cortical area in the pars opercularis of the inferior frontal gyrus dedicated to syntactic processing and in the posterior part of the superior temporal gyrus a region selectively activated by sentence and text processing, and the hypothesis that different working memory perception-actions loops are identifiable for the different language components. These results argue for large-scale architecture networks rather than modular organization of language in the left hemisphere.},
author = {Vigneau, M and Beaucousin, V and Herv\'{e}, P Y and Duffau, H and Crivello, F and Houd\'{e}, O and Mazoyer, B and Tzourio-Mazoyer, N},
doi = {10.1016/j.neuroimage.2005.11.002},
file = {:Users/Brenden/Documents/Mendeley/Vigneau et al. - 2006 - Meta-analyzing left hemisphere language areas phonology, semantics, and sentence processing.pdf:pdf},
issn = {1053-8119},
journal = {NeuroImage},
keywords = {Brain Mapping,Cerebral Cortex,Cerebral Cortex: physiology,Cluster Analysis,Dominance, Cerebral,Dominance, Cerebral: physiology,Humans,Image Processing, Computer-Assisted,Imaging, Three-Dimensional,Language,Magnetic Resonance Imaging,Memory, Short-Term,Memory, Short-Term: physiology,Nerve Net,Nerve Net: physiology,Phonation,Phonation: physiology,Phonetics,Reading,Semantics,Speech Perception,Speech Perception: physiology},
month = may,
number = {4},
pages = {1414--32},
pmid = {16413796},
title = {{Meta-analyzing left hemisphere language areas: phonology, semantics, and sentence processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16413796},
volume = {30},
year = {2006}
}
@article{Viviani1995,
author = {Viviani, Paolo and Flash, Tamar},
file = {:Users/Brenden/Documents/Mendeley/Viviani, Flash - 1995 - Minimum-Jerk, Two-Thirds Power Law, and Isochrony Convering Approaches to Movement Planning.pdf:pdf},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
keywords = {handwriting,program induction},
mendeley-tags = {handwriting,program induction},
number = {1},
pages = {32--53},
title = {{Minimum-Jerk, Two-Thirds Power Law, and Isochrony: Convering Approaches to Movement Planning}},
volume = {21},
year = {1995}
}
@inproceedings{Vlachos,
author = {Vlachos, M. and Kollios, G. and Gunopulos, D.},
booktitle = {Proceedings 18th International Conference on Data Engineering},
doi = {10.1109/ICDE.2002.994784},
file = {:Users/Brenden/Documents/Mendeley/Vlachos, Kollios, Gunopulos - 2002 - Discovering similar multidimensional trajectories.pdf:pdf},
isbn = {0-7695-1531-2},
keywords = {handwriting},
mendeley-tags = {handwriting},
pages = {673--684},
title = {{Discovering similar multidimensional trajectories}},
year = {2002}
}
@inproceedings{Vlachos2003,
author = {Vlachos, Michail and Hadjieleftheriou, Marious and Gunopulos, Dimitrios and Keogh, Eamonn},
booktitle = {SIGKDD},
file = {:Users/Brenden/Documents/Mendeley/Vlachos et al. - 2003 - Indexing Multi-Dimensional Time-Series with Support for Multiple Distance Measures.pdf:pdf},
isbn = {1581137370},
keywords = {handwriting},
mendeley-tags = {handwriting},
title = {{Indexing Multi-Dimensional Time-Series with Support for Multiple Distance Measures}},
year = {2003}
}
@incollection{Vogler1999,
annote = {Interesting parallel between ideas in this paper and the stroke model. Rather than trying to model invidual signs, it models individual phonemes with HMMs. It then strings these HMMs together to model whole signs.
        
The argument they use is for computational tractability. But this might be useful for generalization and one-shot learning also.},
author = {Vogler, Christian and Metaxas, Dimitris},
booktitle = {{Gesture-Based Communication in Human-Computer Interaction. Lecture Notes in Computer Science}},
file = {:Users/Brenden/Documents/Mendeley/Vogler, Metaxas - 1999 - Toward Scalability in ASL Recognition Breaking Down Signs into Phonemes(2).pdf:pdf},
keywords = {part-based models},
mendeley-tags = {part-based models},
pages = {211--224},
title = {{Toward Scalability in ASL Recognition: Breaking Down Signs into Phonemes}},
year = {1999}
}
@article{Vogler1998,
annote = {Models entire "words" as HMMs},
author = {Vogler, Christian and Metaxas, Dimitris},
doi = {10.1109/ICCV.1998.710744},
file = {:Users/Brenden/Documents/Mendeley/Vogler, Metaxas - 1998 - ASL recognition based on a coupling between HMMs and 3D motion analysis.pdf:pdf},
isbn = {8173192219},
journal = {{Sixth International Conference on Computer Vision}},
keywords = {part-based models},
mendeley-tags = {part-based models},
pages = {363--369},
publisher = {Narosa Publishing House},
title = {{ASL recognition based on a coupling between HMMs and 3D motion analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=710744},
year = {1998}
}
@article{Volz2003,
annote = {- Stimuli were pairs of objects
- Subjects indicated which pair they thought would win, and different pairings have different probabilities
- Blocked design of constant probability, same thing 5 times in a row
        
Subjects learn the probabilities in the scanner, and there is a slow learning effect. They also seem to be sensitive to the probabilities
        
Area BA8 was only area activated over a control (just press the button for the indicated winner in the pair), and was sensitive to parametric modulation of the probability
        
But this is a confound between reward (getting it right) and probability. Is this the same thing?},
author = {Volz, Kirsten G and Schubotz, Ricarda I and von Cramon, D.Yves},
doi = {10.1016/S1053-8119(03)00122-8},
file = {:Users/Brenden/Documents/Mendeley/Volz, Schubotz, von Cramon - 2003 - Predicting events of varying probability uncertainty investigated by fMRI.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {MD system},
mendeley-tags = {MD system},
month = jun,
number = {2},
pages = {271--280},
title = {{Predicting events of varying probability: uncertainty investigated by fMRI}},
volume = {19},
year = {2003}
}
@article{Vuori2001,
annote = {Has a way of learning a cluster centroid, while using strokes in DTW space. This uses a particular datapoint as a centroid, I believe.
        
        
        
      },
author = {Vuori, V. and Laaksonen, J. and Oja, E. and Kangas, J.},
doi = {10.1007/PL00013555},
file = {:Users/Brenden/Documents/Mendeley/Vuori et al. - 2001 - Experiments with adaptation strategies for a prototype-based recognition system for isolated handwritten characters.pdf:pdf},
issn = {1433-2833},
journal = {International Journal on Document Analysis and Recognition},
keywords = {adap-,handwriting,handwriting recognition,intelligent user interface,isolated characters,k-nearest neighbor rule,learning systems,nition,online recognition,pattern recog-,tation,unconstrained writing style},
mendeley-tags = {handwriting},
month = mar,
number = {3},
pages = {150--159},
title = {{Experiments with adaptation strategies for a prototype-based recognition system for isolated handwritten characters}},
volume = {3},
year = {2001}
}
@article{Wada1995,
abstract = {We propose a trajectory planning and control theory which provides explanations at the computation, algorithm, representation, and hardware levels for continuous movement such as connected cursive handwriting. The hardware is based on our previously proposed forward-inverse-relaxation neural network. Computationally, the optimization principle is the minimum torque-change criterion. At the representation level, hard constraints satisfied by a trajectory are represented as a set of via-points extracted from handwritten characters. Accordingly, we propose a via-point estimation algorithm that estimates via-points by repeating trajectory formation of a character and via-point extraction from the character. It is shown experimentally that for movements with a single via-point target, the via-point estimation algorithm can assign a point near the actual via-point target. Good quantitative agreement is found between human movement data and the trajectories generated by the proposed model.},
author = {Wada, Y and Kawato, M},
file = {:Users/Brenden/Documents/Mendeley/Wada, Kawato - 1995 - A theory for cursive handwriting based on the minimization principle.pdf:pdf},
issn = {0340-1200},
journal = {Biological Cybernetics},
keywords = {Algorithms,Computer Simulation,Handwriting,Humans,Models,Movement,Movement: physiology,Neural Networks (Computer),Neurological,Pattern Recognition,Psychomotor Performance,Psychomotor Performance: physiology,Visual,Visual: physiology,handwriting,part-based models},
mendeley-tags = {handwriting,part-based models},
month = jun,
number = {1},
pages = {3--13},
pmid = {7654848},
title = {{A theory for cursive handwriting based on the minimization principle.}},
volume = {73},
year = {1995}
}
@article{Walker2013,
abstract = {In the research reported here, we found evidence of the cheerleader effect-people seem more attractive in a group than in isolation. We propose that this effect arises via an interplay of three cognitive phenomena: (a) The visual system automatically computes ensemble representations of faces presented in a group, (b) individual members of the group are biased toward this ensemble average, and (c) average faces are attractive. Taken together, these phenomena suggest that individual faces will seem more attractive when presented in a group because they will appear more similar to the average group face, which is more attractive than group members' individual faces. We tested this hypothesis in five experiments in which subjects rated the attractiveness of faces presented either alone or in a group with the same gender. Our results were consistent with the cheerleader effect.},
annote = {Faces are rated as more attractive when appearing in groups rather than individually. Group photos were cropped to contain either the group or just the person

        
Theory: People encode faces in part by a group average, individual exemplars are pulled towards average, and since average faces are more attractive the individual faces are also more attractive.

        
Exp 1 and 2
True for male and female faces

        
Exp 3
Not due to a simple difference in looking time

        
Exp 4
Theory would predict that large groups, have a more precise average face and would be more attractive
- no significant effect

        
Exp 5
Prediction that blurry faces would have a stronger effect
- no significant difference},
author = {Walker, Drew and Vul, Edward},
doi = {10.1177/0956797613497969},
file = {:Users/Brenden/Documents/Mendeley/Walker, Vul - 2013 - Hierarchical Encoding Makes Individuals in a Group Seem More Attractive.pdf:pdf},
issn = {1467-9280},
journal = {Psychological science},
keywords = {13,18,19,face perception,in the seventh episode,of how i met,of the fourth season,received 1,revision accepted 6,visual perception},
pmid = {24163333},
title = {{Hierarchical Encoding Makes Individuals in a Group Seem More Attractive.}},
volume = {1},
year = {2013}
}
@article{Wang1989,
author = {Wang, P S P and Zhang, Y Y},
file = {:Users/Brenden/Documents/Mendeley/Wang, Zhang - 1989 - A Fast and Flexible Thinning Algorithm.pdf:pdf},
journal = {{IEEE Transactions on Computers}},
keywords = {handwriting,thinning algorithm},
mendeley-tags = {handwriting,thinning algorithm},
number = {5},
pages = {741--745},
title = {{A Fast and Flexible Thinning Algorithm}},
volume = {38},
year = {1989}
}
@article{Wang2006,
abstract = {We develop a new class of hierarchical stochastic image models called spatial random trees (SRTs) which admit polynomial-complexity exact inference algorithms. Our framework of multitree dictionaries is the starting point for this construction. SRTs are stochastic hidden tree models whose leaves are associated with image data. The states at the tree nodes are random variables, and, in addition, the structure of the tree is random and is generated by a probabilistic grammar. We describe an efficient recursive algorithm for obtaining the maximum a posteriori estimate of both the tree structure and the tree states given an image. We also develop an efficient procedure for performing one iteration of the expectation-maximization algorithm and use it to estimate the model parameters from a set of training images. We address other inference problems arising in applications such as maximization of posterior marginals and hypothesis testing. Our models and algorithms are illustrated through several image classification and segmentation experiments, ranging from the segmentation of synthetic images to the classification of natural photographs and the segmentation of scanned documents. In each case, we show that our method substantially improves accuracy over a variety of existing methods},
annote = {Learns multi-resolution tree models for images, where leaf nodes are individual pixels. Unlike previous work, the tree structure is not fixed in advance. Instead, the prior on trees is defined by a grammar the splits rectangular regions into two segments. 
        
Each hidden node, and leaf node, can be associated with a label -- and labels should vary smoothly across the tree. If we want to do segmentation, the discrete label can indicate the segment. If we want to do make a generative model, that label can indicate which component in a mixture of Gaussians we are using.
        
This is a cool method, but its not clear if the learned topology is useful, and it is not visualized.
        
---
Probabilistic grammar model of images -- much like the Zhu et al., Yuille, approach.
        
Stochastic hidden tree model, where the leaf nodes are image data. Their innovation is that the tree itself is random, and generated by a probabilistic grammar. It is hard because the leaves cannot be maped onto a 2D grid. 
        
To solve this, every symbol in the grammar is associated with a 2-D region.
        
We have a hierarchical segmentation of the image into regions. The root has the whole image. Production nodes split the whole image into smaller, rectangular sub-regions. Terminal symbols are at the individual pixel level. Each non-terminal, and terminal symbol can have a label, like a class label. Regions are usually split into two conrguet rectangles. 
        
Each leaf has a cost, which is the negative of its log-probability.
        
Supervised learning: given trees and data, we can learn the cost of the transition rules
        
You can use it for classification, by having each label $j$ represent a Gaussian, that tends to generate particular pixel intensities
        
You can use it for segmentation, with the same method -- define 6 $j$ values if there are 6 regions.},
author = {Wang, W. and Pollak, I. and Wong, T.-S. and Bouman, C.A. and Harper, M.P. and Siskind, J.M.},
doi = {10.1109/TIP.2006.877496},
file = {:Users/Brenden/Documents/Mendeley/Wang et al. - 2006 - Hierarchical Stochastic Image Grammars for Classification and Segmentation.pdf:pdf},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
keywords = {part-based models,program induction},
mendeley-tags = {part-based models,program induction},
month = oct,
number = {10},
pages = {3033--3052},
title = {{Hierarchical Stochastic Image Grammars for Classification and Segmentation}},
volume = {15},
year = {2006}
}
@article{Ward1994,
annote = {Summary:
        
While people most often study classification, generation and imagination are also abilities that likely draw on category knowledge
        
The central tendency in using imagination is to base creations on central features of a predictable, highly related knowledge base.
        
Imagined typically relate to known ones, with a few modifications, and features are correlated and highly structure
        
But this can be overriden by general knowledge and specific enviornmental constraints
        
Relevance to my tasks: Generating new examples of an alphabet
- very reasonable for the model to base characters strongly on previous ones, and sometime even re-produce previous ones exactly
- my model, in terms of re-using known parts in novel ways, is quite a good match for this study
        
----------
categories are most often studied through:
- learning
- classification
- inductive inference
        
Used for many other things:
- invent or diesng new products
- modify existing designs
- develop new characters, creatures, scenes
- imagine new category examples
        
Category exemplar generation:
- design a new example appropriate for some imaginary setting
        
structured imagination: imagination is structured by a particular set of properties characteristic of the environment
        
is imagination unstructured, or does it rely on the same processes as non-creative congition?
                  
models of categorization
                
prototypes, features, exemplars, etc. modeling primarily considered in categorization decision
        
none of htem make predictions about imagination
        
Study was to determine whether category sturcutres place a role, and thus, how the models must be extended
                  
Experiment 1        
People imagined, drew, descrbied an animal living on a planet very different from earth
        
attribute-listing studies predict which properties might be present in novel creations
        
shape and parts are more critical than size, color, so a second member of a category might vary along the more variable dimension
        
Method:
You are visiting planet, imagine finding an animal there
- asked about non-obvious properties
- asked to draw another member of the same species
- draw different species from same planet
        
Coding:
a) propertie of first animal
b) differences between first and second example of species
c) difference between first and second species
        
also, coded for atypical properties (comapred to earth creatures)
        
                  
Results
                
most had major sense organs, and they were typical in that they are common with animals on earth
        
most creatures (60%) were classified as unusual, comapred to earth
        
Tendency was to produce creatures that differ from earth animals in only a limited number of ways
        
Species
+ animals were more similar within species than across
+ shape rarley varied wthin species, as well as sense organs, appendages
+ size often varied within species
        
People treated the task as generating new basic-level categories
        
        Experiment 2
                
It is well-known that attributes of natural categories tend to co-occur. Does this structure influence exemplar generation?
        
People were asked to imagine and draw an animal, and were told it either had feathers, was furry, lived in water, had scales etc.
        
Since people tend to adapt a known species, descriptions were analyzed for references to known species
                  
Results
                
comparison of appendages: 
- feathers were more likely to draw wings
- scales led to more fins
etc.
        
sense organs:
- feathers led to more beaks
- scales led to more gills
also, feathers and scales led to fewer ears, which is not directly predicatble from attribute-listing data
+ thus, you can discover new correlations with this generation task
        
People in "feathers" conditions were likely to mention birds in description, etc.
- scales condition mentieond "fish"
        
Those who did report earth species were less likely to include unusual appendages or unusual senses
                  
Experiment 3
                
These attribute correlations could manifest themselves simply through the activation of exemplars
        
or do they access their general knowledge about why it makes sense for these things to be correlated (wings and feathers)?
        
Here, they described planets that had certain features, like
- "mostly molten rock" with just a few islands, the ability to travel between islands was important
- extremely violent winds above surface, and avoiding winds is important for survival
        
Then, told the animal had feathers or fur
        
Thus, they would not simply retrieve exemplars that they know about.
        
If people used general knowledge here, winged creatures should be more common in the island case than the windy one
        
also, how woudl they deal with a furry creature that needs to get between islands? less likely to use exemplars
        
Conditions
factor 1: molten lava planet or winds
factor 2: fur or feathers
                  
Results
                
Also, creatures were more likely to fly in the molten condition than the windy condition
        
Also, furry creatures tended to fly even in the molten environment
        
other adaptations: many people in windy conditino developed creatures with sunction cups, claws, etc.
- many people in Molten conditinos developed creatures that were heat-resistant feet, 
        
Creatures seemed to look much more creative
        
One creature even had sunglasses and wind collectors!
        
        discussion
                
novel environments influenced creations in predictable ways
        
-when flying was adaptive, most creatures would fly
- when flying was unapative, most creatures did not
        
They used general knowledge, rathe rthan specific exampels
        
The process of imagination is flexible, and it can retrieve no instances and sythensize new exemplars
                  
Experiment 4        
        
Did participants draw conservative creatures that would be believable? Unclear what they should do from instructions
        
Conditions:
1) draw believable and realistici
2) use your wildest imagination
3) control
        
Alos, did they base creatures in science fiction?
        
        Results
                
imagination condition were more likely to include something unusual about their sensory system
        
Results from control condition and "believable" condition were not really any different
        
Thus, subjects extend at least the central structure principles even to extraterrestrials and even when they are asked to be wildly imaginative
                  
Experiment 5        
        
coded 50 creatures in Barlowe's guide to aliens
        
results:
 most had sense oragnas and were symmetric
                  
Discussion
                
When people imagine novel animals, the properties of creations are predictable from research on noncreative aspects of categorization
        
examples are highly structured, like those on earth, even when using "wildest imagination"
        
inventions often take features from previous products, even when they are no longer relevant or sensible
                  
relevance to models
                
presumably, an exemplar model would not be able to mix and matches features without additional structure
        
model might use specific instances, attributes true of general members, beliefs about adapation
        
any model that only included exempalrs would have to explain why creatuers in the molten-fur condition were so non-birdlike, even though the have wings
        
Also, models that do not use specific exempalrs would why exampels int he molten-wings condition were so birdlike
        
Also, attributes seem to be independently accessible in exemplars, since people avoided including large chunks of unncessary and unwated attributes
                  
a tentative model
                
1) first, choose a relevant domain
2) absence of other instruction, choose an existing example and modify it. Also, choose a typical instance of the broader relevant domain
3) if there are no contraints, it might look similar, but otherwise this exemplar could be rejected or modified extensively
4) innovation occurs primarily when the designer consults broader knowledge        
        
The central tendency in using imagination is to base creations on central features of a predictable, highly related knowledge base
      },
author = {Ward, Thomas B},
file = {:Users/Brenden/Documents/Mendeley/Ward - 1994 - Structured Imagination The Role of Category Structure in Exemplar Generation.pdf:pdf},
journal = {Cognitive Psychology},
keywords = {classic psychology,classics on concepts,exemplar generation},
mendeley-tags = {classic psychology,classics on concepts,exemplar generation},
pages = {1--40},
title = {{Structured Imagination: The Role of Category Structure in Exemplar Generation}},
volume = {27},
year = {1994}
}
@article{Ward2002,
author = {Ward, Thomas B and Patterson, Merryl J and Sifonis, Cynthia M and Dodds, Rebecca A and Saunders, Katherine N},
file = {:Users/Brenden/Documents/Mendeley/Ward et al. - 2002 - The role of graded category structure in imaginative thought.pdf:pdf},
journal = {Memory \& Cognition},
keywords = {exemplar generation},
mendeley-tags = {exemplar generation},
number = {2},
pages = {199--216},
title = {{The role of graded category structure in imaginative thought}},
volume = {30},
year = {2002}
}
@article{Weiss2001,
abstract = {Graphical models, such as Bayesian networks and Markov random fields, represent statistical dependencies of variables by a graph. Local "belief propagation" rules of the sort proposed by Pearl (1988) are guaranteed to converge to the correct posterior probabilities in singly connected graphs. Recently, good performance has been obtained by using these same rules on graphs with loops, a method we refer to as loopy belief propagation. Perhaps the most dramatic instance is the near Shannon-limit performance of "Turbo codes," whose decoding algorithm is equivalent to loopy propagation. Except for the case of graphs with a single loop, there has been little theoretical understanding of loopy propagation. Here we analyze belief propagation in networks with arbitrary topologies when the nodes in the graph describe jointly gaussian random variables. We give an analytical formula relating the true posterior probabilities with those calculated using loopy propagation. We give sufficient conditions for convergence and show that when belief propagation converges, it gives the correct posterior means for all graph topologies, not just networks with a single loop. These results motivate using the powerful belief propagation algorithm in a broader class of networks and help clarify the empirical performance results.},
author = {Weiss, Y and Freeman, W T},
doi = {10.1162/089976601750541769},
file = {:Users/Brenden/Documents/Mendeley/Weiss, Freeman - 2001 - Correctness of belief propagation in Gaussian graphical models of arbitrary topology.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {graphical models},
mendeley-tags = {graphical models},
month = oct,
number = {10},
pages = {2173--200},
pmid = {11570995},
title = {{Correctness of belief propagation in Gaussian graphical models of arbitrary topology.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11570995},
volume = {13},
year = {2001}
}
@article{Weiss2002,
abstract = {The pattern of local image velocities on the retina encodes important environmental information. Although humans are generally able to extract this information, they can easily be deceived into seeing incorrect velocities. We show that these 'illusions' arise naturally in a system that attempts to estimate local image velocity. We formulated a model of visual motion perception using standard estimation theory, under the assumptions that (i) there is noise in the initial measurements and (ii) slower motions are more likely to occur than faster ones. We found that specific instantiation of such a velocity estimator can account for a wide variety of psychophysical phenomena.},
annote = {Many motion illusions are Bayes optimal under reasonable assumptions
        
Prior: slow motion is preferred (Gaussian)
Likelihood: noise at the pixel level (Gaussian)
        
Posterior: Pick a consistent motion, with a perference towards slow. This warp is strongest is bad contrast or with shapes that provide little data.
        
Comments: Shouldn't the prior be more complicated than that?
        
The normal velocity, the normal vector to a moving diagonal line, is slower than the true velocity. Thus in noisy conditions (ike low contrast), people perceive it as moving along the normal vector},
author = {Weiss, Yair and Simoncelli, Eero P and Adelson, Edward H},
doi = {10.1038/nn858},
file = {:Users/Brenden/Documents/Mendeley/Weiss, Simoncelli, Adelson - 2002 - Motion illusions as optimal percepts.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Bayesian perception,Contrast Sensitivity,Contrast Sensitivity: physiology,Humans,Models,Motion Perception,Motion Perception: physiology,Neurological,Optical Illusions,Optical Illusions: physiology,Time Factors},
mendeley-tags = {Bayesian perception},
month = jun,
number = {6},
pages = {598--604},
pmid = {12021763},
title = {{Motion illusions as optimal percepts.}},
volume = {5},
year = {2002}
}
@article{Wellman1992,
annote = {General overview of theory theory, as applied to three core domains:
        
physics
psychology
biology
        
General claim that children have specific theories of these domains, rather than general competencies. They genearlly do not confuse phenomena in these three domains.
        
---
        
Piaget: cognitive structures are content independent and domain general. There are domain general stages. 
                  
Framework theories        
are like paradigms in phil. of science
        
In psychology: behaviorism, connectionism -- as opposed to the Rescorla-Wagner model or object permanence
                  
Naive physics
          
Early physical knowledge        
Piaget: objects acquired late in infancy. But he relied on search tasks, which underestimates abilities. 
        
Baillargeon: infants as young as 3-4 months represent continued existance of objects (object permanence). 
        
Spelke: infants (4 months) expect infants expect invisible objects to continue at rest or motion, unless impeded by a solid object
                  
Later physical knowledge        
Gelman: essentialist understanding. Children generalize that members of a category (dogs, nuts) have the same insides, even when a distractor looks more visually similar. Furthermore, insides seem core.
        
McCloskey: naive physics is theoretical, but not always accurate (impetus theory)
                  
Naive psychology
                
Children as young as 3 know that mental dogs can't be petted, but physical dogs can. They distinguish mental and physical (p. 15)
        
Children by 3/4 can understand false beliefs
        
By 2/3, children can understand that emotinos have a causal organization
                  
Early psychology        
Preference to faces, mother's voice, etc.
        
Young infants discriminate biological motion from not
        
But not all of these perferences mean it's mentalistic
        
In the second year, infants point to things that they want other people to attend to (p. 19)
        
By 3/4, children seem to have a rich belief-desire understanding, with some degree of gaze and intention
                  
Naive biology
                
Piaget argued against early animate/inanimate distinction by interview with children, but more sensitive measures show there is an early distinction. Children as young as 3 clearly distinguish (Gelman & Spelke, 1983)
        
Young children do not just use physical similarity. Carey 1985 showed that they do not attribute thiking, eating, etc. to a mechanical monkey
                  
Early biology
                
Smith (1989) -- 12 month olds distinguish toy animates vs. inanimates
        
Examples from Carey 1985
        
Plants are an interesting case, since they are biological but not animate
        
Until age 10, children are confused about what biological means
        
They see little that ties plants and animals together. If property X spans two examples of living things, they don't generalize while adults do.
        
Humans are the prototypical "havers of things". Properties of animals are evaluated by whether humans have it and how similar the animal is to people.
        
 But Inagaki and Hatano point out children can tell the difference between mental/biological
        
Young children (4 years) infer biological aspects of gender
        
4 year olds know that a cow, raised with pigs or plants,  will grow up to have cow characteristics
        
Thus, it is unclear how much biology young children have. It seems less well developed in young children than the other domains. 
                  
General
                
Children clearly distinguish between the 3 domains of thought, while Piaget did not think they did
        
People view phenomena in these domains through particular theoretical lenses
        
While concepts in these domains are not always adult-like, like lacking plants or beliefs, children do not confuse the broader framework theories with eachother
        
It is hard to tell whether the early knowledge coheres into a "theory"
        
It is likely that scientific theories are built from the initial naive theories, rather than buildling
the naive theories from the scientific theories},
author = {Wellman, H M and Gelman, S a},
doi = {10.1146/annurev.ps.43.020192.002005},
file = {:Users/Brenden/Documents/Mendeley/Wellman, Gelman - 1992 - Cognitive development foundational theories of core domains.pdf:pdf},
issn = {0066-4308},
journal = {Annual review of psychology},
keywords = {Child,Child Development,Child Psychology,Cognition,Humans,Infant,Interpersonal Relations,Preschool,Psychological Theory,Thinking,theory theory},
mendeley-tags = {theory theory},
month = jan,
pages = {337--75},
pmid = {1539946},
title = {{Cognitive development: foundational theories of core domains.}},
volume = {43},
year = {1992}
}
@article{Werker1984,
author = {Werker, J F and Tees, R C},
journal = {Infant Behavior and Development},
pages = {49--63},
title = {{Cross-language speech perception: evidence for perceptual reorganization during the first year of life}},
volume = {7},
year = {1984}
}
@article{Werker2007,
abstract = {Across the first year of life, infants show decreased sensitivity to phonetic differences not used in the native language [Werker, J. F., & Tees, R. C. (1984). Cross-language speech perception: evidence for perceptual reorganization during the first year of life. Infant Behaviour and Development, 7, 49-63]. In an artificial language learning manipulation, Maye, Werker, and Gerken [Maye, J., Werker, J. F., & Gerken, L. (2002). Infant sensitivity to distributional information can affect phonetic discrimination. Cognition, 82(3), B101-B111] found that infants change their speech sound categories as a function of the distributional properties of the input. For such a distributional learning mechanism to be functional, however, it is essential that the input speech contain distributional cues to support such perceptual learning. To test this, we recorded Japanese and English mothers teaching words to their infants. Acoustic analyses revealed language-specific differences in the distributions of the cues used by mothers (or cues present in the input) to distinguish the vowels. The robust availability of these cues in maternal speech adds support to the hypothesis that distributional learning is an important mechanism whereby infants establish native language phonetic categories.},
author = {Werker, Janet F and Pons, Ferran and Dietrich, Christiane and Kajikawa, Sachiyo and Fais, Laurel and Amano, Shigeaki},
doi = {10.1016/j.cognition.2006.03.006},
file = {:Users/Brenden/Documents/Mendeley/Werker et al. - 2007 - Infant-directed speech supports phonetic category learning in English and Japanese.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Canada,Humans,Infant,Japan,Phonetics,Speech Perception,Verbal Behavior,Verbal Learning,speech recognition},
mendeley-tags = {speech recognition},
month = apr,
number = {1},
pages = {147--62},
pmid = {16707119},
title = {{Infant-directed speech supports phonetic category learning in English and Japanese.}},
volume = {103},
year = {2007}
}
@article{Wichmann2001,
abstract = {The psychometric function relates an observer's performance to an independent variable, usually a physical quantity of an experimental stimulus. Even if a model is successfully fit to the data and its goodness of fit is acceptable, experimenters require an estimate of the variability of the parameters to assess whether differences across conditions are significant. Accurate estimates of variability are difficult to obtain, however, given the typically small size of psychophysical data sets: Traditional statistical techniques are only asymptotically correct and can be shown to be unreliable in some common situations. Here and in our companion paper (Wichmann & Hill, 2001), we suggest alternative statistical techniques based on Monte Carlo resampling methods. The present paper's principal topic is the estimation of the variability of fitted parameters and derived quantities, such as thresholds and slopes. First, we outline the basic bootstrap procedure and argue in favor of the parametric, as opposed to the nonparametric, bootstrap. Second, we describe how the bootstrap bridging assumption, on which the validity of the procedure depends, can be tested. Third, we show how one's choice of sampling scheme (the placement of sample points on the stimulus axis) strongly affects the reliability of bootstrap confidence intervals, and we make recommendations on how to sample the psychometric function efficiently. Fourth, we show that, under certain circumstances, the (arbitrary) choice of the distribution function can exert an unwanted influence on the size of the bootstrap confidence intervals obtained, and we make recommendations on how to avoid this influence. Finally, we introduce improved confidence intervals (bias corrected and accelerated) that improve on the parametric and percentile-based bootstrap confidence intervals previously used. Software implementing our methods is available.},
author = {Wichmann, F a and Hill, N J},
file = {:Users/Brenden/Documents/Mendeley/Wichmann, Hill - 2001 - The psychometric function II. Bootstrap-based confidence intervals and sampling.pdf:pdf},
issn = {0031-5117},
journal = {Perception & psychophysics},
keywords = {Confidence Intervals,Humans,Models,Monte Carlo Method,Psychometrics,Psychometrics: methods,Psychophysics,Psychophysics: statistics & numerical data,Sensory Thresholds,Statistical},
month = nov,
number = {8},
pages = {1314--29},
pmid = {11800459},
title = {{The psychometric function: II. Bootstrap-based confidence intervals and sampling.}},
volume = {63},
year = {2001}
}
@article{Wichmann2001a,
abstract = {The psychometric function relates an observer's performance to an independent variable, usually some physical quantity of a stimulus in a psychophysical task. This paper, together with its companion paper (Wichmann & Hill, 2001), describes an integrated approach to (1) fitting psychometric functions, (2) assessing the goodness of fit, and (3) providing confidence intervals for the function's parameters and other estimates derived from them, for the purposes of hypothesis testing. The present paper deals with the first two topics, describing a constrained maximum-likelihood method of parameter estimation and developing several goodness-of-fit tests. Using Monte Carlo simulations, we deal with two specific difficulties that arise when fitting functions to psychophysical data. First, we note that human observers are prone to stimulus-independent errors (or lapses). We show that failure to account for this can lead to serious biases in estimates of the psychometric function's parameters and illustrate how the problem may be overcome. Second, we note that psychophysical data sets are usually rather small by the standards required by most of the commonly applied statistical tests. We demonstrate the potential errors of applying traditional chi2 methods to psychophysical data and advocate use of Monte Carlo resampling techniques that do not rely on asymptotic theory. We have made available the software to implement our methods.},
author = {Wichmann, F a and Hill, N J},
file = {:Users/Brenden/Documents/Mendeley/Wichmann, Hill - 2001 - The psychometric function I. Fitting, sampling, and goodness of fit.pdf:pdf},
issn = {0031-5117},
journal = {Perception & psychophysics},
keywords = {Bias (Epidemiology),Confidence Intervals,Humans,Likelihood Functions,Monte Carlo Method,Psychometrics,Psychometrics: methods,Psychophysics,Psychophysics: statistics & numerical data,Sensory Thresholds},
month = nov,
number = {8},
pages = {1293--313},
pmid = {11800458},
title = {{The psychometric function: I. Fitting, sampling, and goodness of fit.}},
volume = {63},
year = {2001}
}
@article{Wightman1992,
abstract = {Numerous studies have indicated that prosodic phrase boundaries may be marked by a variety of acoustic phenomena including segmental lengthening. It has not been established, however, whether this lengthening is restricted to the immediate vicinity of the boundary, or if it extends over some larger region. In this study, segmental lengthening in the vicinity of prosodic boundaries is examined and found to be restricted to the rhyme of the syllable preceding the boundary. By using a normalized measure of segmental lengthening, and by compensating for differences in speaking rate, it is also shown that at least four distinct types of boundaries can be distinguished on the basis of this lengthening.},
annote = {Phonologists agree there is a need for some types of prosody, at different leves of granularity, there is a lot of debate on exactly where these levels are
        
      },
author = {Wightman, C W and Shattuck-Hufnagel, S and Ostendorf, M and Price, P J},
file = {:Users/Brenden/Documents/Mendeley/Wightman et al. - 1992 - Segmental durations in the vicinity of prosodic phrase boundaries.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Attention,Cues,Humans,Phonetics,Pitch Perception,Psychoacoustics,Semantics,Speech Perception,Time Perception,Verbal Behavior},
month = mar,
number = {3},
pages = {1707--17},
pmid = {1564206},
title = {{Segmental durations in the vicinity of prosodic phrase boundaries.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1564206},
volume = {91},
year = {1992}
}
@article{Wilder2011,
abstract = {This paper investigates the classification of shapes into broad natural categories such as animal or leaf. We asked whether such coarse classifications can be achieved by a simple statistical classification of the shape skeleton. We surveyed databases of natural shapes, extracting shape skeletons and tabulating their parameters within each class, seeking shape statistics that effectively discriminated the classes. We conducted two experiments in which human subjects were asked to classify novel shapes into the same natural classes. We compared subjects' classifications to those of a naive Bayesian classifier based on the natural shape statistics, and found good agreement. We conclude that human superordinate shape classifications can be well understood as involving a simple statistical classification of the shape skeleton that has been "tuned" to the natural statistics of shape.},
annote = {How do people classify shape at the superordinate level?

        
- simple parameters based on shape skeletons (maybe just 2)
- classifier tuned to natural statistics

        
No suprise that people can judge similarity of novel shapes with a sufficiently complex representation, but it is surprising that they may just use a few parameters.

        
[-Notes for character project:
can we analyze model parameters, rather than use the bayesian function for classification? seeh which are important?
-similar point about prior distribution learned from experience?]

        

        

        
------
Introduction

        
- classification is known to be hierarchical (Rosch)
- can you classify shape into broad, superordinate categories based on carefully-selected parameters?

        
Parameterization of shape
Most methods create suprious axes, which arise from noise on the shape.

        
Natural statistics:
- visual system adapted to the environemtn
- not much work on statistics of shape -- they use leaf vs. animal

        
Parameters chosen from skeletons:
- number of parts
- maximum depth
- mean depth
- mean branch angle
- mean lenght of each axis
- total sum of aboslute angle
- total sum of angle 
(last tow measure wigliness)

        
Number of parts is gaussian for animals, exponential for leaves (suggesting scale-invariant branching process)

        
Animals have larger sum total angle, due to articulated internal joints

        

        
          
Experiment
- created animal/leaf morphs, asked people to classify as animal or leaf
- found that people accurately tracked the percentage of one class vs. the other in morph

        
          
Experiment 2
        
Same thing, but varied display time, to test for difference in rapid classification/feedforward process

        
Brief presentation idd not alter the strategy substantially

        
          
Model

        
        
Main goal is to see if people are using natural shape statistics.
          

        
        
First, eliminate parametesr that are not useful -- based on non-parametric test.

        
Create naive bayes estimator for each class.

        
Training based on unadulated shapes.
Model selection based on AIC, found just two parameters (number of skeletal branches, total signed axial tuning angle)
- this captures about 81% of training data
- people are n't much better at this task

        
REsults:
Model accounts for about 70-80 percent of the variance in the morphed classificationt ask

        
Conclusion:
No surprise that with a sufficeitnly rich representation, they can compute similarity
+ but it is surprising that they seem to use few parameters

        
Alternative models:
- other more standard features do well at classifiation, but they do not predict the human morphed shapes very well.},
author = {Wilder, John and Feldman, Jacob and Singh, Manish},
doi = {10.1016/j.cognition.2011.01.009},
file = {:Users/Brenden/Documents/Mendeley/Wilder, Feldman, Singh - 2011 - Superordinate shape classification using natural shape statistics.pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
keywords = {Algorithms,Animals,Bayes Theorem,CogSci2013 Symposium,Data Interpretation,Databases,Factual,Female,Form Perception,Form Perception: physiology,Humans,Language,Male,Models,Neurological,Photic Stimulation,Statistical,Young Adult,part-based models},
mendeley-tags = {CogSci2013 Symposium,part-based models},
month = jun,
number = {3},
pages = {325--40},
pmid = {21440250},
title = {{Superordinate shape classification using natural shape statistics.}},
volume = {119},
year = {2011}
}
@article{Williams2010,
abstract = {Research in education and cognitive development suggests that explaining plays a key role in learning and generalization: When learners provide explanations-even to themselves-they learn more effectively and generalize more readily to novel situations. This paper proposes and tests a subsumptive constraints account of this effect. Motivated by philosophical theories of explanation, this account predicts that explaining guides learners to interpret what they are learning in terms of unifying patterns or regularities, which promotes the discovery of broad generalizations. Three experiments provide evidence for the subsumptive constraints account: prompting participants to explain while learning artificial categories promotes the induction of a broad generalization underlying category membership, relative to describing items (Exp. 1), thinking aloud (Exp. 2), or free study (Exp. 3). Although explaining facilitates discovery, Experiment 1 finds that description is more beneficial for learning item details. Experiment 2 additionally suggests that explaining anomalous observations may play a special role in belief revision. The findings provide insight into explanation's role in discovery and generalization.},
author = {Williams, Joseph J and Lombrozo, Tania},
file = {:Users/Brenden/Documents/Mendeley/Williams, Lombrozo - 2010 - The role of explanation in discovery and generalization evidence from category learning.pdf:pdf},
issn = {1551-6709},
journal = {Cognitive science},
keywords = {category learning,explanation,generalization,learning,rich concepts,self-explanation,transfer},
mendeley-tags = {explanation,rich concepts},
number = {5},
pages = {776--806},
pmid = {21564236},
title = {{The role of explanation in discovery and generalization: evidence from category learning.}},
volume = {34},
year = {2010}
}
@article{Willsky2002,
abstract = {Reviews a significant component of the rich field of statistical multiresolution (MR) modeling and processing. These MR methods have found application and permeated the literature of a widely scattered set of disciplines, and one of our principal objectives is to present a single, coherent picture of this framework. A second goal is to describe how this topic fits into the even larger field of MR methods and concepts-in particular, making ties to topics such as wavelets and multigrid methods. A third goal is to provide several alternate viewpoints for this body of work, as the methods and concepts we describe intersect with a number of other fields. The principle focus of our presentation is the class of MR Markov processes defined on pyramidally organized trees. The attractiveness of these models stems from both the very efficient algorithms they admit and their expressive power and broad applicability. We show how a variety of methods and models relate to this framework including models for self-similar and 1/f processes. We also illustrate how these methods have been used in practice.},
author = {Willsky, A.S.},
doi = {10.1109/JPROC.2002.800717},
file = {:Users/Brenden/Documents/Mendeley/Willsky - 2002 - Multiresolution Markov models for signal and image processing.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
month = aug,
number = {8},
pages = {1396--1458},
title = {{Multiresolution Markov models for signal and image processing}},
volume = {90},
year = {2002}
}
@article{Wilson2002,
abstract = {The emerging viewpoint of embodied cognition holds that cognitive processes are deeply rooted in the body's interactions with the world. This position actually houses a number of distinct claims, some of which are more controversial than others. This paper distinguishes and evaluates the following six claims: (1) cognition is situated; (2) cognition is time-pressured; (3) we off-load cognitive work onto the environment; (4) the environment is part of the cognitive system; (5) cognition is for action; (6) off-line cognition is body based. Of these, the first three and the fifth appear to be at least partially true, and their usefulness is best evaluated in terms of the range of their applicability. The fourth claim, I argue, is deeply problematic. The sixth claim has received the least attention in the literature on embodied cognition, but it may in fact be the best documented and most powerful of the six claims.},
annote = {Body has a central role in shaping the mind. The most interesting claim is that perceptual and motor-systems are used for cognition, even when the mind is off-line and detactched from bottom-up data.
        
Claims:
1: Cognition is situated --it takes place in real-world environemnt, and it invovles perception and action. Wilson concludes this is not overly persuasive, there are abilities you can study without it (language, daydreaming, etc.)
        
2: Cognition is time pressured -- it must be understood with time constraints. This is used to point out weakness of traditional AI. Not that persuasive, since we read, do demanding tasks, etc. without time pressure.
        
3: We off-load work to the environment -- we use it to hold or manipulate info. Allows for minimal memory strategies, look when you need the info. Math in general involves symbol off-loading.
        
4: The environment is part of the cognitive system -- we can't study the mind without it. Wilson: Not convincing, the boundary might be arbitrary, but it should depend on the situation and task. Knowing about atoms is not gleaned only from their interactions.
        
5: Cognition is for action -- everything should be understood in contribution to behavior. Wilson, not convincing, a lot of our knowledge is representation neutral,which is adaptive for problem-solving in novel circumstances.
        
6: Off-line cognition is body based -- most important claim for me. Even when decoupled from the environment, the mind uses mechanisms for sensory and motor control.
Examples:
" the function of these sensorimotor resrouces is to run a simulation of some aspect of the physical world, as a means of representing information or drawing inferences.
-- Mental imagery
-- Working memory off-loads onto perceptual/motor systems to get more space
-- Implicit memory: an expert driver uses less mental effor, and with more finesse. In a way, this has been off-loaded to the body
-- Reasoning and problem-solving: monk problem best visualized spaitally},
author = {Wilson, M},
file = {:Users/Brenden/Documents/Mendeley/Wilson - 2002 - Six views of embodied cognition.pdf:pdf},
issn = {10699384},
journal = {Psychonomic Bulletin and Review},
keywords = {embodied cognition},
mendeley-tags = {embodied cognition},
number = {4},
pages = {625--636},
pmid = {12613670},
publisher = {Psychonomic Society Publications},
title = {{Six views of embodied cognition}},
volume = {9},
year = {2002}
}
@article{Wilson1994,
annote = {Note from NIPS invisted talk:
        
Place cells are direction specific, in simple mazes
        
Large burts of unorganized activity when the animal stops moving
        
During non-rem sleep, there are short replays of the track, based on the sequence of place cells
        
Also, this hippocampus activity correlates with visual cortex activity, which re-experiences some of the visual details
        
Model
- neocortex starts off the reactivation
- hippocampus replays the sequence
- neorcortex then reactives the visual cortex
        
Can you influence the dream, when you are listening to a sound that was associated with an aspect of the maze?
- sound associaed with left hand of track, another sound for right hand
- this strongly influences which places cells, whether left or right, during sleep
But this doesn't influence quiet wakefulness
        
If items in a memory/position game are assocaited with sounds, you get better at items that you replay the sounds
        
Replay of squences, in backwards order, during rest
- this can be used for reinforcement learning, when multiplied by a graded temporal discounting filter},
author = {Wilson, MA and McNaughton, BL},
file = {:Users/Brenden/Documents/Mendeley/Wilson, McNaughton - 1994 - Reactivation of hippocampal ensemble memories during sleep.pdf:pdf},
isbn = {1111111111},
journal = {Science},
title = {{Reactivation of hippocampal ensemble memories during sleep}},
url = {http://www.sciencemag.org/content/265/5172/676.short},
volume = {265},
year = {1994}
}
@article{Wilson2004,
abstract = {To examine the role of motor areas in speech perception, we carried out a functional magnetic resonance imaging (fMRI) study in which subjects listened passively to monosyllables and produced the same speech sounds. Listening to speech activated bilaterally a superior portion of ventral premotor cortex that largely overlapped a speech production motor area centered just posteriorly on the border of Brodmann areas 4a and 6, which we distinguished from a more ventral speech production area centered in area 4p. Our findings support the view that the motor system is recruited in mapping acoustic inputs to a phonetic code.},
author = {Wilson, Stephen M and Saygin, Ayşe Pinar and Sereno, Martin I and Iacoboni, Marco},
doi = {10.1038/nn1263},
file = {:Users/Brenden/Documents/Mendeley/Wilson et al. - 2004 - Listening to speech activates motor areas involved in speech production.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Adult,Brain Mapping,Female,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,Motor Cortex,Motor Cortex: physiology,Phonetics,Speech,Speech Perception,Speech Perception: physiology,Speech: physiology,embodied cognition},
mendeley-tags = {embodied cognition},
month = jul,
number = {7},
pages = {701--2},
pmid = {15184903},
shorttitle = {Nat Neurosci},
title = {{Listening to speech activates motor areas involved in speech production.}},
url = {http://dx.doi.org/10.1038/nn1263},
volume = {7},
year = {2004}
}
@article{Winawer2007,
abstract = {English and Russian color terms divide the color spectrum differently. Unlike English, Russian makes an obligatory distinction between lighter blues ("goluboy") and darker blues ("siniy"). We investigated whether this linguistic difference leads to differences in color discrimination. We tested English and Russian speakers in a speeded color discrimination task using blue stimuli that spanned the siniy/goluboy border. We found that Russian speakers were faster to discriminate two colors when they fell into different linguistic categories in Russian (one siniy and the other goluboy) than when they were from the same linguistic category (both siniy or both goluboy). Moreover, this category advantage was eliminated by a verbal, but not a spatial, dual task. These effects were stronger for difficult discriminations (i.e., when the colors were perceptually close) than for easy discriminations (i.e., when the colors were further apart). English speakers tested on the identical stimuli did not show a category advantage in any of the conditions. These results demonstrate that (i) categories in language affect performance on simple perceptual color tasks and (ii) the effect of language is online (and can be disrupted by verbal interference).},
author = {Winawer, Jonathan and Witthoft, Nathan and Frank, Michael C and Wu, Lisa and Wade, Alex R and Boroditsky, Lera},
doi = {10.1073/pnas.0701644104},
file = {:Users/Brenden/Documents/Mendeley/Winawer et al. - 2007 - Russian blues reveal effects of language on color discrimination.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Adolescent,Adult,Child,Color Perception,Discrimination (Psychology),Humans,Language},
month = may,
number = {19},
pages = {7780--5},
pmid = {17470790},
title = {{Russian blues reveal effects of language on color discrimination.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1876524&tool=pmcentrez&rendertype=abstract},
volume = {104},
year = {2007}
}
@article{Wing2000,
abstract = {Handwriting is a classic example of how the details of movement can be scale and plane invariant: letter forms reflecting personal style are unchanged, whether one is writing on a piece of paper, on a blackboard or in the sand using the foot. Recent research points to a role for the parietal cortex in such motor equivalence.},
author = {Wing, A M},
file = {:Users/Brenden/Documents/Mendeley/Wing - 2000 - Motor control Mechanisms of motor equivalence in handwriting.pdf:pdf},
issn = {0960-9822},
journal = {Current biology},
keywords = {Handwriting,Humans,Motor Skills,Motor Skills: physiology,Parietal Lobe,Parietal Lobe: physiology,handwriting,motor equivalence},
mendeley-tags = {handwriting,motor equivalence},
month = mar,
number = {6},
pages = {R245--8},
pmid = {10744963},
title = {{Motor control: Mechanisms of motor equivalence in handwriting.}},
volume = {10},
year = {2000}
}
@inproceedings{Wingate2011,
annote = {Prior on policies, which can reflect abstract prior knowlege about the domain.
        
This is an RL problem. I'm not sure if the agent knows the transition model. But they don't have a policy, and they are doing inference over the policy as the take actions in the world.
        
This can result in the right bias being learned very quickly.},
author = {Wingate, David and Goodman, Noah D and Roy, Daniel M and Kaelbling, Leslie P and Tenenbaum, Joshua B},
booktitle = {{International Joint Conference on Artificial Intelligence (IJCAI)}},
file = {:Users/Brenden/Documents/Mendeley/Wingate et al. - 2011 - Bayesian Policy Search with Policy Priors.pdf:pdf},
keywords = {inverse optimal control},
mendeley-tags = {inverse optimal control},
title = {{Bayesian Policy Search with Policy Priors}},
year = {2011}
}
@article{Winston1980,
author = {Winston, Patrick H},
file = {:Users/Brenden/Documents/Mendeley/Winston - 1980 - Learning and reasoning by analogy.pdf:pdf},
journal = {Communications of the ACM},
keywords = {3,6,61,62,64,65,7,74,analogical reasoning,analogy,and phrases,classic AI,common-sense,computer,cr categories,information retrieval,learning,matching,reasoning,situation identification},
mendeley-tags = {analogy,classic AI},
number = {12},
title = {{Learning and reasoning by analogy}},
volume = {23},
year = {1980}
}
@incollection{Winston1975,
address = {New York},
annote = {An object is represented like:
        
A cone, is sitting on-top-of, a box, and is vertical, which is on top of a box, etc.
        
Learning occurs from a sequence of examples, where the concept starts out as a specific description, and it can be broadened or weakened. 
        
Learning can be most effective when examples are minimally different
        
Concepts were artifcats composed of simple shapes},
author = {Winston, Patrick H},
booktitle = {The Psychology of Computer Vision},
editor = {Winston, Patrick H},
file = {:Users/Brenden/Documents/Mendeley/Winston - 1975 - Learning structural descriptions from examples.pdf:pdf},
publisher = {McGraw-Hill},
title = {{Learning structural descriptions from examples}},
year = {1975}
}
@article{Winston2011,
author = {Winston, PH},
file = {:Users/Brenden/Documents/Mendeley/Winston - 2011 - The Strong Story Hypothesis and the Directed Perception Hypothesis.pdf:pdf},
journal = {Papers from the AAAI fall symposium, Technical report},
keywords = {classic AI},
mendeley-tags = {classic AI},
title = {{The Strong Story Hypothesis and the Directed Perception Hypothesis}},
url = {http://www.aaai.org/ocs/index.php/FSS/FSS11/paper/viewFile/4125/4534},
year = {2011}
}
@article{Witkin1983,
annote = {Difference between naive and expert observer often just a labe on an already preceived rich visual structure
        
It seems like the visual system knows what is important, without knowing why
        
Hierarchical model of imagse
- raw pixels
- extract simple featuers
- instrinsic images (object geometry), also known as the 2.5 D sketch
- describing images with generalized cones (a structural description, like Marr and Nishihara)
- finally, grouped into objects (and perception and cognition blur)
        
Need strong constraints to guide perception
        
Shape from shading is very difficult, particuarly with real-world objects
        
Perception must depend on more qualitative features, since it is robust across different quantiative photometry
        
Depth maps are helpful, but not clear that they are the "central goal of vision"
        
Gestalt movement: "pragnanz" was never made concrete enough to give much preditive power
        
Why is this hard? what are we missing?
                  
Structure
                
Some notion of relations between parts, as a way of describing a unified whole
        
fuzzy identity: our concepts of "parallel" and so on are noise resistant
        
a scene model should be able to regenerate the data, when run through the snythesis procedure
                  
framework
                
based on least-distortion/non-accidental
        
primitive structure is fuzzy identiy relationships among elements replicating in space and time
        
suggests using 3D graphics model of image forming process, to construct the 2D interpretations
                  
conclusion
                
hierarchial model sof ivsion (Marr and Barrow and Tenenbaum)
- weakness: need a 2.5 D sketch
- if this was a proper goal of early vision, it would be easy to recover 
+ but this is not easy to recover
        
but we impose structure on images even when we don't know what is being observed. Thus, the discvoery of sturcture is the primitive form of inference
+ so unlikely to be caused by chance, than it must be related to the causal process
        
Then, the goal of early vision is to decompoe the image into primitives that demand furhter explanation
        
there may not be a strict hiearchy of levels, since the primitive structures are present in the highest levels (it may be a waving flag, but you still perceie the symmetry, parallelism, etc.)
        
      },
author = {Witkin, AP and Tenenbaum, JM},
file = {:Users/Brenden/Documents/Mendeley/Witkin, Tenenbaum - 1983 - On the role of structure in vision.pdf:pdf},
journal = {Human and machine vision},
keywords = {classic AI,part-based models},
mendeley-tags = {classic AI,part-based models},
pages = {481--543},
title = {{On the role of structure in vision}},
volume = {1},
year = {1983}
}
@article{Wixted2005,
author = {Wixted, John T},
file = {:Users/Brenden/Documents/Mendeley/Wixted - 2005 - CURRENT DIRE CTIONS IN PSYCHO LOGICAL SCIENCE What We Once Knew.pdf:pdf},
journal = {Society},
keywords = {0109,92093-0109,address correspondence to john,ca,chology,department of psy-,e-mail,edu,forgetting,jwixted,la jolla,san diego,t,ucsd,university of california,wixted},
number = {1},
pages = {6--9},
title = {{CURRENT DIRE CTIONS IN PSYCHO LOGICAL SCIENCE What We Once Knew}},
volume = {14},
year = {2005}
}
@article{Wolpert1998,
abstract = {Humans demonstrate a remarkable ability to generate accurate and appropriate motor behavior under many different and often uncertain environmental conditions. In this paper, we propose a modular approach to such motor learning and control. We review the behavioral evidence and benefits of modularity, and propose a new architecture based on multiple pairs of inverse (controller) and forward (predictor) models. Within each pair, the inverse and forward models are tightly coupled both during their acquisition, through motor learning, and use, during which the forward models determine the contribution of each inverse model's output to the final motor command. This architecture can simultaneously learn the multiple inverse models necessary for control as well as how to select the inverse models appropriate for a given environment. Finally, we describe specific predictions of the model, which can be tested experimentally.},
author = {Wolpert, D M and Kawato, M},
file = {:Users/Brenden/Documents/Mendeley/Wolpert, Kawato - 1998 - Multiple paired forward and inverse models for motor control.pdf:pdf},
issn = {0893-6080},
journal = {Neural Networks},
keywords = {Bayesian perception,contextual prediction,internal models,modularity,motor control,motor learning},
mendeley-tags = {Bayesian perception},
month = oct,
number = {7-8},
pages = {1317--29},
pmid = {12662752},
title = {{Multiple paired forward and inverse models for motor control.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12662752},
volume = {11},
year = {1998}
}
@article{Wolpert1995,
annote = {There are many reasons for a forward model in motor control
        
2. anticipating and canceling sensory effects of movement
3. can look at errors between desied and actual sesory outcome, providing error signal for learning
4. mental pratice to learn to select between possible actions
        
Problem: moving arm in darkenss. You get cues from proprioception and motor signals, but no state information.
        
Used Kalman filter. Process 1 uses the current state and motor command to predict the next state, with forward dynamics. Process 2 uses sensory output process to predict the sensory feedback from the current state estimate. The error in sensory feedback is used to correct the state.
        
The model relies on proprioception more and more as time goes on, since the state estimate is less and less accurate.
        
The peaking and leveling of the bias is because you rely on proprioception later on.},
author = {Wolpert, Daniel M and Ghahramani, Zoubin and Jordan, Michael I},
file = {:Users/Brenden/Documents/Mendeley/Wolpert, Ghahramani, Jordan - 1995 - An internal model for sensorimotor integration.pdf:pdf},
journal = {Science},
keywords = {Bayesian perception},
mendeley-tags = {Bayesian perception},
pages = {1880--1882},
title = {{An internal model for sensorimotor integration}},
volume = {269},
year = {1995}
}
@article{Wood2008,
abstract = {The analysis of extra-cellular neural recordings typically begins with careful spike sorting and all analysis of the data then rests on the correctness of the resulting spike trains. In many situations this is unproblematic as experimental and spike sorting procedures often focus on well isolated units. There is evidence in the literature, however, that errors in spike sorting can occur even with carefully collected and selected data. Additionally, chronically implanted electrodes and arrays with fixed electrodes cannot be easily adjusted to provide well isolated units. In these situations, multiple units may be recorded and the assignment of waveforms to units may be ambiguous. At the same time, analysis of such data may be both scientifically important and clinically relevant. In this paper we address this issue using a novel probabilistic model that accounts for several important sources of uncertainty and error in spike sorting. In lieu of sorting neural data to produce a single best spike train, we estimate a probabilistic model of spike trains given the observed data. We show how such a distribution over spike sortings can support standard neuroscientific questions while providing a representation of uncertainty in the analysis. As a representative illustration of the approach, we analyzed primary motor cortical tuning with respect to hand movement in data recorded with a chronic multi-electrode array in non-human primates. We found that the probabilistic analysis generally agrees with human sorters but suggests the presence of tuned units not detected by humans.},
annote = {This provides a detailed tutorial to the dp-mixture model, with inference over the alpha (concentration) parameter.},
author = {Wood, Frank and Black, Michael J},
doi = {10.1016/j.jneumeth.2008.04.030},
file = {:Users/Brenden/Documents/Mendeley/Wood, Black - 2008 - A nonparametric Bayesian alternative to spike sorting.pdf:pdf},
issn = {0165-0270},
journal = {Journal of Neuroscience Methods},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Bayes Theorem,Brain Mapping,Computer-Assisted,Haplorhini,Humans,Models,Motor Cortex,Motor Cortex: cytology,Neural Networks (Computer),Neurological,Neurons,Neurons: physiology,Photic Stimulation,Photic Stimulation: methods,Psychomotor Performance,Psychomotor Performance: physiology,Saccades,Saccades: physiology,Signal Processing,perceptual grouping},
mendeley-tags = {perceptual grouping},
month = aug,
number = {1},
pages = {1--12},
pmid = {18602697},
title = {{A nonparametric Bayesian alternative to spike sorting.}},
volume = {173},
year = {2008}
}
@article{Wood2011,
annote = {Bayesian n-gram model as n goes to infinitiy
---
        
Predicting what comes next in a sequence is an age-old problem.
        
We could fit an n-gram model with MLE, but this tends to dramatically over-fit, even when n is small. There are creative techniques to help fix this within the MLE framework (backoff). Also, how do we choose n?
        
Bayesian approach 
        
The occurence of words in a language follow a "power-law" scaling. There are many words that occur disproportionately frequently. It is important to have prior knowledge about this, since MLE of rare symbol probabilities will be very inaccurate.
        
PYP (pitman-yor) exhibits power-law scaling, unlike the dirichlet process.
        
Intuition for PYP:
"stealing from rich and giving to the poor"
How we predict the symbol..
Not only do we have the raw counts N for each word, but we have other counts M. These counts are subtracted for each word, and distributed across the other words (symbols) under the base distribution G0.
        
Context trees:
Assume we have a fixed n-order makrov model. We can make a context tree, where contexts are joined by a parent if they differ by just the last context element.
- we don't want to esimate all of the intermeidate distributions in a naive way... there are too many
- we use hierarchial pitman-yor, where  PYP is the base distribution for the lower level PYP
        
Sequence memoizer (SM)
An extention of the hierarchail PYP model
- we have an infinite length context... we just change that in the model notation.
        
SM: the limit of the hierarchal PYP as the markov order tends to infinity.
        
This might seem nasty, but since the sequence is only a finite length T, we have a only O(T^2) possible contexts that could be relevant to a symbol
        
Also, there are many non-branching chains in the context tree, which we can marginalize out (which can be done exactly). This gives us a context tree where the number of nodes is at most twice the length of the sequence.
        
Inference: can do Gibbs sampling for each symbol prediction, and use sequential monte carlo to use those samples to help estimate the next item
        
Results
NYT corups:
competitive. beating fixed PYP n-gram models
        
Can also be used to adaptively construct coding distributions, which can be used for lossless compression. Better than many in terms of bits/byte 
      },
author = {Wood, Frank and Gasthaus, Jan and Archambeau, C\'{e}dric and James, Lancelot and Teh, Yee Whye},
doi = {10.1145/1897816},
file = {:Users/Brenden/Documents/Mendeley/Wood et al. - 2011 - The sequence memoizer.pdf:pdf},
journal = {Communications of the ACM},
keywords = {classic AI},
mendeley-tags = {classic AI},
pages = {91--98},
title = {{The sequence memoizer}},
volume = {54},
year = {2011}
}
@incollection{Wright1990,
annote = {Asked participants to write with dominant and non-dominant hand. Although visually similar, they differed somewhat in terms of the strokes used in cursive handwriting.
        
Wright takes this to mean that there are different strategies, and the motor program may only be shared at the most abstract (visual similarity) level.
        
But see his follow-up work, where extensive training with the left-hand results in a strong transfer of stroke information. This, in a way, is the opposite conclusion.
        
----
Generalized motor programs
-  Schmidt (1975) had major influence in popularizing the idea amongst psychologists
        
- how much is learning transfered to other effectors?
+ if it can be used on other effectors, then the specification of particular muslces and joints is not a necessary part of a motor program
+ there are variables that can be filled in on the fly
        
Raibert (1977). Striking similarity in shape of darwings, when using a different hand or head
        
Problem of using shape analysis: what is the motor system is capable of forgery?
        
Experiment:
        
Subjects wrote their "name" or "x + y = z" 130 times on the screen using
+ dominant hand small
+ dominant hand large writing
+ non-dominant hand
        
Prototype trial was chosen, marked for strokes, and all other trials were marked like the prototype trial. An average trajectory was formed.
                  
Results        
        
Visual feedback (can watch the previous par of the trace while drawing) doesn't have much of an effect.
        
For a capital "K" in a person's signature, the characterstic loop is largely elimianted in the non-dominant condition.
        
There are some visual differences in the average trajectory in dominant vs. not
        
Non-dominant writing is much less fluid, and slower
        
There is an increase in potential stroke endpoints in the non-dominant condition (as found by algorithm that looks for velocity min.)
                  
Discussion        
There are limits to the claim of effector independence. 
        
Since the strokes are different, then one might think they use different motor programs. If they are the same motor program, then it may be very abstract -- little more than shape information.
        
Different strategies, tied only at the highest level},
author = {Wright, Charles E},
booktitle = {Attention and Performance XIII: Motor representation and control},
editor = {Hillsdale, Jeannerod M},
file = {:Users/Brenden/Documents/Mendeley/Wright - 1990 - Generalized motor programs Reexamining claims of effector independence in writing.pdf:pdf},
keywords = {handwriting},
mendeley-tags = {handwriting},
pages = {294--320},
title = {{Generalized motor programs: Reexamining claims of effector independence in writing}},
year = {1990}
}
@incollection{Wu1999,
annote = {Review paper on gesture recognition. Nothing particularly interesting in here.},
author = {Wu, Ying and Huang, Thomas S},
booktitle = {Gesture-Based Communication in Human-Computer Interaction, Volume 1739 of Springer Lecture Notes in Computer Science},
file = {:Users/Brenden/Documents/Mendeley/Wu, Huang - 1999 - Vision-Based Gesture Recognition A Review.pdf:pdf},
keywords = {part-based models},
mendeley-tags = {part-based models},
pages = {103--115},
title = {{Vision-Based Gesture Recognition: A Review}},
year = {1999}
}
@article{Wynn1990,
abstract = {This study examines the abstractness of children's mental representation of counting, and their understanding that the last number word used in a count tells how many items there are (the cardinal word principle). In the first experiment, twenty-four 2- and 3-year-olds counted objects, actions, and sounds. Children counted objects best, but most showed some ability to generalize their counting to actions and sounds, suggesting that at a very young age, children begin to develop an abstract, generalizable mental representation of the counting routine. However, when asked “how many” following counting, only older children (mean age 3:6) gave the last number word used in the count a majority of the time, suggesting that the younger children did not understand the cardinal word principle. In the second experiment (the “give-a-number” task), the same children were asked to give a puppet one, two, three, five and six items from a pile. The older children counted the items, showing a clear understanding of the cardinal word principle. The younger children succeeded only at giving one and sometimes two items, and never used counting to solve the task. A comparison of individual children's performance across the “how-many” and “give-a-number” tasks shows strong within-child consistency, indicating that children learn the cardinal word principle at roughly 3 1/2years of age. In the third experiment, 18 2- and 3-years-olds were asked several times for one, two, three, five, and six items, to determine the largest numerosity at which each child could succeed consistenly. Results indicate that children learn the meanings of smaller number words before larger ones within their counting range, up to the number three or four. They then learn the cardinal word principle at roughly 3 1/2 years of age, and perform a general induction over this knowledge to acquire the meanings of all the number words within their counting range.},
annote = {        Puzzle: Children can count up to  N. If you then cover the objects and ask how many, they give the wrong answer if they are not CP knowers!
        
Transition to CP knower around age 3.5. This correlates with counting rather than grabbing when asked.
                  
Experiment 1:
                
Children asked to count objects presented visually or auditorily. There is some correspondence to ability to count both, but not exactly the same.
                  
Experimet 2:        
        
Children asked for a certain number of objects
        
Grabbers: just grab a bunch of objects when asked for a certain number
Counters: they count then give you objects
        
Grabbers, if asked to count what they are given, don't seem to understand a correspondence between counting and cardinality. Sometimes they just name the last item the right "number," showing an understanding that counting should end on the cardinality, but missing the general point.
                  
Experiment 3: Children asked to given a certain number of stickers. This was repeated. All children could count to reasonably high numbers.
        
It was found that older Children could count higher. Once children reach a certain number (between 3 and 5), they can count indefinitely high. This is a CP knower.
      },
author = {Wynn, Karen},
doi = {10.1016/0010-0277(90)90003-3},
file = {:Users/Brenden/Documents/Mendeley/Wynn - 1990 - Children's understanding of counting.pdf:pdf},
issn = {00100277},
journal = {Cognition},
keywords = {conceptual change},
mendeley-tags = {conceptual change},
month = aug,
number = {2},
pages = {155--193},
title = {{Children's understanding of counting}},
volume = {36},
year = {1990}
}
@article{Wynn1992,
abstract = {This paper examines how and when children come to understand the way in which counting determines numerosity and learn the meanings of the number words. A 7-month longitudinal study of 2 and 3 year olds shows that, very early on, children already know that the counting words each refer to a distinct, unique numerosity, though they do not yet know to which numerosity each word refers. It is possible that children learn this in part from the syntax of the number words. Despite this early knowledge, however, it takes children a long time (on the order of a year) to learn how the counting system represents numerosity. This suggests that our initial concept of number is represented quite differently from the way the counting system represents number, making it a difficult task for children to map the one Onto the Other.},
annote = {Knowledge of number in longitutdinal study. There a months between groups
        
Do children go through stages "one knowers", "two knowers" etc. up to CP knowers?
        
Yes, past study (1990) did not show the stages.
        
Result:
        
Children know the counting refers to numerosities ("one" refers to one). Most children consistently show a perference for a picture with 1 rather than n, when asked for 1 or n.
        
Children go through discrete stages (see Fig. 3):
1-knower
2-knower
3-knower
CP-knower},
author = {Wynn, Karen},
doi = {10.1016/0010-0285(92)90008-P},
file = {:Users/Brenden/Documents/Mendeley/Wynn - 1992 - Children's acquisition of the number words and the counting system.pdf:pdf},
issn = {00100285},
journal = {Cognitive Psychology},
keywords = {conceptual change},
mendeley-tags = {conceptual change},
month = apr,
number = {2},
pages = {220--251},
title = {{Children's acquisition of the number words and the counting system}},
volume = {24},
year = {1992}
}
@inproceedings{Xie2012,
annote = {Model the generation of asian brush strokes using reinforcment learning.
        
- They plan in a  continuous space, and use policy gradients 
- hand-designed rewards function
- they model strokes at in individual level},
author = {Xie, Ning and Hachiya, Hirotaka and Sugiyama, Masashi},
booktitle = {International Conference on Machine Learning (ICML 2012)},
file = {:Users/Brenden/Documents/Mendeley/Xie, Hachiya, Sugiyama - 2012 - Artist Agent A Reinforcement Learning Approach to Automatic Stroke Generation in Oriental Ink Painting.pdf:pdf},
keywords = {handwriting,inverse optimal control},
mendeley-tags = {handwriting,inverse optimal control},
title = {{Artist Agent: A Reinforcement Learning Approach to Automatic Stroke Generation in Oriental Ink Painting}},
year = {2012}
}
@article{Xu2007,
author = {Xu, F and Tenenbaum, J B},
file = {:Users/Brenden/Documents/Mendeley/Xu, Tenenbaum - 2007 - Word Learning as Bayesian Inference.pdf:pdf},
journal = {Psychological Review},
keywords = {one-shot learning,word learning},
mendeley-tags = {one-shot learning,word learning},
number = {2},
pages = {245--272},
title = {{Word Learning as Bayesian Inference}},
volume = {114},
year = {2007}
}
@article{Xu2007a,
abstract = {We report a new study testing our proposal that word learning may be best explained as an approximate form of Bayesian inference (Xu & Tenenbaum, in press). Children are capable of learning word meanings across a wide range of communicative contexts. In different contexts, learners may encounter different sampling processes generating the examples of word-object pairings they observe. An ideal Bayesian word learner could take into account these differences in the sampling process and adjust his/her inferences about word meaning accordingly. We tested how children and adults learned words for novel object kinds in two sampling contexts, in which the objects to be labeled were sampled either by a knowledgeable teacher or by the learners themselves. Both adults and children generalized more conservatively in the former context; that is, they restricted the label to just those objects most similar to the labeled examples when the exemplars were chosen by a knowledgeable teacher, but not when chosen by the learners themselves. We discuss how this result follows naturally from a Bayesian analysis, but not from other statistical approaches such as associative word-learning models.},
annote = {Word learning accounts:
1) Akin to reasoning, constraints, etc.
2) Associative
        
Their view combines both: hypothesis-based with Bayesian logic
        
Previous paper's best evidence:
One object referred to three times
vs. Three very similar objects referred to once, and you get much sharper generalization
        
New test: vary context, but keep the word-object pairings constant
        
Context 1: The teacher picks three examples of the word
Context 2: The child picks three examples, motivated to win and get a sticker,
        
Strong sampling: p(x | m) propto 1/|m|
Weaker sampling: p(x | m) propto 1
        
Results:
teacher condition: 71% chose subordinate level
learner condition: 29% chose subordinate level
                  
Discussion
                
active learning: usually leads to more effective learning.
But here, they were encouraed to explore conservatively},
author = {Xu, Fei and Tenenbaum, Joshua B},
doi = {10.1111/j.1467-7687.2007.00590.x},
file = {:Users/Brenden/Documents/Mendeley/Xu, Tenenbaum - 2007 - Sensitivity to sampling in Bayesian word learning.pdf:pdf},
issn = {1363-755X},
journal = {Developmental science},
keywords = {Adult,Association Learning,Bayes Theorem,British Columbia,Child,Female,Humans,Male,Models,Preschool,Psychological,Semantics,Verbal Learning,Verbal Learning: physiology,Vocabulary,active learning,classic psychology,classics on concepts,word learning},
mendeley-tags = {active learning,classic psychology,classics on concepts,word learning},
month = may,
number = {3},
pages = {288--97},
pmid = {17444970},
title = {{Sensitivity to sampling in Bayesian word learning}},
volume = {10},
year = {2007}
}
@inproceedings{Yamasaki1999,
annote = {How do you cluster strokes to get a set of prototypes? They present a method for picking the number of strokes, kind of like a stand-in for DPs
        
They also talk about how to share prototypes across the set of characters, but this does not increase categorization performance.
        
        
        
        
      },
author = {Yamasaki, K.},
booktitle = {Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99},
doi = {10.1109/ICDAR.1999.791877},
file = {:Users/Brenden/Documents/Mendeley/Yamasaki - 1999 - Automatic prototype stroke generation based on stroke clustering for on-line handwritten Japanese character recognition.pdf:pdf},
isbn = {0-7695-0318-7},
keywords = {handwriting},
mendeley-tags = {handwriting},
pages = {673--676},
publisher = {Ieee},
title = {{Automatic prototype stroke generation based on stroke clustering for on-line handwritten Japanese character recognition}},
year = {1999}
}
@article{Yanover2006,
author = {Yanover, C and Meltzer, T and Weiss, Y},
file = {:Users/Brenden/Documents/Mendeley/Yanover, Meltzer, Weiss - 2006 - Linear Programming Relaxations and Belief Propagation An Empirical Study.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {graphical models},
mendeley-tags = {graphical models},
pages = {1887--1907},
title = {{Linear Programming Relaxations and Belief Propagation: An Empirical Study}},
volume = {7},
year = {2006}
}
@article{Yildirim2012,
annote = {Neurons in the medial temporal lobe encode multi-sensory percepts
- like an "oprah winfrey" cell
- useful for multi-modal transfers

        
Would the person be able to categorize the same objects when viewed but not grasped?

        
Used: Fribbles (Tarr et al)
- fabricated with a 3D printer

        
First experiment focused on the transfer of category knowledge across modalities

        
Part-based representations of prototypes
(Biederman, Marr, etc.)
- actually LEARNS these representations

        
Previous research shows that identity transfers across visual and haptic domains (trained on either), excellent transfer (even when rotated to a new viewpoint)

        
Also compared similarity judgements in just one of the modalities, and found correlatoin

        
Can people transfer categorical knowlege about objects across modalities? What types of representations/computations might underly this?

        
40 fribbles in 4 categories, 10 exemplars per ceatgory
- high-res 3D printing (graps or see object)
+ about 12 cm cube

        
dataset has 3D model, rendered from canonical viewpoint, and also haptic data from a simulator (joint angle data)
+ haptic features correspond to joint angles, and if you use k-means clustering, you get the right categorty structure

        
          
Experiment

        
        
Either presented photos on a monitor, or touched copies with a blindfulold on

        
Conditions:

        
Group V-H: viusually caetgorize 24 objects
+ then tested with 40 objects, where 6 were familiar and 4 were novel

        
Group H-V: same thing, but haptic was trained first

        
Group Vs-H: same as V-H, except the duration of the visual stimulus was much shorter (3s rather than 8s)
          

          
Results:

        
        
During training, accurary through visual modality improved much more quickly, although haptic modalitiy eventually approached 90% correct as well

        
Generalization performance:
- about as good as the last block of training, where the different was either not significant 

        
          
Model
        
- Bayesian learner for part-based mdoel
- represent object by it's shape
+ after inferring representation, the forward mdoel can predict what the other modality would look like
- also, like a prorotype model

        
shape primitives
+ cylinders, as in Marr & Nishihara

        
Learning:
- not entirely hand-crafted, like previous modelers
-parameters
+ number of parts
+ spatial configuration

        
prior favors a few parts with many connections, and most parts with few connections ( a power law)

        
Parameters
- length, raidus, orientation of each cylinder
(uniform prior)

        
Renderer produces likelihood model (doesn't say exactly how image comparison is done)
- can be rendered in either "featuers" space (visual or haptic)

        
Generative process
1) pick category
2) Pick number of parts, and for each part, pick a cylinder (form its parameters)
+ parts are independent, and parameters of parts are also independent
3) Pick layout of Fribble's parts, by sampling a directed tree Tc, where nodes are parts and edges are which parts connect
+ each part is a node in the tree, where edges show connections
+ spatial configuration S indicates where parts connect, where parts have docking locations
++ cylinders were approxoimated with cube
+ trees are sampled in a way resembling a breadth first search, where higher-up nodes are sampled first 
++ only one part at each docking station. 
- likelihood based on pixel-wise disagreements

        
Specific values of these paramters correspond to a specific Fribble, or a "prototype" Fribble

        
Thus, it cannot represent the variability you actually find in Fribbles, but it can learn a "protoype"

        
          
Results:
        
- prototypes were learned from only 3 binary images of each exemplar, and just a small number of exemplars as well

        
Note: the prototypes look pretty good, but it's not that clear if they are "right"

        
- testing with haptic features, based on Euclidean distance between haptic simulator and exemplars in haptic features space
+ model achieced perfect performance on all test items

        
Model provides excellent qualitative account of what is going on here

        
          
Discussion

        
        
Participants got advance warning on the haptic task, so maybe they practed visual imargery
+ do you need deliberate intent?

        
For newly sighted adults, they get much better at the haptic-to-visual match to sample task, after just a few days
+ improved forward visual model?},
author = {Yildirim, Ilker and Jacobs, RA},
file = {:Users/Brenden/Documents/Mendeley/Yildirim, Jacobs - 2012 - Transfer of object category knowledge across visual and haptic modalities Experimental and computational studi.pdf:pdf},
journal = {Cognition},
keywords = {multisensory perception,part-based models},
mendeley-tags = {part-based models},
pages = {135--148},
title = {{Transfer of object category knowledge across visual and haptic modalities: Experimental and computational studies}},
volume = {126},
year = {2012}
}
@article{Yoshida2005,
abstract = {When language is correlated with regularities in the world, does it enhance the learning of these regularities? This question lies at the core of both notions of linguistic bootstrapping in children and the Whorfian hypothesis. Support for an affirmative answer is provided in an artificial-noun-learning task in which 2-year-old children were taught to distinguish categories of solid and nonsolid things with and without supporting correlated linguistic cues.},
author = {Yoshida, Hanako and Smith, Linda B},
doi = {10.1111/j.0956-7976.2005.00787.x},
file = {:Users/Brenden/Documents/Mendeley/Yoshida, Smith - 2005 - Linguistic cues enhance the learning of perceptual cues.pdf:pdf},
issn = {0956-7976},
journal = {Psychological Science},
keywords = {Attention,Child,Comprehension,Cues,Female,Humans,Language Development,Male,Pattern Recognition,Preschool,Psycholinguistics,Speech Perception,Statistics as Topic,Verbal Learning,Visual},
month = feb,
number = {2},
pages = {90--5},
pmid = {15686573},
title = {{Linguistic cues enhance the learning of perceptual cues.}},
volume = {16},
year = {2005}
}
@article{Yuille2006,
abstract = {We argue that the study of human vision should be aimed at determining how humans perform natural tasks with natural images. Attempts to understand the phenomenology of vision from artificial stimuli, although worthwhile as a starting point, can lead to faulty generalizations about visual systems, because of the enormous complexity of natural images. Dealing with this complexity is daunting, but Bayesian inference on structured probability distributions offers the ability to design theories of vision that can deal with the complexity of natural images, and that use 'analysis by synthesis' strategies with intriguing similarities to the brain. We examine these strategies using recent examples from computer vision, and outline some important implications for cognitive science.},
annote = {Studying vision as analysis by synthesis, where scenes are generated from grammars with a priori unknown number of objects. Inference proceeds by data-driven MCMC.
        
---------
Using artifial stimuli for evaluating computer vision is usually not very insightful, as most algorithms then totally fail on real images
        
Analysis by synthesis in vision
- suggestive evidence by feedback connections and mental imagery
        
There are lots of low-level ambiguities in vision, but at a high level things are often clear.
        
It is likely that we have both bottom-up and top-down proposals in the visual system.
+ For letters embedded in noise, you can extract edges, and use that to suggest possible letters.
        
A benefit to generatives models of images is that we can explain away suprious recognitions, that bottom-up procedures dont
        
Image parsing model:
- unknown nubmer of objects
- each with a location
- a label given the location
- and object parameters given the label
        
Locations form non-overlaping regions
        
Thus, the final image model is a product over all of the possible locations, forming a full generative model for images
        
label could be face, text, background etc.
                  
implications for cognitive science        
- the bottom-up proposals can provide diagonistic information for many categories, which may be what the visual system is doing in those first 40 msec
        
- where does generative model come from?
Ideally, it is also learened. There has been progress here on learing stochastic grammars for speech 
+ also, they currently learnthe generative model for faces/text separetly},
author = {Yuille, Alan and Kersten, Daniel},
doi = {10.1016/j.tics.2006.05.002},
file = {:Users/Brenden/Documents/Mendeley/Yuille, Kersten - 2006 - Vision as Bayesian inference analysis by synthesis.pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Algorithms,Bayes Theorem,Brain,Brain Mapping,Brain: physiology,Field Dependence-Independence,Humans,Markov Chains,Models,Monte Carlo Method,Ocular,Ocular: physiology,Orientation,Orientation: physiology,Pattern Recognition,Probability Theory,Psychological,Signal Detection,Statistical,Vision,Visual,Visual Pathways,Visual Pathways: physiology,Visual: physiology,classic AI,classic psychology},
mendeley-tags = {classic AI,classic psychology},
month = jul,
number = {7},
pages = {301--8},
pmid = {16784882},
title = {{Vision as Bayesian inference: analysis by synthesis?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16784882},
volume = {10},
year = {2006}
}
@article{Zeiler2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1311.2901v3},
author = {Zeiler, Matthew D and Fergus, Rob},
eprint = {arXiv:1311.2901v3},
file = {:Users/Brenden/Documents/Mendeley/Zeiler, Fergus - 2013 - Visualizing and Understanding Convolutional Networks.pdf:pdf},
keywords = {deep learning,one-shot learning},
mendeley-tags = {deep learning,one-shot learning},
title = {{Visualizing and Understanding Convolutional Networks}},
year = {2013}
}
@inproceedings{Zeiler2010,
annote = {Deconvolutional nets
        
- totally unsupervised
- convolutional
- sparsity
- does not restrict the encoder to be the same as the decoder , like RBMS
- there is no encoder, involves solving an optimizaiton problem
        
An image is the product of a latent feature map and a filter (hence the deconvolution), we are working in the opposite direction
        
Cost function encourages sparsity on the latent feature maps
        
Unlike most models, there is no bottom-up inference. Instead, they focus on a high-quality latent representation
        
Can generalize this into a hierarchy, where the later representations are input to higher-levels
        
There is no pooling, sub-sampling, divisive normalization
        
Alternate between optimizatin the filters, then optimization the maps, etc.
        
        Image reconstructoin
                
For a given image, we take learned filters and try to find the optimal latent representation.
                  
Experiments
                
Shows samples from each level, projected down to pixel space. You get higher-level features when you go higher in the representation
        
        Caltech 101
                
Beats sift-based feature detectors
                  
Denoising images
                
Can be used to unsupervised de-noise an image          
          
Filters
                
When trained on cities, there is a pre-dominance of horiztonal and vertical lines, capturing things like parallel lines and rectangle... very cool
        
------
                  
Deep learning for computer vision        
Rob Fergus
        
check out deformable parts models
        
Convnets (convolutional nets) :  did not do very well on caltech 101, other datasets, etc. because there weren't very many examples per clsas
        
Krizhevsky et al. (NIPS2012)
- Yann's basic architecture
- model took a couple of weeks
- dropout
next best (26% error) 
their results (16% error)
        
Convnets can now work on richer vision tasks (but, of course, only labeling)
        
Components of a layer
- filters
- pooling (sum/max)
- (optional) normalization
        
SIFT (similar structure)
- gabor filters
- spatial pooling (histograms in each step)
- normalization
        
non-linearities
- rectified linear : flat for awhile, then linear
+ seem to work better than other non-linearities
        
Pooling gives you invariance to small transformations
        
Normalization
- each feature map can be whitened, within a local neighborhood (column)
+ this would brighten up the detail in some dark parts of the space
        
Why does the Krishensky model work so well?
- what if you drop out a fully connected layer at the top, you only lose 1% performance (16 million parameters)
- if you go from 7 layers to 4 layers, you lose 33% error
+ depth of the network is important
        
IF you look at the feature representation at each level, and use an SVM to predict caltech-101, you get better performance at each level of the network
        
If you translate an image, and look at how it changes the representation, you get more invariance at the higher levels
+ not so good for rotation
        
Visualizing convents
- find the optimal image for a given unit, and then you get a cat
- but this is very dependent on initialization
        
Deconvolutional network
- convolutional net, but everything is backwards, wher ehte last level is the image and the first level is a feature map
        
was it trained with supervsion?
- trained totally unsupervised
- 2nd layer has midlevel featuers
- 3rd layer: object parts
+ can see the top-9 images in the test set that the features respond to (or predict generatively in some sense)
        
Imagenet best performance is now around 11%
- all top contenders are using convolutional nets
        
Training big networks
- do you no longer need to train them layer by layer?
        
Pre-processing
- mean removal
        
Improving generalization
- data augmentation, crops, flips, etc
- weight decay or regularizatoin
        
You want a big model with regularization, so you can get fine structure and not go crazy in low-density region
        
dropout (all models use this)
-flip a coin for each unit, on whether it is on for the training trial
- like an ensemble of models
- reduces co-adapation
- you don't want the noise at test time
        
tricks
- plot your hidden units over samples, and you want to see sparsity and uncorrelation
        
Object detection
- You can train the output to be a 4 dimesional code, which is the location of the bounding box
- so you can train on detection directly
                  
learning from just a few examples        
Decent performance from just 6 examples on Caltech256, which is quite imp
- but do the training examples in Imagenet have the same classes?
        
Yann LeCun was right
        
Not really interesting future directions -- combine with structure grammars... why? how?
        
- Rectified linear units produce sparsity... which is cool
- Also, Rob finds that fully supervised learning is generallymuch better than unsupervised. and it is hard to combine the two
      },
author = {Zeiler, Matthew D. and Krishnan, Dilip and Taylor, Graham W. and Fergus, Rob},
booktitle = {Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR.2010.5539957},
file = {:Users/Brenden/Documents/Mendeley/Zeiler et al. - 2010 - Deconvolutional networks.pdf:pdf},
isbn = {978-1-4244-6984-0},
keywords = {deep learning,handwriting,neural networks},
mendeley-tags = {deep learning,handwriting,neural networks},
month = jun,
pages = {2528--2535},
publisher = {Ieee},
title = {{Deconvolutional networks}},
year = {2010}
}
@article{Zhang1984,
author = {Zhang, T Y and Suen, Ching Y},
file = {:Users/Brenden/Documents/Mendeley/Zhang, Suen - 1984 - A Fast Parallel Algorithm for Thinning Digital Patterns.pdf:pdf},
journal = {{Communications of the ACM}},
keywords = {thinning algorithm},
mendeley-tags = {thinning algorithm},
number = {3},
pages = {236--239},
title = {{A Fast Parallel Algorithm for Thinning Digital Patterns}},
volume = {27},
year = {1984}
}
@inproceedings{Zheng1999,
author = {Zheng, Jing and Ding, Xiaoqing and Wu, Youshou and Lu, Zhan},
booktitle = {Proceedings of 5th International Conference on Document Analysis and Recognition (ICDAR '99)},
file = {:Users/Brenden/Documents/Mendeley/Zheng et al. - 1999 - Spatio-temporal unified model for on-line chinese character recognition.pdf:pdf},
keywords = {handwriting},
mendeley-tags = {handwriting},
title = {{Spatio-temporal unified model for on-line chinese character recognition}},
year = {1999}
}
@inproceedings{Chen2006,
author = {Zhu, Long Leo and Chen, Yuanhao and Yuille, Alan},
booktitle = {Advances in Neural Information Processing Systems 19 (NIPS)},
file = {:Users/Brenden/Documents/Mendeley/Zhu, Chen, Yuille - 2006 - Unsupervised Learning of a Probabilistic Grammar for Object Detection.pdf:pdf},
keywords = {part-based models,program induction},
mendeley-tags = {part-based models,program induction},
pages = {827--834},
title = {{Unsupervised Learning of a Probabilistic Grammar for Object Detection}},
year = {2006}
}
@article{Zhu2009,
abstract = {We introduce a Probabilistic Grammar-Markov Model (PGMM) which couples probabilistic context free grammars and Markov Random Fields. These PGMMs are generative models defined over attributed features and are used to detect and classify objects in natural images. PGMMs are designed so that they can perform rapid inference, parameter learning, and the more difficult task of structure induction. PGMMs can deal with unknown 2D pose (position, orientation, and scale) in both inference and learning, different appearances, or aspects, of the model. The PGMMs can be learnt in an unsupervised manner where the image can contain one of an unknown number of objects of different categories or even be pure background. We first study the weakly supervised case, where each image contains an example of the (single) object of interest, and then generalize to less supervised cases. The goal of this paper is theoretical but, to provide proof of concept, we demonstrate results from this approach on a subset of the Caltech dataset (learning on a training set and evaluating on a testing set). Our results are generally comparable with the current state of the art, and our inference is performed in less than five seconds.},
annote = {A flexible way to model image features, without having to fix the number of parts in advance. This grows out an MRF one part at a time, so we can do structure learning without determining the number of nodes in advance.
        
--
Introduction: hope that this paper bridges between work on grammars in machine learning, and computer vision
        
Want rapid learning/inference, and structure induction, where the structure of the model is unknown
        
Image features are localized and found using SIFT. So we have a bag of features for an image. We now want to model the features of the image. 
        
The model starts with just background features. Objects features are added, which are triplets represented by MRFs. Triplets can be extended with AND nodes (according to the grammar), by taking two of the nodes and adding another to form a new triplet. Conjunctions of features is useful, as unknown in NLP with tri-gram models. Triplets are invariant to scale and rotation.
        
This is also handled with MRFS. Thus we can grow the graph structure to fit an object as necessary.
        
OR nodes allow for multiple views, and these are often selected and improve performance.
        
Thus, you both learn the structure and parameters to represent an object class.},
author = {Zhu, Long and Chen, Yuanhao and Yuille, Alan},
doi = {10.1109/TPAMI.2008.67},
file = {:Users/Brenden/Documents/Mendeley/Zhu, Chen, Yuille - 2009 - Unsupervised learning of Probabilistic Grammar-Markov Models for object categories.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Computer Simulation,Computer-Assisted,Computer-Assisted: methods,Image Interpretation,Markov Chains,Models,Pattern Recognition,Statistical,part-based models,program induction},
mendeley-tags = {part-based models,program induction},
month = jan,
number = {1},
pages = {114--28},
pmid = {19029550},
title = {{Unsupervised learning of Probabilistic Grammar-Markov Models for object categories}},
volume = {31},
year = {2009}
}
@article{Zhu2005,
annote = {textons: fundamental micro-structure of natural images, considered atoms of pre-attentive visual perception
        
very little is known how V1 cells are grouped into larger structures in higher levels
        
Julesz (1981) showed that RT for detecting a target element among distractors
(visual search task)
- some are instantaenous (independent of number of distractors), others are not
        
pre-attentive stage detcts elongated blobs, bars, crosses, terminators etc.
        
They argue that textons should be defined through a generative model of images.
- 
      },
author = {Zhu, Song-Chun and Guo, Cheng-en and Wang, Yizhou and Xu, Zijian},
doi = {10.1023/B:VISI.0000046592.70770.61},
file = {:Users/Brenden/Documents/Mendeley/Zhu et al. - 2005 - What are Textons.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
keywords = {classic AI,lightons,motons,part-based models,textons,textures,transformed component analysis},
mendeley-tags = {classic AI,part-based models},
number = {1/2},
pages = {121--143},
title = {{What are Textons?}},
volume = {62},
year = {2005}
}
@article{Zhu2006,
author = {Zhu, Song-Chun and Mumford, David},
doi = {10.1561/0600000018},
file = {:Users/Brenden/Documents/Mendeley/Zhu, Mumford - 2006 - A Stochastic Grammar of Images.pdf:pdf},
issn = {1572-2740},
journal = {Foundations and Trends in Computer Graphics and Vision},
keywords = {part-based models},
mendeley-tags = {part-based models},
number = {4},
pages = {259--362},
title = {{A Stochastic Grammar of Images}},
volume = {2},
year = {2006}
}
@techreport{ZhuLit2007,
author = {Zhu, X},
institution = {Computer Sciences, University of Wisconsin-Madison},
number = {1530},
title = {{Semi-Supervised Learning Literature Survey}},
year = {2005}
}
@inproceedings{ZhuGibson2010,
author = {Zhu, X and Gibson, B and Jun, K.-S. and Rogers, T and Harrison, J and Kalish, C},
booktitle = {The 27th International Conference on Machine Learning (ICML)},
title = {{Cognitive models of test-item effects in human category learning}},
year = {2010}
}
@inproceedings{Zhu2007,
author = {Zhu, X and Rogers, T and Qian, R and Kalish, C},
booktitle = {{Twenty-Second AAAI Conference on Artificial Intelligence (AAAI-07)}},
title = {{Humans Perform Semi-Supervised Classification Too}},
year = {2007}
}
@techreport{Zhu2003,
annote = {        From Duplicate 1 (                   Semi-supervised learning: From Gaussian fields to Gaussian processes                 - Zhu, Xiaojin; Lafferty, John; Ghahramani, Zoubin )
                
        
        
        From Duplicate 2 (                   Semi-Supervised Learning: From Gaussian Fields to Gaussian Processes                 - Zhu, X; Lafferty, J; Ghahramani, Z )
                
        
        
      },
author = {Zhu, Xiaojin and Lafferty, John and Ghahramani, Zoubin},
file = {:Users/Brenden/Documents/Mendeley/Zhu, Lafferty, Ghahramani - 2003 - Semi-supervised learning From Gaussian fields to Gaussian processes.pdf:pdf},
institution = {Carnegie Mellon University (CMU-CS-03-175)},
keywords = {GGM,sparsity},
mendeley-tags = {GGM,sparsity},
number = {CMU-CS-03-175},
publisher = {Carnegie Mellon University},
title = {{Semi-supervised learning: From Gaussian fields to Gaussian processes}},
year = {2003}
}
@inproceedings{Ziebart2010,
annote = {General method paper for inverse RL framework. 
        
Given a causal model, formulated as an MDP, you have a
known dynamics but an unknown reward function. Try to infer the parameters of the reward function, consistent with behavior, such that entropy is maximized.
        
Consistency is defined as expected feature counts. This problem is convex and can be solved efficiently.
        
Applications in paper:
--inverse stochastic control, if you have linear dynamics
--inverse dynamic games
--bayes net for diagnosis},
author = {Ziebart, Brian D and Bagnell, J Andrew and Dey, Anind K},
booktitle = {International Conference on Machine Learning (ICML 2010)},
file = {:Users/Brenden/Documents/Mendeley/Ziebart, Bagnell, Dey - 2010 - Modeling Interaction via the Principle of Maximum Causal Entropy.pdf:pdf},
keywords = {inverse optimal control,planning},
mendeley-tags = {inverse optimal control,planning},
title = {{Modeling Interaction via the Principle of Maximum Causal Entropy}},
year = {2010}
}
@inproceedings{Ziebart2012,
annote = {Uses inverse RL to investigate how people move their computer mice. The intended application to figure out where the person is moving their mouse -- which has applications for HCI
        
--
State space: [position, first-deriv, second-deriv, etc...]
Actions: vector for velocity
This results in a linear-dynamical system, given a current state and an action.
        
The reward function is parameterized as a quadratic function of the state space. 
        
Task: try to predict the endpoint of a current movement
        
Generally better than some simple competitors, but not great.
      },
author = {Ziebart, Brian D and Dey, Anind K and Bagnell, J Andrew},
booktitle = {{International Conference on Intelligent User Interfaces (IUI 2012)}},
file = {:Users/Brenden/Documents/Mendeley/Ziebart, Dey, Bagnell - 2012 - Probabilistic Pointing Target Prediction via Inverse Optimal Control.pdf:pdf},
isbn = {9781450310482},
keywords = {handwriting,inverse optimal control,planning},
mendeley-tags = {handwriting,inverse optimal control,planning},
title = {{Probabilistic Pointing Target Prediction via Inverse Optimal Control}},
year = {2012}
}
@inproceedings{Ziebart2010a,
annote = {Approach to solving inverse RL problems, where you want to infer the reward function, given the transition model and the agent's actions.
        
They model action as the exponent of reward, which is a linear combination of features.
        
They use maximum entropy, given constraints on the expectation of certain features in the model and the actual data. This is equivalent to maximum likelihood.
        
Application:
        
taxi-cab data, but what were the features here?
      },
author = {Ziebart, Brian D and Maas, Andrew and Bagnell, J Andrew and Dey, Anind K},
booktitle = {{AAAI Conference on Artificial Intelligence (AAAI 2008)}},
file = {:Users/Brenden/Documents/Mendeley/Ziebart et al. - 2008 - Maximum Entropy Inverse Reinforcement Learning.pdf:pdf},
keywords = {imitation learning,inverse optimal control,inverse reinforcement learning,planning},
mendeley-tags = {inverse optimal control,planning},
title = {{Maximum Entropy Inverse Reinforcement Learning}},
year = {2008}
}
@article{Zue2000,
annote = {speech interfaces neeed:
-recognition
-synthesis
        
processing spoken input
- speech recognition. 
+ often contains words outside the system's working vocabulary
++ handled by "trash" models
        
- n-gram models at the word-level as a language model
++ understanding models usually require the text is known with certainty
++ most systems don't try a complete syntactic anaylsis
        
Asadi et al. "Automatic modeling of adding new words to a large vocabularly..."
        
Hetherington and Zue. "New words: Implications for continuous speech..."
        
The synthesis side:
- less work on natural lagnague generation. doesn't do paragraph level planning
        
text to speech synthesis:
- work, but sound unnatural
- recently, concatenative approach that uses uses excised recorded speech
+ usually sounds more natural
        
there are many publicly deloped systems, with all sorts of products
        
new words:
- a new restaurant might open up, etc.
- most systems assume a closed vocabulary},
author = {Zue, V.W. and Glass, J.R.},
doi = {10.1109/5.880078},
file = {:Users/Brenden/Documents/Mendeley/Zue, Glass - 2000 - Conversational interfaces advances and challenges.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {conversational interfaces,speech understanding,spoken dialogue systems,systems},
month = aug,
number = {8},
pages = {1166--1180},
title = {{Conversational interfaces: advances and challenges}},
volume = {88},
year = {2000}
}
@misc{,
file = {:Users/Brenden/Documents/Mendeley/Unknown - Unknown - JurafskyMartinChpt9(1).pdf.pdf:pdf},
title = {{JurafskyMartinChpt9(1).pdf}}
}
@misc{,
file = {:Users/Brenden/Documents/Mendeley/Unknown - Unknown - Gibson_2000.pdf.pdf:pdf},
title = {{Gibson_2000.pdf}}
}
@misc{,
file = {:Users/Brenden/Documents/Mendeley/Unknown - Unknown - Eimas_infant_speech_discrim_Science_1971.pdf.pdf:pdf},
title = {{Eimas_infant_speech_discrim_Science_1971.pdf}}
}
